{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNt5Xk7CcTdGEdETgxImqmQ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/frank-morales2020/Cloud_curious/blob/master/MEMENTO_GROK.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pCa76rvTgIbg"
      },
      "outputs": [],
      "source": [
        "!pip install xai-sdk -q"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# notebook-python\n",
        "# Improved Memento-style agent with real embeddings + growing trajectories\n",
        "\n",
        "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "# 0. INSTALL DEPENDENCIES (run once in Colab)\n",
        "# !pip install -q sentence-transformers\n",
        "\n",
        "import numpy as np\n",
        "from typing import List, Optional\n",
        "from pydantic import BaseModel, Field, ConfigDict\n",
        "from xai_sdk import Client\n",
        "from xai_sdk.chat import user, system\n",
        "from google.colab import userdata\n",
        "from sentence_transformers import SentenceTransformer\n",
        "\n",
        "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "# 1. INITIALIZE\n",
        "XAI_key = userdata.get('XAI_KEY')\n",
        "client = Client(api_host=\"api.x.ai\", api_key=XAI_key)\n",
        "\n",
        "# Real embedding model (small & fast)\n",
        "embedder = SentenceTransformer('all-MiniLM-L6-v2')"
      ],
      "metadata": {
        "id": "GCv8wbZpqniI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "# 2. DATA SCHEMA\n",
        "class TrajectoryStep(BaseModel):\n",
        "    action: str\n",
        "    observation: str = Field(..., description=\"Result or feedback from the action\")\n",
        "\n",
        "class ExperienceCase(BaseModel):\n",
        "    model_config = ConfigDict(arbitrary_types_allowed=True)\n",
        "    problem: str\n",
        "    embedding: np.ndarray\n",
        "    trajectory: List[TrajectoryStep] = Field(default_factory=list)\n",
        "    success: bool = False\n",
        "    final_observation: Optional[str] = None\n",
        "\n",
        "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "# 3. MEMORY ENGINE\n",
        "class MementoMemory:\n",
        "    def __init__(self, similarity_threshold: float = 0.65):\n",
        "        self.cases: List[ExperienceCase] = []\n",
        "        self.threshold = similarity_threshold\n",
        "\n",
        "    def _embed(self, text: str) -> np.ndarray:\n",
        "        return embedder.encode(text, convert_to_numpy=True)\n",
        "\n",
        "    def store(self, problem: str, trajectory: List[TrajectoryStep], success: bool, final_observation: str):\n",
        "        # Simple dedup: don't store if very similar problem already exists\n",
        "        emb = self._embed(problem)\n",
        "        for case in self.cases:\n",
        "            sim = np.dot(emb, case.embedding) / (np.linalg.norm(emb) * np.linalg.norm(case.embedding))\n",
        "            if sim > 0.97:  # almost identical\n",
        "                return\n",
        "\n",
        "        case = ExperienceCase(\n",
        "            problem=problem,\n",
        "            embedding=emb,\n",
        "            trajectory=trajectory,\n",
        "            success=success,\n",
        "            final_observation=final_observation\n",
        "        )\n",
        "        self.cases.append(case)\n",
        "        print(f\"  â†’ Stored new experience ({'SUCCESS' if success else 'FAILURE'})\")\n",
        "\n",
        "    def retrieve_context(self, current_problem: str, top_k: int = 3) -> str:\n",
        "        if not self.cases:\n",
        "            return \"No prior experience available.\"\n",
        "\n",
        "        current_emb = self._embed(current_problem)\n",
        "        scored_cases = []\n",
        "        for case in self.cases:\n",
        "            sim = np.dot(current_emb, case.embedding) / (\n",
        "                np.linalg.norm(current_emb) * np.linalg.norm(case.embedding) + 1e-8\n",
        "            )\n",
        "            if sim >= self.threshold:\n",
        "                scored_cases.append((sim, case))\n",
        "\n",
        "        if not scored_cases:\n",
        "            return \"No sufficiently similar past experiences found.\"\n",
        "\n",
        "        # Sort by similarity descending\n",
        "        scored_cases.sort(key=lambda x: x[0], reverse=True)\n",
        "        top_cases = scored_cases[:top_k]\n",
        "\n",
        "        memory_blocks = []\n",
        "        for sim, case in top_cases:\n",
        "            status = \"SUCCESSFUL\" if case.success else \"FAILED\"\n",
        "            traj_str = \"\\n\".join([f\"  â€¢ {s.action} â†’ {s.observation}\" for s in case.trajectory])\n",
        "            block = (\n",
        "                f\"Similarity: {sim:.3f} | Status: {status}\\n\"\n",
        "                f\"Task: {case.problem}\\n\"\n",
        "                f\"Trajectory:\\n{traj_str}\\n\"\n",
        "                f\"Final outcome: {case.final_observation}\"\n",
        "            )\n",
        "            memory_blocks.append(block)\n",
        "\n",
        "        return \"\\n\\n\".join([\"--- PAST EXPERIENCE ---\"] + memory_blocks) + \"\\n\"\n",
        "\n",
        "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "# 4. AGENT\n",
        "class MementoAgent:\n",
        "    def __init__(self, memory: MementoMemory):\n",
        "        self.memory = memory\n",
        "\n",
        "    def execute(self, task: str):\n",
        "        print(f\"\\nâ•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—\")\n",
        "        print(  f\"â•‘ TARGET: {task}\")\n",
        "        print(  f\"â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\")\n",
        "\n",
        "        mem_context = self.memory.retrieve_context(task)\n",
        "\n",
        "        prompt = (\n",
        "            \"You are an adaptive agent that learns from past experience.\\n\"\n",
        "            \"Use the provided memory to avoid repeating mistakes.\\n\"\n",
        "            \"Always decide between API_V1 (old, often broken) and API_V2 (current, preferred).\\n\\n\"\n",
        "            f\"{mem_context}\\n\"\n",
        "            f\"Current Task: {task}\\n\\n\"\n",
        "            \"Respond concisely. End your answer with exactly one of:\\n\"\n",
        "            \"ACTION: API_V1\\n\"\n",
        "            \"ACTION: API_V2\\n\"\n",
        "        )\n",
        "\n",
        "        # Call Grok\n",
        "        chat_response = client.chat.create(\n",
        "            model=\"grok-4-1-fast-reasoning\",  # or grok-beta / grok-3 / etc.\n",
        "            messages=[\n",
        "                system(\"You are a helpful, reasoning-focused agent.\"),\n",
        "                user(prompt)\n",
        "            ]\n",
        "        )\n",
        "\n",
        "        # Robust content extraction\n",
        "        if hasattr(chat_response, 'choices') and chat_response.choices:\n",
        "            content = chat_response.choices[0].message.content\n",
        "        elif hasattr(chat_response, 'message'):\n",
        "            content = chat_response.message.content\n",
        "        else:\n",
        "            content = str(chat_response)  # fallback\n",
        "\n",
        "        print(\"\\n[GROK REASONING]\")\n",
        "        print(content.strip())\n",
        "        print(\"-\" * 50)\n",
        "\n",
        "        # Parse final action\n",
        "        action = \"API_V1\"\n",
        "        if \"ACTION: API_V2\" in content.upper():\n",
        "            action = \"API_V2\"\n",
        "\n",
        "        # Simulated environment\n",
        "        success = (action == \"API_V2\")\n",
        "        observation = (\n",
        "            \"API call succeeded â€“ report retrieved\"\n",
        "            if success else\n",
        "            \"Error 404: API_V1 is deprecated and no longer available\"\n",
        "        )\n",
        "\n",
        "        print(f\"[ACTION TAKEN]   {action}\")\n",
        "        print(f\"[OBSERVATION]    {observation}\\n\")\n",
        "\n",
        "        # Build trajectory (in real system you would append more steps)\n",
        "        trajectory = [\n",
        "            TrajectoryStep(action=f\"Selected endpoint: {action}\", observation=observation)\n",
        "        ]\n",
        "\n",
        "        # Store full experience\n",
        "        self.memory.store(\n",
        "            problem=task,\n",
        "            trajectory=trajectory,\n",
        "            success=success,\n",
        "            final_observation=observation\n",
        "        )\n",
        "\n",
        "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "# 5. DEMO RUN\n",
        "if __name__ == \"__main__\":\n",
        "    memory_bank = MementoMemory(similarity_threshold=0.68)\n",
        "    agent = MementoAgent(memory_bank)\n",
        "\n",
        "    print(\"=== DEMONSTRATION ===\")\n",
        "\n",
        "    print(\"\\nRUN 1 â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\")\n",
        "    agent.execute(\"Fetch quarterly sales report_alpha\")\n",
        "\n",
        "    print(\"\\nRUN 2 â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\")\n",
        "    agent.execute(\"Retrieve inventory status report_beta\")\n",
        "\n",
        "    print(\"\\nRUN 3 â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\")\n",
        "    agent.execute(\"Download financial summary report_gamma\")\n",
        "\n",
        "    print(\"\\nRUN 4 (very similar to first) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\")\n",
        "    agent.execute(\"Fetch quarterly sales report_delta\")   # should reuse memory"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Os2-qCMngUeW",
        "outputId": "55b89b2c-8722-4461-e5b5-8c1ba0aa3094"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== DEMONSTRATION ===\n",
            "\n",
            "RUN 1 â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
            "\n",
            "â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—\n",
            "â•‘ TARGET: Fetch quarterly sales report_alpha\n",
            "â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
            "\n",
            "[GROK REASONING]\n",
            "messages {\n",
            "  content {\n",
            "    text: \"You are a helpful, reasoning-focused agent.\"\n",
            "  }\n",
            "  role: ROLE_SYSTEM\n",
            "}\n",
            "messages {\n",
            "  content {\n",
            "    text: \"You are an adaptive agent that learns from past experience.\\nUse the provided memory to avoid repeating mistakes.\\nAlways decide between API_V1 (old, often broken) and API_V2 (current, preferred).\\n\\nNo prior experience available.\\nCurrent Task: Fetch quarterly sales report_alpha\\n\\nRespond concisely. End your answer with exactly one of:\\nACTION: API_V1\\nACTION: API_V2\\n\"\n",
            "  }\n",
            "  role: ROLE_USER\n",
            "}\n",
            "model: \"grok-4-1-fast-reasoning\"\n",
            "--------------------------------------------------\n",
            "[ACTION TAKEN]   API_V2\n",
            "[OBSERVATION]    API call succeeded â€“ report retrieved\n",
            "\n",
            "  â†’ Stored new experience (SUCCESS)\n",
            "\n",
            "RUN 2 â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
            "\n",
            "â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—\n",
            "â•‘ TARGET: Retrieve inventory status report_beta\n",
            "â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
            "\n",
            "[GROK REASONING]\n",
            "messages {\n",
            "  content {\n",
            "    text: \"You are a helpful, reasoning-focused agent.\"\n",
            "  }\n",
            "  role: ROLE_SYSTEM\n",
            "}\n",
            "messages {\n",
            "  content {\n",
            "    text: \"You are an adaptive agent that learns from past experience.\\nUse the provided memory to avoid repeating mistakes.\\nAlways decide between API_V1 (old, often broken) and API_V2 (current, preferred).\\n\\nNo sufficiently similar past experiences found.\\nCurrent Task: Retrieve inventory status report_beta\\n\\nRespond concisely. End your answer with exactly one of:\\nACTION: API_V1\\nACTION: API_V2\\n\"\n",
            "  }\n",
            "  role: ROLE_USER\n",
            "}\n",
            "model: \"grok-4-1-fast-reasoning\"\n",
            "--------------------------------------------------\n",
            "[ACTION TAKEN]   API_V2\n",
            "[OBSERVATION]    API call succeeded â€“ report retrieved\n",
            "\n",
            "  â†’ Stored new experience (SUCCESS)\n",
            "\n",
            "RUN 3 â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
            "\n",
            "â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—\n",
            "â•‘ TARGET: Download financial summary report_gamma\n",
            "â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
            "\n",
            "[GROK REASONING]\n",
            "messages {\n",
            "  content {\n",
            "    text: \"You are a helpful, reasoning-focused agent.\"\n",
            "  }\n",
            "  role: ROLE_SYSTEM\n",
            "}\n",
            "messages {\n",
            "  content {\n",
            "    text: \"You are an adaptive agent that learns from past experience.\\nUse the provided memory to avoid repeating mistakes.\\nAlways decide between API_V1 (old, often broken) and API_V2 (current, preferred).\\n\\nNo sufficiently similar past experiences found.\\nCurrent Task: Download financial summary report_gamma\\n\\nRespond concisely. End your answer with exactly one of:\\nACTION: API_V1\\nACTION: API_V2\\n\"\n",
            "  }\n",
            "  role: ROLE_USER\n",
            "}\n",
            "model: \"grok-4-1-fast-reasoning\"\n",
            "--------------------------------------------------\n",
            "[ACTION TAKEN]   API_V2\n",
            "[OBSERVATION]    API call succeeded â€“ report retrieved\n",
            "\n",
            "  â†’ Stored new experience (SUCCESS)\n",
            "\n",
            "RUN 4 (very similar to first) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
            "\n",
            "â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—\n",
            "â•‘ TARGET: Fetch quarterly sales report_delta\n",
            "â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
            "\n",
            "[GROK REASONING]\n",
            "messages {\n",
            "  content {\n",
            "    text: \"You are a helpful, reasoning-focused agent.\"\n",
            "  }\n",
            "  role: ROLE_SYSTEM\n",
            "}\n",
            "messages {\n",
            "  content {\n",
            "    text: \"You are an adaptive agent that learns from past experience.\\nUse the provided memory to avoid repeating mistakes.\\nAlways decide between API_V1 (old, often broken) and API_V2 (current, preferred).\\n\\n--- PAST EXPERIENCE ---\\n\\nSimilarity: 0.809 | Status: SUCCESSFUL\\nTask: Fetch quarterly sales report_alpha\\nTrajectory:\\n  â€¢ Selected endpoint: API_V2 â†’ API call succeeded â€“ report retrieved\\nFinal outcome: API call succeeded â€“ report retrieved\\n\\nCurrent Task: Fetch quarterly sales report_delta\\n\\nRespond concisely. End your answer with exactly one of:\\nACTION: API_V1\\nACTION: API_V2\\n\"\n",
            "  }\n",
            "  role: ROLE_USER\n",
            "}\n",
            "model: \"grok-4-1-fast-reasoning\"\n",
            "--------------------------------------------------\n",
            "[ACTION TAKEN]   API_V2\n",
            "[OBSERVATION]    API call succeeded â€“ report retrieved\n",
            "\n",
            "  â†’ Stored new experience (SUCCESS)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## GPT4 AND GROK4.1"
      ],
      "metadata": {
        "id": "usii6rRHkwbR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "# MEMENTO COMPARISON â€” Grok-4.1 vs GPT-4.1 + o4-mini (FINAL #1)\n",
        "# All issues fixed: roles, temperature, max_tokens, executor prompt, syntax\n",
        "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "\n",
        "# !pip install -q sentence-transformers openai xai-sdk\n",
        "\n",
        "import numpy as np\n",
        "from typing import List\n",
        "from pydantic import BaseModel, Field, ConfigDict\n",
        "from xai_sdk import Client as XAIClient\n",
        "from xai_sdk.chat import system, user\n",
        "from openai import OpenAI\n",
        "from google.colab import userdata\n",
        "from sentence_transformers import SentenceTransformer\n",
        "\n",
        "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "# 1. CLIENTS\n",
        "XAI_KEY = userdata.get('XAI_KEY')\n",
        "OPENAI_KEY = userdata.get('OPENAI_API_KEY')   # â† Must be set in Colab Secrets\n",
        "\n",
        "xai_client = XAIClient(api_host=\"api.x.ai\", api_key=XAI_KEY)\n",
        "openai_client = OpenAI(api_key=OPENAI_KEY)\n",
        "\n",
        "embedder = SentenceTransformer('all-MiniLM-L6-v2')"
      ],
      "metadata": {
        "id": "Sjf3ZAu7qU9D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "# 2. MODELS\n",
        "class Step(BaseModel):\n",
        "    thought: str\n",
        "    action: str\n",
        "    observation: str\n",
        "\n",
        "class Case(BaseModel):\n",
        "    model_config = ConfigDict(arbitrary_types_allowed=True)\n",
        "    task: str\n",
        "    task_embedding: np.ndarray\n",
        "    trajectory: List[Step] = Field(default_factory=list)\n",
        "    final_success: bool = False\n",
        "    final_reward: float = 0.0\n",
        "\n",
        "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "# 3. MEMORY\n",
        "class MementoCaseBank:\n",
        "    def __init__(self, top_k=3, sim_threshold=0.60):\n",
        "        self.cases: List[Case] = []\n",
        "        self.top_k = top_k\n",
        "        self.sim_threshold = sim_threshold\n",
        "\n",
        "    def _embed(self, text: str) -> np.ndarray:\n",
        "        return embedder.encode(text, convert_to_numpy=True)\n",
        "\n",
        "    def add(self, task: str, trajectory: List[Step], success: bool, reward: float):\n",
        "        emb = self._embed(task)\n",
        "        for c in self.cases:\n",
        "            norm = np.linalg.norm(emb) * np.linalg.norm(c.task_embedding) + 1e-8\n",
        "            sim = np.dot(emb, c.task_embedding) / norm\n",
        "            if sim > 0.97:\n",
        "                if success and reward > c.final_reward:\n",
        "                    c.trajectory = trajectory\n",
        "                    c.final_success = success\n",
        "                    c.final_reward = reward\n",
        "                return\n",
        "        self.cases.append(Case(task=task, task_embedding=emb, trajectory=trajectory,\n",
        "                               final_success=success, final_reward=reward))\n",
        "\n",
        "    def retrieve(self, current_task: str) -> str:\n",
        "        if not self.cases:\n",
        "            return \"No past cases.\"\n",
        "\n",
        "        emb = self._embed(current_task)\n",
        "        scored = []\n",
        "\n",
        "        for c in self.cases:\n",
        "            norm = np.linalg.norm(emb) * np.linalg.norm(c.task_embedding) + 1e-8\n",
        "            sim = np.dot(emb, c.task_embedding) / norm\n",
        "            if sim >= self.sim_threshold:\n",
        "                scored.append((sim, c))\n",
        "\n",
        "        if not scored:\n",
        "            return \"No similar cases found.\"\n",
        "\n",
        "        scored.sort(key=lambda x: (-x[0], -x[1].final_reward))\n",
        "        top = scored[:self.top_k]\n",
        "\n",
        "        blocks = []\n",
        "        for sim, c in top:\n",
        "            traj = \"\\n\".join(\n",
        "                f\"  â€¢ {s.thought[:65] + '...' if len(s.thought) > 65 else s.thought} â†’ \"\n",
        "                f\"{s.action} â†’ {s.observation[:65] + '...' if len(s.observation) > 65 else s.observation}\"\n",
        "                for s in c.trajectory\n",
        "            )\n",
        "            blocks.append(f\"Sim: {sim:.3f} | Reward: {c.final_reward:.2f}\\nTask: {c.task}\\n{traj}\")\n",
        "\n",
        "        return \"--- RETRIEVED SUCCESSFUL STRATEGIES ---\\n\\n\" + \"\\n\\n\".join(blocks) + \"\\n\"\n",
        "\n",
        "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "# 4. AGENT\n",
        "class MementoAgent:\n",
        "    def __init__(self, memory: MementoCaseBank, backend: str = \"grok\"):\n",
        "        self.memory = memory\n",
        "        self.backend = backend.lower()\n",
        "        self.max_steps = 4\n",
        "\n",
        "    def _call_planner(self, prompt: str) -> str:\n",
        "        if self.backend == \"grok\":\n",
        "            resp = xai_client.chat.create(\n",
        "                model=\"grok-4-1-fast-reasoning\",\n",
        "                messages=[system(\"You are a precise memory-driven planner.\"), user(prompt)]\n",
        "            )\n",
        "            return resp.choices[0].message.content if hasattr(resp, 'choices') else str(resp)\n",
        "\n",
        "        resp = openai_client.chat.completions.create(\n",
        "            model=\"gpt-4.1\",\n",
        "            messages=[\n",
        "                {\"role\": \"system\", \"content\": \"You are a precise Memento-style planner.\"},\n",
        "                {\"role\": \"user\", \"content\": prompt}\n",
        "            ],\n",
        "            temperature=0.0,\n",
        "            max_tokens=400\n",
        "        )\n",
        "        return resp.choices[0].message.content\n",
        "\n",
        "    def _call_executor(self, action: str, task: str) -> str:\n",
        "        if self.backend == \"grok\":\n",
        "            return \"Success: data retrieved via reliable endpoint\"\n",
        "\n",
        "        exe_prompt = (\n",
        "            f\"For task '{task}' and action '{action}':\\n\"\n",
        "            \"Return ONLY exactly one of these two lines and nothing else:\\n\"\n",
        "            \"Success: data retrieved\\n\"\n",
        "            \"Error: failed to retrieve data\"\n",
        "        )\n",
        "        resp = openai_client.chat.completions.create(\n",
        "            model=\"o4-mini\",\n",
        "            messages=[{\"role\": \"user\", \"content\": exe_prompt}],\n",
        "            seed=42\n",
        "        )\n",
        "        return resp.choices[0].message.content.strip()\n",
        "\n",
        "    def run(self, task: str, force_first_failure: bool = False):\n",
        "        print(f\"\\n{'â•'*75}\\n{self.backend.upper()} â†’ {task}\\n{'â•'*75}\")\n",
        "\n",
        "        context = self.memory.retrieve(task)\n",
        "        trajectory: List[Step] = []\n",
        "        success = False\n",
        "\n",
        "        for step_idx in range(1, self.max_steps + 1):\n",
        "            prompt = (\n",
        "                \"CRITICAL:\\n\"\n",
        "                \"â€¢ Start with: THOUGHT: From memory: ... Therefore I will...\\n\"\n",
        "                \"â€¢ Then: ACTION: USE_ENDPOINT or ACTION: FINISH\\n\\n\"\n",
        "                f\"{context}\\n\"\n",
        "                f\"Task: {task} (step {step_idx}/{self.max_steps})\\n\"\n",
        "            )\n",
        "\n",
        "            content = self._call_planner(prompt)\n",
        "\n",
        "            print(f\"[Step {step_idx} â€” {self.backend.upper()} Planner]\")\n",
        "            print(content.strip()[:500] + (\"...\" if len(content) > 500 else \"\"))\n",
        "\n",
        "            thought = \"No thought parsed\"\n",
        "            action_raw = \"USE_ENDPOINT\"\n",
        "            for line in content.splitlines():\n",
        "                line = line.strip()\n",
        "                if line.upper().startswith(\"THOUGHT:\"):\n",
        "                    thought = line[8:].strip()\n",
        "                elif line.upper().startswith(\"ACTION:\"):\n",
        "                    action_raw = line[7:].strip().upper()\n",
        "\n",
        "            if \"FINISH\" in action_raw:\n",
        "                trajectory.append(Step(thought=thought, action=\"FINISH\", observation=\"Complete\"))\n",
        "                success = True\n",
        "                break\n",
        "\n",
        "            if force_first_failure and len(self.memory.cases) == 0 and step_idx == 1:\n",
        "                obs = \"Forced demo failure â€” learning unreliable endpoint\"\n",
        "            else:\n",
        "                obs = self._call_executor(\"USE_ENDPOINT\", task)\n",
        "\n",
        "            trajectory.append(Step(thought=thought, action=\"USE_ENDPOINT\", observation=obs))\n",
        "            print(f\"â†’ Obs: {obs}\")\n",
        "\n",
        "            if \"Success\" in obs or \"retrieved\" in obs.lower():\n",
        "                success = True\n",
        "                break\n",
        "\n",
        "        final_reward = 1.0 if success else 0.0\n",
        "        print(f\"\\n[FINAL {self.backend.upper()}] Success = {success} | Reward = {final_reward:.2f}\\n\")\n",
        "        self.memory.add(task, trajectory, success, final_reward)\n",
        "\n",
        "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "# 5. COMPARISON\n",
        "if __name__ == \"__main__\":\n",
        "    print(\"ðŸš€ MEMENTO COMPARISON â€” Grok vs GPT-4.1 + o4-mini\\n\")\n",
        "\n",
        "    tasks = [\n",
        "        \"Fetch quarterly sales report Q1 2025\",\n",
        "        \"Retrieve inventory status Europe region\",\n",
        "        \"Fetch quarterly sales report Q2 2025\",\n",
        "        \"Get marketing campaign performance Q1 2025\",\n",
        "        \"Fetch quarterly sales report Q3 2025\"\n",
        "    ]\n",
        "\n",
        "    # Grok\n",
        "    bank_grok = MementoCaseBank()\n",
        "    agent_grok = MementoAgent(bank_grok, backend=\"grok\")\n",
        "    print(\"=== GROK-4.1 MODE ===\")\n",
        "    for i, t in enumerate(tasks, 1):\n",
        "        agent_grok.run(t, force_first_failure=(i == 1))\n",
        "\n",
        "    # Paper\n",
        "    bank_paper = MementoCaseBank()\n",
        "    agent_paper = MementoAgent(bank_paper, backend=\"openai\")\n",
        "    print(\"\\n=== PAPER MODE ===\")\n",
        "    for i, t in enumerate(tasks, 1):\n",
        "        agent_paper.run(t, force_first_failure=(i == 1))\n",
        "\n",
        "    # Table\n",
        "    print(\"\\n\" + \"=\"*100)\n",
        "    print(\"COMPARISON SUMMARY\")\n",
        "    print(\"=\"*100)\n",
        "    print(f\"{'Task':<50} {'Grok Steps':<12} {'Paper Steps':<12} {'Grok Succ':<10} {'Paper Succ':<10} {'Faster'}\")\n",
        "    print(\"-\"*100)\n",
        "    for i, task in enumerate(tasks):\n",
        "        g_steps = len(bank_grok.cases[i].trajectory) if i < len(bank_grok.cases) else \"N/A\"\n",
        "        p_steps = len(bank_paper.cases[i].trajectory) if i < len(bank_paper.cases) else \"N/A\"\n",
        "        g_succ = \"Yes\" if i < len(bank_grok.cases) and bank_grok.cases[i].final_success else \"No\"\n",
        "        p_succ = \"Yes\" if i < len(bank_paper.cases) and bank_paper.cases[i].final_success else \"No\"\n",
        "        faster = \"Tie\" if g_steps == p_steps else (\"Paper\" if isinstance(p_steps, int) and isinstance(g_steps, int) and p_steps < g_steps else \"Grok\")\n",
        "        print(f\"{task[:49]:<50} {g_steps:<12} {p_steps:<12} {g_succ:<10} {p_succ:<10} {faster}\")\n",
        "    print(\"=\"*100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n1JL5UoCk79-",
        "outputId": "7b09476e-d49b-4136-991f-6f5622185ade"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ðŸš€ MEMENTO COMPARISON â€” Grok vs GPT-4.1 + o4-mini\n",
            "\n",
            "=== GROK-4.1 MODE ===\n",
            "\n",
            "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
            "GROK â†’ Fetch quarterly sales report Q1 2025\n",
            "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
            "[Step 1 â€” GROK Planner]\n",
            "messages {\n",
            "  content {\n",
            "    text: \"You are a precise memory-driven planner.\"\n",
            "  }\n",
            "  role: ROLE_SYSTEM\n",
            "}\n",
            "messages {\n",
            "  content {\n",
            "    text: \"CRITICAL:\\nâ€¢ Start with: THOUGHT: From memory: ... Therefore I will...\\nâ€¢ Then: ACTION: USE_ENDPOINT or ACTION: FINISH\\n\\nNo past cases.\\nTask: Fetch quarterly sales report Q1 2025 (step 1/4)\\n\"\n",
            "  }\n",
            "  role: ROLE_USER\n",
            "}\n",
            "model: \"grok-4-1-fast-reasoning\"\n",
            "â†’ Obs: Forced demo failure â€” learning unreliable endpoint\n",
            "[Step 2 â€” GROK Planner]\n",
            "messages {\n",
            "  content {\n",
            "    text: \"You are a precise memory-driven planner.\"\n",
            "  }\n",
            "  role: ROLE_SYSTEM\n",
            "}\n",
            "messages {\n",
            "  content {\n",
            "    text: \"CRITICAL:\\nâ€¢ Start with: THOUGHT: From memory: ... Therefore I will...\\nâ€¢ Then: ACTION: USE_ENDPOINT or ACTION: FINISH\\n\\nNo past cases.\\nTask: Fetch quarterly sales report Q1 2025 (step 2/4)\\n\"\n",
            "  }\n",
            "  role: ROLE_USER\n",
            "}\n",
            "model: \"grok-4-1-fast-reasoning\"\n",
            "â†’ Obs: Success: data retrieved via reliable endpoint\n",
            "\n",
            "[FINAL GROK] Success = True | Reward = 1.00\n",
            "\n",
            "\n",
            "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
            "GROK â†’ Retrieve inventory status Europe region\n",
            "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
            "[Step 1 â€” GROK Planner]\n",
            "messages {\n",
            "  content {\n",
            "    text: \"You are a precise memory-driven planner.\"\n",
            "  }\n",
            "  role: ROLE_SYSTEM\n",
            "}\n",
            "messages {\n",
            "  content {\n",
            "    text: \"CRITICAL:\\nâ€¢ Start with: THOUGHT: From memory: ... Therefore I will...\\nâ€¢ Then: ACTION: USE_ENDPOINT or ACTION: FINISH\\n\\nNo similar cases found.\\nTask: Retrieve inventory status Europe region (step 1/4)\\n\"\n",
            "  }\n",
            "  role: ROLE_USER\n",
            "}\n",
            "model: \"grok-4-1-fast-reasoning\"\n",
            "â†’ Obs: Success: data retrieved via reliable endpoint\n",
            "\n",
            "[FINAL GROK] Success = True | Reward = 1.00\n",
            "\n",
            "\n",
            "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
            "GROK â†’ Fetch quarterly sales report Q2 2025\n",
            "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
            "[Step 1 â€” GROK Planner]\n",
            "messages {\n",
            "  content {\n",
            "    text: \"You are a precise memory-driven planner.\"\n",
            "  }\n",
            "  role: ROLE_SYSTEM\n",
            "}\n",
            "messages {\n",
            "  content {\n",
            "    text: \"CRITICAL:\\nâ€¢ Start with: THOUGHT: From memory: ... Therefore I will...\\nâ€¢ Then: ACTION: USE_ENDPOINT or ACTION: FINISH\\n\\n--- RETRIEVED SUCCESSFUL STRATEGIES ---\\n\\nSim: 0.966 | Reward: 1.00\\nTask: Fetch quarterly sales report Q1 2025\\n  â€¢ No thought parsed â†’ USE_ENDPOINT â†’ Forced demo failure â€” learning unreliable endpoint\\n  â€¢ No thought parsed â†’ USE_ENDPOINT ...\n",
            "â†’ Obs: Success: data retrieved via reliable endpoint\n",
            "\n",
            "[FINAL GROK] Success = True | Reward = 1.00\n",
            "\n",
            "\n",
            "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
            "GROK â†’ Get marketing campaign performance Q1 2025\n",
            "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
            "[Step 1 â€” GROK Planner]\n",
            "messages {\n",
            "  content {\n",
            "    text: \"You are a precise memory-driven planner.\"\n",
            "  }\n",
            "  role: ROLE_SYSTEM\n",
            "}\n",
            "messages {\n",
            "  content {\n",
            "    text: \"CRITICAL:\\nâ€¢ Start with: THOUGHT: From memory: ... Therefore I will...\\nâ€¢ Then: ACTION: USE_ENDPOINT or ACTION: FINISH\\n\\nNo similar cases found.\\nTask: Get marketing campaign performance Q1 2025 (step 1/4)\\n\"\n",
            "  }\n",
            "  role: ROLE_USER\n",
            "}\n",
            "model: \"grok-4-1-fast-reasoning\"\n",
            "â†’ Obs: Success: data retrieved via reliable endpoint\n",
            "\n",
            "[FINAL GROK] Success = True | Reward = 1.00\n",
            "\n",
            "\n",
            "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
            "GROK â†’ Fetch quarterly sales report Q3 2025\n",
            "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
            "[Step 1 â€” GROK Planner]\n",
            "messages {\n",
            "  content {\n",
            "    text: \"You are a precise memory-driven planner.\"\n",
            "  }\n",
            "  role: ROLE_SYSTEM\n",
            "}\n",
            "messages {\n",
            "  content {\n",
            "    text: \"CRITICAL:\\nâ€¢ Start with: THOUGHT: From memory: ... Therefore I will...\\nâ€¢ Then: ACTION: USE_ENDPOINT or ACTION: FINISH\\n\\n--- RETRIEVED SUCCESSFUL STRATEGIES ---\\n\\nSim: 0.955 | Reward: 1.00\\nTask: Fetch quarterly sales report Q1 2025\\n  â€¢ No thought parsed â†’ USE_ENDPOINT â†’ Forced demo failure â€” learning unreliable endpoint\\n  â€¢ No thought parsed â†’ USE_ENDPOINT ...\n",
            "â†’ Obs: Success: data retrieved via reliable endpoint\n",
            "\n",
            "[FINAL GROK] Success = True | Reward = 1.00\n",
            "\n",
            "\n",
            "=== PAPER MODE ===\n",
            "\n",
            "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
            "OPENAI â†’ Fetch quarterly sales report Q1 2025\n",
            "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
            "[Step 1 â€” OPENAI Planner]\n",
            "THOUGHT: From memory: The user wants to fetch the quarterly sales report for Q1 2025. The first step is to identify and access the appropriate endpoint or system where sales reports are stored. Therefore I will check the available endpoints for sales report retrieval.\n",
            "\n",
            "ACTION: USE_ENDPOINT\n",
            "â†’ Obs: Forced demo failure â€” learning unreliable endpoint\n",
            "[Step 2 â€” OPENAI Planner]\n",
            "THOUGHT: From memory: This is step 2 of 4 for fetching the quarterly sales report for Q1 2025. Step 1 is likely to have involved identifying the report or confirming access. Therefore I will proceed to use the appropriate endpoint to retrieve the Q1 2025 sales report.\n",
            "\n",
            "ACTION: USE_ENDPOINT\n",
            "â†’ Obs: Success: data retrieved\n",
            "\n",
            "[FINAL OPENAI] Success = True | Reward = 1.00\n",
            "\n",
            "\n",
            "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
            "OPENAI â†’ Retrieve inventory status Europe region\n",
            "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
            "[Step 1 â€” OPENAI Planner]\n",
            "THOUGHT: From memory: The user wants to retrieve the inventory status for the Europe region, and this is step 1 of 4. Therefore I will initiate the process to retrieve the inventory status for the Europe region.\n",
            "\n",
            "ACTION: USE_ENDPOINT inventory_status_retrieve(region=\"Europe\")\n",
            "â†’ Obs: Success: data retrieved\n",
            "\n",
            "[FINAL OPENAI] Success = True | Reward = 1.00\n",
            "\n",
            "\n",
            "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
            "OPENAI â†’ Fetch quarterly sales report Q2 2025\n",
            "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
            "[Step 1 â€” OPENAI Planner]\n",
            "THOUGHT: From memory: The user wants to fetch the quarterly sales report for Q2 2025, and this is step 1 of 4 for fetching such reports. Therefore I will initiate the process to fetch the Q2 2025 sales report, starting with step 1.\n",
            "\n",
            "ACTION: USE_ENDPOINT\n",
            "â†’ Obs: Success: data retrieved\n",
            "\n",
            "[FINAL OPENAI] Success = True | Reward = 1.00\n",
            "\n",
            "\n",
            "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
            "OPENAI â†’ Get marketing campaign performance Q1 2025\n",
            "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
            "[Step 1 â€” OPENAI Planner]\n",
            "THOUGHT: From memory: The user wants to get the marketing campaign performance for Q1 2025, and this is step 1 of 4. Therefore I will initiate the process to retrieve or prepare the relevant campaign performance data for Q1 2025.\n",
            "\n",
            "ACTION: USE_ENDPOINT\n",
            "â†’ Obs: Success: data retrieved\n",
            "\n",
            "[FINAL OPENAI] Success = True | Reward = 1.00\n",
            "\n",
            "\n",
            "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
            "OPENAI â†’ Fetch quarterly sales report Q3 2025\n",
            "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
            "[Step 1 â€” OPENAI Planner]\n",
            "THOUGHT: From memory: The user wants to fetch the quarterly sales report for Q3 2025. Previous successful strategies involved using the USE_ENDPOINT action to retrieve the data for similar tasks (Q1 and Q2 2025). Therefore I will attempt to use the endpoint to fetch the Q3 2025 report.\n",
            "\n",
            "ACTION: USE_ENDPOINT\n",
            "â†’ Obs: Success: data retrieved\n",
            "\n",
            "[FINAL OPENAI] Success = True | Reward = 1.00\n",
            "\n",
            "\n",
            "====================================================================================================\n",
            "COMPARISON SUMMARY\n",
            "====================================================================================================\n",
            "Task                                               Grok Steps   Paper Steps  Grok Succ  Paper Succ Faster\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Fetch quarterly sales report Q1 2025               2            2            Yes        Yes        Tie\n",
            "Retrieve inventory status Europe region            1            1            Yes        Yes        Tie\n",
            "Fetch quarterly sales report Q2 2025               1            1            Yes        Yes        Tie\n",
            "Get marketing campaign performance Q1 2025         1            1            Yes        Yes        Tie\n",
            "Fetch quarterly sales report Q3 2025               1            1            Yes        Yes        Tie\n",
            "====================================================================================================\n"
          ]
        }
      ]
    }
  ]
}