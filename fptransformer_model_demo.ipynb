{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "ENfXEAQtzbK8",
        "ctH2mbLikx4O"
      ],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyOz0dAEgeOryAKA26kd5NEm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/frank-morales2020/Cloud_curious/blob/master/fptransformer_model_demo.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install colab-env -q\n",
        "!pip install transformers datasets torch -q\n",
        "!pip install geopy -q\n",
        "import colab_env"
      ],
      "metadata": {
        "id": "Qz47jn9NCcVf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import colab_env\n",
        "import os\n",
        "\n",
        "access_token_write = os.getenv(\"HUGGINGFACE_ACCESS_TOKEN_WRITE\")\n",
        "\n",
        "from huggingface_hub import login\n",
        "\n",
        "login(\n",
        "  token=access_token_write, # ADD YOUR TOKEN HERE\n",
        "  add_to_git_credential=True\n",
        ")"
      ],
      "metadata": {
        "id": "-fTdYX3qGB7-"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from huggingface_hub import HfApi\n",
        "api = HfApi()\n",
        "api.get_token_permission(token=access_token_write)\n",
        "repo_id = 'frankmorales2020/FlightPlan_Transformer_LLM'\n",
        "api.delete_repo(repo_id=repo_id)"
      ],
      "metadata": {
        "id": "m73qgudjGBFz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The code covers the complete process of training, evaluation, and validation for a built-from-scratch Transformer model for waypoint coordinate prediction using a Sequence-to-Sequence (Seq2Seq) architecture.\n",
        "\n",
        "Here's a breakdown of how the code addresses each stage:\n",
        "\n",
        "1. Building the Model:\n",
        "\n",
        "* * It defines a custom Transformer model (Seq2SeqCoordsTransformer) with an encoder-decoder structure and attention mechanisms.\n",
        "\n",
        "* * It includes positional encoding to capture sequence order information.\n",
        "\n",
        "* * The output layer is designed to predict both waypoint coordinates and the waypoint count.\n",
        "\n",
        "2. Training:\n",
        "\n",
        "* * It uses a training loop to update the model's parameters using the training dataset.\n",
        "* * It employs an optimizer (AdamW) and a combined loss function (CombinedLossSeq2Seq) that considers both coordinate and count prediction errors.\n",
        "* * Data augmentation is applied during training to improve the model's robustness.\n",
        "\n",
        "3. Evaluation and Validation:\n",
        "\n",
        "* * The code splits the data into training, validation, and test sets.\n",
        "\n",
        "* * After each training epoch, the model is evaluated on the validation set to monitor its performance on unseen data.\n",
        "\n",
        "* * Early stopping is implemented to prevent overfitting and select the best-performing model.\n",
        "\n",
        "4. Inference and Testing:\n",
        "\n",
        "* * After training, the best model is loaded and used for inference on the test set.\n",
        "\n",
        "* * The code calculates various evaluation metrics, including average coordinate loss, count loss, and average absolute count difference, to assess the model's accuracy and generalization ability.\n",
        "\n",
        "In summary, the code provides a comprehensive implementation of a Seq2Seq Transformer model for flight plan waypoint prediction, including all the necessary steps for training, evaluation, validation, and testing. This suggests a well-structured and thorough approach to developing a model for this task."
      ],
      "metadata": {
        "id": "gCk0PHMDxn6K"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## FlightPlanTransformer"
      ],
      "metadata": {
        "id": "ENfXEAQtzbK8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ==============================================================================\n",
        "# FINAL CODE - Restores count_loss_weight = 300.0 for best reported result (1.1700), includes bug fixes.\n",
        "# WARNING: This script trains a NEW model architecture (FlightPlanTransformer)\n",
        "# for direct coordinate regression [cite: 1, 3 in DRD.pdf]. The hf_repo_id is set\n",
        "# to \"frankmorales2020/FlightPlan_Transformer_LLM\" as requested.\n",
        "# Attempting to LOAD a model from this ID later in the script will likely FAIL\n",
        "# or produce incorrect results if it contains weights from an incompatible\n",
        "# architecture. Set load_from_hf=False in loading section below to test locally saved model.\n",
        "# ==============================================================================\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import DataLoader, Subset\n",
        "from datasets import load_dataset, DatasetDict\n",
        "from transformers import AutoTokenizer\n",
        "# Ensure tqdm.notebook is used for interactive environments like Colab/Jupyter\n",
        "try:\n",
        "    from tqdm.notebook import tqdm\n",
        "except ImportError:\n",
        "    from tqdm import tqdm\n",
        "import math\n",
        "import numpy as np\n",
        "import os\n",
        "import json\n",
        "import shutil # For removing temp directories during deployment\n",
        "import random # For data augmentation\n",
        "\n",
        "# --- Hugging Face Hub Integration ---\n",
        "try:\n",
        "    from huggingface_hub import HfApi, HfFolder, login, create_repo, upload_file, notebook_login, hf_hub_download\n",
        "    access_token_write = os.getenv(\"HUGGINGFACE_ACCESS_TOKEN_WRITE\")\n",
        "    if access_token_write:\n",
        "        print(\"Attempting Hugging Face login using environment token...\")\n",
        "        try: login(token=access_token_write, add_to_git_credential=True); print(\"HF login successful.\")\n",
        "        except Exception as e: print(f\"HF login with token failed: {e}.\")\n",
        "    else: print(\"HF write token not found. Manual login may be needed.\")\n",
        "except ImportError:\n",
        "    print(\"Warning: huggingface_hub not found. Deployment/loading features unavailable.\")\n",
        "    HfApi = None; hf_hub_download = None\n",
        "\n",
        "# --- Configuration ---\n",
        "# >>> Setting repo ID as requested <<<\n",
        "hf_repo_id = \"frankmorales2020/FlightPlan_Transformer_LLM\" # As requested, see WARNING above.\n",
        "\n",
        "tokenizer_name = \"gpt2\"\n",
        "dataset_name = \"frankmorales2020/flight_plan_waypoints\"\n",
        "# Model Hyperparameters\n",
        "embedding_dimension = 256; num_heads = 8; feed_forward_dimension = 1024\n",
        "num_encoder_layers = 6; sequence_length = 128; dropout_probability = 0.1\n",
        "# Training Hyperparameters\n",
        "batch_size = 16; learning_rate = 3e-5\n",
        "num_epochs = 30 # Keeping increased epochs for early stopping\n",
        "\n",
        "## 300.0 Average Absolute Count Difference: 1.5350\n",
        "count_loss_weight = 1.0 # Set to value associated with 1.1700 result\n",
        "\n",
        "coordinate_pad_value = 0.0\n",
        "train_subset_size = None; eval_subset_size = None\n",
        "# Early Stopping Configuration\n",
        "early_stopping_patience = 5\n",
        "min_delta = 0.0001\n",
        "best_model_save_path = \"./best_flight_plan_model.bin\"\n",
        "# Data Augmentation Config\n",
        "augment_training_data = True\n",
        "coord_noise_level = 0.01\n",
        "\n",
        "# --- Explicitly Setting max_waypoints ---\n",
        "max_waypoints = 10\n",
        "print(f\"Using explicitly set max_waypoints: {max_waypoints}\")\n",
        "\n",
        "# --- Tokenizer Setup ---\n",
        "print(f\"Loading tokenizer: {tokenizer_name}\")\n",
        "tokenizer = AutoTokenizer.from_pretrained(tokenizer_name)\n",
        "if tokenizer.pad_token is None:\n",
        "    if tokenizer.eos_token: tokenizer.pad_token = tokenizer.eos_token\n",
        "    else: tokenizer.add_special_tokens({'pad_token': '[PAD]'})\n",
        "print(f\"Tokenizer vocabulary size: {tokenizer.vocab_size}\")\n",
        "\n",
        "# --- Load Dataset ---\n",
        "print(f\"Loading dataset: {dataset_name}\")\n",
        "try: dataset = load_dataset(dataset_name); print(\"Dataset loaded.\")\n",
        "except Exception as e: raise SystemExit(f\"ERROR: Failed to load dataset '{dataset_name}'. Error: {e}\") from e\n",
        "\n",
        "# --- Data Preprocessing Function (with optional augmentation) ---\n",
        "print(\"Defining data preprocessing function...\")\n",
        "def preprocess_data(examples, is_training=False):\n",
        "    if \"input\" not in examples or \"waypoints\" not in examples or \"label\" not in examples: return {\"input_ids\": [], \"attention_mask\": [], \"target_coords\": [], \"target_count\": [], \"coord_mask\": []}\n",
        "    tokenized_inputs = tokenizer(examples[\"input\"], padding=\"max_length\", truncation=True, max_length=sequence_length)\n",
        "    target_coordinates, target_counts, coordinate_masks = [], [], []\n",
        "    waypoints_list = examples[\"waypoints\"] if isinstance(examples[\"waypoints\"], list) else []\n",
        "    labels_list = examples[\"label\"] if isinstance(examples[\"label\"], list) else []\n",
        "    min_len = min(len(waypoints_list), len(labels_list))\n",
        "    for i in range(min_len):\n",
        "        waypoints, label = waypoints_list[i], labels_list[i]\n",
        "        try:\n",
        "            if isinstance(waypoints, list) and all(isinstance(wp, (list, tuple)) and len(wp) == 2 for wp in waypoints): waypoints_float = [[float(lat), float(lon)] for lat, lon in waypoints]\n",
        "            else: raise TypeError(\"Waypoints format incorrect\")\n",
        "        except (ValueError, TypeError, IndexError): waypoints_float = []\n",
        "        if is_training and augment_training_data and waypoints_float:\n",
        "            augmented_waypoints = []\n",
        "            for lat, lon in waypoints_float:\n",
        "                noise_lat = random.uniform(-coord_noise_level, coord_noise_level); noise_lon = random.uniform(-coord_noise_level, coord_noise_level)\n",
        "                augmented_waypoints.append([lat + noise_lat, lon + noise_lon])\n",
        "            waypoints_to_process = augmented_waypoints\n",
        "        else: waypoints_to_process = waypoints_float\n",
        "        padded_waypoints = waypoints_to_process[:max_waypoints]; num_actual_waypoints = len(padded_waypoints)\n",
        "        mask = [1.0] * num_actual_waypoints + [0.0] * (max_waypoints - num_actual_waypoints)\n",
        "        while len(padded_waypoints) < max_waypoints: padded_waypoints.append([coordinate_pad_value, coordinate_pad_value])\n",
        "        target_coordinates.append(padded_waypoints)\n",
        "        try: target_counts.append(float(label)) # [cite: 3 in DRD.pdf]\n",
        "        except (ValueError, TypeError): target_counts.append(0.0)\n",
        "        coordinate_masks.append(mask)\n",
        "    tokenized_inputs[\"target_coords\"], tokenized_inputs[\"target_count\"], tokenized_inputs[\"coord_mask\"] = target_coordinates, target_counts, coordinate_masks\n",
        "    return tokenized_inputs\n",
        "\n",
        "# --- Apply Preprocessing and Split ---\n",
        "print(\"Applying preprocessing (with augmentation for training set)...\")\n",
        "columns_to_remove_post_preprocess = [\"distance\", \"distance_category\", \"waypoint_names\"]\n",
        "columns_to_remove_train_val = ['input', 'waypoints', 'label'] + columns_to_remove_post_preprocess\n",
        "columns_to_remove_test = ['waypoints', 'label'] + columns_to_remove_post_preprocess\n",
        "try:\n",
        "    train_testvalid_original = dataset['train'].train_test_split(test_size=0.2, seed=42)\n",
        "    test_valid_original = train_testvalid_original['test'].train_test_split(test_size=0.5, seed=42)\n",
        "    processed_train = train_testvalid_original['train'].map(lambda examples: preprocess_data(examples, is_training=True), batched=True, remove_columns=columns_to_remove_train_val)\n",
        "    processed_validation = test_valid_original['test'].map(lambda examples: preprocess_data(examples, is_training=False), batched=True, remove_columns=columns_to_remove_train_val)\n",
        "    processed_test = test_valid_original['train'].map(lambda examples: preprocess_data(examples, is_training=False), batched=True, remove_columns=columns_to_remove_test)\n",
        "    original_test_set_for_comparison = test_valid_original['train']\n",
        "    processed_train.set_format(\"torch\"); processed_validation.set_format(\"torch\"); processed_test.set_format(\"torch\")\n",
        "    print(\"Preprocessing complete.\")\n",
        "except Exception as e: raise SystemExit(f\"ERROR during preprocessing: {e}\") from e\n",
        "\n",
        "# Select data for training/evaluation/testing\n",
        "train_data = processed_train.shuffle(seed=42).select(range(min(train_subset_size, len(processed_train)))) if train_subset_size else processed_train\n",
        "eval_data = processed_validation.shuffle(seed=42).select(range(min(eval_subset_size, len(processed_validation)))) if eval_subset_size else processed_validation\n",
        "test_data_processed = processed_test\n",
        "print(f\"Using Train: {len(train_data)}, Validation: {len(eval_data)}, Test: {len(test_data_processed)} samples.\")\n",
        "\n",
        "# --- Data Loaders ---\n",
        "print(\"Creating DataLoaders...\")\n",
        "try:\n",
        "    train_dataloader = DataLoader(train_data, batch_size=batch_size, shuffle=True, drop_last=True)\n",
        "    eval_dataloader = DataLoader(eval_data, batch_size=batch_size, drop_last=False)\n",
        "    test_dataloader = DataLoader(test_data_processed, batch_size=batch_size, drop_last=False)\n",
        "    print(f\"Loaders created (Train/Eval/Test batches): {len(train_dataloader)} / {len(eval_dataloader)} / {len(test_dataloader)}\")\n",
        "except Exception as e: raise SystemExit(f\"ERROR creating DataLoaders: {e}\") from e\n",
        "\n",
        "# --- Model Definition ---\n",
        "print(\"Defining the FlightPlanTransformer model...\")\n",
        "class FlightPlanTransformer(nn.Module):\n",
        "    # (Definition predicts coordinates [cite: 1 in DRD.pdf])\n",
        "    def __init__(self, vocab_size, embed_dim, num_heads, ff_hidden_dim, num_layers, block_size, max_waypoints, dropout=0.1):\n",
        "        super().__init__(); self.max_waypoints = max_waypoints; self.embed_dim = embed_dim\n",
        "        self.token_embedding = nn.Embedding(vocab_size, embed_dim); self.pos_embedding = nn.Embedding(block_size + 1, embed_dim)\n",
        "        encoder_layer = nn.TransformerEncoderLayer(embed_dim, num_heads, ff_hidden_dim, dropout, batch_first=True, activation=nn.GELU())\n",
        "        self.encoder = nn.TransformerEncoder(encoder_layer, num_layers); self.pooler = lambda x: x.mean(dim=1)\n",
        "        self.coord_head = nn.Linear(embed_dim, max_waypoints * 2); self.count_head = nn.Linear(embed_dim, 1); self.dropout = nn.Dropout(dropout)\n",
        "        for p in self.parameters():\n",
        "             if p.dim() > 1: nn.init.xavier_uniform_(p)\n",
        "    def forward(self, input_ids, attention_mask):\n",
        "        batch_size, seq_len = input_ids.shape; input_ids = input_ids.clamp(0, self.token_embedding.num_embeddings - 1); tok_embed = self.token_embedding(input_ids)\n",
        "        positions = torch.arange(0, seq_len, dtype=torch.long, device=input_ids.device).unsqueeze(0).repeat(batch_size, 1); positions = positions.clamp(0, self.pos_embedding.num_embeddings - 1); pos_embed = self.pos_embedding(positions)\n",
        "        x = self.dropout(tok_embed + pos_embed); src_key_padding_mask = (attention_mask == 0); encoder_output = self.encoder(x, src_key_padding_mask=src_key_padding_mask)\n",
        "        pooled_output = self.pooler(encoder_output); predicted_coords_flat = self.coord_head(pooled_output); predicted_coords = predicted_coords_flat.view(batch_size, self.max_waypoints, 2)\n",
        "        predicted_count = self.count_head(pooled_output); return predicted_coords, predicted_count\n",
        "\n",
        "# --- Loss Function Definition (Corrected) ---\n",
        "print(\"Defining the CombinedLoss function (Corrected)...\")\n",
        "class CombinedLoss(nn.Module):\n",
        "    # (Definition includes count penalty [cite: 3 in DRD.pdf])\n",
        "    def __init__(self, count_loss_weight=300.0): # Using count_loss_weight=300.0\n",
        "        super().__init__()\n",
        "        self.coord_loss_fn = nn.MSELoss(reduction='none')\n",
        "        self.count_loss_fn = nn.MSELoss()\n",
        "        self.count_loss_weight = count_loss_weight # Bug fix applied\n",
        "\n",
        "    def forward(self, predicted_coords, predicted_count, target_coords, target_count, coord_mask):\n",
        "        coord_loss_elementwise = self.coord_loss_fn(predicted_coords, target_coords); expanded_mask = coord_mask.unsqueeze(-1).expand_as(predicted_coords); masked_coord_loss = coord_loss_elementwise * expanded_mask\n",
        "        num_actual_coords = expanded_mask.sum(); mean_coord_loss = masked_coord_loss.sum() / num_actual_coords if num_actual_coords > 0 else torch.tensor(0.0, device=predicted_coords.device)\n",
        "        target_count = target_count.view_as(predicted_count); count_loss = self.count_loss_fn(predicted_count, target_count)\n",
        "        total_loss = mean_coord_loss + self.count_loss_weight * count_loss\n",
        "        if not torch.isfinite(total_loss): total_loss = torch.tensor(0.0, requires_grad=True, device=predicted_coords.device); mean_coord_loss = torch.tensor(0.0); count_loss = torch.tensor(0.0)\n",
        "        return total_loss, mean_coord_loss, count_loss\n",
        "\n",
        "# --- Instantiate Model, Loss, Optimizer ---\n",
        "print(\"Instantiating model, loss function, and optimizer...\")\n",
        "model = FlightPlanTransformer(vocab_size=tokenizer.vocab_size, embed_dim=embedding_dimension, num_heads=num_heads, ff_hidden_dim=feed_forward_dimension, num_layers=num_encoder_layers, block_size=sequence_length, max_waypoints=max_waypoints, dropout=dropout_probability)\n",
        "loss_fn = CombinedLoss(count_loss_weight=count_loss_weight) # Passes 300.0 here\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\"); model.to(device)\n",
        "print(f\"Model moved to: {device}. Parameters: {sum(p.numel() for p in model.parameters() if p.requires_grad):,}\")\n",
        "\n",
        "# --- Training Loop with Early Stopping ---\n",
        "print(f\"Starting training for up to {num_epochs} epochs with Early Stopping (patience={early_stopping_patience})...\")\n",
        "training_stats = []\n",
        "best_eval_loss = float('inf')\n",
        "epochs_no_improve = 0\n",
        "\n",
        "# TQDM applied to the outer epoch loop\n",
        "epoch_iterator = tqdm(range(num_epochs), desc=\"Overall Training Progress\")\n",
        "for epoch in epoch_iterator:\n",
        "    model.train()\n",
        "    # TQDM applied to the training DataLoader\n",
        "    batch_iterator_train = tqdm(train_dataloader, desc=f\"Epoch {epoch + 1}/{num_epochs} Training\", leave=False)\n",
        "    for batch in batch_iterator_train:\n",
        "        try:\n",
        "            input_ids, attention_mask = batch['input_ids'].to(device), batch['attention_mask'].to(device)\n",
        "            target_coords, target_count = batch['target_coords'].float().to(device), batch['target_count'].float().to(device)\n",
        "            coord_mask = batch['coord_mask'].float().to(device); optimizer.zero_grad()\n",
        "            predicted_coords, predicted_count = model(input_ids, attention_mask)\n",
        "            loss, coord_loss, count_loss = loss_fn(predicted_coords, predicted_count, target_coords, target_count, coord_mask)\n",
        "            if torch.isfinite(loss) and loss > 0:\n",
        "                loss.backward(); torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0); optimizer.step()\n",
        "                batch_iterator_train.set_postfix({'loss': f\"{loss.item():.4f}\", 'coord': f\"{coord_loss.item():.4f}\", 'count': f\"{count_loss.item():.4f}\"})\n",
        "        except Exception as e: print(f\"\\nERROR training batch: {e}\"); continue\n",
        "\n",
        "    # --- Evaluation Phase (Modified to track coord loss) ---\n",
        "    model.eval()\n",
        "    eval_losses, eval_coord_losses, eval_count_losses = [], [], []\n",
        "    # TQDM applied to the evaluation DataLoader\n",
        "    batch_iterator_eval = tqdm(eval_dataloader, desc=f\"Epoch {epoch + 1}/{num_epochs} Evaluation\", leave=False)\n",
        "    with torch.no_grad():\n",
        "        for batch in batch_iterator_eval:\n",
        "            try:\n",
        "                input_ids, attention_mask = batch['input_ids'].to(device), batch['attention_mask'].to(device)\n",
        "                target_coords, target_count = batch['target_coords'].float().to(device), batch['target_count'].float().to(device)\n",
        "                coord_mask = batch['coord_mask'].float().to(device)\n",
        "                predicted_coords, predicted_count = model(input_ids, attention_mask)\n",
        "                loss, coord_loss, count_loss = loss_fn(predicted_coords, predicted_count, target_coords, target_count, coord_mask)\n",
        "                if torch.isfinite(loss): eval_losses.append(loss.item()); eval_coord_losses.append(coord_loss.item()); eval_count_losses.append(count_loss.item())\n",
        "                batch_iterator_eval.set_postfix({'loss': f\"{loss.item():.4f}\", 'coord': f\"{coord_loss.item():.4f}\", 'count': f\"{count_loss.item():.4f}\"})\n",
        "            except Exception as e: print(f\"\\nERROR eval batch: {e}\"); continue\n",
        "\n",
        "    avg_eval_loss = np.mean(eval_losses) if eval_losses else float('inf')\n",
        "    avg_eval_coord_loss = np.mean(eval_coord_losses) if eval_coord_losses else float('inf')\n",
        "    avg_eval_count_loss = np.mean(eval_count_losses) if eval_count_losses else float('inf')\n",
        "    print(f\"\\n--- Epoch {epoch + 1}/{num_epochs} Eval Summary ---\")\n",
        "    print(f\"  Avg Eval Loss: {avg_eval_loss:.4f} (Coord: {avg_eval_coord_loss:.4f}, Count: {avg_eval_count_loss:.4f})\")\n",
        "    training_stats.append({'epoch': epoch + 1, 'eval_loss': avg_eval_loss, 'eval_coord_loss': avg_eval_coord_loss, 'eval_count_loss': avg_eval_count_loss})\n",
        "    epoch_iterator.set_postfix({'Avg Eval Loss': f\"{avg_eval_loss:.4f}\", 'Avg Coord Loss': f\"{avg_eval_coord_loss:.4f}\"})\n",
        "\n",
        "    # --- Early Stopping Check ---\n",
        "    if avg_eval_loss < best_eval_loss - min_delta:\n",
        "        best_eval_loss = avg_eval_loss; epochs_no_improve = 0\n",
        "        try: torch.save(model.state_dict(), best_model_save_path); print(f\"  New best model saved (Eval Loss: {best_eval_loss:.4f})\")\n",
        "        except Exception as e: print(f\"  ERROR saving best model: {e}\")\n",
        "    else:\n",
        "        epochs_no_improve += 1; print(f\"  No improvement in eval loss for {epochs_no_improve} epoch(s).\")\n",
        "    if epochs_no_improve >= early_stopping_patience:\n",
        "        print(f\"\\n--- Early stopping triggered after {epoch + 1} epochs ---\"); break\n",
        "\n",
        "# --- End of Training Loop ---\n",
        "print(\"\\n--- Training loop finished ---\")\n",
        "print(f\"Best validation loss achieved: {best_eval_loss:.4f}\")\n",
        "\n",
        "# --- Load the best model state before saving/deploying ---\n",
        "print(f\"\\nLoading best model state from {best_model_save_path} for final steps...\")\n",
        "try:\n",
        "    if os.path.exists(best_model_save_path): state_dict = torch.load(best_model_save_path, map_location=device); model.load_state_dict(state_dict); print(\"Loaded best model weights.\")\n",
        "    else: print(f\"Warning: Best model checkpoint not found. Using state from last epoch.\")\n",
        "except Exception as e: print(f\"ERROR loading best model state: {e}. Using state from last epoch.\")\n",
        "\n",
        "# --- Saving the model Locally ---\n",
        "print(\"\\nSaving best model locally...\")\n",
        "model_save_path = \"./flight_plan_coord_model_final\"\n",
        "os.makedirs(model_save_path, exist_ok=True)\n",
        "try:\n",
        "    torch.save(model.state_dict(), os.path.join(model_save_path, \"pytorch_model.bin\"))\n",
        "    tokenizer.save_pretrained(model_save_path)\n",
        "    config_to_save = {\"vocab_size\": tokenizer.vocab_size, \"embed_dim\": embedding_dimension, \"num_heads\": num_heads,\"ff_hidden_dim\": feed_forward_dimension, \"num_layers\": num_encoder_layers,\"block_size\": sequence_length, \"max_waypoints\": max_waypoints, \"dropout\": dropout_probability,\"architecture\": model.__class__.__name__}\n",
        "    with open(os.path.join(model_save_path, \"config.json\"), \"w\") as f: json.dump(config_to_save, f, indent=4)\n",
        "    print(f\"Model saved to {model_save_path}\")\n",
        "except Exception as e: print(f\"ERROR saving model locally: {e}\")\n",
        "\n",
        "# --- Deployment to Hugging Face Hub ---\n",
        "# Includes README generation/upload adapted from\n",
        "print(f\"\\n--- Attempting Deployment of Best Model to Hugging Face Hub: {hf_repo_id} ---\")\n",
        "if HfApi and hf_hub_download:\n",
        "    try:\n",
        "        print(f\"Creating/accessing repository '{hf_repo_id}'...\")\n",
        "        create_repo(hf_repo_id, private=False, exist_ok=True)\n",
        "        api = HfApi()\n",
        "\n",
        "        # --- README Generation (YAML FINAL FIX v3 - Simplified) ---\n",
        "        print(\"Generating README.md content (YAML FINAL FIX)...\")\n",
        "        readme_content = f\"\"\"---\n",
        "license: apache-2.0\n",
        "tags:\n",
        "  - flight-planning\n",
        "  - transformer\n",
        "  - coordinate-prediction\n",
        "---\n",
        "# Flight Plan Coordinate Prediction Model ({model.__class__.__name__})\n",
        "Model trained for the AI agent for flight planning project [2025-02-08]. Predicts coordinates directly [cite: 1 in DRD.pdf]. Trained with early stopping & high count weight.\n",
        "## Model Description\n",
        "{model.__class__.__name__} architecture predicting lat/lon coordinates and waypoint count. Trained using coordinate regression with noise augmentation.\n",
        "* Embed Dim: {embedding_dimension}, Heads: {num_heads}, Layers: {num_encoder_layers}, Max Waypoints: {max_waypoints}\n",
        "## Intended Use\n",
        "Research prototype. **Not for real-world navigation.**\n",
        "## Limitations\n",
        "Accuracy depends on data. Fixed max waypoints ({max_waypoints}). Not certified. **Architecture likely differs from previous versions in this repo.** High count weight may impact coordinate precision.\n",
        "## How to Use\n",
        "Requires loading the custom `{model.__class__.__name__}` class and weights from *this specific training run*.\n",
        "## Training Data\n",
        "Trained on `{dataset_name}`.\n",
        "## Contact\n",
        "Frank Morales, BEng, MEng, SMIEEE (Boeing ATF) - https://www.linkedin.com/in/frank-morales1964/\"\"\"\n",
        "        try:\n",
        "            with open(\"README.md\", \"w\", encoding=\"utf-8\") as f: f.write(readme_content)\n",
        "            print(\"Uploading README.md...\")\n",
        "            api.upload_file(path_or_fileobj=\"README.md\", path_in_repo=\"README.md\", repo_id=hf_repo_id, repo_type=\"model\", commit_message=\"Update README (coord model v4)\")\n",
        "            os.remove(\"README.md\"); print(\"README.md uploaded.\")\n",
        "        except Exception as e: print(f\"ERROR creating/uploading README.md: {e}\")\n",
        "\n",
        "        print(f\"Uploading model files from {model_save_path}...\")\n",
        "        api.upload_folder(folder_path=model_save_path, repo_id=hf_repo_id, repo_type=\"model\", commit_message=f\"Upload trained {model.__class__.__name__} (coord v8, weight=300)\")\n",
        "        print(f\"Model files uploaded: https://huggingface.co/{hf_repo_id}\")\n",
        "    except Exception as e: print(f\"ERROR deploying to HF Hub: {e}\")\n",
        "else: print(\"Skipping deployment: huggingface_hub library/login unavailable.\")\n",
        "\n",
        "\n",
        "# --- Model Loading and Test Set Evaluation ---\n",
        "print(\"\\n--- Loading Model and Evaluating on Test Set ---\")\n",
        "\n",
        "# Define generation function again\n",
        "def generate_flight_plan_coords(trained_model, tokenizer_instance, query_text, device_instance):\n",
        "    trained_model.eval(); trained_model.to(device_instance)\n",
        "    try:\n",
        "        inputs = tokenizer_instance(query_text, return_tensors='pt', padding=True, truncation=True, max_length=sequence_length)\n",
        "        input_ids, attention_mask = inputs['input_ids'].to(device_instance), inputs['attention_mask'].to(device_instance)\n",
        "        with torch.no_grad(): predicted_coords, predicted_count = trained_model(input_ids, attention_mask)\n",
        "        num_waypoints = max(0, min(int(round(predicted_count.item())), trained_model.max_waypoints))\n",
        "        final_waypoints = predicted_coords[0, :num_waypoints, :].cpu().numpy().tolist()\n",
        "        return final_waypoints, num_waypoints, predicted_count.item()\n",
        "    except Exception as e: print(f\"ERROR generating for query '{query_text}': {e}\"); return [], 0, 0.0\n",
        "\n",
        "# --- Load the model ---\n",
        "# >>> RECOMMENDED: Set load_from_hf = False to test the locally saved best model <<<\n",
        "load_from_hf = False # <<< Changed default to False to avoid loading incompatible Hub model >>>\n",
        "model_load_id = hf_repo_id if load_from_hf else model_save_path\n",
        "loaded_model = None; loaded_tokenizer = None\n",
        "print(f\"Attempting to load model {'from HF Hub' if load_from_hf else 'from Local Path'}...\")\n",
        "print(f\"  Path/ID: {model_load_id}\")\n",
        "\n",
        "\n",
        "if hf_hub_download: # Need hf_hub_download even for local if config/tokenizer might be missing locally but present on hub\n",
        "    try:\n",
        "        # Determine paths based on load source\n",
        "        if load_from_hf:\n",
        "            tokenizer_load_path = model_load_id\n",
        "            config_load_path = hf_hub_download(repo_id=model_load_id, filename=\"config.json\")\n",
        "            weights_load_path = hf_hub_download(repo_id=model_load_id, filename=\"pytorch_model.bin\")\n",
        "        else: # Loading from local\n",
        "            tokenizer_load_path = model_save_path\n",
        "            config_load_path = os.path.join(model_save_path, \"config.json\")\n",
        "            # Load the BEST model saved by early stopping\n",
        "            weights_load_path = best_model_save_path\n",
        "            if not os.path.exists(weights_load_path):\n",
        "                 print(f\"Warning: Best model file {weights_load_path} not found, trying final saved model...\")\n",
        "                 weights_load_path = os.path.join(model_save_path, \"pytorch_model.bin\") # Fallback\n",
        "            # Check if necessary files exist locally\n",
        "            if not os.path.exists(config_load_path) or not os.path.exists(weights_load_path) or not os.path.exists(os.path.join(tokenizer_load_path, 'tokenizer_config.json')):\n",
        "                 raise FileNotFoundError(f\"Required model files not found locally at {model_save_path} or {best_model_save_path}\")\n",
        "\n",
        "        # Load components\n",
        "        loaded_tokenizer = AutoTokenizer.from_pretrained(tokenizer_load_path)\n",
        "        with open(config_load_path, 'r') as f: config_dict = json.load(f)\n",
        "\n",
        "        # Architecture check\n",
        "        if config_dict.get(\"architecture\") != \"FlightPlanTransformer\":\n",
        "             print(f\"\\n>>> WARNING: Config architecture ('{config_dict.get('architecture')}') may not match 'FlightPlanTransformer'. Ensure correct model is being loaded. <<<\\n\")\n",
        "\n",
        "        # Instantiate model from config\n",
        "        loaded_model = FlightPlanTransformer(vocab_size=config_dict['vocab_size'], embed_dim=config_dict['embed_dim'], num_heads=config_dict['num_heads'], ff_hidden_dim=config_dict['ff_hidden_dim'], num_layers=config_dict['num_layers'], block_size=config_dict['block_size'], max_waypoints=config_dict['max_waypoints'], dropout=config_dict['dropout'])\n",
        "\n",
        "        # Load weights\n",
        "        state_dict = torch.load(weights_load_path, map_location=device)\n",
        "        loaded_model.load_state_dict(state_dict); loaded_model.to(device); loaded_model.eval()\n",
        "        print(\"Model loading successful.\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"\\n>>> ERROR loading model from {model_load_id}: {e} <<<\")\n",
        "        if load_from_hf: print(f\"  This might be due to incompatible architecture at '{hf_repo_id}'.\")\n",
        "        print(f\"  Ensure model files exist and are compatible at the specified path.\\n\")\n",
        "        loaded_model = None\n",
        "else: print(\"Skipping model loading: huggingface_hub library not available.\")\n",
        "\n",
        "\n",
        "# --- Run Inference Loop and Calculate Loss on Test Set ---\n",
        "if loaded_model and loaded_tokenizer:\n",
        "    print(\"\\nRunning inference and loss calculation on the test set...\")\n",
        "    test_results = []\n",
        "    # Use the PREPROCESSED test dataloader for loss calculation\n",
        "    test_iterator_batches = tqdm(test_dataloader, desc=\"Processing Test Set Batches\")\n",
        "    total_test_count_diff = 0\n",
        "    total_test_samples_loss = 0 # Samples processed for loss\n",
        "    total_test_samples_gen = 0 # Samples processed for generation/count diff\n",
        "    test_coord_losses = []\n",
        "    test_count_losses = []\n",
        "\n",
        "    loaded_model.eval()\n",
        "    with torch.no_grad():\n",
        "        for batch in test_iterator_batches:\n",
        "            try:\n",
        "                input_ids = batch['input_ids'].to(device)\n",
        "                attention_mask = batch['attention_mask'].to(device)\n",
        "                target_coords = batch['target_coords'].float().to(device)\n",
        "                target_count = batch['target_count'].float().to(device)\n",
        "                coord_mask = batch['coord_mask'].float().to(device)\n",
        "\n",
        "                # Get predictions\n",
        "                predicted_coords, predicted_count = loaded_model(input_ids, attention_mask)\n",
        "\n",
        "                # Calculate Losses for the batch\n",
        "                loss, coord_loss, count_loss = loss_fn(predicted_coords, predicted_count, target_coords, target_count, coord_mask)\n",
        "                if torch.isfinite(coord_loss): test_coord_losses.append(coord_loss.item() * input_ids.size(0))\n",
        "                if torch.isfinite(count_loss): test_count_losses.append(count_loss.item() * input_ids.size(0))\n",
        "\n",
        "                # Calculate Count Difference for the batch\n",
        "                pred_count_rounded = torch.round(predicted_count).int()\n",
        "                actual_count_batch = target_count.int()\n",
        "                batch_count_diff = torch.abs(pred_count_rounded - actual_count_batch).sum().item()\n",
        "                total_test_count_diff += batch_count_diff\n",
        "                total_test_samples_loss += input_ids.size(0) # Assume samples used for loss = batch size\n",
        "\n",
        "                test_iterator_batches.set_postfix({ 'batch_coord_loss': f\"{coord_loss.item():.4f}\", 'batch_count_loss': f\"{count_loss.item():.4f}\"})\n",
        "\n",
        "            except Exception as e: print(f\"\\nERROR processing test batch: {e}\"); continue\n",
        "\n",
        "    # --- Separate Loop for Generation Metrics (if needed) ---\n",
        "    # The loop above is efficient for loss calc on batches.\n",
        "    # For per-sample generation and count diff average, iterate samples:\n",
        "    print(\"\\nCalculating generation metrics on test samples...\")\n",
        "    original_test_set_for_gen = original_test_set_for_comparison # Use the set with original 'input'\n",
        "    test_iterator_samples = tqdm(range(len(original_test_set_for_gen)), desc=\"Generating Test Samples\")\n",
        "    total_count_diff_gen = 0\n",
        "    total_test_samples_gen = len(original_test_set_for_gen)\n",
        "\n",
        "    for i in test_iterator_samples:\n",
        "         try:\n",
        "            sample = original_test_set_for_gen[i]\n",
        "            query = sample.get('input', '')\n",
        "            actual_waypoints_raw = sample.get('waypoints', [])\n",
        "            if isinstance(actual_waypoints_raw, np.ndarray): actual_waypoints = actual_waypoints_raw.tolist()\n",
        "            elif isinstance(actual_waypoints_raw, list): actual_waypoints = actual_waypoints_raw\n",
        "            else: actual_waypoints = []\n",
        "            actual_count = len(actual_waypoints) if isinstance(actual_waypoints, list) else 0\n",
        "            if not query: total_test_samples_gen-=1; continue # Adjust count if skipping\n",
        "\n",
        "            pred_waypoints, pred_count_rounded, pred_count_raw = generate_flight_plan_coords(loaded_model, loaded_tokenizer, query, device)\n",
        "            count_diff = abs(pred_count_rounded - actual_count); total_count_diff_gen += count_diff\n",
        "            # test_results.append(...) # Append detailed results if needed\n",
        "            test_iterator_samples.set_postfix({'avg_count_diff': f\"{total_count_diff_gen / (i + 1):.2f}\"})\n",
        "         except Exception as e: print(f\"\\nERROR generating for test sample {i}: {e}\"); total_test_samples_gen-=1; continue\n",
        "\n",
        "\n",
        "    # Calculate overall metrics\n",
        "    avg_test_coord_loss = np.sum(test_coord_losses) / total_test_samples_loss if total_test_samples_loss > 0 else 0\n",
        "    avg_test_count_loss = np.sum(test_count_losses) / total_test_samples_loss if total_test_samples_loss > 0 else 0\n",
        "    avg_test_count_difference = total_count_diff_gen / total_test_samples_gen if total_test_samples_gen > 0 else 0\n",
        "\n",
        "    print(f\"\\n--- Final Test Set Evaluation Summary ---\")\n",
        "    print(f\"  Average Absolute Count Difference: {avg_test_count_difference:.4f}\")\n",
        "    print(f\"  Average Coordinate Loss (MSE):   {avg_test_coord_loss:.4f}\")\n",
        "else: print(\"\\nSkipping test set evaluation: model/tokenizer loading failed or unavailable.\")\n",
        "\n",
        "print(\"\\n--- Script Finished ---\")"
      ],
      "metadata": {
        "id": "SvfVQFshSdGT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## New architecture - Seq2SeqCoordsTransformer"
      ],
      "metadata": {
        "id": "F33XZHmSXrof"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ==============================================================================\n",
        "# FINAL CODE (Seq2Seq Arch + Classification Count + Corrected count_loss_weight=100.0)\n",
        "# Includes: Seq2Seq, LR=1e-5, Coord Norm+Sigmoid, Learned SOS, isclose Mask,\n",
        "#           count_loss_weight=100.0, patience=10, Augmentation, CPU Debugging.\n",
        "# WARNING: hf_repo_id points to frankmorales2020/FlightPlan_Transformer_LLM.\n",
        "# Loading from this ID later will likely FAIL due to incompatible architecture.\n",
        "# ==============================================================================\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import DataLoader, Subset\n",
        "from datasets import load_dataset, DatasetDict\n",
        "from transformers import AutoTokenizer\n",
        "# Ensure tqdm.notebook is used for interactive environments like Colab/Jupyter\n",
        "try:\n",
        "    from tqdm.notebook import tqdm\n",
        "except ImportError:\n",
        "    from tqdm import tqdm\n",
        "import math\n",
        "import numpy as np\n",
        "import os\n",
        "import json\n",
        "import shutil\n",
        "import random\n",
        "import traceback # For printing full tracebacks on error\n",
        "\n",
        "# --- Hugging Face Hub Integration ---\n",
        "try:\n",
        "    from huggingface_hub import HfApi, HfFolder, login, create_repo, upload_file, notebook_login, hf_hub_download\n",
        "    access_token_write = os.getenv(\"HUGGINGFACE_ACCESS_TOKEN_WRITE\")\n",
        "    # Suppressing login attempt messages\n",
        "except ImportError:\n",
        "    print(\"Warning: huggingface_hub not found. Deployment/loading features unavailable.\")\n",
        "    HfApi = None; hf_hub_download = None\n",
        "\n",
        "# --- Configuration ---\n",
        "hf_repo_id = \"frankmorales2020/FlightPlan_Transformer_LLM\" # As requested, see WARNING above.\n",
        "tokenizer_name = \"gpt2\"\n",
        "dataset_name = \"frankmorales2020/flight_plan_waypoints\"\n",
        "# Model Hyperparameters\n",
        "embedding_dimension = 256; nhead = 8; num_encoder_layers = 4; num_decoder_layers = 4\n",
        "dim_feedforward = 1024; transformer_dropout = 0.1\n",
        "# Training Hyperparameters\n",
        "batch_size = 16\n",
        "learning_rate = 1e-5 # Keeping reduced LR\n",
        "num_epochs = 5\n",
        "# >>> PARAMETER CORRECTION: Setting count weight to 100.0 <<<\n",
        "count_loss_weight = 100.0 # Increased significantly to improve count accuracy\n",
        "coordinate_pad_value = 0.0\n",
        "train_subset_size = None; eval_subset_size = None\n",
        "# Early Stopping Configuration\n",
        "early_stopping_patience = 10 # Keeping increased patience\n",
        "min_delta = 0.0001\n",
        "best_model_save_path = \"./best_seq2seq_model_clf_count.bin\"\n",
        "# Data Augmentation Config\n",
        "augment_training_data = True\n",
        "coord_noise_level = 0.01\n",
        "# Coordinate Scaling Params\n",
        "LAT_MIN, LAT_MAX = -90.0, 90.0; LON_MIN, LON_MAX = -180.0, 180.0\n",
        "COORD_EPSILON = 1e-6\n",
        "print(f\"Using Coord Scaling: Lat ({LAT_MIN}, {LAT_MAX}), Lon ({LON_MIN}, {LON_MAX})\")\n",
        "\n",
        "# --- Explicitly Setting max_waypoints ---\n",
        "max_waypoints = 10\n",
        "num_count_classes = max_waypoints + 1\n",
        "max_coord_seq_len = max_waypoints + 1\n",
        "max_text_seq_len = 128\n",
        "print(f\"Using max_waypoints: {max_waypoints} => Num Count Classes: {num_count_classes}\")\n",
        "print(f\"Max Decoder Seq Len: {max_coord_seq_len}\")\n",
        "\n",
        "\n",
        "# >>> FORCING CPU EXECUTION FOR DEBUGGING <<<\n",
        "device = torch.device(\"cpu\")\n",
        "print(f\"*** RUNNING ON CPU FOR DEBUGGING ***\")\n",
        "\n",
        "\n",
        "# --- Tokenizer Setup ---\n",
        "print(f\"Loading tokenizer: {tokenizer_name}\")\n",
        "tokenizer = AutoTokenizer.from_pretrained(tokenizer_name)\n",
        "special_tokens_dict = {}\n",
        "if tokenizer.bos_token is None: special_tokens_dict['bos_token'] = '[SOS]'\n",
        "if tokenizer.eos_token is None: special_tokens_dict['eos_token'] = '[EOS]'\n",
        "if tokenizer.pad_token is None: special_tokens_dict['pad_token'] = '[PAD]'\n",
        "num_added_toks = tokenizer.add_special_tokens(special_tokens_dict)\n",
        "if num_added_toks > 0: print(f\"Added {num_added_toks} special tokens: {special_tokens_dict}\")\n",
        "sos_token_id = tokenizer.bos_token_id; eos_token_id = tokenizer.eos_token_id; pad_token_id = tokenizer.pad_token_id\n",
        "vocab_size = len(tokenizer)\n",
        "print(f\"Tokenizer vocabulary size: {vocab_size}\")\n",
        "print(f\"SOS ID: {sos_token_id}, EOS ID: {eos_token_id}, PAD ID: {pad_token_id}\")\n",
        "\n",
        "# --- Load Dataset ---\n",
        "print(f\"Loading dataset: {dataset_name}\")\n",
        "try: dataset = load_dataset(dataset_name); print(\"Dataset loaded.\")\n",
        "except Exception as e: raise SystemExit(f\"ERROR: Failed to load dataset '{dataset_name}'. Error: {e}\") from e\n",
        "\n",
        "\n",
        "# --- Coordinate Normalization / Denormalization ---\n",
        "PAD_COORD_NORM_LAT = max(0.0, min(1.0, (coordinate_pad_value - LAT_MIN) / (LAT_MAX - LAT_MIN + COORD_EPSILON)))\n",
        "PAD_COORD_NORM_LON = max(0.0, min(1.0, (coordinate_pad_value - LON_MIN) / (LON_MAX - LON_MIN + COORD_EPSILON)))\n",
        "PAD_COORD_NORM = [PAD_COORD_NORM_LAT, PAD_COORD_NORM_LON]\n",
        "print(f\"Using PAD_COORD_NORM: {PAD_COORD_NORM}\")\n",
        "\n",
        "def normalize_coords(coords_list):\n",
        "    normalized = []\n",
        "    for coords in coords_list:\n",
        "        lat, lon = coords[0], coords[1]\n",
        "        norm_lat = (lat - LAT_MIN) / (LAT_MAX - LAT_MIN + COORD_EPSILON)\n",
        "        norm_lon = (lon - LON_MIN) / (LON_MAX - LON_MIN + COORD_EPSILON)\n",
        "        norm_lat = max(0.0, min(1.0, norm_lat)); norm_lon = max(0.0, min(1.0, norm_lon))\n",
        "        normalized.append([norm_lat, norm_lon])\n",
        "    return normalized\n",
        "\n",
        "def denormalize_coords(norm_coords_list):\n",
        "    denormalized = []\n",
        "    for norm_coords in norm_coords_list:\n",
        "        norm_lat, norm_lon = norm_coords[0], norm_coords[1]\n",
        "        if abs(norm_lat - PAD_COORD_NORM[0]) < COORD_EPSILON and abs(norm_lon - PAD_COORD_NORM[1]) < COORD_EPSILON: lat, lon = coordinate_pad_value, coordinate_pad_value\n",
        "        else: lat = norm_lat * (LAT_MAX - LAT_MIN + COORD_EPSILON) + LAT_MIN; lon = norm_lon * (LON_MAX - LON_MIN + COORD_EPSILON) + LON_MIN\n",
        "        denormalized.append([lat, lon])\n",
        "    return denormalized\n",
        "\n",
        "# --- Data Preprocessing Function (Seq2Seq, Norm, Correct SOS/EOS Handling v2) ---\n",
        "print(\"Defining data preprocessing function...\")\n",
        "def preprocess_seq2seq_data(examples, is_training=False):\n",
        "    # Returns integer target_count\n",
        "    if \"input\" not in examples or \"waypoints\" not in examples or \"label\" not in examples: return {\"input_ids\": [], \"attention_mask\": [], \"decoder_input_coords_norm\": [], \"target_coords_output_norm\": [], \"target_count\": [], \"coord_mask\": []}\n",
        "    encoder_inputs = tokenizer(examples[\"input\"], padding=\"max_length\", truncation=True, max_length=max_text_seq_len)\n",
        "    input_ids = encoder_inputs[\"input_ids\"]; attention_mask = encoder_inputs[\"attention_mask\"]\n",
        "    decoder_input_batch_norm, target_output_batch_norm, target_counts_batch, coord_masks_batch = [], [], [], []\n",
        "    waypoints_list = examples[\"waypoints\"] if isinstance(examples[\"waypoints\"], list) else []; labels_list = examples[\"label\"] if isinstance(examples[\"label\"], list) else []\n",
        "    min_len = min(len(waypoints_list), len(labels_list))\n",
        "\n",
        "    for i in range(min_len):\n",
        "        waypoints, label = waypoints_list[i], labels_list[i]\n",
        "        try:\n",
        "            if isinstance(waypoints, list) and all(isinstance(wp, (list, tuple)) and len(wp) == 2 for wp in waypoints): waypoints_float = [[float(lat), float(lon)] for lat, lon in waypoints]\n",
        "            else: raise TypeError(\"Waypoints format incorrect\")\n",
        "        except (ValueError, TypeError, IndexError): waypoints_float = []\n",
        "\n",
        "        if is_training and augment_training_data and waypoints_float:\n",
        "            augmented_waypoints = []\n",
        "            for lat, lon in waypoints_float: noise_lat=random.uniform(-coord_noise_level,coord_noise_level); noise_lon=random.uniform(-coord_noise_level,coord_noise_level); augmented_waypoints.append([lat+noise_lat,lon+noise_lon])\n",
        "            coords_processed = augmented_waypoints\n",
        "        else: coords_processed = waypoints_float\n",
        "\n",
        "        coords_truncated = coords_processed[:max_waypoints]; num_actual_waypoints = len(coords_truncated)\n",
        "        coords_normalized = normalize_coords(coords_truncated)\n",
        "        decoder_input_seq_norm = coords_normalized\n",
        "        target_output_seq_norm = coords_normalized + [PAD_COORD_NORM]\n",
        "        decoder_input_padding_len = max_waypoints - len(decoder_input_seq_norm); decoder_input_seq_norm.extend([PAD_COORD_NORM] * decoder_input_padding_len)\n",
        "        target_output_padding_len = max_coord_seq_len - len(target_output_seq_norm); target_output_seq_norm.extend([PAD_COORD_NORM] * target_output_padding_len)\n",
        "        coord_mask = [1.0] * (num_actual_waypoints + 1) + [0.0] * target_output_padding_len\n",
        "\n",
        "        decoder_input_batch_norm.append(decoder_input_seq_norm)\n",
        "        target_output_batch_norm.append(target_output_seq_norm)\n",
        "        coord_masks_batch.append(coord_mask)\n",
        "        try:\n",
        "            count_label = int(round(float(label))); count_label = max(0, min(max_waypoints, count_label))\n",
        "            target_counts_batch.append(count_label)\n",
        "        except (ValueError, TypeError): target_counts_batch.append(0)\n",
        "\n",
        "    return {\"input_ids\": input_ids, \"attention_mask\": attention_mask, \"decoder_input_coords_norm\": decoder_input_batch_norm, \"target_coords_output_norm\": target_output_batch_norm, \"target_count\": target_counts_batch, \"coord_mask\": coord_masks_batch}\n",
        "\n",
        "\n",
        "# --- Apply Preprocessing and Split ---\n",
        "print(\"Applying preprocessing (with augmentation for training set)...\")\n",
        "columns_to_remove_post_preprocess = [\"distance\", \"distance_category\", \"waypoint_names\"]\n",
        "columns_to_remove_train_val = ['input', 'waypoints', 'label'] + columns_to_remove_post_preprocess\n",
        "columns_to_remove_test = ['waypoints', 'label'] + columns_to_remove_post_preprocess\n",
        "try:\n",
        "    train_testvalid_original = dataset['train'].train_test_split(test_size=0.2, seed=42)\n",
        "    test_valid_original = train_testvalid_original['test'].train_test_split(test_size=0.5, seed=42)\n",
        "    processed_train = train_testvalid_original['train'].map(lambda examples: preprocess_seq2seq_data(examples, is_training=True), batched=True, remove_columns=columns_to_remove_train_val)\n",
        "    processed_validation = test_valid_original['test'].map(lambda examples: preprocess_seq2seq_data(examples, is_training=False), batched=True, remove_columns=columns_to_remove_train_val)\n",
        "    processed_test_for_loss = test_valid_original['train'].map(lambda examples: preprocess_seq2seq_data(examples, is_training=False), batched=True, remove_columns=['input', 'waypoints', 'label'] + columns_to_remove_test)\n",
        "    original_test_set_for_comparison = test_valid_original['train']\n",
        "    processed_train.set_format(\"torch\"); processed_validation.set_format(\"torch\"); processed_test_for_loss.set_format(\"torch\")\n",
        "    print(\"Preprocessing complete.\")\n",
        "except Exception as e: raise SystemExit(f\"ERROR during preprocessing: {e}\") from e\n",
        "\n",
        "# Select data for training/evaluation/testing\n",
        "train_data = processed_train.shuffle(seed=42).select(range(min(train_subset_size, len(processed_train)))) if train_subset_size else processed_train\n",
        "eval_data = processed_validation.shuffle(seed=42).select(range(min(eval_subset_size, len(processed_validation)))) if eval_subset_size else processed_validation\n",
        "test_data_processed_for_loss = processed_test_for_loss\n",
        "print(f\"Using Train: {len(train_data)}, Validation: {len(eval_data)}, Test (for loss): {len(test_data_processed_for_loss)} samples.\")\n",
        "\n",
        "# --- Data Loaders ---\n",
        "print(\"Creating DataLoaders...\")\n",
        "try:\n",
        "    train_dataloader = DataLoader(train_data, batch_size=batch_size, shuffle=True, drop_last=True)\n",
        "    eval_dataloader = DataLoader(eval_data, batch_size=batch_size, drop_last=False)\n",
        "    test_dataloader_for_loss = DataLoader(test_data_processed_for_loss, batch_size=batch_size, drop_last=False)\n",
        "    print(f\"Loaders created (Train/Eval/Test batches): {len(train_dataloader)} / {len(eval_dataloader)} / {len(test_dataloader_for_loss)}\")\n",
        "except Exception as e: raise SystemExit(f\"ERROR creating DataLoaders: {e}\") from e\n",
        "\n",
        "# --- Positional Encoding ---\n",
        "class PositionalEncoding(nn.Module):\n",
        "    def __init__(self, d_model: int, dropout: float = 0.1, max_len: int = 5000):\n",
        "        super().__init__(); self.dropout = nn.Dropout(p=dropout)\n",
        "        position = torch.arange(max_len).unsqueeze(1); div_term = torch.exp(torch.arange(0, d_model, 2) * (-math.log(10000.0) / d_model))\n",
        "        pe = torch.zeros(max_len, d_model); pe[:, 0::2] = torch.sin(position * div_term); pe[:, 1::2] = torch.cos(position * div_term)\n",
        "        self.register_buffer('pe', pe)\n",
        "    def forward(self, x): x = x + self.pe[:x.size(1), :].unsqueeze(0); return self.dropout(x)\n",
        "\n",
        "# --- Model Definition (Encoder-Decoder Transformer with Classification Count Head) ---\n",
        "print(\"Defining the Seq2SeqCoordsTransformer model (Classification Count Head)...\")\n",
        "class Seq2SeqCoordsTransformer(nn.Module):\n",
        "    def __init__(self, num_encoder_layers: int, num_decoder_layers: int, emb_size: int, nhead: int, src_vocab_size: int, num_count_classes: int, tgt_coord_dim: int = 2, dim_feedforward: int = 512, dropout: float = 0.1, max_text_len: int = 128, max_coord_len: int = 12):\n",
        "        super().__init__(); self.emb_size = emb_size; self.max_coord_len = max_coord_len\n",
        "        self.src_tok_emb = nn.Embedding(src_vocab_size, emb_size); self.pos_encoder_enc = PositionalEncoding(emb_size, dropout, max_len=max_text_len); self.pos_encoder_dec = PositionalEncoding(emb_size, dropout, max_len=max_coord_len)\n",
        "        self.coord_input_proj = nn.Linear(tgt_coord_dim, emb_size); self.coord_output_proj = nn.Linear(emb_size, tgt_coord_dim)\n",
        "        self.sos_embedding = nn.Parameter(torch.randn(1, 1, emb_size) * 0.02)\n",
        "        self.transformer = nn.Transformer(d_model=emb_size, nhead=nhead, num_encoder_layers=num_encoder_layers, num_decoder_layers=num_decoder_layers, dim_feedforward=dim_feedforward, dropout=dropout, batch_first=True)\n",
        "        self.encoder_pooler = lambda x: x.mean(dim=1)\n",
        "        self.count_head = nn.Linear(emb_size, num_count_classes) # Classification head\n",
        "        self._reset_parameters()\n",
        "    def _reset_parameters(self):\n",
        "        for p in self.parameters():\n",
        "            if p.dim() > 1: nn.init.xavier_uniform_(p)\n",
        "    def forward(self, src_input_ids: torch.Tensor, tgt_input_coords_norm: torch.Tensor, src_mask: torch.Tensor, tgt_mask: torch.Tensor, src_padding_mask: torch.Tensor, tgt_padding_mask: torch.Tensor, memory_key_padding_mask: torch.Tensor):\n",
        "        src_input_ids_clamped = src_input_ids.clamp(0, self.src_tok_emb.num_embeddings - 1); src_emb_lookup = self.src_tok_emb(src_input_ids_clamped); src_emb = self.pos_encoder_enc(src_emb_lookup)\n",
        "        memory = self.transformer.encoder(src_emb, src_key_padding_mask=src_padding_mask); pooled_encoder_output = self.encoder_pooler(memory)\n",
        "        predicted_count_logits = self.count_head(pooled_encoder_output) # Output logits\n",
        "        batch_size = tgt_input_coords_norm.size(0)\n",
        "        coord_vals_emb = self.coord_input_proj(tgt_input_coords_norm); sos_emb_batch = self.sos_embedding.repeat(batch_size, 1, 1)\n",
        "        tgt_emb = torch.cat([sos_emb_batch, coord_vals_emb], dim=1); tgt_emb = self.pos_encoder_dec(tgt_emb)\n",
        "        decoder_output = self.transformer.decoder(tgt_emb, memory, tgt_mask=tgt_mask, memory_key_padding_mask=memory_key_padding_mask, tgt_key_padding_mask=tgt_padding_mask)\n",
        "        projected_coords = self.coord_output_proj(decoder_output); predicted_coords_normalized = torch.sigmoid(projected_coords)\n",
        "        return predicted_coords_normalized, predicted_count_logits # Return logits\n",
        "\n",
        "    def encode(self, src_input_ids: torch.Tensor, src_mask: torch.Tensor): # src_mask is padding mask\n",
        "        src_input_ids_clamped = src_input_ids.clamp(0, self.src_tok_emb.num_embeddings - 1); src_emb_lookup = self.src_tok_emb(src_input_ids_clamped); src_emb = self.pos_encoder_enc(src_emb_lookup)\n",
        "        memory = self.transformer.encoder(src_emb, src_key_padding_mask=src_mask); pooled_memory = self.encoder_pooler(memory)\n",
        "        predicted_count_logits = self.count_head(pooled_memory); return memory, predicted_count_logits # Return logits\n",
        "\n",
        "# --- Utility Functions for Seq2Seq ---\n",
        "def generate_square_subsequent_mask(sz, device): return torch.triu(torch.ones(sz, sz, device=device) * float('-inf'), diagonal=1)\n",
        "def create_mask(src_input_ids, target_output_norm, pad_idx, device): # Use target output shape for target mask dims\n",
        "    src_seq_len = src_input_ids.shape[1]; tgt_seq_len = target_output_norm.shape[1]\n",
        "    tgt_mask = generate_square_subsequent_mask(tgt_seq_len, device)\n",
        "    src_padding_mask = (src_input_ids == pad_idx)\n",
        "    pad_tensor = torch.tensor(PAD_COORD_NORM, device=device).unsqueeze(0).unsqueeze(0)\n",
        "    tgt_padding_mask = torch.all(torch.isclose(target_output_norm, pad_tensor), dim=-1) # Check against normalized pad\n",
        "    memory_key_padding_mask = src_padding_mask\n",
        "    return tgt_mask, src_padding_mask, tgt_padding_mask, memory_key_padding_mask\n",
        "\n",
        "# --- Loss Function Definition (Classification Count Loss) ---\n",
        "print(\"Defining the CombinedLoss function (Classification Count Loss)...\")\n",
        "class CombinedLossSeq2Seq(nn.Module):\n",
        "    def __init__(self, count_loss_weight=100.0): # Using 100.0 now\n",
        "        super().__init__(); self.coord_loss_fn = nn.MSELoss(reduction='none')\n",
        "        self.count_loss_fn = nn.CrossEntropyLoss() # Using CrossEntropy\n",
        "        self.count_loss_weight = count_loss_weight\n",
        "    def forward(self, predicted_coords_norm, predicted_count_logits, target_coords_output_norm, target_count_labels, coord_mask):\n",
        "        # predicted_count_logits: (N, num_classes), target_count_labels: (N,) LongTensor\n",
        "        effective_coord_mask = coord_mask.unsqueeze(-1).expand_as(predicted_coords_norm)\n",
        "        coord_loss_elementwise = self.coord_loss_fn(predicted_coords_norm, target_coords_output_norm)\n",
        "        masked_coord_loss = coord_loss_elementwise * effective_coord_mask\n",
        "        num_actual_elements = effective_coord_mask.sum(); mean_coord_loss = masked_coord_loss.sum() / num_actual_elements if num_actual_elements > 0 else torch.tensor(0.0, device=predicted_coords_norm.device)\n",
        "        # Ensure labels are long and clamped\n",
        "        target_count_labels = target_count_labels.long().clamp(0, predicted_count_logits.size(1) - 1)\n",
        "        count_loss = self.count_loss_fn(predicted_count_logits, target_count_labels) # CrossEntropy loss calculation\n",
        "        total_loss = mean_coord_loss + self.count_loss_weight * count_loss\n",
        "        if not torch.isfinite(total_loss): total_loss = torch.tensor(0.0, requires_grad=True, device=predicted_coords_norm.device); mean_coord_loss = torch.tensor(0.0); count_loss = torch.tensor(0.0)\n",
        "        return total_loss, mean_coord_loss, count_loss # Return CE loss for count\n",
        "\n",
        "# --- Instantiate Model, Loss, Optimizer ---\n",
        "print(\"Instantiating Seq2Seq model (Classification Count), loss function, and optimizer...\")\n",
        "model = Seq2SeqCoordsTransformer(num_encoder_layers=num_encoder_layers, num_decoder_layers=num_decoder_layers, emb_size=embedding_dimension, nhead=nhead, src_vocab_size=vocab_size, num_count_classes=num_count_classes, tgt_coord_dim=2, dim_feedforward=dim_feedforward, dropout=transformer_dropout, max_text_len=max_text_seq_len, max_coord_len=max_coord_seq_len)\n",
        "loss_fn = CombinedLossSeq2Seq(count_loss_weight=count_loss_weight) # Passes 100.0\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate)\n",
        "model.to(device)\n",
        "model.src_tok_emb = nn.Embedding(vocab_size, embedding_dimension).to(device)\n",
        "print(f\"Model moved to: {device}. Parameters: {sum(p.numel() for p in model.parameters() if p.requires_grad):,}\")\n",
        "\n",
        "\n",
        "# --- Training Loop with Early Stopping (Classification Count) ---\n",
        "print(f\"Starting training for up to {num_epochs} epochs with Early Stopping (patience={early_stopping_patience}) on CPU...\")\n",
        "training_stats = []\n",
        "best_eval_loss = float('inf')\n",
        "epochs_no_improve = 0\n",
        "\n",
        "epoch_iterator = tqdm(range(num_epochs), desc=\"Overall Training Progress\")\n",
        "for epoch in epoch_iterator:\n",
        "    model.train()\n",
        "    batch_iterator_train = tqdm(train_dataloader, desc=f\"Epoch {epoch + 1}/{num_epochs} Training\", leave=False)\n",
        "    for batch in batch_iterator_train:\n",
        "        try:\n",
        "            input_ids = batch['input_ids'].to(device)\n",
        "            decoder_input_norm_wp_only = batch['decoder_input_coords_norm'].float().to(device)\n",
        "            target_output_norm = batch['target_coords_output_norm'].float().to(device)\n",
        "            target_cnt_labels = batch['target_count'].long().to(device) # Target is LONG type\n",
        "            output_coord_mask = batch['coord_mask'].float().to(device)\n",
        "            tgt_mask, src_padding_mask, tgt_padding_mask, memory_key_padding_mask = create_mask(input_ids, target_output_norm, pad_token_id, device) # Use target shape for mask\n",
        "            optimizer.zero_grad()\n",
        "            predicted_coords_norm, predicted_count_logits = model(src_input_ids=input_ids, tgt_input_coords_norm=decoder_input_norm_wp_only, src_mask=None, tgt_mask=tgt_mask, src_padding_mask=src_padding_mask, tgt_padding_mask=tgt_padding_mask, memory_key_padding_mask=memory_key_padding_mask)\n",
        "            loss, coord_loss_norm, count_loss = loss_fn(predicted_coords_norm, predicted_count_logits, target_output_norm, target_cnt_labels, output_coord_mask) # Pass logits/labels\n",
        "            if torch.isfinite(loss) and loss > 0:\n",
        "                loss.backward(); torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0); optimizer.step()\n",
        "                batch_iterator_train.set_postfix({'loss': f\"{loss.item():.4f}\", 'coord_N': f\"{coord_loss_norm.item():.4f}\", 'count_CE': f\"{count_loss.item():.4f}\"}) # Use count_CE\n",
        "        except Exception as e: print(f\"\\nERROR training batch: {e}\\n{traceback.format_exc()}\"); continue\n",
        "\n",
        "    # --- Evaluation Phase ---\n",
        "    model.eval()\n",
        "    eval_losses, eval_coord_losses_norm, eval_count_losses = [], [], []\n",
        "    batch_iterator_eval = tqdm(eval_dataloader, desc=f\"Epoch {epoch + 1}/{num_epochs} Evaluation\", leave=False)\n",
        "    with torch.no_grad():\n",
        "        for batch in batch_iterator_eval:\n",
        "            try:\n",
        "                input_ids = batch['input_ids'].to(device)\n",
        "                decoder_input_norm_wp_only = batch['decoder_input_coords_norm'].float().to(device)\n",
        "                target_output_norm = batch['target_coords_output_norm'].float().to(device)\n",
        "                target_cnt_labels = batch['target_count'].long().to(device) # Target is LONG type\n",
        "                output_coord_mask = batch['coord_mask'].float().to(device)\n",
        "                tgt_mask, src_padding_mask, tgt_padding_mask, memory_key_padding_mask = create_mask(input_ids, target_output_norm, pad_token_id, device)\n",
        "                predicted_coords_norm, predicted_count_logits = model(src_input_ids=input_ids, tgt_input_coords_norm=decoder_input_norm_wp_only, src_mask=None, tgt_mask=tgt_mask, src_padding_mask=src_padding_mask, tgt_padding_mask=tgt_padding_mask, memory_key_padding_mask=memory_key_padding_mask)\n",
        "                loss, coord_loss_norm, count_loss = loss_fn(predicted_coords_norm, predicted_count_logits, target_output_norm, target_cnt_labels, output_coord_mask) # Pass logits/labels\n",
        "                if torch.isfinite(loss): eval_losses.append(loss.item()); eval_coord_losses_norm.append(coord_loss_norm.item()); eval_count_losses.append(count_loss.item())\n",
        "                batch_iterator_eval.set_postfix({'loss': f\"{loss.item():.4f}\", 'coord_N': f\"{coord_loss_norm.item():.4f}\", 'count_CE': f\"{count_loss.item():.4f}\"}) # Use count_CE\n",
        "            except Exception as e: print(f\"\\nERROR eval batch: {e}\\n{traceback.format_exc()}\"); continue\n",
        "\n",
        "    avg_eval_loss = np.mean(eval_losses) if eval_losses else float('inf')\n",
        "    avg_eval_coord_loss_norm = np.mean(eval_coord_losses_norm) if eval_coord_losses_norm else float('inf')\n",
        "    avg_eval_count_loss = np.mean(eval_count_losses) if eval_count_losses else float('inf') # Avg CrossEntropy loss\n",
        "    print(f\"\\n--- Epoch {epoch + 1}/{num_epochs} Eval Summary ---\")\n",
        "    print(f\"  Avg Eval Loss: {avg_eval_loss:.4f} (CoordNorm: {avg_eval_coord_loss_norm:.4f}, CountCE: {avg_eval_count_loss:.4f})\") # Use CountCE\n",
        "    training_stats.append({'epoch': epoch + 1, 'eval_loss': avg_eval_loss, 'eval_coord_loss_norm': avg_eval_coord_loss_norm, 'eval_count_loss_ce': avg_eval_count_loss}) # Use count_CE\n",
        "    epoch_iterator.set_postfix({'Avg Eval Loss': f\"{avg_eval_loss:.4f}\", 'Avg CoordNorm Loss': f\"{avg_eval_coord_loss_norm:.4f}\", 'Avg CountCE Loss': f\"{avg_eval_count_loss:.4f}\"}) # Use CountCE\n",
        "\n",
        "    # --- Early Stopping Check ---\n",
        "    if avg_eval_loss < best_eval_loss - min_delta:\n",
        "        best_eval_loss = avg_eval_loss; epochs_no_improve = 0\n",
        "        try: torch.save(model.state_dict(), best_model_save_path); print(f\"  New best model saved (Eval Loss: {best_eval_loss:.4f})\")\n",
        "        except Exception as e: print(f\"  ERROR saving best model: {e}\")\n",
        "    else:\n",
        "        epochs_no_improve += 1; print(f\"  No improvement in eval loss for {epochs_no_improve} epoch(s).\")\n",
        "    if epochs_no_improve >= early_stopping_patience:\n",
        "        print(f\"\\n--- Early stopping triggered after {epoch + 1} epochs ---\"); break\n",
        "\n",
        "print(\"\\n--- Training loop finished ---\")\n",
        "print(f\"Best validation loss achieved: {best_eval_loss:.4f}\")\n",
        "\n",
        "# --- Load the best model state before saving/deploying ---\n",
        "print(f\"\\nLoading best model state from {best_model_save_path} for final steps...\")\n",
        "try:\n",
        "    if os.path.exists(best_model_save_path): state_dict = torch.load(best_model_save_path, map_location=device); model.load_state_dict(state_dict); print(\"Loaded best model weights.\")\n",
        "    else: print(f\"Warning: Best model checkpoint not found. Using state from last epoch.\")\n",
        "except Exception as e: print(f\"ERROR loading best model state: {e}. Using state from last epoch.\")\n",
        "\n",
        "# --- Saving the model Locally ---\n",
        "print(\"\\nSaving best model locally...\")\n",
        "model_save_path = \"./flight_plan_seq2seq_clf_model_final\" # New path name\n",
        "os.makedirs(model_save_path, exist_ok=True)\n",
        "try:\n",
        "    torch.save(model.state_dict(), os.path.join(model_save_path, \"pytorch_model.bin\"))\n",
        "    tokenizer.save_pretrained(model_save_path)\n",
        "    config_to_save = {\"vocab_size\": vocab_size, \"emb_size\": embedding_dimension, \"nhead\": nhead, \"num_encoder_layers\": num_encoder_layers, \"num_decoder_layers\": num_decoder_layers, \"dim_feedforward\": dim_feedforward, \"dropout\": transformer_dropout, \"max_text_len\": max_text_seq_len, \"max_coord_len\": max_coord_seq_len, \"max_waypoints\": max_waypoints,\n",
        "                      \"num_count_classes\": num_count_classes, # Save num classes info\n",
        "                      \"architecture\": model.__class__.__name__}\n",
        "    with open(os.path.join(model_save_path, \"config.json\"), \"w\") as f: json.dump(config_to_save, f, indent=4)\n",
        "    print(f\"Model saved to {model_save_path}\")\n",
        "except Exception as e: print(f\"ERROR saving model locally: {e}\")\n",
        "\n",
        "# --- Deployment to Hugging Face Hub ---\n",
        "print(f\"\\n--- Attempting Deployment of Best Model to Hugging Face Hub: {hf_repo_id} ---\")\n",
        "# WARNING: This will overwrite the target repo ID with the new Seq2Seq model!\n",
        "if HfApi and hf_hub_download:\n",
        "    try:\n",
        "        print(f\"Creating/accessing repository '{hf_repo_id}'...\")\n",
        "        create_repo(hf_repo_id, private=False, exist_ok=True)\n",
        "        api = HfApi()\n",
        "        # --- README Generation (Updated for Classification Count) ---\n",
        "        print(\"Generating README.md content...\")\n",
        "        readme_content = f\"\"\"---\n",
        "license: apache-2.0\n",
        "tags:\n",
        "  - flight-planning\n",
        "  - transformer\n",
        "  - coordinate-prediction\n",
        "  - sequence-to-sequence\n",
        "  - count-classification\n",
        "---\n",
        "# Flight Plan Coordinate Prediction Model ({model.__class__.__name__})\n",
        "Encoder-Decoder Transformer model trained for AI flight planning project. Predicts normalized coordinates directly and waypoint count via classification.\n",
        "## Model Description\n",
        "{model.__class__.__name__} architecture using `torch.nn.Transformer`. Predicts normalized lat/lon coordinates autoregressively and waypoint count (0-{max_waypoints}) via classification head on encoder output.\n",
        "* Embed Dim: {embedding_dimension}, Heads: {nhead}, Enc Layers: {num_encoder_layers}, Dec Layers: {num_decoder_layers}, Max Waypoints: {max_waypoints}\n",
        "## Intended Use\n",
        "Research prototype. **Not for real-world navigation.**\n",
        "## Limitations\n",
        "Accuracy depends on data/tuning. Fixed max waypoints ({max_waypoints}). Not certified. **Architecture differs significantly from previous versions in this repo.**\n",
        "## How to Use\n",
        "Requires loading the custom `{model.__class__.__name__}` class and weights. Generation requires autoregressive decoding and taking argmax of count logits.\n",
        "## Training Data\n",
        "Trained on `{dataset_name}`.\n",
        "## Contact\n",
        "Frank Morales, BEng, MEng, SMIEEE (Boeing ATF) - https://www.linkedin.com/in/frank-morales1964/\"\"\"\n",
        "        try:\n",
        "            with open(\"README.md\", \"w\", encoding=\"utf-8\") as f: f.write(readme_content)\n",
        "            print(\"Uploading README.md...\"); api.upload_file(path_or_fileobj=\"README.md\", path_in_repo=\"README.md\", repo_id=hf_repo_id, repo_type=\"model\", commit_message=\"Update README (Seq2Seq Clf Count)\"); os.remove(\"README.md\"); print(\"README.md uploaded.\")\n",
        "        except Exception as e: print(f\"ERROR creating/uploading README.md: {e}\")\n",
        "\n",
        "        print(f\"Uploading model files from {model_save_path}...\")\n",
        "        api.upload_folder(folder_path=model_save_path, repo_id=hf_repo_id, repo_type=\"model\", commit_message=f\"Upload trained {model.__class__.__name__} (Seq2Seq, Clf Count)\")\n",
        "        print(f\"Model files uploaded: https://huggingface.co/{hf_repo_id}\")\n",
        "    except Exception as e: print(f\"ERROR deploying to HF Hub: {e}\")\n",
        "else: print(\"Skipping deployment: huggingface_hub library/login unavailable.\")"
      ],
      "metadata": {
        "id": "iaNzLIDZdtIy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "1. Avg Eval Loss:\n",
        "\n",
        "* Meaning: This represents the average loss calculated on the evaluation dataset after each epoch of training. It's a crucial metric to assess the model's overall performance and its ability to generalize to unseen data. A lower Avg Eval Loss generally indicates a better-performing model.\n",
        "\n",
        "* Calculation: It's the average of the combined loss values calculated for each batch of data in the evaluation set. This combined loss is a weighted sum of CoordNorm and CountCE, reflecting the importance of both waypoint coordinate accuracy and waypoint count accuracy.\n",
        "\n",
        "2. CoordNorm:\n",
        "\n",
        "* Meaning: This component of the loss measures the error in predicting the normalized waypoint coordinates (latitude and longitude). \"Norm\" likely refers to the normalization applied to the coordinates to scale them to a standard range.\n",
        "\n",
        "* Calculation: CoordNorm is calculated using a loss function, likely Mean Squared Error (MSE), applied to the difference between the predicted normalized coordinates and the actual normalized coordinates. The masking ensures that padding values in the sequences are ignored during loss calculation.\n",
        "\n",
        "3. CountCE:\n",
        "\n",
        "* Meaning: This component measures the error in predicting the correct number of waypoints in the flight plan. \"CE\" most likely stands for Cross-Entropy, a common loss function used for classification tasks.\n",
        "\n",
        "* Calculation: CountCE is calculated using the Cross-Entropy loss function. It compares the model's predicted probability distribution over the possible waypoint counts to the actual waypoint count. A lower CountCE indicates better accuracy in predicting the number of waypoints.\n",
        "\n",
        "4. How they are combined:\n",
        "\n",
        "* The Avg Eval Loss is calculated as a weighted sum of CoordNorm and CountCE, where the count_loss_weight hyperparameter determines the relative importance of the count prediction:\n",
        "\n",
        "Avg Eval Loss = (Average CoordNorm over all batches) + (count_loss_weight * Average CountCE over all batches)\n",
        "Use code with caution\n",
        "In this particular training, a high count_loss_weight (e.g., 100 or 300) is often used, suggesting that accurate prediction of the waypoint count is prioritized.\n",
        "\n",
        "5. In summary:\n",
        "\n",
        "* Avg Eval Loss provides an overall assessment of the model's performance.\n",
        "\n",
        "* CoordNorm measures the accuracy of waypoint coordinate prediction.\n",
        "\n",
        "* CountCE measures the accuracy of waypoint count prediction.\n",
        "\n",
        "These components are combined using a weighted sum to calculate the overall loss, allowing for control over the importance of each aspect.\n",
        "By monitoring these metrics during training, we can track the model's progress and ensure it's learning to predict flight plans effectively.\n"
      ],
      "metadata": {
        "id": "RPQ5_HavtRHd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## evaluation model2"
      ],
      "metadata": {
        "id": "PVPQKDTVcW1Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Seq2SeqCoordsTransformer(nn.Module):\n",
        "    def __init__(self, num_encoder_layers: int, num_decoder_layers: int, emb_size: int, nhead: int, src_vocab_size: int, num_count_classes: int, tgt_coord_dim: int = 2, dim_feedforward: int = 512, dropout: float = 0.1, max_text_len: int = 128, max_coord_len: int = 12):\n",
        "        super().__init__(); self.emb_size = emb_size; self.max_coord_len = max_coord_len\n",
        "        self.src_tok_emb = nn.Embedding(src_vocab_size, emb_size); self.pos_encoder_enc = PositionalEncoding(emb_size, dropout, max_len=max_text_len); self.pos_encoder_dec = PositionalEncoding(emb_size, dropout, max_len=max_coord_len)\n",
        "        self.coord_input_proj = nn.Linear(tgt_coord_dim, emb_size); self.coord_output_proj = nn.Linear(emb_size, tgt_coord_dim)\n",
        "        self.sos_embedding = nn.Parameter(torch.randn(1, 1, emb_size) * 0.02)\n",
        "        self.transformer = nn.Transformer(d_model=emb_size, nhead=nhead, num_encoder_layers=num_encoder_layers, num_decoder_layers=num_decoder_layers, dim_feedforward=dim_feedforward, dropout=dropout, batch_first=True)\n",
        "        self.encoder_pooler = lambda x: x.mean(dim=1)\n",
        "        self.count_head = nn.Linear(emb_size, num_count_classes) # Classification head\n",
        "        self._reset_parameters()\n",
        "    def _reset_parameters(self):\n",
        "        for p in self.parameters():\n",
        "            if p.dim() > 1: nn.init.xavier_uniform_(p)\n",
        "    def forward(self, src_input_ids: torch.Tensor, tgt_input_coords_norm: torch.Tensor, src_mask: torch.Tensor, tgt_mask: torch.Tensor, src_padding_mask: torch.Tensor, tgt_padding_mask: torch.Tensor, memory_key_padding_mask: torch.Tensor):\n",
        "        src_input_ids_clamped = src_input_ids.clamp(0, self.src_tok_emb.num_embeddings - 1); src_emb_lookup = self.src_tok_emb(src_input_ids_clamped); src_emb = self.pos_encoder_enc(src_emb_lookup)\n",
        "        memory = self.transformer.encoder(src_emb, src_key_padding_mask=src_padding_mask); pooled_encoder_output = self.encoder_pooler(memory)\n",
        "        predicted_count_logits = self.count_head(pooled_encoder_output) # Output logits\n",
        "        batch_size = tgt_input_coords_norm.size(0)\n",
        "        coord_vals_emb = self.coord_input_proj(tgt_input_coords_norm); sos_emb_batch = self.sos_embedding.repeat(batch_size, 1, 1)\n",
        "        tgt_emb = torch.cat([sos_emb_batch, coord_vals_emb], dim=1); tgt_emb = self.pos_encoder_dec(tgt_emb)\n",
        "        decoder_output = self.transformer.decoder(tgt_emb, memory, tgt_mask=tgt_mask, memory_key_padding_mask=memory_key_padding_mask, tgt_key_padding_mask=tgt_padding_mask)\n",
        "        projected_coords = self.coord_output_proj(decoder_output); predicted_coords_normalized = torch.sigmoid(projected_coords)\n",
        "        return predicted_coords_normalized, predicted_count_logits # Return logits\n",
        "\n",
        "    def encode(self, src_input_ids: torch.Tensor, src_mask: torch.Tensor): # src_mask is padding mask\n",
        "        src_input_ids_clamped = src_input_ids.clamp(0, self.src_tok_emb.num_embeddings - 1); src_emb_lookup = self.src_tok_emb(src_input_ids_clamped); src_emb = self.pos_encoder_enc(src_emb_lookup)\n",
        "        memory = self.transformer.encoder(src_emb, src_key_padding_mask=src_mask); pooled_memory = self.encoder_pooler(memory)\n",
        "        predicted_count_logits = self.count_head(pooled_memory); return memory, predicted_count_logits # Return logits\n"
      ],
      "metadata": {
        "id": "hvL9vDZpgSZ5"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#model_load_id='/content/gdrive/MyDrive/model/flight_plan_seq2seq_clf_model_final/'\n",
        "#model_save_path='/content/gdrive/MyDrive/model/flight_plan_seq2seq_clf_model_final'\n",
        "#best_model_save_path='/content/gdrive/MyDrive/model/flight_plan_seq2seq_clf_model_final'"
      ],
      "metadata": {
        "id": "FD8HmNEl7jJI"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_src_mask(src, pad_token_id):\n",
        "    \"\"\"\n",
        "    Creates a source mask for the Transformer model.\n",
        "\n",
        "    Args:\n",
        "        src: The source sequence tensor (input_ids).\n",
        "        pad_token_id: The ID of the padding token.\n",
        "\n",
        "    Returns:\n",
        "        A source mask tensor.\n",
        "    \"\"\"\n",
        "    src_seq_len = src.shape[1] # Get the length of the source sequence\n",
        "    src_mask = torch.triu(torch.ones((src_seq_len, src_seq_len), device=device), diagonal=1).type(torch.bool)  # Create an upper triangular mask\n",
        "\n",
        "    src_padding_mask = (src == pad_token_id).to(device)  # Get padding positions\n",
        "    src_mask = src_mask | src_padding_mask.unsqueeze(1).expand(-1, src_seq_len, -1)\n",
        "\n",
        "    return src_mask\n",
        "\n",
        "\n",
        "def create_tgt_padding_mask(tgt, pad_token_id):\n",
        "    \"\"\"\n",
        "    Creates a target padding mask for the Transformer model.\n",
        "\n",
        "    Args:\n",
        "        tgt: The target sequence tensor (decoder input).\n",
        "        pad_token_id: The ID of the padding token.\n",
        "\n",
        "    Returns:\n",
        "        A target padding mask tensor.\n",
        "    \"\"\"\n",
        "    tgt_padding_mask = (tgt == pad_token_id).transpose(0, 1).to(device)  # Find padding positions and transpose\n",
        "    return tgt_padding_mask\n",
        "\n",
        "\n",
        "\n",
        "def create_src_padding_mask(input_ids, pad_token_id):\n",
        "    \"\"\"\n",
        "    Creates a source padding mask for the Transformer model.\n",
        "\n",
        "    Args:\n",
        "        input_ids: The input IDs tensor.\n",
        "        pad_token_id: The ID of the padding token.\n",
        "\n",
        "    Returns:\n",
        "        A padding mask tensor where padding positions are 1 and other positions are 0.\n",
        "    \"\"\"\n",
        "    src_padding_mask = input_ids == pad_token_id  # Find padding positions\n",
        "    return src_padding_mask.to(device) # Move the mask to the device (if needed)\n",
        "\n",
        "\n",
        "def create_tgt_mask(tgt_seq_len, device):\n",
        "    \"\"\"\n",
        "    Creates a target mask for the Transformer model.\n",
        "\n",
        "    Args:\n",
        "        tgt_seq_len: The length of the target sequence.\n",
        "        device: The device to place the mask on.\n",
        "\n",
        "    Returns:\n",
        "        A target mask tensor.\n",
        "    \"\"\"\n",
        "    tgt_mask = torch.triu(torch.ones((tgt_seq_len, tgt_seq_len), device=device), diagonal=1).type(torch.bool) # Create upper triangular mask\n",
        "    return tgt_mask\n",
        "\n",
        "def create_tgt_input_coords(max_len, device, sos_token_id, pad_token_id):\n",
        "    \"\"\"\n",
        "    Creates the target input coordinates tensor.\n",
        "\n",
        "    Args:\n",
        "        max_len: The maximum length of the target sequence.\n",
        "        device: The device to place the tensor on.\n",
        "        sos_token_id: The ID of the SOS token.\n",
        "        pad_token_id: The ID of the PAD token.\n",
        "\n",
        "    Returns:\n",
        "        A tensor representing the target input coordinates.\n",
        "    \"\"\"\n",
        "    # 1. Initialize with SOS token\n",
        "    tgt_input_coords = torch.tensor([[sos_token_id]], device=device, dtype=torch.long)\n",
        "\n",
        "    # 2. Pad if necessary (adapt to your model's padding logic)\n",
        "    if max_len > 1:  # If the target sequence is longer than just SOS\n",
        "        padding = torch.tensor([[pad_token_id] * (max_len - 1)], device=device, dtype=torch.long)\n",
        "        tgt_input_coords = torch.cat([tgt_input_coords, padding], dim=1)\n",
        "\n",
        "    return tgt_input_coords\n",
        "\n",
        "\n",
        "# In generate_flight_plan_seq2seq\n",
        "def generate_square_subsequent_mask(sz, device):\n",
        "    mask = (torch.triu(torch.ones((sz, sz), device=device)) == 1).transpose(0, 1)\n",
        "    mask = mask.float().masked_fill(mask == 0, float('-inf')).masked_fill(mask == 1, float(0.0))\n",
        "    return mask\n",
        "\n",
        "# In generate_flight_plan_seq2seq\n",
        "def generate_square_subsequent_mask(sz, device):\n",
        "    mask = (torch.triu(torch.ones((sz, sz), device=device)) == 1).transpose(0, 1)\n",
        "    mask = mask.float().masked_fill(mask == 0, float('-inf')).masked_fill(mask == 1, float(0.0))\n",
        "    return mask\n"
      ],
      "metadata": {
        "id": "JxBLd_cG93EH"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "source": [
        "def create_mask(src, tgt, pad_token_id, device):\n",
        "    src_seq_len = src.shape[1]\n",
        "    tgt_seq_len = tgt.shape[1]\n",
        "\n",
        "    tgt_mask = generate_square_subsequent_mask(tgt_seq_len, device)\n",
        "\n",
        "    # Reshape src_padding_mask to 2D\n",
        "    src_padding_mask = (src == pad_token_id)  # Create boolean mask for padding tokens\n",
        "\n",
        "    # Use src_padding_mask for memory_key_padding_mask (Decoder's attention to Encoder output)\n",
        "    memory_key_padding_mask = src_padding_mask\n",
        "\n",
        "    return tgt_mask, src_padding_mask, tgt_padding_mask, memory_key_padding_mask"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "kVk5iyxy5_rt"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "    from huggingface_hub import HfApi, HfFolder, login, create_repo, upload_file, notebook_login, hf_hub_download\n",
        "    # ... other code related to Hugging Face Hub ...\n",
        "except ImportError:\n",
        "    print(\"Warning: huggingface_hub not found. Deployment/loading features unavailable.\")\n",
        "    HfApi = None  # If the import fails, set HfApi to None\n",
        "    hf_hub_download = None  # Set hf_hub_download to None as well"
      ],
      "metadata": {
        "id": "St5q54B3euwa"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Generation Function (Updated for Classification Count Head) ---\n",
        "import torch\n",
        "\n",
        "def generate_square_subsequent_mask(sz, device):\n",
        "    mask = (torch.triu(torch.ones((sz, sz), device=device)) == 1).transpose(0, 1)\n",
        "    mask = mask.float().masked_fill(mask == 0, float('-inf')).masked_fill(mask == 1, float(0.0))\n",
        "    return mask"
      ],
      "metadata": {
        "id": "KE4j54YA3sy1"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "source": [
        "def generate_flight_plan_seq2seq(trained_model, tokenizer_instance, query_text, device_instance, max_len=10):\n",
        "    \"\"\"Generates a flight plan (waypoints) using a Seq2Seq Transformer model.\n",
        "\n",
        "    Args:\n",
        "        trained_model: The trained Seq2Seq Transformer model.\n",
        "        tokenizer_instance: The tokenizer used for the model.\n",
        "        query_text: The input query text describing the flight plan.\n",
        "        device_instance: The device (CPU or GPU) to run the model on.\n",
        "        max_len: The maximum number of waypoints to generate.\n",
        "\n",
        "    Returns:\n",
        "        A tuple containing:\n",
        "            - final_waypoints: A list of generated waypoints [[lat1, lon1], [lat2, lon2], ...].\n",
        "            - num_waypoints: The predicted number of waypoints.\n",
        "            - predicted_count_raw: The raw predicted count (before rounding).\n",
        "    \"\"\"\n",
        "    trained_model.eval()\n",
        "    trained_model.to(device_instance)\n",
        "\n",
        "    try:\n",
        "        # 1. Tokenize and prepare input\n",
        "        inputs = tokenizer_instance(query_text, return_tensors='pt', padding=True, truncation=True)\n",
        "        input_ids = inputs['input_ids'].to(device_instance)\n",
        "\n",
        "        # 2. Create masks (outside the loop, for initial values)\n",
        "        pad_token_id = tokenizer_instance.pad_token_id\n",
        "        dummy_tgt_input_coords_norm = torch.zeros(input_ids.shape[0], max_len, dtype=torch.float32, device=device_instance)\n",
        "        tgt_mask, _, tgt_padding_mask, _ = create_mask(input_ids, dummy_tgt_input_coords_norm, pad_token_id, device_instance)\n",
        "\n",
        "        # 3. Get encoder outputs\n",
        "        # No explicit encoder output retrieval is needed for this architecture.\n",
        "\n",
        "        # 4. Decoder loop (with mask recreation)\n",
        "        decoder_input = trained_model.sos_embedding.repeat(input_ids.shape[0], 1, 1).to(device_instance)\n",
        "        generated_coords = []\n",
        "\n",
        "        for _ in range(max_len):\n",
        "            # Recreate src_padding_mask and memory_key_padding_mask within the loop\n",
        "            # Pass the original input_ids to create_mask\n",
        "            _, src_padding_mask, _, memory_key_padding_mask = create_mask(input_ids, decoder_input, pad_token_id, device_instance)\n",
        "\n",
        "            with torch.no_grad():\n",
        "                forward_outputs = trained_model(src_input_ids=input_ids,\n",
        "                                                tgt_input_coords_norm=decoder_input,\n",
        "                                                src_mask=None, tgt_mask=tgt_mask,\n",
        "                                                src_padding_mask=src_padding_mask,\n",
        "                                                tgt_padding_mask=tgt_padding_mask,\n",
        "                                                memory_key_padding_mask=memory_key_padding_mask)\n",
        "\n",
        "                predicted_coords_norm = forward_outputs[0]  # Get predicted coordinates\n",
        "                predicted_count_logits = forward_outputs[1] # Get predicted count logits\n",
        "\n",
        "            # Process predicted coordinates\n",
        "            last_coord_norm = predicted_coords_norm[:, -1, :]  # Take the last generated coordinate\n",
        "            generated_coords.append(last_coord_norm)\n",
        "            decoder_input = torch.cat([decoder_input, last_coord_norm.unsqueeze(1)], dim=1)  # Append to decoder input\n",
        "\n",
        "        # Process generated coordinates and count\n",
        "        generated_coords_tensor = torch.stack(generated_coords, dim=1)  # Stack to get (batch_size, seq_len, 2)\n",
        "        final_waypoints = denormalize_coords(generated_coords_tensor[0].cpu().numpy().tolist())  # Denormalize\n",
        "\n",
        "        predicted_count_probs = F.softmax(predicted_count_logits, dim=-1)  # Apply softmax to get probabilities\n",
        "        predicted_count_raw = predicted_count_probs.argmax(dim=-1).item()  # Get the index with the highest probability\n",
        "        num_waypoints = max(0, min(int(predicted_count_raw), max_len)) # Clamp to max_len, minimum to 0.\n",
        "\n",
        "        return final_waypoints, num_waypoints, predicted_count_raw\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"ERROR generating for query '{query_text}': {e}\\n{traceback.format_exc()}\")\n",
        "        return [], 0, 0.0"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "COTu7Dt53f3b"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from warnings import simplefilter\n",
        "simplefilter(action='ignore')\n",
        "\n",
        "import os\n",
        "from transformers import AutoTokenizer\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "import json\n",
        "import traceback\n",
        "from tqdm import tqdm\n",
        "\n",
        "# --- Model Loading and Test Set Evaluation (Refactored for Seq2Seq Clf Count) --- # 410\n",
        "print(\"\\n--- Loading Model and Evaluating on Test Set ---\")\n",
        "\n",
        "\n",
        "# --- Load the model ---\n",
        "load_from_hf = False # Defaulting to False\n",
        "model_load_id = hf_repo_id if load_from_hf else model_save_path\n",
        "loaded_model = None; loaded_tokenizer = None\n",
        "print(f\"Attempting to load Seq2Seq model from: {model_load_id} (Using {'HF Hub' if load_from_hf else 'Local Path'})\")\n",
        "\n",
        "if hf_hub_download:\n",
        "    try:\n",
        "        if load_from_hf:\n",
        "             if \"YOUR_USERNAME\" in model_load_id or model_load_id == \"frankmorales2020/FlightPlan_Transformer_LLM\": raise ValueError(f\"Refusing to load potentially incompatible model from '{model_load_id}'. Update hf_repo_id or set load_from_hf=False.\")\n",
        "             tokenizer_load_path = model_load_id; config_load_path = hf_hub_download(repo_id=model_load_id, filename=\"config.json\"); weights_load_path = hf_hub_download(repo_id=model_load_id, filename=\"pytorch_model.bin\")\n",
        "        else: # Loading from local\n",
        "             tokenizer_load_path = model_save_path; config_load_path = os.path.join(model_save_path, \"config.json\"); weights_load_path = best_model_save_path\n",
        "             if not os.path.exists(weights_load_path): print(f\"Warning: Best model file {weights_load_path} not found, trying final...\"); weights_load_path = os.path.join(model_save_path, \"pytorch_model.bin\")\n",
        "             if not all(os.path.exists(p) for p in [config_load_path, weights_load_path, os.path.join(tokenizer_load_path, 'tokenizer_config.json')]): raise FileNotFoundError(f\"Required model files not found locally.\")\n",
        "\n",
        "        loaded_tokenizer = AutoTokenizer.from_pretrained(tokenizer_load_path)\n",
        "        with open(config_load_path, 'r') as f: config_dict = json.load(f)\n",
        "        expected_arch = \"Seq2SeqCoordsTransformer\"; loaded_arch = config_dict.get(\"architecture\")\n",
        "        if loaded_arch != expected_arch: print(f\"\\n>>> WARNING: Config architecture ('{loaded_arch}') != Expected ('{expected_arch}'). Ensure correct model type is loaded. <<<\\n\")\n",
        "\n",
        "        # Use loaded config values, providing defaults\n",
        "        loaded_model = Seq2SeqCoordsTransformer(\n",
        "            num_encoder_layers=config_dict.get('num_encoder_layers', num_encoder_layers),\n",
        "            num_decoder_layers=config_dict.get('num_decoder_layers', num_decoder_layers),\n",
        "            emb_size=config_dict.get('emb_size', embedding_dimension),\n",
        "            nhead=config_dict.get('nhead', nhead),\n",
        "            src_vocab_size=len(loaded_tokenizer),\n",
        "            # Get num_count_classes from config\n",
        "            num_count_classes=config_dict.get('num_count_classes', num_count_classes),\n",
        "            tgt_coord_dim=2,\n",
        "            dim_feedforward=config_dict.get('dim_feedforward', dim_feedforward),\n",
        "            dropout=config_dict.get('dropout', transformer_dropout),\n",
        "            max_text_len=config_dict.get('max_text_len', max_text_seq_len),\n",
        "            max_coord_len=config_dict.get('max_coord_len', max_coord_seq_len)\n",
        "        )\n",
        "        loaded_model.to(device)\n",
        "\n",
        "        state_dict = torch.load(weights_load_path, map_location=device)\n",
        "        # Handle embedding resize AFTER model instantiation and moving to device\n",
        "        current_tokenizer_vocab_size = len(loaded_tokenizer)\n",
        "        if state_dict.get('src_tok_emb.weight') is not None and state_dict['src_tok_emb.weight'].size(0) != current_tokenizer_vocab_size:\n",
        "            print(f\"Resizing embedding weights from {state_dict['src_tok_emb.weight'].size(0)} to {current_tokenizer_vocab_size}\")\n",
        "            loaded_model.src_tok_emb = nn.Embedding(current_tokenizer_vocab_size, embedding_dimension).to(device)\n",
        "            new_emb = loaded_model.src_tok_emb.weight.data\n",
        "            common_size = min(state_dict['src_tok_emb.weight'].size(0), new_emb.size(0))\n",
        "            new_emb[:common_size, :] = state_dict['src_tok_emb.weight'][:common_size, :]\n",
        "            state_dict['src_tok_emb.weight'] = new_emb\n",
        "        elif 'src_tok_emb.weight' not in state_dict:\n",
        "             print(\"Warning: src_tok_emb.weight not found in state_dict. Initializing embedding layer.\")\n",
        "             loaded_model.src_tok_emb = nn.Embedding(current_tokenizer_vocab_size, embedding_dimension).to(device)\n",
        "        else: # Ensure model's embedding layer matches state dict if no resize needed\n",
        "             loaded_model.src_tok_emb = nn.Embedding(current_tokenizer_vocab_size, embedding_dimension).to(device)\n",
        "\n",
        "        # Load state dict - use strict=False due to potential architecture changes or saved optimizer states\n",
        "        load_result = loaded_model.load_state_dict(state_dict, strict=False)\n",
        "        print(f\"Model load result (strict=False): Missing keys: {load_result.missing_keys}, Unexpected keys: {load_result.unexpected_keys}\")\n",
        "        loaded_model.eval(); print(\"Model loading successful.\")\n",
        "\n",
        "    except Exception as e: print(f\"\\n>>> ERROR loading model from {model_load_id}: {e}\\n{traceback.format_exc()}\"); loaded_model = None\n",
        "else: print(\"Skipping model loading: huggingface_hub library not available.\")\n",
        "\n",
        "\n",
        "# --- Run Inference Loop and Calculate Loss on Test Set (Classification Count) ---\n",
        "if loaded_model and loaded_tokenizer:\n",
        "    print(\"\\nRunning inference and loss calculation on the test set using Seq2Seq model...\")\n",
        "    test_results = []\n",
        "    test_iterator_batches = tqdm(test_dataloader_for_loss, desc=\"Processing Test Set Batches for Loss\")\n",
        "    total_test_samples_loss = 0; test_coord_losses_norm = []; test_count_losses_ce = [] # Store NORMALIZED coord loss and CE count loss\n",
        "\n",
        "    loaded_model.eval()\n",
        "    with torch.no_grad():\n",
        "        for batch in test_iterator_batches:\n",
        "            try:\n",
        "                input_ids = batch['input_ids'].to(device); attn_mask = batch['attention_mask'].to(device)\n",
        "                decoder_input_norm_wp_only = batch['decoder_input_coords_norm'].float().to(device); target_output_norm = batch['target_coords_output_norm'].float().to(device)\n",
        "                target_cnt_labels = batch['target_count'].long().to(device); output_coord_mask = batch['coord_mask'].float().to(device) # Target is LONG type labels\n",
        "                tgt_mask, src_padding_mask, tgt_padding_mask, memory_key_padding_mask = create_mask(input_ids, target_output_norm, pad_token_id, device)\n",
        "                predicted_coords_norm, predicted_count_logits = model(src_input_ids=input_ids, tgt_input_coords_norm=decoder_input_norm_wp_only, src_mask=None, tgt_mask=tgt_mask, src_padding_mask=src_padding_mask, tgt_padding_mask=tgt_padding_mask, memory_key_padding_mask=memory_key_padding_mask)\n",
        "                # Calculate loss using logits and labels\n",
        "                loss, coord_loss_norm, count_loss_ce = loss_fn(predicted_coords_norm, predicted_count_logits, target_output_norm, target_cnt_labels, output_coord_mask)\n",
        "                if torch.isfinite(coord_loss_norm): test_coord_losses_norm.append(coord_loss_norm.item() * input_ids.size(0))\n",
        "                if torch.isfinite(count_loss_ce): test_count_losses_ce.append(count_loss_ce.item() * input_ids.size(0))\n",
        "                total_test_samples_loss += input_ids.size(0)\n",
        "                test_iterator_batches.set_postfix({'batch_coord_norm_loss': f\"{coord_loss_norm.item():.4f}\", 'batch_count_CE_loss': f\"{count_loss_ce.item():.4f}\"}) # Show CE loss\n",
        "            except Exception as e: print(f\"\\nERROR processing test batch for loss: {e}\"); continue\n",
        "\n",
        "    # --- Loop for Generation Metrics ---\n",
        "    print(\"\\nCalculating generation metrics on test samples...\")\n",
        "    original_test_set_for_gen = original_test_set_for_comparison\n",
        "    test_iterator_samples = tqdm(range(len(original_test_set_for_gen)), desc=\"Generating Test Samples\")\n",
        "    total_count_diff_gen = 0; total_test_samples_gen = len(original_test_set_for_gen)\n",
        "    count_correct = 0 # Track number of perfectly predicted counts\n",
        "\n",
        "    for i in test_iterator_samples:\n",
        "         try:\n",
        "            sample = original_test_set_for_gen[i]; query = sample.get('input', ''); actual_waypoints_raw = sample.get('waypoints', [])\n",
        "            if isinstance(actual_waypoints_raw, np.ndarray): actual_waypoints = actual_waypoints_raw.tolist()\n",
        "            elif isinstance(actual_waypoints_raw, list): actual_waypoints = actual_waypoints_raw\n",
        "            else: actual_waypoints = []\n",
        "            # Get actual count label\n",
        "            try: actual_count_label = int(round(float(sample.get('label', 0)))); actual_count_label = max(0, min(max_waypoints, actual_count_label))\n",
        "            except: actual_count_label = 0\n",
        "            if not query: total_test_samples_gen-=1; continue\n",
        "\n",
        "            # Use the generation function which now returns predicted count index (0 to max_waypoints)\n",
        "            pred_waypoints, pred_count_index, pred_count_logits = generate_flight_plan_seq2seq(loaded_model, loaded_tokenizer, query, device)\n",
        "            # Use the generation function which now returns predicted count index (0 to max_waypoints)\n",
        "            #pred_waypoints, pred_count_index, pred_count_logits = generate_flight_plan_seq2seq(loaded_model, loaded_tokenizer, query, device)\n",
        "            count_diff = abs(pred_count_index - actual_count_label); total_count_diff_gen += count_diff\n",
        "            if pred_count_index == actual_count_label: count_correct += 1 # Check accuracy\n",
        "            test_results.append({'query': query, 'predicted_waypoints': pred_waypoints, 'predicted_count': pred_count_index, 'actual_count': actual_count_label})\n",
        "            test_iterator_samples.set_postfix({'avg_count_diff': f\"{total_count_diff_gen / (i + 1):.2f}\"})\n",
        "         except Exception as e: print(f\"\\nERROR generating for test sample {i}: {e}\"); total_test_samples_gen-=1; continue\n",
        "\n",
        "    # Calculate overall metrics\n",
        "    avg_test_coord_loss_norm = np.sum(test_coord_losses_norm) / total_test_samples_loss if total_test_samples_loss > 0 else 0\n",
        "    avg_test_count_loss_ce = np.sum(test_count_losses_ce) / total_test_samples_loss if total_test_samples_loss > 0 else 0 # Avg CE Loss\n",
        "    avg_test_count_difference = total_count_diff_gen / total_test_samples_gen if total_test_samples_gen > 0 else 0\n",
        "    test_count_accuracy = count_correct / total_test_samples_gen if total_test_samples_gen > 0 else 0\n",
        "\n",
        "    print(f\"\\n--- Final Test Set Evaluation Summary ---\")\n",
        "    print(f\"  Average Absolute Count Difference: {avg_test_count_difference:.4f}\")\n",
        "    print(f\"  Count Prediction Accuracy:         {test_count_accuracy:.4f}\") # Added count accuracy\n",
        "    print(f\"  Average Coordinate Loss (MSE, Normalized): {avg_test_coord_loss_norm:.4f}\")\n",
        "    print(f\"  Average Count Loss (CrossEntropy):       {avg_test_count_loss_ce:.4f}\") # Added CE loss avg\n",
        "\n",
        "else: print(\"\\nSkipping test set evaluation: model/tokenizer loading failed or unavailable.\")\n",
        "\n",
        "print(\"\\n--- Script Finished ---\")\n"
      ],
      "metadata": {
        "id": "4dQDGtuY2tU5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ls -ltha /content/gdrive/MyDrive/model/flight_plan_seq2seq_clf_model_final"
      ],
      "metadata": {
        "id": "tUergq4HhZoL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## original"
      ],
      "metadata": {
        "id": "ctH2mbLikx4O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# --- Model Loading and Test Set Evaluation (Refactored for Seq2Seq Clf Count) ---\n",
        "print(\"\\n--- Loading Model and Evaluating on Test Set ---\")\n",
        "\n",
        "# --- Generation Function (Updated for Classification Count Head) ---\n",
        "def generate_flight_plan_seq2seq(trained_model, tokenizer_instance, query_text, device_instance, max_len=max_coord_seq_len):\n",
        "    trained_model.eval(); trained_model.to(device_instance)\n",
        "    try:\n",
        "        inputs = tokenizer_instance(query_text, return_tensors='pt', padding='longest', truncation=True, max_length=max_text_seq_len)\n",
        "        src_input_ids = inputs['input_ids'].to(device_instance); src_padding_mask = (src_input_ids == pad_token_id)\n",
        "        with torch.no_grad():\n",
        "            # >>> FIX: Encode now returns logits <<<\n",
        "            memory, predicted_count_logits = trained_model.encode(src_input_ids, src_padding_mask)\n",
        "            # >>> FIX: Get predicted count index from logits <<<\n",
        "            pred_count_index = torch.argmax(predicted_count_logits, dim=1).item() # This is the predicted count (0 to max_waypoints)\n",
        "\n",
        "        # Start decoding with SOS embedding\n",
        "        decoder_input_embeddings = trained_model.sos_embedding.repeat(1, 1, 1) # (N=1, 1, E)\n",
        "        generated_denorm_coords_list = []\n",
        "\n",
        "        for step in range(max_waypoints): # Generate up to max_waypoints coordinates\n",
        "            current_tgt_len = decoder_input_embeddings.size(1)\n",
        "            tgt_mask = generate_square_subsequent_mask(current_tgt_len, device_instance) # (T, T)\n",
        "            memory_key_padding_mask = src_padding_mask # (N, S)\n",
        "            tgt_padding_mask = torch.zeros(1, current_tgt_len, dtype=torch.bool, device=device_instance) # (N, T)\n",
        "\n",
        "            tgt_emb_with_pe = trained_model.pos_encoder_dec(decoder_input_embeddings) # (N, T, E)\n",
        "            decoder_output = trained_model.transformer.decoder(tgt_emb_with_pe, memory, tgt_mask=tgt_mask, memory_key_padding_mask=memory_key_padding_mask, tgt_key_padding_mask=tgt_padding_mask)\n",
        "            predicted_norm_coord_next = torch.sigmoid(trained_model.coord_output_proj(decoder_output[:, -1:, :])) # (1, 1, 2) Normalized\n",
        "\n",
        "            # Denormalize prediction to store\n",
        "            predicted_denorm_coord_next = denormalize_coords(predicted_norm_coord_next.squeeze(0).cpu().numpy().tolist())\n",
        "            new_denorm_coord_value = predicted_denorm_coord_next[0]\n",
        "            if isinstance(new_denorm_coord_value, list) and len(new_denorm_coord_value) == 2: generated_denorm_coords_list.append(new_denorm_coord_value)\n",
        "            else: print(f\"Warning: Invalid denorm coord predicted: {new_denorm_coord_value}\"); break\n",
        "\n",
        "            # Prepare next input embedding\n",
        "            next_input_emb = trained_model.coord_input_proj(predicted_norm_coord_next) # Project normalized prediction\n",
        "            decoder_input_embeddings = torch.cat([decoder_input_embeddings, next_input_emb], dim=1)\n",
        "\n",
        "            # Stop if we've generated the predicted number of points\n",
        "            if len(generated_denorm_coords_list) >= pred_count_index: break\n",
        "\n",
        "        final_waypoints = generated_denorm_coords_list\n",
        "        # Return the predicted count index (which is the count) and raw logits if needed\n",
        "        return final_waypoints, pred_count_index, predicted_count_logits.squeeze().cpu().numpy() # Return index and logits\n",
        "\n",
        "    except Exception as e: print(f\"ERROR generating for query '{query_text}': {e}\\n{traceback.format_exc()}\"); return [], 0, np.array([])\n",
        "\n",
        "\n",
        "# --- Load the model ---\n",
        "load_from_hf = False # Defaulting to False\n",
        "model_load_id = hf_repo_id if load_from_hf else model_save_path\n",
        "loaded_model = None; loaded_tokenizer = None\n",
        "print(f\"Attempting to load Seq2Seq model from: {model_load_id} (Using {'HF Hub' if load_from_hf else 'Local Path'})\")\n",
        "\n",
        "if hf_hub_download:\n",
        "    try:\n",
        "        if load_from_hf:\n",
        "             if \"YOUR_USERNAME\" in model_load_id or model_load_id == \"frankmorales2020/FlightPlan_Transformer_LLM\": raise ValueError(f\"Refusing to load potentially incompatible model from '{model_load_id}'. Update hf_repo_id or set load_from_hf=False.\")\n",
        "             tokenizer_load_path = model_load_id; config_load_path = hf_hub_download(repo_id=model_load_id, filename=\"config.json\"); weights_load_path = hf_hub_download(repo_id=model_load_id, filename=\"pytorch_model.bin\")\n",
        "        else: # Loading from local\n",
        "             tokenizer_load_path = model_save_path; config_load_path = os.path.join(model_save_path, \"config.json\"); weights_load_path = best_model_save_path\n",
        "             if not os.path.exists(weights_load_path): print(f\"Warning: Best model file {weights_load_path} not found, trying final...\"); weights_load_path = os.path.join(model_save_path, \"pytorch_model.bin\")\n",
        "             if not all(os.path.exists(p) for p in [config_load_path, weights_load_path, os.path.join(tokenizer_load_path, 'tokenizer_config.json')]): raise FileNotFoundError(f\"Required model files not found locally.\")\n",
        "\n",
        "        loaded_tokenizer = AutoTokenizer.from_pretrained(tokenizer_load_path)\n",
        "        with open(config_load_path, 'r') as f: config_dict = json.load(f)\n",
        "        expected_arch = \"Seq2SeqCoordsTransformer\"; loaded_arch = config_dict.get(\"architecture\")\n",
        "        if loaded_arch != expected_arch: print(f\"\\n>>> WARNING: Config architecture ('{loaded_arch}') != Expected ('{expected_arch}'). Ensure correct model type is loaded. <<<\\n\")\n",
        "\n",
        "        # Use loaded config values, providing defaults\n",
        "        loaded_model = Seq2SeqCoordsTransformer(\n",
        "            num_encoder_layers=config_dict.get('num_encoder_layers', num_encoder_layers),\n",
        "            num_decoder_layers=config_dict.get('num_decoder_layers', num_decoder_layers),\n",
        "            emb_size=config_dict.get('emb_size', embedding_dimension),\n",
        "            nhead=config_dict.get('nhead', nhead),\n",
        "            src_vocab_size=len(loaded_tokenizer),\n",
        "            # Get num_count_classes from config\n",
        "            num_count_classes=config_dict.get('num_count_classes', num_count_classes),\n",
        "            tgt_coord_dim=2,\n",
        "            dim_feedforward=config_dict.get('dim_feedforward', dim_feedforward),\n",
        "            dropout=config_dict.get('dropout', transformer_dropout),\n",
        "            max_text_len=config_dict.get('max_text_len', max_text_seq_len),\n",
        "            max_coord_len=config_dict.get('max_coord_len', max_coord_seq_len)\n",
        "        )\n",
        "        loaded_model.to(device)\n",
        "\n",
        "        state_dict = torch.load(weights_load_path, map_location=device)\n",
        "        # Handle embedding resize AFTER model instantiation and moving to device\n",
        "        current_tokenizer_vocab_size = len(loaded_tokenizer)\n",
        "        if state_dict.get('src_tok_emb.weight') is not None and state_dict['src_tok_emb.weight'].size(0) != current_tokenizer_vocab_size:\n",
        "            print(f\"Resizing embedding weights from {state_dict['src_tok_emb.weight'].size(0)} to {current_tokenizer_vocab_size}\")\n",
        "            loaded_model.src_tok_emb = nn.Embedding(current_tokenizer_vocab_size, embedding_dimension).to(device)\n",
        "            new_emb = loaded_model.src_tok_emb.weight.data\n",
        "            common_size = min(state_dict['src_tok_emb.weight'].size(0), new_emb.size(0))\n",
        "            new_emb[:common_size, :] = state_dict['src_tok_emb.weight'][:common_size, :]\n",
        "            state_dict['src_tok_emb.weight'] = new_emb\n",
        "        elif 'src_tok_emb.weight' not in state_dict:\n",
        "             print(\"Warning: src_tok_emb.weight not found in state_dict. Initializing embedding layer.\")\n",
        "             loaded_model.src_tok_emb = nn.Embedding(current_tokenizer_vocab_size, embedding_dimension).to(device)\n",
        "        else: # Ensure model's embedding layer matches state dict if no resize needed\n",
        "             loaded_model.src_tok_emb = nn.Embedding(current_tokenizer_vocab_size, embedding_dimension).to(device)\n",
        "\n",
        "        # Load state dict - use strict=False due to potential architecture changes or saved optimizer states\n",
        "        load_result = loaded_model.load_state_dict(state_dict, strict=False)\n",
        "        print(f\"Model load result (strict=False): Missing keys: {load_result.missing_keys}, Unexpected keys: {load_result.unexpected_keys}\")\n",
        "        loaded_model.eval(); print(\"Model loading successful.\")\n",
        "\n",
        "    except Exception as e: print(f\"\\n>>> ERROR loading model from {model_load_id}: {e}\\n{traceback.format_exc()}\"); loaded_model = None\n",
        "else: print(\"Skipping model loading: huggingface_hub library not available.\")\n",
        "\n",
        "\n",
        "# --- Run Inference Loop and Calculate Loss on Test Set (Classification Count) ---\n",
        "if loaded_model and loaded_tokenizer:\n",
        "    print(\"\\nRunning inference and loss calculation on the test set using Seq2Seq model...\")\n",
        "    test_results = []\n",
        "    test_iterator_batches = tqdm(test_dataloader_for_loss, desc=\"Processing Test Set Batches for Loss\")\n",
        "    total_test_samples_loss = 0; test_coord_losses_norm = []; test_count_losses_ce = [] # Store NORMALIZED coord loss and CE count loss\n",
        "\n",
        "    loaded_model.eval()\n",
        "    with torch.no_grad():\n",
        "        for batch in test_iterator_batches:\n",
        "            try:\n",
        "                input_ids = batch['input_ids'].to(device); attn_mask = batch['attention_mask'].to(device)\n",
        "                decoder_input_norm_wp_only = batch['decoder_input_coords_norm'].float().to(device); target_output_norm = batch['target_coords_output_norm'].float().to(device)\n",
        "                target_cnt_labels = batch['target_count'].long().to(device); output_coord_mask = batch['coord_mask'].float().to(device) # Target is LONG type labels\n",
        "                tgt_mask, src_padding_mask, tgt_padding_mask, memory_key_padding_mask = create_mask(input_ids, target_output_norm, pad_token_id, device)\n",
        "                predicted_coords_norm, predicted_count_logits = model(src_input_ids=input_ids, tgt_input_coords_norm=decoder_input_norm_wp_only, src_mask=None, tgt_mask=tgt_mask, src_padding_mask=src_padding_mask, tgt_padding_mask=tgt_padding_mask, memory_key_padding_mask=memory_key_padding_mask)\n",
        "                # Calculate loss using logits and labels\n",
        "                loss, coord_loss_norm, count_loss_ce = loss_fn(predicted_coords_norm, predicted_count_logits, target_output_norm, target_cnt_labels, output_coord_mask)\n",
        "                if torch.isfinite(coord_loss_norm): test_coord_losses_norm.append(coord_loss_norm.item() * input_ids.size(0))\n",
        "                if torch.isfinite(count_loss_ce): test_count_losses_ce.append(count_loss_ce.item() * input_ids.size(0))\n",
        "                total_test_samples_loss += input_ids.size(0)\n",
        "                test_iterator_batches.set_postfix({'batch_coord_norm_loss': f\"{coord_loss_norm.item():.4f}\", 'batch_count_CE_loss': f\"{count_loss_ce.item():.4f}\"}) # Show CE loss\n",
        "            except Exception as e: print(f\"\\nERROR processing test batch for loss: {e}\"); continue\n",
        "\n",
        "    # --- Loop for Generation Metrics ---\n",
        "    print(\"\\nCalculating generation metrics on test samples...\")\n",
        "    original_test_set_for_gen = original_test_set_for_comparison\n",
        "    test_iterator_samples = tqdm(range(len(original_test_set_for_gen)), desc=\"Generating Test Samples\")\n",
        "    total_count_diff_gen = 0; total_test_samples_gen = len(original_test_set_for_gen)\n",
        "    count_correct = 0 # Track number of perfectly predicted counts\n",
        "\n",
        "    for i in test_iterator_samples:\n",
        "         try:\n",
        "            sample = original_test_set_for_gen[i]; query = sample.get('input', ''); actual_waypoints_raw = sample.get('waypoints', [])\n",
        "            if isinstance(actual_waypoints_raw, np.ndarray): actual_waypoints = actual_waypoints_raw.tolist()\n",
        "            elif isinstance(actual_waypoints_raw, list): actual_waypoints = actual_waypoints_raw\n",
        "            else: actual_waypoints = []\n",
        "            # Get actual count label\n",
        "            try: actual_count_label = int(round(float(sample.get('label', 0)))); actual_count_label = max(0, min(max_waypoints, actual_count_label))\n",
        "            except: actual_count_label = 0\n",
        "            if not query: total_test_samples_gen-=1; continue\n",
        "\n",
        "            # Use the generation function which now returns predicted count index (0 to max_waypoints)\n",
        "            pred_waypoints, pred_count_index, pred_count_logits = generate_flight_plan_seq2seq(loaded_model, loaded_tokenizer, query, device)\n",
        "            count_diff = abs(pred_count_index - actual_count_label); total_count_diff_gen += count_diff\n",
        "            if pred_count_index == actual_count_label: count_correct += 1 # Check accuracy\n",
        "            test_results.append({'query': query, 'predicted_waypoints': pred_waypoints, 'predicted_count': pred_count_index, 'actual_count': actual_count_label})\n",
        "            test_iterator_samples.set_postfix({'avg_count_diff': f\"{total_count_diff_gen / (i + 1):.2f}\"})\n",
        "         except Exception as e: print(f\"\\nERROR generating for test sample {i}: {e}\"); total_test_samples_gen-=1; continue\n",
        "\n",
        "    # Calculate overall metrics\n",
        "    avg_test_coord_loss_norm = np.sum(test_coord_losses_norm) / total_test_samples_loss if total_test_samples_loss > 0 else 0\n",
        "    avg_test_count_loss_ce = np.sum(test_count_losses_ce) / total_test_samples_loss if total_test_samples_loss > 0 else 0 # Avg CE Loss\n",
        "    avg_test_count_difference = total_count_diff_gen / total_test_samples_gen if total_test_samples_gen > 0 else 0\n",
        "    test_count_accuracy = count_correct / total_test_samples_gen if total_test_samples_gen > 0 else 0\n",
        "\n",
        "    print(f\"\\n--- Final Test Set Evaluation Summary ---\")\n",
        "    print(f\"  Average Absolute Count Difference: {avg_test_count_difference:.4f}\")\n",
        "    print(f\"  Count Prediction Accuracy:         {test_count_accuracy:.4f}\") # Added count accuracy\n",
        "    print(f\"  Average Coordinate Loss (MSE, Normalized): {avg_test_coord_loss_norm:.4f}\")\n",
        "    print(f\"  Average Count Loss (CrossEntropy):       {avg_test_count_loss_ce:.4f}\") # Added CE loss avg\n",
        "\n",
        "else: print(\"\\nSkipping test set evaluation: model/tokenizer loading failed or unavailable.\")\n",
        "\n",
        "print(\"\\n--- Script Finished ---\")"
      ],
      "metadata": {
        "id": "7TM5Ossnk0if"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}