{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP0lPactWMYWDFfjX8lD4/5",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/frank-morales2020/Cloud_curious/blob/master/PosgresML.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W_3lJ5XcikHD"
      },
      "outputs": [],
      "source": [
        "#!pip install pgml\n",
        "#!python3 -m asyncio\n",
        "\n",
        "#!pip install datasets\n",
        "#!pip install colab-env --upgrade\n",
        "\n",
        "# install PSQL WITH DEV Libraries AND PGVECTOR\n",
        "!apt install postgresql postgresql-contrib &>log\n",
        "!service postgresql restart\n",
        "!sudo apt install postgresql-server-dev-all\n",
        "\n",
        "!pip install pgml-extension\n",
        "\n",
        "\n",
        "\n",
        "from pgml import TransformerPipeline\n",
        "pipe = TransformerPipeline(\"text-generation\", \"TheBloke/zephyr-7B-beta-GPTQ\", {\"model_type\": \"mistral\", \"revision\": \"main\", \"device_map\": \"auto\"}, \"postgres://pg:ml@sql.cloud.postgresml.org:6432/pgml\")\n",
        "async for t in await pipe.transform_stream(\"AI is going to\", {\"max_new_tokens\": 10}):\n",
        "   print(t)\n",
        "\n",
        "\n",
        "from pgml import migrate\n",
        "\n",
        "#async for t in await pipe.transform_stream(\"AI is going to\", {\"max_new_tokens\": 100}):\n",
        "#   print(t)\n",
        "\n",
        "\n",
        "#https://github.com/postgresml/postgresml/tree/master/pgml-sdks/pgml/python\n",
        "\n",
        "from pgml import Collection, Model, Splitter, Pipeline\n",
        "from datasets import load_dataset\n",
        "from time import time\n",
        "from dotenv import load_dotenv\n",
        "from rich.console import Console\n",
        "import asyncio\n",
        "\n",
        "def main():\n",
        "        load_dotenv()\n",
        "        console = Console()\n",
        "\n",
        "        # Initialize collection\n",
        "        collection = Collection(\"quora_collection\")\n",
        "            # Create a pipeline using the default model and splitter\n",
        "        model = Model()\n",
        "        splitter = Splitter()\n",
        "        pipeline = Pipeline(\"quorav1\", model, splitter)\n",
        "        collection.add_pipeline(pipeline)\n",
        "\n",
        "# Prep documents for upserting\n",
        "        data = load_dataset(\"squad\", split=\"train\")\n",
        "        data = data.to_pandas()\n",
        "        data = data.drop_duplicates(subset=[\"context\"])\n",
        "        documents = [\n",
        "            {\"id\": r[\"id\"], \"text\": r[\"context\"], \"title\": r[\"title\"]}\n",
        "            for r in data.to_dict(orient=\"records\")\n",
        "        ]\n",
        "\n",
        "        # Upsert documents\n",
        "        collection.upsert_documents(documents[:200])\n",
        "\n",
        "            # Query\n",
        "        query = \"Who won 20 grammy awards?\"\n",
        "        results = collection.query().vector_recall(query, pipeline).limit(5).fetch_all()\n",
        "        console.print(results)\n",
        "        # Archive collection\n",
        "        collection.archive()\n",
        "\n",
        "asyncio.run(main())\n",
        "\n",
        "#await main()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pgml\n",
        "!pip install colab-env --upgrade\n",
        "!pip install psycopg2\n",
        "#!pip install pgml_extension\n",
        "\n",
        "import colab_env\n",
        "#!git clone https://github.com/postgresml/postgresml.git\n",
        "\n",
        "# install PSQL WITH DEV Libraries AND PGVECTOR\n",
        "!apt install postgresql postgresql-contrib &>log\n",
        "!service postgresql restart\n",
        "!sudo apt install postgresql-server-dev-all\n",
        "\n",
        "#!pip install -r /content/postgresml/pgml-extension/requirements.txt\n",
        "\n",
        "### PGML EXTENSIONS\n",
        "#!mkdir /content/installs\n",
        "#%cp -pr /content/gdrive/MyDrive/datasets/pgml-extension-1.0.1/ /content/installs/\n",
        "#%cd /content/installs/pgml-extension-1.0.1/\n",
        "#!sudo python3 /content/installs/pgml-extension-1.0.1/setup.py install\n",
        "#!pip install pgml-extension\n",
        "\n",
        "#!cp /content/postgresml/pgml-extension/pgml.control /usr/share/postgresql/14/extension/\n",
        "#!ls /usr/share/postgresql/14/extension/*control*\n",
        "\n",
        "# PostGRES SQL Settings\n",
        "#!sudo -u postgres psql -c \"CREATE USER postgres WITH SUPERUSER\"\n",
        "!sudo -u postgres psql -c \"ALTER USER postgres PASSWORD 'postgres'\"\n",
        "!sudo -u postgres psql -c \"CREATE SCHEMA IF NOT EXISTS pgml AUTHORIZATION postgres\"\n",
        "!sudo -u postgres psql -c \"CREATE DATABASE pgml OWNER postgres\"\n",
        "\n",
        "import psycopg2 as ps\n",
        "DB_NAME = \"postgres\"\n",
        "#DB_NAME = \"pgml\"\n",
        "\n",
        "DATABASE_URL=\"postgres://postgres:postgres@localhost:5432/pgml\"\n",
        "#DATABASE_URL=\"postgres://user:pass@.db.cloud.postgresml.org:6432/pgml\"\n",
        "\n",
        "\n",
        "DATABASE_URL=\"postgres://pg:ml@sql.cloud.postgresml.org:6432/pgml\"\n",
        "\n",
        "\n",
        "\n",
        "#DB_NAME = \"pgml\"\n",
        "DB_USER = \"postgres\"\n",
        "DB_PASS = \"postgres\"\n",
        "DB_HOST = \"localhost\"\n",
        "DB_PORT = \"5432\"\n",
        "\n",
        "conn = ps.connect(database=DB_NAME,\n",
        "\t\t\t\t\t\t\tuser=DB_USER,\n",
        "\t\t\t\t\t\t\tpassword=DB_PASS,\n",
        "\t\t\t\t\t\t\thost=DB_HOST,\n",
        "\t\t\t\t\t\t\tport=DB_PORT)\n",
        "\n",
        "!cp -pr /content/gdrive/MyDrive/tools/pgvector /content/\n",
        "print()\n",
        "%cd /content/pgvector\n",
        "\n",
        "print('START: PG VECTOR COMPILATION')\n",
        "!make\n",
        "!make install # may need sudo\n",
        "print('END: PG VECTOR COMPILATION')\n",
        "print()\n",
        "\n",
        "#CREATE EXTENSION IF NOT EXISTS btree_gist\n",
        "!sudo -u postgres psql -c \"CREATE EXTENSION IF NOT EXISTS vector\"\n",
        "\n",
        "\n",
        "!sudo -u postgres psql -c \"DROP TABLE reviews\"\n",
        "\n",
        "cur = conn.cursor() # creating a cursor\n",
        "cur.execute(\"\"\"\n",
        "                            CREATE TABLE reviews\n",
        "                            (text TEXT, embedding vector(1536))\n",
        "                         \"\"\")\n",
        "\n",
        "conn.commit()\n",
        "print(\"TABLE Review Created successfully\")\n",
        "conn.close()\n",
        "cur.close()\n",
        "\n",
        "#pgml_extension.transform(task, inputs, args)\n",
        "print()\n",
        "import pgml\n",
        "client = pgml.OpenSourceAI(DATABASE_URL)\n",
        "\n",
        "results = client.chat_completions_create(\n",
        "    \"HuggingFaceH4/zephyr-7b-beta\",\n",
        "    [\n",
        "        {\n",
        "            \"role\": \"system\",\n",
        "            \"content\": \"You are a friendly chatbot who always responds in the style of a pirate\",\n",
        "        },\n",
        "        {\n",
        "            \"role\": \"user\",\n",
        "            \"content\": \"How many helicopters can a human eat in one sitting?\",\n",
        "        },\n",
        "    ],\n",
        "    temperature=0.85,\n",
        ")\n",
        "print()\n",
        "#print(results)\n",
        "\n",
        "for c in results:\n",
        "    print(c)\n",
        "\n",
        "#CREATE EXTENSION IF NOT EXISTS btree_gist\n",
        "#!sudo -u postgres psql -c \"CREATE EXTENSION IF NOT EXISTS pgml\"\n",
        "#!sudo -u postgres psql -c \"SELECT pgml.version()\""
      ],
      "metadata": {
        "id": "_T2negKGpsx0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pgml\n",
        "client = pgml.OpenSourceAI(DATABASE_URL)\n",
        "results = client.chat_completions_create(\n",
        "    \"HuggingFaceH4/zephyr-7b-beta\",\n",
        "    [\n",
        "        {\n",
        "            \"role\": \"system\",\n",
        "            \"content\": \"You are a friendly chatbot who always responds in the style of a pirate\",\n",
        "        },\n",
        "        {\n",
        "            \"role\": \"user\",\n",
        "            #\"content\": \"How many helicopters can a human eat in one sitting?\",\n",
        "            \"content\": \"write an essay about AI\",\n",
        "        },\n",
        "    ],\n",
        "    temperature=0.85,\n",
        ")\n",
        "print(results['choices'][0]['message']['content'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oR5BdXlZC7lS",
        "outputId": "ab7116a3-f1f6-4498-f27d-540065bb3d9c"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Avast, me hearties! Today we be talking 'bout a topic thatâ€™s got the entire tech world awash with possibilities - Artificial Intelligence (AI). AI is the talk of the town, and with good reason. Itâ€™s a technology thatâ€™s evolving at a rapid pace, revolutionizing the way we live, work and interact with the world around us.\n",
            "\n",
            "At its core, AI is all about teaching machines to learn and adapt in a way thatâ€™s similar to how humans do. Itâ€™s about creating intelligent, autonomous systems that can understand, reason, and act upon the information presented to them. AI has the potential to solve some of the most complex problems that humans have been grappling with for centuries- everything from medical diagnosis to traffic management, from financial forecasting to space exploration, and from language translation to entertainment.\n",
            "\n",
            "AI is powered by a range of technologies, including machine learning, natural language processing, computer vision, and reinforcement learning. These technologies allow AI systems to process, analyze, and interpret vast amounts of data, and draw insights and recommendations that humans canâ€™t.\n",
            "\n",
            "Machine learning, for example, is the core of AI. It involves feeding large datasets into algorithms that can learn, adapt, and predict outcomes based on patterns and trends in the data. These algorithms can be supervised, unsupervised, or reinforcement learning algorithms. Supervised learning algorithms learn by analyzing labeled data, while unsupervised learning algorithms learn by analyzing unlabeled data. Reinforcement learning algorithms learn by trying different actions or decisions and receiving feedback in the form of rewards or penalties.\n",
            "\n",
            "Natural language processing (NLP) is another powerful AI technology. It involves teaching machines to understand and interpret human language. NLP algorithms can read and analyze text, identify entities, relationships, and sentiment, and generate responses that are accurate and relevant. NLP has a range of applications, including language translation, customer service, and content creation.\n",
            "\n",
            "Computer vision is the technology that allows AI systems to interpret and understand visual information. It involves teaching machines to recognize objects, scenes, and actions in images and videos. Computer vision algorithms can analyze images, segment objects, and label them based on their features, such as color, shape, and texture. Computer vision has a range of applications, including object detection, segmentation, and tracking, as well as medical imaging and robotics.\n",
            "\n",
            "Reinforcement learning is the technology that enables AI systems to learn by interacting with their environment. It involves teaching machines to make decisions by trying different actions and receiving feedback in the form of rewards or penalties. Reinforcement learning algorithms can learn to make decisions in complex, dynamic environments, such as games, financial markets, and robotics.\n",
            "\n",
            "AI has the potential to transform a range of industries and domains, creating new opportunities and challenges. In healthcare, for example, AI can be used to diagnose diseases, recommend treatments, and monitor patients. In finance, AI can be used to predict stock prices, manage risk, and optimize portfolios. In education, AI can be used to personalize learning, adapt to student needs, and provide feedback. In transportation, AI can be used to improve safety, reduce congestion, and optimize routes.\n",
            "\n",
            "But AI is not without its challenges. AI systems are still relatively new, and there are a number of issues that need to be addressed before they can be widely adopted. One of the biggest challenges is data. AI systems are only as good as the data they are trained on, and high-quality, labeled data is not always easy to come by. This is particularly true in areas like healthcare and finance, where the data is sensitive, confidential, and subject to strict privacy and security constraints.\n",
            "\n",
            "Another challenge is explainability. AI systems can make complex decisions based on vast amounts of data, but it can be difficult to understand how those decisions were made. This is a critical issue, as it can be difficult to trust and rely on a system that is opaque and unpredictable. There is a growing movement to promote explainable AI, which involves making AI systems more transparent, auditable, and explainable.\n",
            "\n",
            "Finally, there is the issue of job displacement. As AI systems become more intelligent and autonomous, there is a growing concern that they will displace jobs that are currently performed by humans. This is a complex issue, as it involves a range of factors, including the nature of the task, the level of expertise required, and the economics of automation. Itâ€™s clear that AI will displace some jobs, but itâ€™s equally clear that it will create new jobs and opportunities as well.\n",
            "\n",
            "In conclusion, AI is a technology thatâ€™s changing the way we live, work, and interact with the\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pgml import Collection, Model, Splitter, Pipeline\n",
        "import asyncio\n",
        "\n",
        "async def main():\n",
        "    # Initialize collection\n",
        "    collection = Collection(\"sample_collection\")\n",
        "    # Create a pipeline using the default model and splitter\n",
        "    model = Model()\n",
        "    splitter = Splitter()\n",
        "    pipeline = Pipeline(\"sample_pipeline\", model, splitter)\n",
        "    await collection.add_pipeline(pipeline)\n",
        "    documents = [\n",
        "      {\n",
        "          id: \"Document One\",\n",
        "          text: \"document one contents...\",\n",
        "      },\n",
        "      {\n",
        "          id: \"Document Two\",\n",
        "          text: \"document two contents...\",\n",
        "      },\n",
        "                 ]\n",
        "    await collection.upsert_documents(documents)\n",
        "    # Query\n",
        "    query = \"Some user query that will match document one first\"\n",
        "    results = await collection.query().vector_recall(query, pipeline).limit(2).fetch_all()\n",
        "    print(results)\n",
        "    # Archive collection\n",
        "    await collection.archive()\n",
        "\n",
        "    asyncio.run(main())\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "  print('YES')\n",
        "  #asyncio.run(main())\n",
        "  #import asyncio\n",
        "  loop = asyncio.get_event_loop()\n",
        "  loop.create_task(main())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pWSUU9hVG831",
        "outputId": "3ce5e277-ee0f-4899-d5ff-9229d8d03841"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "YES\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/lib/python3.10/tokenize.py:527: RuntimeWarning: coroutine 'main' was never awaited\n",
            "  pseudomatch = _compile(PseudoToken).match(line, pos)\n",
            "RuntimeWarning: Enable tracemalloc to get the object allocation traceback\n",
            "ERROR:asyncio:Task exception was never retrieved\n",
            "future: <Task finished name='Task-6' coro=<main() done, defined at <ipython-input-28-c0eb2d0ec014>:4> exception=RustPanic('rust future panicked')>\n",
            "Traceback (most recent call last):\n",
            "  File \"<ipython-input-28-c0eb2d0ec014>\", line 11, in main\n",
            "    await collection.add_pipeline(pipeline)\n",
            "pyo3_asyncio.RustPanic: rust future panicked\n"
          ]
        }
      ]
    }
  ]
}