{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO97yPZ7u83T0uP3iQud4if",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/frank-morales2020/Cloud_curious/blob/master/posgresml.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W_3lJ5XcikHD"
      },
      "outputs": [],
      "source": [
        "#!pip install pgml\n",
        "#!python3 -m asyncio\n",
        "\n",
        "#!pip install datasets\n",
        "#!pip install colab-env --upgrade\n",
        "\n",
        "# install PSQL WITH DEV Libraries AND PGVECTOR\n",
        "!apt install postgresql postgresql-contrib &>log\n",
        "!service postgresql restart\n",
        "!sudo apt install postgresql-server-dev-all\n",
        "\n",
        "!pip install pgml-extension\n",
        "\n",
        "\n",
        "\n",
        "from pgml import TransformerPipeline\n",
        "pipe = TransformerPipeline(\"text-generation\", \"TheBloke/zephyr-7B-beta-GPTQ\", {\"model_type\": \"mistral\", \"revision\": \"main\", \"device_map\": \"auto\"}, \"postgres://pg:ml@sql.cloud.postgresml.org:6432/pgml\")\n",
        "async for t in await pipe.transform_stream(\"AI is going to\", {\"max_new_tokens\": 10}):\n",
        "   print(t)\n",
        "\n",
        "\n",
        "from pgml import migrate\n",
        "\n",
        "#async for t in await pipe.transform_stream(\"AI is going to\", {\"max_new_tokens\": 100}):\n",
        "#   print(t)\n",
        "\n",
        "\n",
        "#https://github.com/postgresml/postgresml/tree/master/pgml-sdks/pgml/python\n",
        "\n",
        "from pgml import Collection, Model, Splitter, Pipeline\n",
        "from datasets import load_dataset\n",
        "from time import time\n",
        "from dotenv import load_dotenv\n",
        "from rich.console import Console\n",
        "import asyncio\n",
        "\n",
        "def main():\n",
        "        load_dotenv()\n",
        "        console = Console()\n",
        "\n",
        "        # Initialize collection\n",
        "        collection = Collection(\"quora_collection\")\n",
        "            # Create a pipeline using the default model and splitter\n",
        "        model = Model()\n",
        "        splitter = Splitter()\n",
        "        pipeline = Pipeline(\"quorav1\", model, splitter)\n",
        "        collection.add_pipeline(pipeline)\n",
        "\n",
        "# Prep documents for upserting\n",
        "        data = load_dataset(\"squad\", split=\"train\")\n",
        "        data = data.to_pandas()\n",
        "        data = data.drop_duplicates(subset=[\"context\"])\n",
        "        documents = [\n",
        "            {\"id\": r[\"id\"], \"text\": r[\"context\"], \"title\": r[\"title\"]}\n",
        "            for r in data.to_dict(orient=\"records\")\n",
        "        ]\n",
        "\n",
        "        # Upsert documents\n",
        "        collection.upsert_documents(documents[:200])\n",
        "\n",
        "            # Query\n",
        "        query = \"Who won 20 grammy awards?\"\n",
        "        results = collection.query().vector_recall(query, pipeline).limit(5).fetch_all()\n",
        "        console.print(results)\n",
        "        # Archive collection\n",
        "        collection.archive()\n",
        "\n",
        "asyncio.run(main())\n",
        "\n",
        "#await main()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pgml\n",
        "!pip install colab-env --upgrade\n",
        "!pip install psycopg2\n",
        "#!pip install pgml_extension\n",
        "\n",
        "import colab_env\n",
        "#!git clone https://github.com/postgresml/postgresml.git\n",
        "\n",
        "# install PSQL WITH DEV Libraries AND PGVECTOR\n",
        "!apt install postgresql postgresql-contrib &>log\n",
        "!service postgresql restart\n",
        "!sudo apt install postgresql-server-dev-all\n",
        "\n",
        "#!pip install -r /content/postgresml/pgml-extension/requirements.txt\n",
        "\n",
        "### PGML EXTENSIONS\n",
        "#!mkdir /content/installs\n",
        "#%cp -pr /content/gdrive/MyDrive/datasets/pgml-extension-1.0.1/ /content/installs/\n",
        "#%cd /content/installs/pgml-extension-1.0.1/\n",
        "#!sudo python3 /content/installs/pgml-extension-1.0.1/setup.py install\n",
        "#!pip install pgml-extension\n",
        "\n",
        "#!cp /content/postgresml/pgml-extension/pgml.control /usr/share/postgresql/14/extension/\n",
        "#!ls /usr/share/postgresql/14/extension/*control*\n",
        "\n",
        "# PostGRES SQL Settings\n",
        "#!sudo -u postgres psql -c \"CREATE USER postgres WITH SUPERUSER\"\n",
        "!sudo -u postgres psql -c \"ALTER USER postgres PASSWORD 'postgres'\"\n",
        "!sudo -u postgres psql -c \"CREATE SCHEMA IF NOT EXISTS pgml AUTHORIZATION postgres\"\n",
        "!sudo -u postgres psql -c \"CREATE DATABASE pgml OWNER postgres\"\n",
        "\n",
        "import psycopg2 as ps\n",
        "DB_NAME = \"postgres\"\n",
        "#DB_NAME = \"pgml\"\n",
        "\n",
        "DATABASE_URL=\"postgres://postgres:postgres@localhost:5432/pgml\"\n",
        "#DATABASE_URL=\"postgres://user:pass@.db.cloud.postgresml.org:6432/pgml\"\n",
        "\n",
        "\n",
        "DATABASE_URL=\"postgres://pg:ml@sql.cloud.postgresml.org:6432/pgml\"\n",
        "\n",
        "\n",
        "\n",
        "#DB_NAME = \"pgml\"\n",
        "DB_USER = \"postgres\"\n",
        "DB_PASS = \"postgres\"\n",
        "DB_HOST = \"localhost\"\n",
        "DB_PORT = \"5432\"\n",
        "\n",
        "conn = ps.connect(database=DB_NAME,\n",
        "\t\t\t\t\t\t\tuser=DB_USER,\n",
        "\t\t\t\t\t\t\tpassword=DB_PASS,\n",
        "\t\t\t\t\t\t\thost=DB_HOST,\n",
        "\t\t\t\t\t\t\tport=DB_PORT)\n",
        "\n",
        "!cp -pr /content/gdrive/MyDrive/tools/pgvector /content/\n",
        "print()\n",
        "%cd /content/pgvector\n",
        "\n",
        "print('START: PG VECTOR COMPILATION')\n",
        "!make\n",
        "!make install # may need sudo\n",
        "print('END: PG VECTOR COMPILATION')\n",
        "print()\n",
        "\n",
        "#CREATE EXTENSION IF NOT EXISTS btree_gist\n",
        "!sudo -u postgres psql -c \"CREATE EXTENSION IF NOT EXISTS vector\"\n",
        "\n",
        "\n",
        "!sudo -u postgres psql -c \"DROP TABLE reviews\"\n",
        "\n",
        "cur = conn.cursor() # creating a cursor\n",
        "cur.execute(\"\"\"\n",
        "                            CREATE TABLE reviews\n",
        "                            (text TEXT, embedding vector(1536))\n",
        "                         \"\"\")\n",
        "\n",
        "conn.commit()\n",
        "print(\"TABLE Review Created successfully\")\n",
        "conn.close()\n",
        "cur.close()\n",
        "\n",
        "#pgml_extension.transform(task, inputs, args)\n",
        "print()\n",
        "import pgml\n",
        "client = pgml.OpenSourceAI(DATABASE_URL)\n",
        "\n",
        "results = client.chat_completions_create(\n",
        "    \"HuggingFaceH4/zephyr-7b-beta\",\n",
        "    [\n",
        "        {\n",
        "            \"role\": \"system\",\n",
        "            \"content\": \"You are a friendly chatbot who always responds in the style of a pirate\",\n",
        "        },\n",
        "        {\n",
        "            \"role\": \"user\",\n",
        "            \"content\": \"How many helicopters can a human eat in one sitting?\",\n",
        "        },\n",
        "    ],\n",
        "    temperature=0.85,\n",
        ")\n",
        "print()\n",
        "#print(results)\n",
        "\n",
        "for c in results:\n",
        "    print(c)\n",
        "\n",
        "#CREATE EXTENSION IF NOT EXISTS btree_gist\n",
        "#!sudo -u postgres psql -c \"CREATE EXTENSION IF NOT EXISTS pgml\"\n",
        "#!sudo -u postgres psql -c \"SELECT pgml.version()\""
      ],
      "metadata": {
        "id": "_T2negKGpsx0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# https://postgresml.org/docs/\n",
        "\n",
        "import pgml\n",
        "client = pgml.OpenSourceAI(DATABASE_URL)\n",
        "results = client.chat_completions_create(\n",
        "    \"HuggingFaceH4/zephyr-7b-beta\",\n",
        "    [\n",
        "        {\n",
        "            \"role\": \"system\",\n",
        "            \"content\": \"You are a friendly chatbot who always responds in the style of a pirate\",\n",
        "        },\n",
        "        {\n",
        "            \"role\": \"user\",\n",
        "            #\"content\": \"How many helicopters can a human eat in one sitting?\",\n",
        "            \"content\": \"write an essay about AI\",\n",
        "        },\n",
        "    ],\n",
        "    temperature=0.85,\n",
        "    max_tokens=1024,\n",
        ")\n",
        "print(results['choices'][0]['message']['content'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oR5BdXlZC7lS",
        "outputId": "d3af2bc6-3709-4903-a86f-166798f8a511"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ahoy, me hearties! I be glad to speak to ye 'bout the wondrous subject o' AI. AI, or Artificial Intelligence, is an emerging field of computer science that aims to replicate intelligent human-like behavior in machines by programming them to adapt, learn, and reason.\n",
            "\n",
            "The history of AI can be traced back to the 1950s when scientists and mathematicians, including Alan Turing and John McCarthy, began to explore the potential of creating intelligent machines. At that time, the term \"AI\" was coined, and the concept was broadly defined as the ability of computers to mimic the cognitive abilities of human beings, such as perception, reasoning, and problem-solving.\n",
            "\n",
            "Over the years, AI has come a long way, and today it is being used in numerous applications across various domains. Some popular examples of AI applications include virtual assistants, self-driving cars, language translation systems, and medical diagnosis systems.\n",
            "\n",
            "One of the most significant achievements of AI is its ability to learn and adapt. Through machine learning algorithms, AI systems can continuously improve their performance by analyzing large datasets and identifying patterns and relationships. This learning process enables AI systems to make more accurate decisions and predictions, which can significantly improve their efficiency and efficacy in real-world applications.\n",
            "\n",
            "Another key aspect of AI is its ability to reason and make decisions. AI systems can process vast amounts of data and information, and they can use that information to make intelligent and informed decisions. This capability is particularly useful in industries such as finance, where AI systems can be used to analyze complex financial data and make investment recommendations based on that data.\n",
            "\n",
            "AI also has the potential to revolutionize various industries, including healthcare, education, and transportation. For example, AI-powered diagnostic systems can help doctors to make more accurate diagnoses, and AI-powered education systems can provide personalized learning experiences to students. In transportation, AI-powered self-driving cars can significantly improve road safety by eliminating the risks associated with human error.\n",
            "\n",
            "Of course, AI is not without its limitations and challenges. One of the main challenges of AI is the issue of data privacy and security. Since AI systems rely on large datasets, there is a risk that sensitive and confidential data could be compromised. To address this challenge, it is essential to ensure that data is securely handled and that users have control over their data.\n",
            "\n",
            "Another challenge of AI is the issue of job displacement. As AI systems become more sophisticated and replace certain human tasks, there is a risk that certain jobs could be automated, potentially leading to job losses. To address this challenge, it is essential to ensure that workers are trained and upskilled to adapt to the changing nature of work in the AI era.\n",
            "\n",
            "In conclusion, AI is an exciting and rapidly expanding field that has the potential to revolutionize various aspects of our lives. While there are challenges and limitations associated with AI, it is clear that AI will play an increasingly important role in shaping our future. As AI systems become more sophisticated, it is essential to ensure that they are developed and implemented in a responsible and ethical manner, and that they are used to benefit society as a whole.\n",
            "\n",
            "Until next time, me hearties, keep your ears peeled for more rumblings in the world of AI!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pgml import Collection, Model, Splitter, Pipeline\n",
        "import asyncio\n",
        "\n",
        "async def main():\n",
        "    # Initialize collection\n",
        "    collection = Collection(\"sample_collection\")\n",
        "    # Create a pipeline using the default model and splitter\n",
        "    model = Model()\n",
        "    splitter = Splitter()\n",
        "    pipeline = Pipeline(\"sample_pipeline\", model, splitter)\n",
        "    await collection.add_pipeline(pipeline)\n",
        "    documents = [\n",
        "      {\n",
        "          id: \"Document One\",\n",
        "          text: \"document one contents...\",\n",
        "      },\n",
        "      {\n",
        "          id: \"Document Two\",\n",
        "          text: \"document two contents...\",\n",
        "      },\n",
        "                 ]\n",
        "    await collection.upsert_documents(documents)\n",
        "    # Query\n",
        "    query = \"Some user query that will match document one first\"\n",
        "    results = await collection.query().vector_recall(query, pipeline).limit(2).fetch_all()\n",
        "    print(results)\n",
        "    # Archive collection\n",
        "    await collection.archive()\n",
        "\n",
        "    asyncio.run(main())\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "  print('YES')\n",
        "  #asyncio.run(main())\n",
        "  #import asyncio\n",
        "  loop = asyncio.get_event_loop()\n",
        "  loop.create_task(main())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pWSUU9hVG831",
        "outputId": "3ce5e277-ee0f-4899-d5ff-9229d8d03841"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "YES\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/lib/python3.10/tokenize.py:527: RuntimeWarning: coroutine 'main' was never awaited\n",
            "  pseudomatch = _compile(PseudoToken).match(line, pos)\n",
            "RuntimeWarning: Enable tracemalloc to get the object allocation traceback\n",
            "ERROR:asyncio:Task exception was never retrieved\n",
            "future: <Task finished name='Task-6' coro=<main() done, defined at <ipython-input-28-c0eb2d0ec014>:4> exception=RustPanic('rust future panicked')>\n",
            "Traceback (most recent call last):\n",
            "  File \"<ipython-input-28-c0eb2d0ec014>\", line 11, in main\n",
            "    await collection.add_pipeline(pipeline)\n",
            "pyo3_asyncio.RustPanic: rust future panicked\n"
          ]
        }
      ]
    }
  ]
}