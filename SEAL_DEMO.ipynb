{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100",
      "authorship_tag": "ABX9TyOZogYHlICzg2PXjkroURsT",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/frank-morales2020/Cloud_curious/blob/master/SEAL_DEMO.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://github.com/Continual-Intelligence/SEAL/tree/main"
      ],
      "metadata": {
        "id": "8ELjlTPOQIcc"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rPC9FQyR23cJ"
      },
      "outputs": [],
      "source": [
        "!git clone https://github.com/Continual-Intelligence/SEAL.git\n",
        "%cd SEAL\n",
        "!pip install -r requirements.txt -q\n",
        "!pip install colab-env -q\n",
        "import colab_env"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tuahowyn1Zg7",
        "outputId": "0b9fa71c-3324-4256-d359-76d5b077c084"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Thu Jul  3 10:29:40 2025       \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n",
            "|-----------------------------------------+------------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                        |               MIG M. |\n",
            "|=========================================+========================+======================|\n",
            "|   0  NVIDIA A100-SXM4-40GB          Off |   00000000:00:04.0 Off |                    0 |\n",
            "| N/A   31C    P0             43W /  400W |       0MiB /  40960MiB |      0%      Default |\n",
            "|                                         |                        |             Disabled |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "                                                                                         \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                              |\n",
            "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
            "|        ID   ID                                                               Usage      |\n",
            "|=========================================================================================|\n",
            "|  No running processes found                                                             |\n",
            "+-----------------------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import colab_env\n",
        "import os\n",
        "\n",
        "access_token_write = os.getenv(\"HUGGINGFACE_ACCESS_TOKEN_WRITE\")\n",
        "\n",
        "from huggingface_hub import login\n",
        "\n",
        "login(\n",
        "  token=access_token_write,\n",
        "  add_to_git_credential=True\n",
        ")"
      ],
      "metadata": {
        "id": "r9riExTm6J-9"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!sh /content/SEAL/few-shot/launch.sh"
      ],
      "metadata": {
        "id": "M4-79zgcMRHb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "DATA_DIR='/content/SEAL/few-shot/data'\n",
        "!python /content/SEAL/few-shot/self-edit.py  \\\n",
        "    --experiment_name=training_set_iteration_1 \\\n",
        "    --challenge_file={DATA_DIR}/arc-agi_training_challenges_filtered_1B_training_set.json \\\n",
        "    --solution_file={DATA_DIR}/arc-agi_training_solutions_filtered_1B_training_set.json \\\n",
        "    --model_name=meta-llama/Llama-3.2-1B-Instruct \\\n",
        "    --n_tasks=1 \\\n",
        "    --n_self_edits_per_task=15"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "twKPB5UC30_w",
        "outputId": "a06c2d4d-1f81-4d04-ce7f-fce1b4021eb4"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-07-03 10:36:08.479950: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
            "2025-07-03 10:36:08.497782: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1751538968.519379   62479 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1751538968.525991   62479 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2025-07-03 10:36:08.548080: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "INFO 07-03 10:36:12 [__init__.py:244] Automatically detected platform cuda.\n",
            "Phase 1: Generating configs using self-edit model...\n",
            "INFO 07-03 10:36:30 [config.py:823] This model supports multiple tasks: {'generate', 'classify', 'reward', 'embed', 'score'}. Defaulting to 'generate'.\n",
            "INFO 07-03 10:36:30 [config.py:2195] Chunked prefill is enabled with max_num_batched_tokens=8192.\n",
            "WARNING 07-03 10:36:32 [utils.py:2597] We must use the `spawn` multiprocessing start method. Overriding VLLM_WORKER_MULTIPROC_METHOD to 'spawn'. See https://docs.vllm.ai/en/latest/usage/troubleshooting.html#python-multiprocessing for more information. Reason: CUDA is initialized\n",
            "2025-07-03 10:36:37.975947: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1751538997.996813   62753 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1751538998.003195   62753 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "WARNING 07-03 10:36:40 [env_override.py:17] NCCL_CUMEM_ENABLE is set to 0, skipping override. This may increase memory overhead with cudagraph+allreduce: https://github.com/NVIDIA/nccl/issues/1234\n",
            "INFO 07-03 10:36:40 [__init__.py:244] Automatically detected platform cuda.\n",
            "INFO 07-03 10:36:44 [core.py:455] Waiting for init message from front-end.\n",
            "INFO 07-03 10:36:44 [core.py:70] Initializing a V1 LLM engine (v0.9.1) with config: model='meta-llama/Llama-3.2-1B-Instruct', speculative_config=None, tokenizer='meta-llama/Llama-3.2-1B-Instruct', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config={}, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=131072, download_dir=None, load_format=LoadFormat.AUTO, tensor_parallel_size=1, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto,  device_config=cuda, decoding_config=DecodingConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_backend=''), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=meta-llama/Llama-3.2-1B-Instruct, num_scheduler_steps=1, multi_step_stream_outputs=True, enable_prefix_caching=True, chunked_prefill_enabled=True, use_async_output_proc=True, pooler_config=None, compilation_config={\"level\":3,\"debug_dump_path\":\"\",\"cache_dir\":\"\",\"backend\":\"\",\"custom_ops\":[\"none\"],\"splitting_ops\":[\"vllm.unified_attention\",\"vllm.unified_attention_with_output\"],\"use_inductor\":true,\"compile_sizes\":[],\"inductor_compile_config\":{\"enable_auto_functionalized_v2\":false},\"inductor_passes\":{},\"use_cudagraph\":true,\"cudagraph_num_of_warmups\":1,\"cudagraph_capture_sizes\":[512,504,496,488,480,472,464,456,448,440,432,424,416,408,400,392,384,376,368,360,352,344,336,328,320,312,304,296,288,280,272,264,256,248,240,232,224,216,208,200,192,184,176,168,160,152,144,136,128,120,112,104,96,88,80,72,64,56,48,40,32,24,16,8,4,2,1],\"cudagraph_copy_inputs\":false,\"full_cuda_graph\":false,\"max_capture_size\":512,\"local_cache_dir\":null}\n",
            "WARNING 07-03 10:36:45 [utils.py:2737] Methods determine_num_available_blocks,device_config,get_cache_block_size_bytes,initialize_cache not implemented in <vllm.v1.worker.gpu_worker.Worker object at 0x7923b8befa90>\n",
            "INFO 07-03 10:36:45 [parallel_state.py:1065] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0\n",
            "WARNING 07-03 10:36:45 [topk_topp_sampler.py:59] FlashInfer is not available. Falling back to the PyTorch-native implementation of top-p & top-k sampling. For the best performance, please install FlashInfer.\n",
            "INFO 07-03 10:36:45 [gpu_model_runner.py:1595] Starting to load model meta-llama/Llama-3.2-1B-Instruct...\n",
            "INFO 07-03 10:36:46 [gpu_model_runner.py:1600] Loading model from scratch...\n",
            "INFO 07-03 10:36:46 [cuda.py:252] Using Flash Attention backend on V1 engine.\n",
            "INFO 07-03 10:36:46 [weight_utils.py:292] Using model weights format ['*.safetensors']\n",
            "INFO 07-03 10:36:46 [weight_utils.py:345] No model.safetensors.index.json found in remote.\n",
            "Loading safetensors checkpoint shards: 100% 1/1 [00:00<00:00,  1.51it/s]\n",
            "INFO 07-03 10:36:47 [default_loader.py:272] Loading weights took 0.71 seconds\n",
            "INFO 07-03 10:36:48 [gpu_model_runner.py:1624] Model loading took 2.3185 GiB and 1.240163 seconds\n",
            "INFO 07-03 10:36:54 [backends.py:462] Using cache directory: /root/.cache/vllm/torch_compile_cache/3800301869/rank_0_0 for vLLM's torch.compile\n",
            "INFO 07-03 10:36:54 [backends.py:472] Dynamo bytecode transform time: 5.82 s\n",
            "INFO 07-03 10:36:58 [backends.py:135] Directly load the compiled graph(s) for shape None from the cache, took 3.698 s\n",
            "INFO 07-03 10:36:58 [monitor.py:34] torch.compile takes 5.82 s in total\n",
            "INFO 07-03 10:37:00 [gpu_worker.py:227] Available KV cache memory: 32.02 GiB\n",
            "INFO 07-03 10:37:00 [kv_cache_utils.py:715] GPU KV cache size: 1,049,200 tokens\n",
            "INFO 07-03 10:37:00 [kv_cache_utils.py:719] Maximum concurrency for 131,072 tokens per request: 8.00x\n",
            "INFO 07-03 10:37:30 [gpu_model_runner.py:2048] Graph capturing finished in 30 secs, took 0.30 GiB\n",
            "INFO 07-03 10:37:30 [core.py:171] init engine (profile, create kv cache, warmup model) took 41.99 seconds\n",
            "Adding requests: 100% 1/1 [00:00<00:00, 330.65it/s]\n",
            "Processed prompts: 100% 1/1 [00:00<00:00,  2.02it/s, est. speed input: 834.58 toks/s, output: 175.80 toks/s]\n",
            "New config for task 44f52bb0: {'data_generation': {'use_basic_augmentations': False, 'use_size_augmentations': False, 'use_chain_augmentations': False, 'use_repeat_augmentations': False}, 'training': {'strategy': 'train_using_all_tokens', 'learning_rate': 0.01, 'num_train_epochs': 5}}\n",
            "Adding requests: 100% 1/1 [00:00<00:00, 540.50it/s]\n",
            "Processed prompts: 100% 1/1 [00:00<00:00,  2.49it/s, est. speed input: 1029.74 toks/s, output: 216.91 toks/s]\n",
            "New config for task 44f52bb0: {'data_generation': {'use_basic_augmentations': False, 'use_size_augmentations': False, 'use_chain_augmentations': True, 'use_repeat_augmentations': False}, 'training': {'strategy': 'train_using_all_tokens', 'learning_rate': 0.001, 'num_train_epochs': 3}}\n",
            "Adding requests: 100% 1/1 [00:00<00:00, 593.67it/s]\n",
            "Processed prompts: 100% 1/1 [00:00<00:00,  2.12it/s, est. speed input: 875.77 toks/s, output: 237.49 toks/s]\n",
            "New config for task 44f52bb0: {'data_generation': {'use_basic_augmentations': False, 'use_size_augmentations': False, 'use_chain_augmentations': False, 'use_repeat_augmentations': False}, 'training': {'strategy': 'train_using_all_tokens', 'learning_rate': 0.01, 'num_train_epochs': 3, 'use_tfidf': True, 'num_iterations': 100000, 'batch_size': 32}}\n",
            "Adding requests: 100% 1/1 [00:00<00:00, 595.11it/s]\n",
            "Processed prompts: 100% 1/1 [00:00<00:00,  2.64it/s, est. speed input: 1090.88 toks/s, output: 229.79 toks/s]\n",
            "New config for task 44f52bb0: {'data_generation': {'use_basic_augmentations': True, 'use_size_augmentations': False, 'use_chain_augmentations': False, 'use_repeat_augmentations': False}, 'training': {'strategy': 'train_using_all_tokens', 'learning_rate': 0.01, 'num_train_epochs': 5}}\n",
            "Adding requests: 100% 1/1 [00:00<00:00, 594.01it/s]\n",
            "Processed prompts: 100% 1/1 [00:00<00:00,  2.72it/s, est. speed input: 1124.90 toks/s, output: 236.95 toks/s]\n",
            "New config for task 44f52bb0: {'data_generation': {'use_basic_augmentations': True, 'use_size_augmentations': True, 'use_chain_augmentations': True, 'use_repeat_augmentations': False}, 'training': {'strategy': 'train_using_all_tokens', 'learning_rate': 0.001, 'num_train_epochs': 3}}\n",
            "Adding requests: 100% 1/1 [00:00<00:00, 593.42it/s]\n",
            "Processed prompts: 100% 1/1 [00:00<00:00,  2.73it/s, est. speed input: 1128.18 toks/s, output: 237.64 toks/s]\n",
            "New config for task 44f52bb0: {'data_generation': {'use_basic_augmentations': False, 'use_size_augmentations': False, 'use_chain_augmentations': False, 'use_repeat_augmentations': False}, 'training': {'strategy': 'train_using_output_tokens', 'learning_rate': 0.001, 'num_train_epochs': 5}}\n",
            "Adding requests: 100% 1/1 [00:00<00:00, 546.77it/s]\n",
            "Processed prompts: 100% 1/1 [00:00<00:00,  2.53it/s, est. speed input: 1045.30 toks/s, output: 220.19 toks/s]\n",
            "New config for task 44f52bb0: {'data_generation': {'use_basic_augmentations': True, 'use_size_augmentations': False, 'use_chain_augmentations': True, 'use_repeat_augmentations': False}, 'training': {'strategy': 'train_using_all_tokens', 'learning_rate': 0.01, 'num_train_epochs': 5}}\n",
            "Adding requests: 100% 1/1 [00:00<00:00, 595.27it/s]\n",
            "Processed prompts: 100% 1/1 [00:00<00:00,  2.64it/s, est. speed input: 1091.20 toks/s, output: 237.78 toks/s]\n",
            "New config for task 44f52bb0: {'data_generation': {'use_basic_augmentations': 'false', 'use_size_augmentations': 'false', 'use_chain_augmentations': 'false', 'use_repeat_augmentations': 'false'}, 'training': {'strategy': 'stochastic_basic', 'learning_rate': 0.001, 'num_train_epochs': 3}}\n",
            "Adding requests: 100% 1/1 [00:00<00:00, 615.81it/s]\n",
            "Processed prompts: 100% 1/1 [00:00<00:00,  2.68it/s, est. speed input: 1107.39 toks/s, output: 233.26 toks/s]\n",
            "New config for task 44f52bb0: {'data_generation': {'use_basic_augmentations': True, 'use_size_augmentations': True, 'use_chain_augmentations': False, 'use_repeat_augmentations': False}, 'training': {'strategy': 'train_using_all_tokens', 'learning_rate': 0.001, 'num_train_epochs': 3}}\n",
            "Adding requests: 100% 1/1 [00:00<00:00, 621.75it/s]\n",
            "Processed prompts: 100% 1/1 [00:00<00:00,  2.71it/s, est. speed input: 1120.22 toks/s, output: 235.97 toks/s]\n",
            "New config for task 44f52bb0: {'data_generation': {'use_basic_augmentations': False, 'use_size_augmentations': False, 'use_chain_augmentations': True, 'use_repeat_augmentations': False}, 'training': {'strategy': 'train_using_all_tokens', 'learning_rate': 0.001, 'num_train_epochs': 10}}\n",
            "Adding requests: 100% 1/1 [00:00<00:00, 259.81it/s]\n",
            "Processed prompts: 100% 1/1 [00:00<00:00,  2.71it/s, est. speed input: 1121.05 toks/s, output: 236.14 toks/s]\n",
            "New config for task 44f52bb0: {'data_generation': {'use_basic_augmentations': True, 'use_size_augmentations': True, 'use_chain_augmentations': False, 'use_repeat_augmentations': True}, 'training': {'strategy': 'train_using_all_tokens', 'learning_rate': 0.01, 'num_train_epochs': 2}}\n",
            "Adding requests: 100% 1/1 [00:00<00:00, 616.81it/s]\n",
            "Processed prompts: 100% 1/1 [00:00<00:00,  2.71it/s, est. speed input: 1121.00 toks/s, output: 236.13 toks/s]\n",
            "New config for task 44f52bb0: {'data_generation': {'use_basic_augmentations': True, 'use_size_augmentations': True, 'use_chain_augmentations': False, 'use_repeat_augmentations': False}, 'training': {'strategy': 'train_using_all_tokens', 'learning_rate': 1.0, 'num_train_epochs': 5}}\n",
            "Adding requests: 100% 1/1 [00:00<00:00, 617.99it/s]\n",
            "Processed prompts: 100% 1/1 [00:00<00:00,  2.69it/s, est. speed input: 1112.23 toks/s, output: 234.28 toks/s]\n",
            "New config for task 44f52bb0: {'data_generation': {'use_basic_augmentations': True, 'use_size_augmentations': False, 'use_chain_augmentations': True, 'use_repeat_augmentations': True}, 'training': {'strategy': 'train_using_all_tokens', 'learning_rate': 0.01, 'num_train_epochs': 3}}\n",
            "Adding requests: 100% 1/1 [00:00<00:00, 606.29it/s]\n",
            "Processed prompts: 100% 1/1 [00:00<00:00,  2.69it/s, est. speed input: 1110.18 toks/s, output: 233.85 toks/s]\n",
            "New config for task 44f52bb0: {'data_generation': {'use_basic_augmentations': True, 'use_size_augmentations': True, 'use_chain_augmentations': False, 'use_repeat_augmentations': False}, 'training': {'strategy': 'train_using_all_tokens', 'learning_rate': 0.01, 'num_train_epochs': 5}}\n",
            "Adding requests: 100% 1/1 [00:00<00:00, 564.36it/s]\n",
            "Processed prompts: 100% 1/1 [00:00<00:00,  2.32it/s, est. speed input: 958.35 toks/s, output: 201.87 toks/s]\n",
            "New config for task 44f52bb0: {'data_generation': {'use_basic_augmentations': True, 'use_size_augmentations': False, 'use_chain_augmentations': True, 'use_repeat_augmentations': True}, 'training': {'strategy': 'train_using_all_tokens', 'learning_rate': 0.01, 'num_train_epochs': 3}}\n",
            "[rank0]:[W703 10:37:37.554428540 ProcessGroupNCCL.cpp:1476] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())\n",
            "Phase 1 complete.\n",
            "\n",
            "Phase 2: Training models using generated configs...\n",
            "Training on 69 examples for 5 epochs, lr: 0.01\n",
            "No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n",
            "Starting training...\n",
            "{'loss': 3.1439, 'grad_norm': 1.834293246269226, 'learning_rate': 0.0, 'epoch': 0.03}\n",
            "{'loss': 3.1674, 'grad_norm': 1.8317646980285645, 'learning_rate': 0.0009090909090909091, 'epoch': 0.06}\n",
            "{'loss': 1.8162, 'grad_norm': 0.5597311854362488, 'learning_rate': 0.0018181818181818182, 'epoch': 0.09}\n",
            "{'loss': 1.2533, 'grad_norm': 0.9108178615570068, 'learning_rate': 0.002727272727272727, 'epoch': 0.11}\n",
            "{'loss': 1.9457, 'grad_norm': 4.176822185516357, 'learning_rate': 0.0036363636363636364, 'epoch': 0.14}\n",
            "{'loss': 0.7168, 'grad_norm': 1.9196336269378662, 'learning_rate': 0.004545454545454545, 'epoch': 0.17}\n",
            "{'loss': 0.4419, 'grad_norm': 0.5770339965820312, 'learning_rate': 0.005454545454545454, 'epoch': 0.2}\n",
            "{'loss': 0.9352, 'grad_norm': 2.4775688648223877, 'learning_rate': 0.006363636363636364, 'epoch': 0.23}\n",
            "{'loss': 2.1105, 'grad_norm': 10.876291275024414, 'learning_rate': 0.007272727272727273, 'epoch': 0.26}\n",
            "{'loss': 2.4495, 'grad_norm': 12.074249267578125, 'learning_rate': 0.008181818181818182, 'epoch': 0.29}\n",
            "{'loss': 2.4508, 'grad_norm': 7.516407012939453, 'learning_rate': 0.00909090909090909, 'epoch': 0.31}\n",
            "{'loss': 6.2159, 'grad_norm': 9.950382232666016, 'learning_rate': 0.01, 'epoch': 0.34}\n",
            "{'loss': 12.4963, 'grad_norm': 19.697444915771484, 'learning_rate': 0.009999082642158971, 'epoch': 0.37}\n",
            "{'loss': 10.1638, 'grad_norm': 22.669652938842773, 'learning_rate': 0.00999633090525405, 'epoch': 0.4}\n",
            "{'loss': 8.3375, 'grad_norm': 6.9918084144592285, 'learning_rate': 0.009991745799016205, 'epoch': 0.43}\n",
            "{'loss': 12.2938, 'grad_norm': 7.214596271514893, 'learning_rate': 0.009985329005918702, 'epoch': 0.46}\n",
            "{'loss': 13.9115, 'grad_norm': 8.380569458007812, 'learning_rate': 0.009977082880559724, 'epoch': 0.49}\n",
            "{'loss': 11.4104, 'grad_norm': 4.872331142425537, 'learning_rate': 0.009967010448798375, 'epoch': 0.51}\n",
            "{'loss': 9.5446, 'grad_norm': 4.7248029708862305, 'learning_rate': 0.009955115406644356, 'epoch': 0.54}\n",
            "{'loss': 9.106, 'grad_norm': 5.148559093475342, 'learning_rate': 0.009941402118901743, 'epoch': 0.57}\n",
            "{'loss': 8.5194, 'grad_norm': 4.864954471588135, 'learning_rate': 0.00992587561756735, 'epoch': 0.6}\n",
            "{'loss': 7.5527, 'grad_norm': 3.4612040519714355, 'learning_rate': 0.009908541599984276, 'epoch': 0.63}\n",
            "{'loss': 6.3746, 'grad_norm': 2.681631326675415, 'learning_rate': 0.009889406426751296, 'epoch': 0.66}\n",
            "{'loss': 6.3573, 'grad_norm': 1.9358649253845215, 'learning_rate': 0.009868477119388895, 'epoch': 0.69}\n",
            "{'loss': 5.7449, 'grad_norm': 2.1273598670959473, 'learning_rate': 0.009845761357762758, 'epoch': 0.71}\n",
            "{'loss': 5.4136, 'grad_norm': 8.367140769958496, 'learning_rate': 0.009821267477265706, 'epoch': 0.74}\n",
            "{'loss': 5.3816, 'grad_norm': 3.105698585510254, 'learning_rate': 0.009795004465759065, 'epoch': 0.77}\n",
            "{'loss': 5.0068, 'grad_norm': 1.695292353630066, 'learning_rate': 0.009766981960274652, 'epoch': 0.8}\n",
            "{'loss': 4.6219, 'grad_norm': 0.986676812171936, 'learning_rate': 0.009737210243478522, 'epoch': 0.83}\n",
            "{'loss': 4.3846, 'grad_norm': 0.97871333360672, 'learning_rate': 0.009705700239897808, 'epoch': 0.86}\n",
            "{'loss': 4.4818, 'grad_norm': 1.1072497367858887, 'learning_rate': 0.009672463511912055, 'epoch': 0.89}\n",
            "{'loss': 4.4475, 'grad_norm': 1.1389906406402588, 'learning_rate': 0.009637512255510475, 'epoch': 0.91}\n",
            "{'loss': 4.2058, 'grad_norm': 1.1316758394241333, 'learning_rate': 0.009600859295816708, 'epoch': 0.94}\n",
            "{'loss': 4.1269, 'grad_norm': 0.7016121745109558, 'learning_rate': 0.009562518082382749, 'epoch': 0.97}\n",
            "{'loss': 3.8847, 'grad_norm': 0.706536054611206, 'learning_rate': 0.00952250268425371, 'epoch': 1.0}\n",
            "{'loss': 3.6755, 'grad_norm': 0.2775759994983673, 'learning_rate': 0.009480827784805279, 'epoch': 1.03}\n",
            "{'loss': 3.6508, 'grad_norm': 0.5804733633995056, 'learning_rate': 0.009437508676355772, 'epoch': 1.06}\n",
            "{'loss': 3.6972, 'grad_norm': 0.9423337578773499, 'learning_rate': 0.009392561254554713, 'epoch': 1.09}\n",
            "{'loss': 3.5902, 'grad_norm': 0.8675497770309448, 'learning_rate': 0.009346002012550026, 'epoch': 1.11}\n",
            "{'loss': 3.477, 'grad_norm': 0.7091462016105652, 'learning_rate': 0.009297848034936006, 'epoch': 1.14}\n",
            "{'loss': 3.6254, 'grad_norm': 0.8736729025840759, 'learning_rate': 0.009248116991484227, 'epoch': 1.17}\n",
            "{'loss': 3.3697, 'grad_norm': 0.37598517537117004, 'learning_rate': 0.00919682713065975, 'epoch': 1.2}\n",
            "{'loss': 3.4571, 'grad_norm': 1.0033050775527954, 'learning_rate': 0.009143997272924973, 'epoch': 1.23}\n",
            "{'loss': 3.236, 'grad_norm': 0.37300506234169006, 'learning_rate': 0.009089646803833588, 'epoch': 1.26}\n",
            "{'loss': 3.2618, 'grad_norm': 0.6652799248695374, 'learning_rate': 0.00903379566691719, 'epoch': 1.29}\n",
            "{'loss': 3.1311, 'grad_norm': 0.37432244420051575, 'learning_rate': 0.008976464356367134, 'epoch': 1.31}\n",
            "{'loss': 3.1297, 'grad_norm': 0.5881084203720093, 'learning_rate': 0.00891767390951432, 'epoch': 1.34}\n",
            "{'loss': 3.0874, 'grad_norm': 0.37067148089408875, 'learning_rate': 0.008857445899109716, 'epoch': 1.37}\n",
            "{'loss': 3.0682, 'grad_norm': 0.38478565216064453, 'learning_rate': 0.008795802425408353, 'epoch': 1.4}\n",
            "{'loss': 2.9504, 'grad_norm': 0.4953271150588989, 'learning_rate': 0.008732766108059812, 'epoch': 1.43}\n",
            "{'loss': 2.8923, 'grad_norm': 5.767369270324707, 'learning_rate': 0.008668360077808093, 'epoch': 1.46}\n",
            "{'loss': 3.2157, 'grad_norm': 1.1597455739974976, 'learning_rate': 0.008602607968003936, 'epoch': 1.49}\n",
            "{'loss': 2.9478, 'grad_norm': 0.4218854308128357, 'learning_rate': 0.008535533905932738, 'epoch': 1.51}\n",
            "{'loss': 2.8567, 'grad_norm': 0.3611922860145569, 'learning_rate': 0.008467162503961208, 'epoch': 1.54}\n",
            "{'loss': 2.801, 'grad_norm': 0.2951056957244873, 'learning_rate': 0.008397518850506028, 'epoch': 1.57}\n",
            "{'loss': 2.8212, 'grad_norm': 0.32665005326271057, 'learning_rate': 0.008326628500827826, 'epoch': 1.6}\n",
            "{'loss': 2.8513, 'grad_norm': 0.36537790298461914, 'learning_rate': 0.008254517467653858, 'epoch': 1.63}\n",
            "{'loss': 2.8052, 'grad_norm': 0.366021990776062, 'learning_rate': 0.008181212211632798, 'epoch': 1.66}\n",
            "{'loss': 2.6942, 'grad_norm': 0.18329626321792603, 'learning_rate': 0.008106739631625216, 'epoch': 1.69}\n",
            "{'loss': 2.7452, 'grad_norm': 0.3158070147037506, 'learning_rate': 0.00803112705483319, 'epoch': 1.71}\n",
            "{'loss': 2.7316, 'grad_norm': 0.37066149711608887, 'learning_rate': 0.007954402226772803, 'epoch': 1.74}\n",
            "{'loss': 2.6908, 'grad_norm': 0.8363568186759949, 'learning_rate': 0.007876593301093103, 'epoch': 1.77}\n",
            "{'loss': 2.7138, 'grad_norm': 0.33947110176086426, 'learning_rate': 0.007797728829245321, 'epoch': 1.8}\n",
            "{'loss': 2.7334, 'grad_norm': 0.3647868037223816, 'learning_rate': 0.007717837750006106, 'epoch': 1.83}\n",
            "{'loss': 2.7317, 'grad_norm': 0.32030773162841797, 'learning_rate': 0.007636949378858646, 'epoch': 1.86}\n",
            "{'loss': 2.7136, 'grad_norm': 0.33376240730285645, 'learning_rate': 0.0075550933972355514, 'epoch': 1.89}\n",
            "{'loss': 2.599, 'grad_norm': 0.36578187346458435, 'learning_rate': 0.007472299841627451, 'epoch': 1.91}\n",
            "{'loss': 2.593, 'grad_norm': 0.25475117564201355, 'learning_rate': 0.0073885990925613146, 'epoch': 1.94}\n",
            "{'loss': 2.6093, 'grad_norm': 0.25981664657592773, 'learning_rate': 0.007304021863452525, 'epoch': 1.97}\n",
            "{'loss': 2.5699, 'grad_norm': 0.24558775126934052, 'learning_rate': 0.007218599189334799, 'epoch': 2.0}\n",
            "{'loss': 2.5122, 'grad_norm': 0.18896794319152832, 'learning_rate': 0.007132362415472099, 'epoch': 2.03}\n",
            "{'loss': 2.5091, 'grad_norm': 0.15823079645633698, 'learning_rate': 0.007045343185856701, 'epoch': 2.06}\n",
            "{'loss': 2.5367, 'grad_norm': 0.389404296875, 'learning_rate': 0.0069575734315976455, 'epoch': 2.09}\n",
            "{'loss': 2.4774, 'grad_norm': 0.2885155975818634, 'learning_rate': 0.006869085359203844, 'epoch': 2.11}\n",
            "{'loss': 2.4222, 'grad_norm': 0.2529257535934448, 'learning_rate': 0.006779911438766117, 'epoch': 2.14}\n",
            "{'loss': 2.4627, 'grad_norm': 0.311204195022583, 'learning_rate': 0.006690084392042514, 'epoch': 2.17}\n",
            "{'loss': 2.3963, 'grad_norm': 0.25161343812942505, 'learning_rate': 0.006599637180451295, 'epoch': 2.2}\n",
            "{'loss': 2.3575, 'grad_norm': 0.2776014506816864, 'learning_rate': 0.006508602992975962, 'epoch': 2.23}\n",
            "{'loss': 2.2862, 'grad_norm': 0.7198169231414795, 'learning_rate': 0.006417015233986786, 'epoch': 2.26}\n",
            "{'loss': 2.2592, 'grad_norm': 0.17315664887428284, 'learning_rate': 0.00632490751098331, 'epoch': 2.29}\n",
            "{'loss': 2.2074, 'grad_norm': 0.15471212565898895, 'learning_rate': 0.006232313622262297, 'epoch': 2.31}\n",
            "{'loss': 2.1972, 'grad_norm': 0.29056641459465027, 'learning_rate': 0.006139267544515689, 'epoch': 2.34}\n",
            "{'loss': 2.1838, 'grad_norm': 0.26225703954696655, 'learning_rate': 0.006045803420363084, 'epoch': 2.37}\n",
            "{'loss': 2.204, 'grad_norm': 0.4012642800807953, 'learning_rate': 0.005951955545823342, 'epoch': 2.4}\n",
            "{'loss': 2.1592, 'grad_norm': 0.4061194062232971, 'learning_rate': 0.005857758357729892, 'epoch': 2.43}\n",
            "{'loss': 2.0823, 'grad_norm': 0.3005290925502777, 'learning_rate': 0.0057632464210943726, 'epoch': 2.46}\n",
            "{'loss': 2.0743, 'grad_norm': 0.22171685099601746, 'learning_rate': 0.005668454416423242, 'epoch': 2.49}\n",
            "{'loss': 2.039, 'grad_norm': 0.7855501174926758, 'learning_rate': 0.0055734171269920035, 'epoch': 2.51}\n",
            "{'loss': 2.0792, 'grad_norm': 0.9377843141555786, 'learning_rate': 0.005478169426081711, 'epoch': 2.54}\n",
            "{'loss': 1.982, 'grad_norm': 53.58595657348633, 'learning_rate': 0.00538274626418248, 'epoch': 2.57}\n",
            "{'loss': 2.1625, 'grad_norm': 0.4869045913219452, 'learning_rate': 0.005287182656168617, 'epoch': 2.6}\n",
            "{'loss': 2.0521, 'grad_norm': 0.23561373353004456, 'learning_rate': 0.005191513668450177, 'epoch': 2.63}\n",
            "{'loss': 2.0449, 'grad_norm': 0.36150842905044556, 'learning_rate': 0.005095774406105571, 'epoch': 2.66}\n",
            "{'loss': 2.1118, 'grad_norm': 0.77519291639328, 'learning_rate': 0.005, 'epoch': 2.69}\n",
            "{'loss': 1.9557, 'grad_norm': 0.24636414647102356, 'learning_rate': 0.00490422559389443, 'epoch': 2.71}\n",
            "{'loss': 1.9249, 'grad_norm': 1.2258869409561157, 'learning_rate': 0.004808486331549823, 'epoch': 2.74}\n",
            "{'loss': 1.9388, 'grad_norm': 0.3184869885444641, 'learning_rate': 0.004712817343831384, 'epoch': 2.77}\n",
            "{'loss': 1.9312, 'grad_norm': 2.3453221321105957, 'learning_rate': 0.0046172537358175215, 'epoch': 2.8}\n",
            "{'loss': 1.9641, 'grad_norm': 1.3485889434814453, 'learning_rate': 0.004521830573918289, 'epoch': 2.83}\n",
            "{'loss': 1.9611, 'grad_norm': 0.3393351435661316, 'learning_rate': 0.0044265828730079984, 'epoch': 2.86}\n",
            "{'loss': 1.9397, 'grad_norm': 0.3120068609714508, 'learning_rate': 0.004331545583576757, 'epoch': 2.89}\n",
            "{'loss': 1.902, 'grad_norm': 0.18928678333759308, 'learning_rate': 0.004236753578905627, 'epoch': 2.91}\n",
            "{'loss': 1.9199, 'grad_norm': 0.2790687680244446, 'learning_rate': 0.004142241642270108, 'epoch': 2.94}\n",
            "{'loss': 1.9135, 'grad_norm': 0.7729037404060364, 'learning_rate': 0.004048044454176658, 'epoch': 2.97}\n",
            "{'loss': 1.8667, 'grad_norm': 0.2006930410861969, 'learning_rate': 0.0039541965796369176, 'epoch': 3.0}\n",
            "{'loss': 1.8571, 'grad_norm': 0.26996055245399475, 'learning_rate': 0.003860732455484313, 'epoch': 3.03}\n",
            "{'loss': 1.8396, 'grad_norm': 0.25569120049476624, 'learning_rate': 0.0037676863777377054, 'epoch': 3.06}\n",
            "{'loss': 1.8016, 'grad_norm': 0.14673249423503876, 'learning_rate': 0.0036750924890166926, 'epoch': 3.09}\n",
            "{'loss': 1.8313, 'grad_norm': 1.871271014213562, 'learning_rate': 0.0035829847660132147, 'epoch': 3.11}\n",
            "{'loss': 1.7804, 'grad_norm': 0.1430312693119049, 'learning_rate': 0.0034913970070240387, 'epoch': 3.14}\n",
            "{'loss': 1.777, 'grad_norm': 0.135570228099823, 'learning_rate': 0.003400362819548706, 'epoch': 3.17}\n",
            "{'loss': 1.7497, 'grad_norm': 0.13168972730636597, 'learning_rate': 0.003309915607957487, 'epoch': 3.2}\n",
            "{'loss': 1.744, 'grad_norm': 0.13655899465084076, 'learning_rate': 0.0032200885612338843, 'epoch': 3.23}\n",
            "{'loss': 1.7288, 'grad_norm': 0.11626484990119934, 'learning_rate': 0.0031309146407961564, 'epoch': 3.26}\n",
            "{'loss': 1.771, 'grad_norm': 1.2986811399459839, 'learning_rate': 0.0030424265684023555, 'epoch': 3.29}\n",
            "{'loss': 1.724, 'grad_norm': 0.12648199498653412, 'learning_rate': 0.0029546568141433005, 'epoch': 3.31}\n",
            "{'loss': 1.7376, 'grad_norm': 0.13384220004081726, 'learning_rate': 0.002867637584527901, 'epoch': 3.34}\n",
            "{'loss': 1.7137, 'grad_norm': 0.12947440147399902, 'learning_rate': 0.002781400810665201, 'epoch': 3.37}\n",
            "{'loss': 1.704, 'grad_norm': 0.16121940314769745, 'learning_rate': 0.0026959781365474755, 'epoch': 3.4}\n",
            "{'loss': 1.6786, 'grad_norm': 0.13720345497131348, 'learning_rate': 0.002611400907438685, 'epoch': 3.43}\n",
            "{'loss': 1.6703, 'grad_norm': 0.07898290455341339, 'learning_rate': 0.002527700158372548, 'epoch': 3.46}\n",
            "{'loss': 1.6675, 'grad_norm': 0.11500786244869232, 'learning_rate': 0.0024449066027644475, 'epoch': 3.49}\n",
            "{'loss': 1.6518, 'grad_norm': 0.10322480648756027, 'learning_rate': 0.002363050621141354, 'epoch': 3.51}\n",
            "{'loss': 1.633, 'grad_norm': 0.08750660717487335, 'learning_rate': 0.002282162249993895, 'epoch': 3.54}\n",
            "{'loss': 1.6453, 'grad_norm': 0.932433009147644, 'learning_rate': 0.00220227117075468, 'epoch': 3.57}\n",
            "{'loss': 1.6137, 'grad_norm': 0.07066971808671951, 'learning_rate': 0.002123406698906897, 'epoch': 3.6}\n",
            "{'loss': 1.6043, 'grad_norm': 30.003957748413086, 'learning_rate': 0.002045597773227199, 'epoch': 3.63}\n",
            "{'loss': 1.5963, 'grad_norm': 0.1287412941455841, 'learning_rate': 0.0019688729451668116, 'epoch': 3.66}\n",
            "{'loss': 1.5828, 'grad_norm': 0.12382068485021591, 'learning_rate': 0.0018932603683747857, 'epoch': 3.69}\n",
            "{'loss': 1.5732, 'grad_norm': 0.088368259370327, 'learning_rate': 0.0018187877883672021, 'epoch': 3.71}\n",
            "{'loss': 1.5804, 'grad_norm': 0.1249910518527031, 'learning_rate': 0.0017454825323461448, 'epoch': 3.74}\n",
            "{'loss': 1.5686, 'grad_norm': 0.09675870835781097, 'learning_rate': 0.0016733714991721738, 'epoch': 3.77}\n",
            "{'loss': 1.5545, 'grad_norm': 0.09971150755882263, 'learning_rate': 0.0016024811494939723, 'epoch': 3.8}\n",
            "{'loss': 1.5475, 'grad_norm': 0.10853297263383865, 'learning_rate': 0.001532837496038792, 'epoch': 3.83}\n",
            "{'loss': 1.5375, 'grad_norm': 0.0639328733086586, 'learning_rate': 0.0014644660940672626, 'epoch': 3.86}\n",
            "{'loss': 1.5328, 'grad_norm': 0.14794857800006866, 'learning_rate': 0.0013973920319960654, 'epoch': 3.89}\n",
            "{'loss': 1.5261, 'grad_norm': 0.14708155393600464, 'learning_rate': 0.0013316399221919074, 'epoch': 3.91}\n",
            "{'loss': 1.5123, 'grad_norm': 0.06857065856456757, 'learning_rate': 0.0012672338919401866, 'epoch': 3.94}\n",
            "{'loss': 1.5043, 'grad_norm': 0.06886033713817596, 'learning_rate': 0.0012041975745916472, 'epoch': 3.97}\n",
            "{'loss': 1.5373, 'grad_norm': 0.12730497121810913, 'learning_rate': 0.0011425541008902851, 'epoch': 4.0}\n",
            "{'loss': 1.4945, 'grad_norm': 0.09828527271747589, 'learning_rate': 0.001082326090485679, 'epoch': 4.03}\n",
            "{'loss': 1.5062, 'grad_norm': 0.09805078059434891, 'learning_rate': 0.0010235356436328674, 'epoch': 4.06}\n",
            "{'loss': 1.4786, 'grad_norm': 0.06701244413852692, 'learning_rate': 0.0009662043330828085, 'epoch': 4.09}\n",
            "{'loss': 1.4727, 'grad_norm': 0.055659569799900055, 'learning_rate': 0.0009103531961664119, 'epoch': 4.11}\n",
            "{'loss': 1.493, 'grad_norm': 0.10536576062440872, 'learning_rate': 0.0008560027270750276, 'epoch': 4.14}\n",
            "{'loss': 1.4646, 'grad_norm': 0.06844184547662735, 'learning_rate': 0.0008031728693402502, 'epoch': 4.17}\n",
            "{'loss': 1.4642, 'grad_norm': 0.07040298730134964, 'learning_rate': 0.0007518830085157735, 'epoch': 4.2}\n",
            "{'loss': 1.462, 'grad_norm': 0.08152750134468079, 'learning_rate': 0.0007021519650639951, 'epoch': 4.23}\n",
            "{'loss': 1.4521, 'grad_norm': 0.09187129139900208, 'learning_rate': 0.0006539979874499747, 'epoch': 4.26}\n",
            "{'loss': 1.4566, 'grad_norm': 0.07013708353042603, 'learning_rate': 0.000607438745445289, 'epoch': 4.29}\n",
            "{'loss': 1.4454, 'grad_norm': 0.0553586371243, 'learning_rate': 0.0005624913236442286, 'epoch': 4.31}\n",
            "{'loss': 1.4389, 'grad_norm': 0.06473860889673233, 'learning_rate': 0.0005191722151947225, 'epoch': 4.34}\n",
            "{'loss': 1.4358, 'grad_norm': 0.05748317018151283, 'learning_rate': 0.00047749731574629197, 'epoch': 4.37}\n",
            "{'loss': 1.4492, 'grad_norm': 0.07000581920146942, 'learning_rate': 0.00043748191761725007, 'epoch': 4.4}\n",
            "{'loss': 1.4313, 'grad_norm': 0.05632973462343216, 'learning_rate': 0.0003991407041832912, 'epoch': 4.43}\n",
            "{'loss': 1.4291, 'grad_norm': 0.05749412626028061, 'learning_rate': 0.0003624877444895269, 'epoch': 4.46}\n",
            "{'loss': 1.4308, 'grad_norm': 0.05845792591571808, 'learning_rate': 0.000327536488087945, 'epoch': 4.49}\n",
            "{'loss': 1.4236, 'grad_norm': 0.052068546414375305, 'learning_rate': 0.0002942997601021924, 'epoch': 4.51}\n",
            "{'loss': 1.4363, 'grad_norm': 0.06764800101518631, 'learning_rate': 0.00026278975652147874, 'epoch': 4.54}\n",
            "{'loss': 1.4225, 'grad_norm': 0.0557447224855423, 'learning_rate': 0.0002330180397253473, 'epoch': 4.57}\n",
            "{'loss': 1.4192, 'grad_norm': 0.0531352199614048, 'learning_rate': 0.00020499553424093485, 'epoch': 4.6}\n",
            "{'loss': 1.4138, 'grad_norm': 0.05690469220280647, 'learning_rate': 0.00017873252273429508, 'epoch': 4.63}\n",
            "{'loss': 1.4186, 'grad_norm': 0.04826560243964195, 'learning_rate': 0.00015423864223724048, 'epoch': 4.66}\n",
            "{'loss': 1.4137, 'grad_norm': 0.046256281435489655, 'learning_rate': 0.0001315228806111052, 'epoch': 4.69}\n",
            "{'loss': 1.419, 'grad_norm': 0.04576503485441208, 'learning_rate': 0.00011059357324870456, 'epoch': 4.71}\n",
            "{'loss': 1.4136, 'grad_norm': 0.04555777460336685, 'learning_rate': 9.145840001572537e-05, 'epoch': 4.74}\n",
            "{'loss': 1.4317, 'grad_norm': 0.059433866292238235, 'learning_rate': 7.41243824326504e-05, 'epoch': 4.77}\n",
            "{'loss': 1.4293, 'grad_norm': 0.06013276055455208, 'learning_rate': 5.859788109825792e-05, 'epoch': 4.8}\n",
            "{'loss': 1.4157, 'grad_norm': 0.04010764881968498, 'learning_rate': 4.48845933556441e-05, 'epoch': 4.83}\n",
            "{'loss': 1.4134, 'grad_norm': 0.05522267147898674, 'learning_rate': 3.2989551201624835e-05, 'epoch': 4.86}\n",
            "{'loss': 1.4186, 'grad_norm': 0.04071363806724548, 'learning_rate': 2.2917119440275525e-05, 'epoch': 4.89}\n",
            "{'loss': 1.4129, 'grad_norm': 0.04497969150543213, 'learning_rate': 1.4670994081297795e-05, 'epoch': 4.91}\n",
            "{'loss': 1.4265, 'grad_norm': 0.06267490237951279, 'learning_rate': 8.254200983794368e-06, 'epoch': 4.94}\n",
            "{'loss': 1.4417, 'grad_norm': 0.09234052151441574, 'learning_rate': 3.669094745950008e-06, 'epoch': 4.97}\n",
            "{'loss': 1.4405, 'grad_norm': 0.09511551260948181, 'learning_rate': 9.173578410281991e-07, 'epoch': 5.0}\n",
            "{'train_runtime': 20.9565, 'train_samples_per_second': 16.463, 'train_steps_per_second': 8.351, 'train_loss': 2.763708281687328, 'epoch': 5.0}\n",
            "100% 175/175 [00:20<00:00,  8.35it/s]\n",
            "Training complete.\n",
            "Model saved to loras/self-edit/training_set_iteration_1/44f52bb0/0\n",
            "Training on 250 examples for 3 epochs, lr: 0.001\n",
            "No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n",
            "Starting training...\n",
            "{'loss': 2.5665, 'grad_norm': 1.9509400129318237, 'learning_rate': 0.0, 'epoch': 0.01}\n",
            "{'loss': 2.5476, 'grad_norm': 1.996376872062683, 'learning_rate': 9.090909090909092e-05, 'epoch': 0.02}\n",
            "{'loss': 2.4515, 'grad_norm': 2.1817433834075928, 'learning_rate': 0.00018181818181818183, 'epoch': 0.02}\n",
            "{'loss': 3.6322, 'grad_norm': 14.001766204833984, 'learning_rate': 0.00027272727272727274, 'epoch': 0.03}\n",
            "{'loss': 0.9098, 'grad_norm': 0.274923712015152, 'learning_rate': 0.00036363636363636367, 'epoch': 0.04}\n",
            "{'loss': 2.0197, 'grad_norm': 13.538469314575195, 'learning_rate': 0.00045454545454545455, 'epoch': 0.05}\n",
            "{'loss': 0.8237, 'grad_norm': 0.29172948002815247, 'learning_rate': 0.0005454545454545455, 'epoch': 0.06}\n",
            "{'loss': 0.7261, 'grad_norm': 0.29898500442504883, 'learning_rate': 0.0006363636363636364, 'epoch': 0.06}\n",
            "{'loss': 0.6007, 'grad_norm': 0.2781522870063782, 'learning_rate': 0.0007272727272727273, 'epoch': 0.07}\n",
            "{'loss': 0.5008, 'grad_norm': 0.21337664127349854, 'learning_rate': 0.0008181818181818183, 'epoch': 0.08}\n",
            "{'loss': 0.4096, 'grad_norm': 0.19373396039009094, 'learning_rate': 0.0009090909090909091, 'epoch': 0.09}\n",
            "{'loss': 0.3229, 'grad_norm': 0.18487854301929474, 'learning_rate': 0.001, 'epoch': 0.1}\n",
            "{'loss': 0.2419, 'grad_norm': 0.16040173172950745, 'learning_rate': 0.0009999813776583146, 'epoch': 0.1}\n",
            "{'loss': 0.1934, 'grad_norm': 0.22141557931900024, 'learning_rate': 0.0009999255120204248, 'epoch': 0.11}\n",
            "{'loss': 0.1276, 'grad_norm': 0.2024843841791153, 'learning_rate': 0.0009998324072477264, 'epoch': 0.12}\n",
            "{'loss': 0.107, 'grad_norm': 0.11341504007577896, 'learning_rate': 0.0009997020702755353, 'epoch': 0.13}\n",
            "{'loss': 0.1262, 'grad_norm': 0.1711958944797516, 'learning_rate': 0.0009995345108125698, 'epoch': 0.14}\n",
            "{'loss': 0.1102, 'grad_norm': 0.09164190292358398, 'learning_rate': 0.0009993297413402281, 'epoch': 0.14}\n",
            "{'loss': 0.1462, 'grad_norm': 0.2505791187286377, 'learning_rate': 0.0009990877771116587, 'epoch': 0.15}\n",
            "{'loss': 0.1173, 'grad_norm': 0.6054385900497437, 'learning_rate': 0.0009988086361506238, 'epoch': 0.16}\n",
            "{'loss': 0.1403, 'grad_norm': 0.14331883192062378, 'learning_rate': 0.0009984923392501567, 'epoch': 0.17}\n",
            "{'loss': 0.174, 'grad_norm': 0.5379816293716431, 'learning_rate': 0.0009981389099710132, 'epoch': 0.18}\n",
            "{'loss': 0.1325, 'grad_norm': 0.4085267186164856, 'learning_rate': 0.0009977483746399167, 'epoch': 0.18}\n",
            "{'loss': 0.1098, 'grad_norm': 0.1417696177959442, 'learning_rate': 0.0009973207623475964, 'epoch': 0.19}\n",
            "{'loss': 0.1152, 'grad_norm': 0.20360249280929565, 'learning_rate': 0.0009968561049466214, 'epoch': 0.2}\n",
            "{'loss': 0.1461, 'grad_norm': 0.20058415830135345, 'learning_rate': 0.000996354437049027, 'epoch': 0.21}\n",
            "{'loss': 0.1042, 'grad_norm': 0.069297194480896, 'learning_rate': 0.0009958157960237375, 'epoch': 0.22}\n",
            "{'loss': 0.0966, 'grad_norm': 0.0661221519112587, 'learning_rate': 0.0009952402219937815, 'epoch': 0.22}\n",
            "{'loss': 0.1052, 'grad_norm': 0.1254531592130661, 'learning_rate': 0.0009946277578333045, 'epoch': 0.23}\n",
            "{'loss': 0.1189, 'grad_norm': 0.12189889699220657, 'learning_rate': 0.0009939784491643732, 'epoch': 0.24}\n",
            "{'loss': 0.1154, 'grad_norm': 0.09294037520885468, 'learning_rate': 0.0009932923443535797, 'epoch': 0.25}\n",
            "{'loss': 0.107, 'grad_norm': 0.05901477113366127, 'learning_rate': 0.000992569494508437, 'epoch': 0.26}\n",
            "{'loss': 0.1173, 'grad_norm': 0.0680423453450203, 'learning_rate': 0.0009918099534735718, 'epoch': 0.26}\n",
            "{'loss': 0.1049, 'grad_norm': 0.0973038524389267, 'learning_rate': 0.0009910137778267152, 'epoch': 0.27}\n",
            "{'loss': 0.0931, 'grad_norm': 0.08089791983366013, 'learning_rate': 0.0009901810268744867, 'epoch': 0.28}\n",
            "{'loss': 0.0913, 'grad_norm': 0.059649333357810974, 'learning_rate': 0.0009893117626479776, 'epoch': 0.29}\n",
            "{'loss': 0.0833, 'grad_norm': 0.060450926423072815, 'learning_rate': 0.0009884060498981295, 'epoch': 0.3}\n",
            "{'loss': 0.0793, 'grad_norm': 0.08254130184650421, 'learning_rate': 0.0009874639560909118, 'epoch': 0.3}\n",
            "{'loss': 0.0769, 'grad_norm': 0.07809055596590042, 'learning_rate': 0.0009864855514022954, 'epoch': 0.31}\n",
            "{'loss': 0.0668, 'grad_norm': 0.06858183443546295, 'learning_rate': 0.000985470908713026, 'epoch': 0.32}\n",
            "{'loss': 0.0545, 'grad_norm': 0.04612034931778908, 'learning_rate': 0.0009844201036031952, 'epoch': 0.33}\n",
            "{'loss': 0.0841, 'grad_norm': 0.09125059098005295, 'learning_rate': 0.0009833332143466098, 'epoch': 0.34}\n",
            "{'loss': 0.0633, 'grad_norm': 0.06847044825553894, 'learning_rate': 0.0009822103219049626, 'epoch': 0.34}\n",
            "{'loss': 0.0639, 'grad_norm': 0.08950985968112946, 'learning_rate': 0.0009810515099218002, 'epoch': 0.35}\n",
            "{'loss': 0.0644, 'grad_norm': 0.05597555637359619, 'learning_rate': 0.0009798568647162937, 'epoch': 0.36}\n",
            "{'loss': 0.055, 'grad_norm': 0.07715335488319397, 'learning_rate': 0.000978626475276808, 'epoch': 0.37}\n",
            "{'loss': 0.0542, 'grad_norm': 0.05022798851132393, 'learning_rate': 0.0009773604332542728, 'epoch': 0.38}\n",
            "{'loss': 0.0797, 'grad_norm': 0.09050104767084122, 'learning_rate': 0.0009760588329553571, 'epoch': 0.38}\n",
            "{'loss': 0.0605, 'grad_norm': 0.06781982630491257, 'learning_rate': 0.0009747217713354427, 'epoch': 0.39}\n",
            "{'loss': 0.0707, 'grad_norm': 0.07923895865678787, 'learning_rate': 0.000973349347991403, 'epoch': 0.4}\n",
            "{'loss': 0.0659, 'grad_norm': 0.07683028280735016, 'learning_rate': 0.0009719416651541838, 'epoch': 0.41}\n",
            "{'loss': 0.0656, 'grad_norm': 0.07027646899223328, 'learning_rate': 0.0009704988276811882, 'epoch': 0.42}\n",
            "{'loss': 0.0688, 'grad_norm': 0.07227003574371338, 'learning_rate': 0.000969020943048466, 'epoch': 0.42}\n",
            "{'loss': 0.0577, 'grad_norm': 0.04286564886569977, 'learning_rate': 0.0009675081213427075, 'epoch': 0.43}\n",
            "{'loss': 0.059, 'grad_norm': 0.04542744904756546, 'learning_rate': 0.0009659604752530434, 'epoch': 0.44}\n",
            "{'loss': 0.0524, 'grad_norm': 0.044208694249391556, 'learning_rate': 0.0009643781200626511, 'epoch': 0.45}\n",
            "{'loss': 0.0606, 'grad_norm': 0.060591232031583786, 'learning_rate': 0.0009627611736401667, 'epoch': 0.46}\n",
            "{'loss': 0.0545, 'grad_norm': 0.05508186295628548, 'learning_rate': 0.0009611097564309052, 'epoch': 0.46}\n",
            "{'loss': 0.0543, 'grad_norm': 0.049437787383794785, 'learning_rate': 0.0009594239914478886, 'epoch': 0.47}\n",
            "{'loss': 0.059, 'grad_norm': 0.04806055873632431, 'learning_rate': 0.0009577040042626832, 'epoch': 0.48}\n",
            "{'loss': 0.0426, 'grad_norm': 0.054589223116636276, 'learning_rate': 0.0009559499229960451, 'epoch': 0.49}\n",
            "{'loss': 0.0596, 'grad_norm': 0.09323544055223465, 'learning_rate': 0.000954161878308377, 'epoch': 0.5}\n",
            "{'loss': 0.0525, 'grad_norm': 0.08067356795072556, 'learning_rate': 0.0009523400033899956, 'epoch': 0.5}\n",
            "{'loss': 0.0376, 'grad_norm': 0.05366262048482895, 'learning_rate': 0.0009504844339512095, 'epoch': 0.51}\n",
            "{'loss': 0.0468, 'grad_norm': 0.05283346772193909, 'learning_rate': 0.0009485953082122116, 'epoch': 0.52}\n",
            "{'loss': 0.0647, 'grad_norm': 0.08128848671913147, 'learning_rate': 0.0009466727668927816, 'epoch': 0.53}\n",
            "{'loss': 0.0559, 'grad_norm': 0.04613122344017029, 'learning_rate': 0.000944716953201805, 'epoch': 0.54}\n",
            "{'loss': 0.0407, 'grad_norm': 0.042240358889102936, 'learning_rate': 0.0009427280128266049, 'epoch': 0.54}\n",
            "{'loss': 0.0451, 'grad_norm': 0.04968243092298508, 'learning_rate': 0.0009407060939220907, 'epoch': 0.55}\n",
            "{'loss': 0.0685, 'grad_norm': 0.05652259662747383, 'learning_rate': 0.000938651347099721, 'epoch': 0.56}\n",
            "{'loss': 0.0582, 'grad_norm': 0.2563461661338806, 'learning_rate': 0.0009365639254162854, 'epoch': 0.57}\n",
            "{'loss': 0.053, 'grad_norm': 0.041997719556093216, 'learning_rate': 0.0009344439843625034, 'epoch': 0.58}\n",
            "{'loss': 0.0777, 'grad_norm': 0.24242213368415833, 'learning_rate': 0.0009322916818514413, 'epoch': 0.58}\n",
            "{'loss': 0.0543, 'grad_norm': 0.03203805163502693, 'learning_rate': 0.0009301071782067504, 'epoch': 0.59}\n",
            "{'loss': 0.0566, 'grad_norm': 0.05238569527864456, 'learning_rate': 0.0009278906361507238, 'epoch': 0.6}\n",
            "{'loss': 0.0469, 'grad_norm': 0.03123827837407589, 'learning_rate': 0.0009256422207921756, 'epoch': 0.61}\n",
            "{'loss': 0.0571, 'grad_norm': 0.046699874103069305, 'learning_rate': 0.0009233620996141421, 'epoch': 0.62}\n",
            "{'loss': 0.0407, 'grad_norm': 0.03792277351021767, 'learning_rate': 0.0009210504424614059, 'epoch': 0.62}\n",
            "{'loss': 0.045, 'grad_norm': 0.03699639067053795, 'learning_rate': 0.0009187074215278444, 'epoch': 0.63}\n",
            "{'loss': 0.0382, 'grad_norm': 0.040777552872896194, 'learning_rate': 0.0009163332113436032, 'epoch': 0.64}\n",
            "{'loss': 0.055, 'grad_norm': 0.05898863077163696, 'learning_rate': 0.0009139279887620955, 'epoch': 0.65}\n",
            "{'loss': 0.0434, 'grad_norm': 0.047220103442668915, 'learning_rate': 0.0009114919329468282, 'epoch': 0.66}\n",
            "{'loss': 0.0342, 'grad_norm': 0.053833283483982086, 'learning_rate': 0.0009090252253580565, 'epoch': 0.66}\n",
            "{'loss': 0.0435, 'grad_norm': 0.04988204687833786, 'learning_rate': 0.0009065280497392663, 'epoch': 0.67}\n",
            "{'loss': 0.0491, 'grad_norm': 0.05138235539197922, 'learning_rate': 0.0009040005921034883, 'epoch': 0.68}\n",
            "{'loss': 0.0452, 'grad_norm': 0.06905630230903625, 'learning_rate': 0.0009014430407194413, 'epoch': 0.69}\n",
            "{'loss': 0.0355, 'grad_norm': 0.0625533014535904, 'learning_rate': 0.0008988555860975081, 'epoch': 0.7}\n",
            "{'loss': 0.0612, 'grad_norm': 0.08273851126432419, 'learning_rate': 0.0008962384209755452, 'epoch': 0.7}\n",
            "{'loss': 0.0479, 'grad_norm': 0.057264313101768494, 'learning_rate': 0.000893591740304525, 'epoch': 0.71}\n",
            "{'loss': 0.0577, 'grad_norm': 0.08110925555229187, 'learning_rate': 0.000890915741234015, 'epoch': 0.72}\n",
            "{'loss': 0.0341, 'grad_norm': 0.061251260340213776, 'learning_rate': 0.0008882106230974909, 'epoch': 0.73}\n",
            "{'loss': 0.0595, 'grad_norm': 0.07505261898040771, 'learning_rate': 0.0008854765873974899, 'epoch': 0.74}\n",
            "{'loss': 0.045, 'grad_norm': 0.046505678445100784, 'learning_rate': 0.0008827138377905998, 'epoch': 0.74}\n",
            "{'loss': 0.0486, 'grad_norm': 0.10108454525470734, 'learning_rate': 0.0008799225800722895, 'epoch': 0.75}\n",
            "{'loss': 0.0487, 'grad_norm': 0.053457245230674744, 'learning_rate': 0.0008771030221615785, 'epoch': 0.76}\n",
            "{'loss': 0.038, 'grad_norm': 0.04135006666183472, 'learning_rate': 0.0008742553740855505, 'epoch': 0.77}\n",
            "{'loss': 0.0331, 'grad_norm': 0.03917704150080681, 'learning_rate': 0.0008713798479637072, 'epoch': 0.78}\n",
            "{'loss': 0.0492, 'grad_norm': 0.12902775406837463, 'learning_rate': 0.0008684766579921683, 'epoch': 0.78}\n",
            "{'loss': 0.0455, 'grad_norm': 0.08230173587799072, 'learning_rate': 0.0008655460204277166, 'epoch': 0.79}\n",
            "{'loss': 0.0523, 'grad_norm': 0.08598536252975464, 'learning_rate': 0.0008625881535716883, 'epoch': 0.8}\n",
            "{'loss': 0.0538, 'grad_norm': 0.06621865183115005, 'learning_rate': 0.0008596032777537123, 'epoch': 0.81}\n",
            "{'loss': 0.0413, 'grad_norm': 0.03943479806184769, 'learning_rate': 0.0008565916153152981, 'epoch': 0.82}\n",
            "{'loss': 0.0325, 'grad_norm': 0.04471590369939804, 'learning_rate': 0.0008535533905932737, 'epoch': 0.82}\n",
            "{'loss': 0.0384, 'grad_norm': 0.03763299435377121, 'learning_rate': 0.0008504888299030747, 'epoch': 0.83}\n",
            "{'loss': 0.0444, 'grad_norm': 0.03709616884589195, 'learning_rate': 0.0008473981615218862, 'epoch': 0.84}\n",
            "{'loss': 0.0512, 'grad_norm': 0.04257385805249214, 'learning_rate': 0.0008442816156716386, 'epoch': 0.85}\n",
            "{'loss': 0.0406, 'grad_norm': 0.03049798682332039, 'learning_rate': 0.0008411394245018588, 'epoch': 0.86}\n",
            "{'loss': 0.0462, 'grad_norm': 0.048172980546951294, 'learning_rate': 0.0008379718220723773, 'epoch': 0.86}\n",
            "{'loss': 0.0571, 'grad_norm': 0.052323415875434875, 'learning_rate': 0.0008347790443358929, 'epoch': 0.87}\n",
            "{'loss': 0.0367, 'grad_norm': 0.03685518726706505, 'learning_rate': 0.0008315613291203976, 'epoch': 0.88}\n",
            "{'loss': 0.0503, 'grad_norm': 0.05240253359079361, 'learning_rate': 0.0008283189161114601, 'epoch': 0.89}\n",
            "{'loss': 0.0438, 'grad_norm': 0.04212407022714615, 'learning_rate': 0.000825052046834372, 'epoch': 0.9}\n",
            "{'loss': 0.0503, 'grad_norm': 0.04311520978808403, 'learning_rate': 0.0008217609646361573, 'epoch': 0.9}\n",
            "{'loss': 0.0515, 'grad_norm': 0.058047160506248474, 'learning_rate': 0.0008184459146674447, 'epoch': 0.91}\n",
            "{'loss': 0.0472, 'grad_norm': 0.054865140467882156, 'learning_rate': 0.0008151071438642068, 'epoch': 0.92}\n",
            "{'loss': 0.056, 'grad_norm': 0.0756087526679039, 'learning_rate': 0.0008117449009293668, 'epoch': 0.93}\n",
            "{'loss': 0.0628, 'grad_norm': 0.06988260895013809, 'learning_rate': 0.0008083594363142716, 'epoch': 0.94}\n",
            "{'loss': 0.0469, 'grad_norm': 0.07930245995521545, 'learning_rate': 0.0008049510022000364, 'epoch': 0.94}\n",
            "{'loss': 0.0487, 'grad_norm': 0.047369807958602905, 'learning_rate': 0.0008015198524787601, 'epoch': 0.95}\n",
            "{'loss': 0.0362, 'grad_norm': 0.03693088889122009, 'learning_rate': 0.0007980662427346127, 'epoch': 0.96}\n",
            "{'loss': 0.0394, 'grad_norm': 0.04531088471412659, 'learning_rate': 0.0007945904302247968, 'epoch': 0.97}\n",
            "{'loss': 0.0434, 'grad_norm': 0.04064812883734703, 'learning_rate': 0.0007910926738603854, 'epoch': 0.98}\n",
            "{'loss': 0.05, 'grad_norm': 0.0709369108080864, 'learning_rate': 0.0007875732341870349, 'epoch': 0.98}\n",
            "{'loss': 0.0512, 'grad_norm': 0.0895075723528862, 'learning_rate': 0.0007840323733655779, 'epoch': 0.99}\n",
            "{'loss': 0.0536, 'grad_norm': 0.06188540160655975, 'learning_rate': 0.0007804703551524948, 'epoch': 1.0}\n",
            "{'loss': 0.0462, 'grad_norm': 0.060701899230480194, 'learning_rate': 0.0007768874448802665, 'epoch': 1.01}\n",
            "{'loss': 0.0344, 'grad_norm': 0.034690890461206436, 'learning_rate': 0.0007732839094376105, 'epoch': 1.02}\n",
            "{'loss': 0.033, 'grad_norm': 0.04330513998866081, 'learning_rate': 0.0007696600172495997, 'epoch': 1.02}\n",
            "{'loss': 0.0416, 'grad_norm': 0.06628140062093735, 'learning_rate': 0.0007660160382576683, 'epoch': 1.03}\n",
            "{'loss': 0.0522, 'grad_norm': 0.039199937134981155, 'learning_rate': 0.000762352243899504, 'epoch': 1.04}\n",
            "{'loss': 0.0399, 'grad_norm': 0.06436163187026978, 'learning_rate': 0.0007586689070888284, 'epoch': 1.05}\n",
            "{'loss': 0.0376, 'grad_norm': 0.03326388821005821, 'learning_rate': 0.000754966302195068, 'epoch': 1.06}\n",
            "{'loss': 0.0466, 'grad_norm': 0.22759786248207092, 'learning_rate': 0.0007512447050229165, 'epoch': 1.06}\n",
            "{'loss': 0.0375, 'grad_norm': 0.033143289387226105, 'learning_rate': 0.0007475043927917907, 'epoch': 1.07}\n",
            "{'loss': 0.0436, 'grad_norm': 0.081292524933815, 'learning_rate': 0.00074374564411518, 'epoch': 1.08}\n",
            "{'loss': 0.0449, 'grad_norm': 0.05998510122299194, 'learning_rate': 0.0007399687389798933, 'epoch': 1.09}\n",
            "{'loss': 0.0341, 'grad_norm': 0.051888324320316315, 'learning_rate': 0.0007361739587252019, 'epoch': 1.1}\n",
            "{'loss': 0.0325, 'grad_norm': 0.04631279408931732, 'learning_rate': 0.0007323615860218843, 'epoch': 1.1}\n",
            "{'loss': 0.0337, 'grad_norm': 0.032559555023908615, 'learning_rate': 0.000728531904851169, 'epoch': 1.11}\n",
            "{'loss': 0.0419, 'grad_norm': 0.06632743030786514, 'learning_rate': 0.0007246852004835807, 'epoch': 1.12}\n",
            "{'loss': 0.0374, 'grad_norm': 0.03855524957180023, 'learning_rate': 0.0007208217594576922, 'epoch': 1.13}\n",
            "{'loss': 0.0246, 'grad_norm': 0.03662220016121864, 'learning_rate': 0.0007169418695587791, 'epoch': 1.14}\n",
            "{'loss': 0.0485, 'grad_norm': 0.04862547665834427, 'learning_rate': 0.0007130458197973828, 'epoch': 1.14}\n",
            "{'loss': 0.0426, 'grad_norm': 0.04307984933257103, 'learning_rate': 0.0007091339003877826, 'epoch': 1.15}\n",
            "{'loss': 0.0428, 'grad_norm': 0.062149956822395325, 'learning_rate': 0.0007052064027263785, 'epoch': 1.16}\n",
            "{'loss': 0.0386, 'grad_norm': 0.03965204209089279, 'learning_rate': 0.0007012636193699837, 'epoch': 1.17}\n",
            "{'loss': 0.047, 'grad_norm': 0.04515772685408592, 'learning_rate': 0.0006973058440140341, 'epoch': 1.18}\n",
            "{'loss': 0.0384, 'grad_norm': 0.045660268515348434, 'learning_rate': 0.0006933333714707094, 'epoch': 1.18}\n",
            "{'loss': 0.0383, 'grad_norm': 0.04428654909133911, 'learning_rate': 0.0006893464976469738, 'epoch': 1.19}\n",
            "{'loss': 0.0348, 'grad_norm': 0.0641777366399765, 'learning_rate': 0.0006853455195225339, 'epoch': 1.2}\n",
            "{'loss': 0.0468, 'grad_norm': 0.06633547693490982, 'learning_rate': 0.000681330735127716, 'epoch': 1.21}\n",
            "{'loss': 0.0281, 'grad_norm': 0.03727198392152786, 'learning_rate': 0.0006773024435212678, 'epoch': 1.22}\n",
            "{'loss': 0.0231, 'grad_norm': 0.0358891561627388, 'learning_rate': 0.00067326094476808, 'epoch': 1.22}\n",
            "{'loss': 0.0396, 'grad_norm': 0.05207749083638191, 'learning_rate': 0.0006692065399168352, 'epoch': 1.23}\n",
            "{'loss': 0.026, 'grad_norm': 0.03370264545083046, 'learning_rate': 0.0006651395309775837, 'epoch': 1.24}\n",
            "{'loss': 0.0402, 'grad_norm': 0.06652317941188812, 'learning_rate': 0.0006610602208992453, 'epoch': 1.25}\n",
            "{'loss': 0.0345, 'grad_norm': 0.042770855128765106, 'learning_rate': 0.000656968913547045, 'epoch': 1.26}\n",
            "{'loss': 0.0405, 'grad_norm': 0.027857841923832893, 'learning_rate': 0.0006528659136798764, 'epoch': 1.26}\n",
            "{'loss': 0.0398, 'grad_norm': 0.051363661885261536, 'learning_rate': 0.0006487515269276015, 'epoch': 1.27}\n",
            "{'loss': 0.0332, 'grad_norm': 0.10746639221906662, 'learning_rate': 0.0006446260597682839, 'epoch': 1.28}\n",
            "{'loss': 0.0547, 'grad_norm': 0.04498382657766342, 'learning_rate': 0.0006404898195053597, 'epoch': 1.29}\n",
            "{'loss': 0.0359, 'grad_norm': 0.04132302105426788, 'learning_rate': 0.0006363431142447468, 'epoch': 1.3}\n",
            "{'loss': 0.0374, 'grad_norm': 0.033768873661756516, 'learning_rate': 0.0006321862528718945, 'epoch': 1.3}\n",
            "{'loss': 0.0345, 'grad_norm': 0.04383179917931557, 'learning_rate': 0.0006280195450287736, 'epoch': 1.31}\n",
            "{'loss': 0.0409, 'grad_norm': 0.03982057049870491, 'learning_rate': 0.000623843301090813, 'epoch': 1.32}\n",
            "{'loss': 0.0378, 'grad_norm': 0.04364291578531265, 'learning_rate': 0.0006196578321437789, 'epoch': 1.33}\n",
            "{'loss': 0.0318, 'grad_norm': 0.02914765104651451, 'learning_rate': 0.0006154634499606029, 'epoch': 1.34}\n",
            "{'loss': 0.0406, 'grad_norm': 0.05049699917435646, 'learning_rate': 0.0006112604669781572, 'epoch': 1.34}\n",
            "{'loss': 0.0461, 'grad_norm': 0.07385257631540298, 'learning_rate': 0.000607049196273983, 'epoch': 1.35}\n",
            "{'loss': 0.0279, 'grad_norm': 0.1171673834323883, 'learning_rate': 0.0006028299515429683, 'epoch': 1.36}\n",
            "{'loss': 0.0423, 'grad_norm': 0.040432240813970566, 'learning_rate': 0.0005986030470739811, 'epoch': 1.37}\n",
            "{'loss': 0.0462, 'grad_norm': 0.03808748722076416, 'learning_rate': 0.0005943687977264583, 'epoch': 1.38}\n",
            "{'loss': 0.0279, 'grad_norm': 0.04956631734967232, 'learning_rate': 0.000590127518906953, 'epoch': 1.38}\n",
            "{'loss': 0.044, 'grad_norm': 0.042174018919467926, 'learning_rate': 0.0005858795265456381, 'epoch': 1.39}\n",
            "{'loss': 0.0555, 'grad_norm': 0.042539939284324646, 'learning_rate': 0.0005816251370727748, 'epoch': 1.4}\n",
            "{'loss': 0.036, 'grad_norm': 0.04529274255037308, 'learning_rate': 0.0005773646673951406, 'epoch': 1.41}\n",
            "{'loss': 0.043, 'grad_norm': 0.03991679474711418, 'learning_rate': 0.0005730984348724242, 'epoch': 1.42}\n",
            "{'loss': 0.0484, 'grad_norm': 0.09358622878789902, 'learning_rate': 0.0005688267572935842, 'epoch': 1.42}\n",
            "{'loss': 0.0415, 'grad_norm': 0.05086303874850273, 'learning_rate': 0.0005645499528531784, 'epoch': 1.43}\n",
            "{'loss': 0.034, 'grad_norm': 0.030686277896165848, 'learning_rate': 0.0005602683401276614, 'epoch': 1.44}\n",
            "{'loss': 0.0274, 'grad_norm': 0.03217245638370514, 'learning_rate': 0.0005559822380516539, 'epoch': 1.45}\n",
            "{'loss': 0.0325, 'grad_norm': 0.03327067941427231, 'learning_rate': 0.000551691965894185, 'epoch': 1.46}\n",
            "{'loss': 0.0322, 'grad_norm': 0.04309355095028877, 'learning_rate': 0.0005473978432349112, 'epoch': 1.46}\n",
            "{'loss': 0.0357, 'grad_norm': 0.029657967388629913, 'learning_rate': 0.0005431001899403097, 'epoch': 1.47}\n",
            "{'loss': 0.0422, 'grad_norm': 0.04041197896003723, 'learning_rate': 0.0005387993261398532, 'epoch': 1.48}\n",
            "{'loss': 0.0383, 'grad_norm': 0.030094388872385025, 'learning_rate': 0.0005344955722021623, 'epoch': 1.49}\n",
            "{'loss': 0.0386, 'grad_norm': 0.05254252254962921, 'learning_rate': 0.0005301892487111431, 'epoch': 1.5}\n",
            "{'loss': 0.0273, 'grad_norm': 0.029796646907925606, 'learning_rate': 0.0005258806764421047, 'epoch': 1.5}\n",
            "{'loss': 0.0208, 'grad_norm': 0.035640813410282135, 'learning_rate': 0.0005215701763378673, 'epoch': 1.51}\n",
            "{'loss': 0.0305, 'grad_norm': 0.029878905043005943, 'learning_rate': 0.0005172580694848541, 'epoch': 1.52}\n",
            "{'loss': 0.0236, 'grad_norm': 0.027692146599292755, 'learning_rate': 0.0005129446770891738, 'epoch': 1.53}\n",
            "{'loss': 0.0298, 'grad_norm': 0.0589413084089756, 'learning_rate': 0.0005086303204526943, 'epoch': 1.54}\n",
            "{'loss': 0.0519, 'grad_norm': 0.04576193168759346, 'learning_rate': 0.0005043153209491095, 'epoch': 1.54}\n",
            "{'loss': 0.0211, 'grad_norm': 0.020834360271692276, 'learning_rate': 0.0005, 'epoch': 1.55}\n",
            "{'loss': 0.0336, 'grad_norm': 0.02638666145503521, 'learning_rate': 0.0004956846790508906, 'epoch': 1.56}\n",
            "{'loss': 0.0354, 'grad_norm': 0.03243497759103775, 'learning_rate': 0.0004913696795473058, 'epoch': 1.57}\n",
            "{'loss': 0.0217, 'grad_norm': 0.03610800951719284, 'learning_rate': 0.0004870553229108264, 'epoch': 1.58}\n",
            "{'loss': 0.0349, 'grad_norm': 0.03027985990047455, 'learning_rate': 0.0004827419305151461, 'epoch': 1.58}\n",
            "{'loss': 0.0404, 'grad_norm': 0.040826745331287384, 'learning_rate': 0.00047842982366213274, 'epoch': 1.59}\n",
            "{'loss': 0.0322, 'grad_norm': 0.03332851827144623, 'learning_rate': 0.0004741193235578952, 'epoch': 1.6}\n",
            "{'loss': 0.0305, 'grad_norm': 0.029187142848968506, 'learning_rate': 0.0004698107512888569, 'epoch': 1.61}\n",
            "{'loss': 0.0261, 'grad_norm': 0.0238957479596138, 'learning_rate': 0.0004655044277978375, 'epoch': 1.62}\n",
            "{'loss': 0.0269, 'grad_norm': 0.037846241146326065, 'learning_rate': 0.0004612006738601469, 'epoch': 1.62}\n",
            "{'loss': 0.0271, 'grad_norm': 0.049601148813962936, 'learning_rate': 0.00045689981005969026, 'epoch': 1.63}\n",
            "{'loss': 0.0352, 'grad_norm': 0.03152813762426376, 'learning_rate': 0.00045260215676508895, 'epoch': 1.64}\n",
            "{'loss': 0.0323, 'grad_norm': 0.04135900363326073, 'learning_rate': 0.000448308034105815, 'epoch': 1.65}\n",
            "{'loss': 0.0303, 'grad_norm': 0.042408671230077744, 'learning_rate': 0.0004440177619483461, 'epoch': 1.66}\n",
            "{'loss': 0.0534, 'grad_norm': 0.06559509038925171, 'learning_rate': 0.00043973165987233853, 'epoch': 1.66}\n",
            "{'loss': 0.0308, 'grad_norm': 0.028987828642129898, 'learning_rate': 0.0004354500471468217, 'epoch': 1.67}\n",
            "{'loss': 0.0314, 'grad_norm': 0.034489355981349945, 'learning_rate': 0.00043117324270641603, 'epoch': 1.68}\n",
            "{'loss': 0.0408, 'grad_norm': 0.05253983289003372, 'learning_rate': 0.00042690156512757607, 'epoch': 1.69}\n",
            "{'loss': 0.0264, 'grad_norm': 0.02656593918800354, 'learning_rate': 0.0004226353326048593, 'epoch': 1.7}\n",
            "{'loss': 0.0298, 'grad_norm': 0.03894497826695442, 'learning_rate': 0.00041837486292722534, 'epoch': 1.7}\n",
            "{'loss': 0.0387, 'grad_norm': 0.02983788773417473, 'learning_rate': 0.00041412047345436195, 'epoch': 1.71}\n",
            "{'loss': 0.0256, 'grad_norm': 0.022988177835941315, 'learning_rate': 0.00040987248109304716, 'epoch': 1.72}\n",
            "{'loss': 0.0277, 'grad_norm': 0.0177913848310709, 'learning_rate': 0.0004056312022735417, 'epoch': 1.73}\n",
            "{'loss': 0.0344, 'grad_norm': 0.021078940480947495, 'learning_rate': 0.000401396952926019, 'epoch': 1.74}\n",
            "{'loss': 0.0194, 'grad_norm': 0.018454724922776222, 'learning_rate': 0.00039717004845703176, 'epoch': 1.74}\n",
            "{'loss': 0.036, 'grad_norm': 0.023949138820171356, 'learning_rate': 0.000392950803726017, 'epoch': 1.75}\n",
            "{'loss': 0.0198, 'grad_norm': 0.021090423688292503, 'learning_rate': 0.00038873953302184284, 'epoch': 1.76}\n",
            "{'loss': 0.0226, 'grad_norm': 0.022361135110259056, 'learning_rate': 0.0003845365500393974, 'epoch': 1.77}\n",
            "{'loss': 0.0436, 'grad_norm': 0.03031732141971588, 'learning_rate': 0.00038034216785622126, 'epoch': 1.78}\n",
            "{'loss': 0.0266, 'grad_norm': 0.02116701938211918, 'learning_rate': 0.00037615669890918703, 'epoch': 1.78}\n",
            "{'loss': 0.0523, 'grad_norm': 0.03589257970452309, 'learning_rate': 0.00037198045497122644, 'epoch': 1.79}\n",
            "{'loss': 0.0351, 'grad_norm': 0.027688296511769295, 'learning_rate': 0.00036781374712810557, 'epoch': 1.8}\n",
            "{'loss': 0.0318, 'grad_norm': 0.029689250513911247, 'learning_rate': 0.0003636568857552531, 'epoch': 1.81}\n",
            "{'loss': 0.0354, 'grad_norm': 0.022617217153310776, 'learning_rate': 0.0003595101804946404, 'epoch': 1.82}\n",
            "{'loss': 0.0329, 'grad_norm': 0.02276267111301422, 'learning_rate': 0.0003553739402317162, 'epoch': 1.82}\n",
            "{'loss': 0.0323, 'grad_norm': 0.03028242662549019, 'learning_rate': 0.0003512484730723986, 'epoch': 1.83}\n",
            "{'loss': 0.0215, 'grad_norm': 0.024533720687031746, 'learning_rate': 0.00034713408632012366, 'epoch': 1.84}\n",
            "{'loss': 0.0245, 'grad_norm': 0.025495730340480804, 'learning_rate': 0.00034303108645295497, 'epoch': 1.85}\n",
            "{'loss': 0.0307, 'grad_norm': 0.02683868631720543, 'learning_rate': 0.0003389397791007548, 'epoch': 1.86}\n",
            "{'loss': 0.0282, 'grad_norm': 0.07693135738372803, 'learning_rate': 0.00033486046902241664, 'epoch': 1.86}\n",
            "{'loss': 0.0395, 'grad_norm': 0.03425309434533119, 'learning_rate': 0.0003307934600831648, 'epoch': 1.87}\n",
            "{'loss': 0.0393, 'grad_norm': 0.03061363659799099, 'learning_rate': 0.00032673905523192, 'epoch': 1.88}\n",
            "{'loss': 0.0246, 'grad_norm': 0.023625727742910385, 'learning_rate': 0.00032269755647873217, 'epoch': 1.89}\n",
            "{'loss': 0.0308, 'grad_norm': 0.038232166320085526, 'learning_rate': 0.000318669264872284, 'epoch': 1.9}\n",
            "{'loss': 0.0158, 'grad_norm': 0.018703633919358253, 'learning_rate': 0.00031465448047746623, 'epoch': 1.9}\n",
            "{'loss': 0.0337, 'grad_norm': 0.032019756734371185, 'learning_rate': 0.0003106535023530262, 'epoch': 1.91}\n",
            "{'loss': 0.0293, 'grad_norm': 0.022046532481908798, 'learning_rate': 0.0003066666285292906, 'epoch': 1.92}\n",
            "{'loss': 0.0317, 'grad_norm': 0.031043419614434242, 'learning_rate': 0.000302694155985966, 'epoch': 1.93}\n",
            "{'loss': 0.0272, 'grad_norm': 0.044742148369550705, 'learning_rate': 0.0002987363806300163, 'epoch': 1.94}\n",
            "{'loss': 0.0318, 'grad_norm': 0.035815849900245667, 'learning_rate': 0.0002947935972736217, 'epoch': 1.94}\n",
            "{'loss': 0.0418, 'grad_norm': 0.03732993081212044, 'learning_rate': 0.00029086609961221754, 'epoch': 1.95}\n",
            "{'loss': 0.0241, 'grad_norm': 0.03144503012299538, 'learning_rate': 0.00028695418020261755, 'epoch': 1.96}\n",
            "{'loss': 0.0231, 'grad_norm': 0.023503873497247696, 'learning_rate': 0.00028305813044122096, 'epoch': 1.97}\n",
            "{'loss': 0.0431, 'grad_norm': 0.09766217321157455, 'learning_rate': 0.00027917824054230785, 'epoch': 1.98}\n",
            "{'loss': 0.0186, 'grad_norm': 0.02140769548714161, 'learning_rate': 0.00027531479951641924, 'epoch': 1.98}\n",
            "{'loss': 0.0404, 'grad_norm': 0.036735594272613525, 'learning_rate': 0.0002714680951488312, 'epoch': 1.99}\n",
            "{'loss': 0.0317, 'grad_norm': 0.02762417681515217, 'learning_rate': 0.00026763841397811573, 'epoch': 2.0}\n",
            "{'loss': 0.0325, 'grad_norm': 0.024625319987535477, 'learning_rate': 0.00026382604127479813, 'epoch': 2.01}\n",
            "{'loss': 0.03, 'grad_norm': 0.032144445925951004, 'learning_rate': 0.00026003126102010693, 'epoch': 2.02}\n",
            "{'loss': 0.0239, 'grad_norm': 0.0420197993516922, 'learning_rate': 0.0002562543558848202, 'epoch': 2.02}\n",
            "{'loss': 0.0356, 'grad_norm': 0.070401132106781, 'learning_rate': 0.0002524956072082093, 'epoch': 2.03}\n",
            "{'loss': 0.0363, 'grad_norm': 0.028402438387274742, 'learning_rate': 0.00024875529497708353, 'epoch': 2.04}\n",
            "{'loss': 0.0355, 'grad_norm': 0.032858092337846756, 'learning_rate': 0.0002450336978049322, 'epoch': 2.05}\n",
            "{'loss': 0.0361, 'grad_norm': 0.03473181277513504, 'learning_rate': 0.00024133109291117155, 'epoch': 2.06}\n",
            "{'loss': 0.0291, 'grad_norm': 0.026535488665103912, 'learning_rate': 0.000237647756100496, 'epoch': 2.06}\n",
            "{'loss': 0.0393, 'grad_norm': 0.2990277409553528, 'learning_rate': 0.00023398396174233177, 'epoch': 2.07}\n",
            "{'loss': 0.0308, 'grad_norm': 0.027459047734737396, 'learning_rate': 0.00023033998275040046, 'epoch': 2.08}\n",
            "{'loss': 0.0311, 'grad_norm': 0.02361467480659485, 'learning_rate': 0.0002267160905623895, 'epoch': 2.09}\n",
            "{'loss': 0.0304, 'grad_norm': 0.0770203173160553, 'learning_rate': 0.00022311255511973344, 'epoch': 2.1}\n",
            "{'loss': 0.023, 'grad_norm': 0.063829205930233, 'learning_rate': 0.00021952964484750527, 'epoch': 2.1}\n",
            "{'loss': 0.0206, 'grad_norm': 0.0232810378074646, 'learning_rate': 0.00021596762663442215, 'epoch': 2.11}\n",
            "{'loss': 0.0369, 'grad_norm': 0.03942691162228584, 'learning_rate': 0.00021242676581296528, 'epoch': 2.12}\n",
            "{'loss': 0.0283, 'grad_norm': 0.031497083604335785, 'learning_rate': 0.00020890732613961478, 'epoch': 2.13}\n",
            "{'loss': 0.0277, 'grad_norm': 0.04264726862311363, 'learning_rate': 0.00020540956977520319, 'epoch': 2.14}\n",
            "{'loss': 0.0206, 'grad_norm': 0.028572803363204002, 'learning_rate': 0.00020193375726538737, 'epoch': 2.14}\n",
            "{'loss': 0.0343, 'grad_norm': 0.03047868236899376, 'learning_rate': 0.00019848014752123978, 'epoch': 2.15}\n",
            "{'loss': 0.0254, 'grad_norm': 0.031172549352049828, 'learning_rate': 0.00019504899779996355, 'epoch': 2.16}\n",
            "{'loss': 0.0201, 'grad_norm': 0.10748810321092606, 'learning_rate': 0.00019164056368572847, 'epoch': 2.17}\n",
            "{'loss': 0.033, 'grad_norm': 0.08352633565664291, 'learning_rate': 0.00018825509907063325, 'epoch': 2.18}\n",
            "{'loss': 0.0239, 'grad_norm': 0.06610353291034698, 'learning_rate': 0.00018489285613579326, 'epoch': 2.18}\n",
            "{'loss': 0.0156, 'grad_norm': 0.022256921976804733, 'learning_rate': 0.0001815540853325555, 'epoch': 2.19}\n",
            "{'loss': 0.0265, 'grad_norm': 0.03145048767328262, 'learning_rate': 0.00017823903536384262, 'epoch': 2.2}\n",
            "{'loss': 0.023, 'grad_norm': 0.02594875358045101, 'learning_rate': 0.0001749479531656279, 'epoch': 2.21}\n",
            "{'loss': 0.0331, 'grad_norm': 0.0370432548224926, 'learning_rate': 0.00017168108388853997, 'epoch': 2.22}\n",
            "{'loss': 0.022, 'grad_norm': 0.04037904739379883, 'learning_rate': 0.00016843867087960252, 'epoch': 2.22}\n",
            "{'loss': 0.0377, 'grad_norm': 0.04664299264550209, 'learning_rate': 0.00016522095566410728, 'epoch': 2.23}\n",
            "{'loss': 0.0233, 'grad_norm': 0.04603979364037514, 'learning_rate': 0.00016202817792762282, 'epoch': 2.24}\n",
            "{'loss': 0.0155, 'grad_norm': 0.045671429485082626, 'learning_rate': 0.0001588605754981413, 'epoch': 2.25}\n",
            "{'loss': 0.0358, 'grad_norm': 0.040602851659059525, 'learning_rate': 0.00015571838432836137, 'epoch': 2.26}\n",
            "{'loss': 0.0166, 'grad_norm': 0.022765228524804115, 'learning_rate': 0.00015260183847811383, 'epoch': 2.26}\n",
            "{'loss': 0.0365, 'grad_norm': 0.040708813816308975, 'learning_rate': 0.00014951117009692527, 'epoch': 2.27}\n",
            "{'loss': 0.0283, 'grad_norm': 0.03336372599005699, 'learning_rate': 0.00014644660940672628, 'epoch': 2.28}\n",
            "{'loss': 0.0398, 'grad_norm': 0.041876643896102905, 'learning_rate': 0.00014340838468470196, 'epoch': 2.29}\n",
            "{'loss': 0.0306, 'grad_norm': 0.052547991275787354, 'learning_rate': 0.00014039672224628786, 'epoch': 2.3}\n",
            "{'loss': 0.0259, 'grad_norm': 0.02697574347257614, 'learning_rate': 0.0001374118464283119, 'epoch': 2.3}\n",
            "{'loss': 0.0309, 'grad_norm': 0.03284761309623718, 'learning_rate': 0.0001344539795722834, 'epoch': 2.31}\n",
            "{'loss': 0.0257, 'grad_norm': 0.03424517810344696, 'learning_rate': 0.00013152334200783168, 'epoch': 2.32}\n",
            "{'loss': 0.0246, 'grad_norm': 0.04505788907408714, 'learning_rate': 0.00012862015203629273, 'epoch': 2.33}\n",
            "{'loss': 0.039, 'grad_norm': 0.048230789601802826, 'learning_rate': 0.0001257446259144494, 'epoch': 2.34}\n",
            "{'loss': 0.0192, 'grad_norm': 0.024943819269537926, 'learning_rate': 0.0001228969778384214, 'epoch': 2.34}\n",
            "{'loss': 0.0296, 'grad_norm': 0.02617984265089035, 'learning_rate': 0.00012007741992771066, 'epoch': 2.35}\n",
            "{'loss': 0.018, 'grad_norm': 0.024759460240602493, 'learning_rate': 0.0001172861622094003, 'epoch': 2.36}\n",
            "{'loss': 0.0179, 'grad_norm': 0.024899566546082497, 'learning_rate': 0.0001145234126025102, 'epoch': 2.37}\n",
            "{'loss': 0.0254, 'grad_norm': 0.03321586176753044, 'learning_rate': 0.00011178937690250917, 'epoch': 2.38}\n",
            "{'loss': 0.0181, 'grad_norm': 0.02550005540251732, 'learning_rate': 0.0001090842587659851, 'epoch': 2.38}\n",
            "{'loss': 0.0213, 'grad_norm': 0.022761255502700806, 'learning_rate': 0.00010640825969547497, 'epoch': 2.39}\n",
            "{'loss': 0.0256, 'grad_norm': 0.026720523834228516, 'learning_rate': 0.00010376157902445487, 'epoch': 2.4}\n",
            "{'loss': 0.0163, 'grad_norm': 0.024454303085803986, 'learning_rate': 0.00010114441390249201, 'epoch': 2.41}\n",
            "{'loss': 0.0253, 'grad_norm': 0.03608481585979462, 'learning_rate': 9.85569592805588e-05, 'epoch': 2.42}\n",
            "{'loss': 0.023, 'grad_norm': 0.03035515919327736, 'learning_rate': 9.599940789651179e-05, 'epoch': 2.42}\n",
            "{'loss': 0.0204, 'grad_norm': 0.07080752402544022, 'learning_rate': 9.347195026073368e-05, 'epoch': 2.43}\n",
            "{'loss': 0.0345, 'grad_norm': 0.03783209249377251, 'learning_rate': 9.09747746419436e-05, 'epoch': 2.44}\n",
            "{'loss': 0.0259, 'grad_norm': 0.03514103591442108, 'learning_rate': 8.850806705317183e-05, 'epoch': 2.45}\n",
            "{'loss': 0.0336, 'grad_norm': 0.030673278495669365, 'learning_rate': 8.60720112379046e-05, 'epoch': 2.46}\n",
            "{'loss': 0.0327, 'grad_norm': 0.02846437878906727, 'learning_rate': 8.366678865639687e-05, 'epoch': 2.46}\n",
            "{'loss': 0.0209, 'grad_norm': 0.0654098242521286, 'learning_rate': 8.129257847215571e-05, 'epoch': 2.47}\n",
            "{'loss': 0.0167, 'grad_norm': 0.03271156921982765, 'learning_rate': 7.894955753859412e-05, 'epoch': 2.48}\n",
            "{'loss': 0.024, 'grad_norm': 0.02776711992919445, 'learning_rate': 7.663790038585794e-05, 'epoch': 2.49}\n",
            "{'loss': 0.0322, 'grad_norm': 0.035732850432395935, 'learning_rate': 7.435777920782444e-05, 'epoch': 2.5}\n",
            "{'loss': 0.0314, 'grad_norm': 0.05226382240653038, 'learning_rate': 7.21093638492763e-05, 'epoch': 2.5}\n",
            "{'loss': 0.0175, 'grad_norm': 0.029963267967104912, 'learning_rate': 6.989282179324962e-05, 'epoch': 2.51}\n",
            "{'loss': 0.0403, 'grad_norm': 0.047011785209178925, 'learning_rate': 6.770831814855882e-05, 'epoch': 2.52}\n",
            "{'loss': 0.0288, 'grad_norm': 0.03676379844546318, 'learning_rate': 6.555601563749674e-05, 'epoch': 2.53}\n",
            "{'loss': 0.0291, 'grad_norm': 0.031096259132027626, 'learning_rate': 6.343607458371459e-05, 'epoch': 2.54}\n",
            "{'loss': 0.0177, 'grad_norm': 0.029437728226184845, 'learning_rate': 6.134865290027902e-05, 'epoch': 2.54}\n",
            "{'loss': 0.0264, 'grad_norm': 0.03258918598294258, 'learning_rate': 5.92939060779093e-05, 'epoch': 2.55}\n",
            "{'loss': 0.0182, 'grad_norm': 0.03205026686191559, 'learning_rate': 5.72719871733951e-05, 'epoch': 2.56}\n",
            "{'loss': 0.0345, 'grad_norm': 0.04179414361715317, 'learning_rate': 5.5283046798195126e-05, 'epoch': 2.57}\n",
            "{'loss': 0.0266, 'grad_norm': 0.03784145042300224, 'learning_rate': 5.3327233107218545e-05, 'epoch': 2.58}\n",
            "{'loss': 0.0207, 'grad_norm': 0.021555641666054726, 'learning_rate': 5.140469178778845e-05, 'epoch': 2.58}\n",
            "{'loss': 0.0139, 'grad_norm': 0.026732292026281357, 'learning_rate': 4.9515566048790485e-05, 'epoch': 2.59}\n",
            "{'loss': 0.0272, 'grad_norm': 0.044315192848443985, 'learning_rate': 4.765999661000442e-05, 'epoch': 2.6}\n",
            "{'loss': 0.0291, 'grad_norm': 0.040800921618938446, 'learning_rate': 4.583812169162299e-05, 'epoch': 2.61}\n",
            "{'loss': 0.0332, 'grad_norm': 0.038669876754283905, 'learning_rate': 4.405007700395497e-05, 'epoch': 2.62}\n",
            "{'loss': 0.0241, 'grad_norm': 0.028934381902217865, 'learning_rate': 4.2295995737316854e-05, 'epoch': 2.62}\n",
            "{'loss': 0.0259, 'grad_norm': 0.027036992833018303, 'learning_rate': 4.057600855211141e-05, 'epoch': 2.63}\n",
            "{'loss': 0.0249, 'grad_norm': 0.02697373554110527, 'learning_rate': 3.8890243569094874e-05, 'epoch': 2.64}\n",
            "{'loss': 0.0349, 'grad_norm': 0.030481120571494102, 'learning_rate': 3.7238826359833275e-05, 'epoch': 2.65}\n",
            "{'loss': 0.0346, 'grad_norm': 0.03719937056303024, 'learning_rate': 3.562187993734883e-05, 'epoch': 2.66}\n",
            "{'loss': 0.0234, 'grad_norm': 0.0241860318928957, 'learning_rate': 3.40395247469566e-05, 'epoch': 2.66}\n",
            "{'loss': 0.0207, 'grad_norm': 0.03990934044122696, 'learning_rate': 3.249187865729264e-05, 'epoch': 2.67}\n",
            "{'loss': 0.0179, 'grad_norm': 0.0344419963657856, 'learning_rate': 3.097905695153408e-05, 'epoch': 2.68}\n",
            "{'loss': 0.0373, 'grad_norm': 0.035503286868333817, 'learning_rate': 2.9501172318811832e-05, 'epoch': 2.69}\n",
            "{'loss': 0.0302, 'grad_norm': 0.03958304598927498, 'learning_rate': 2.8058334845816213e-05, 'epoch': 2.7}\n",
            "{'loss': 0.0244, 'grad_norm': 0.03231925144791603, 'learning_rate': 2.6650652008597063e-05, 'epoch': 2.7}\n",
            "{'loss': 0.0228, 'grad_norm': 0.030287276953458786, 'learning_rate': 2.527822866455731e-05, 'epoch': 2.71}\n",
            "{'loss': 0.0238, 'grad_norm': 0.029560768976807594, 'learning_rate': 2.3941167044642943e-05, 'epoch': 2.72}\n",
            "{'loss': 0.0255, 'grad_norm': 0.028618382290005684, 'learning_rate': 2.2639566745727203e-05, 'epoch': 2.73}\n",
            "{'loss': 0.0222, 'grad_norm': 0.026483586058020592, 'learning_rate': 2.137352472319215e-05, 'epoch': 2.74}\n",
            "{'loss': 0.0168, 'grad_norm': 0.024391919374465942, 'learning_rate': 2.0143135283706258e-05, 'epoch': 2.74}\n",
            "{'loss': 0.0342, 'grad_norm': 0.035938285291194916, 'learning_rate': 1.8948490078199765e-05, 'epoch': 2.75}\n",
            "{'loss': 0.0226, 'grad_norm': 0.030297113582491875, 'learning_rate': 1.7789678095037452e-05, 'epoch': 2.76}\n",
            "{'loss': 0.0343, 'grad_norm': 0.0330573171377182, 'learning_rate': 1.6666785653390248e-05, 'epoch': 2.77}\n",
            "{'loss': 0.0145, 'grad_norm': 0.019473973661661148, 'learning_rate': 1.557989639680496e-05, 'epoch': 2.78}\n",
            "{'loss': 0.0301, 'grad_norm': 0.02965218387544155, 'learning_rate': 1.4529091286973995e-05, 'epoch': 2.78}\n",
            "{'loss': 0.0191, 'grad_norm': 0.02557460404932499, 'learning_rate': 1.351444859770462e-05, 'epoch': 2.79}\n",
            "{'loss': 0.0157, 'grad_norm': 0.022207114845514297, 'learning_rate': 1.2536043909088191e-05, 'epoch': 2.8}\n",
            "{'loss': 0.0277, 'grad_norm': 0.02965834178030491, 'learning_rate': 1.159395010187042e-05, 'epoch': 2.81}\n",
            "{'loss': 0.0168, 'grad_norm': 0.0376359187066555, 'learning_rate': 1.0688237352022346e-05, 'epoch': 2.82}\n",
            "{'loss': 0.0146, 'grad_norm': 0.019745660945773125, 'learning_rate': 9.818973125513276e-06, 'epoch': 2.82}\n",
            "{'loss': 0.018, 'grad_norm': 0.028559641912579536, 'learning_rate': 8.986222173284874e-06, 'epoch': 2.83}\n",
            "{'loss': 0.0302, 'grad_norm': 0.035809677094221115, 'learning_rate': 8.190046526428241e-06, 'epoch': 2.84}\n",
            "{'loss': 0.0262, 'grad_norm': 0.034075260162353516, 'learning_rate': 7.4305054915631e-06, 'epoch': 2.85}\n",
            "{'loss': 0.0311, 'grad_norm': 0.03838583827018738, 'learning_rate': 6.7076556464202296e-06, 'epoch': 2.86}\n",
            "{'loss': 0.0341, 'grad_norm': 0.040984705090522766, 'learning_rate': 6.021550835626777e-06, 'epoch': 2.86}\n",
            "{'loss': 0.0237, 'grad_norm': 0.033527690917253494, 'learning_rate': 5.372242166695684e-06, 'epoch': 2.87}\n",
            "{'loss': 0.0217, 'grad_norm': 0.02568862773478031, 'learning_rate': 4.759778006218407e-06, 'epoch': 2.88}\n",
            "{'loss': 0.037, 'grad_norm': 0.04157214239239693, 'learning_rate': 4.184203976262513e-06, 'epoch': 2.89}\n",
            "{'loss': 0.0277, 'grad_norm': 0.03870908170938492, 'learning_rate': 3.645562950973014e-06, 'epoch': 2.9}\n",
            "{'loss': 0.0317, 'grad_norm': 0.03404885530471802, 'learning_rate': 3.143895053378698e-06, 'epoch': 2.9}\n",
            "{'loss': 0.0234, 'grad_norm': 0.029451383277773857, 'learning_rate': 2.6792376524036878e-06, 'epoch': 2.91}\n",
            "{'loss': 0.0234, 'grad_norm': 0.025792663916945457, 'learning_rate': 2.251625360083387e-06, 'epoch': 2.92}\n",
            "{'loss': 0.0163, 'grad_norm': 0.026851512491703033, 'learning_rate': 1.8610900289867672e-06, 'epoch': 2.93}\n",
            "{'loss': 0.0275, 'grad_norm': 0.03580421581864357, 'learning_rate': 1.5076607498433204e-06, 'epoch': 2.94}\n",
            "{'loss': 0.0249, 'grad_norm': 0.028389448300004005, 'learning_rate': 1.1913638493762368e-06, 'epoch': 2.94}\n",
            "{'loss': 0.0241, 'grad_norm': 0.031769443303346634, 'learning_rate': 9.12222888341252e-07, 'epoch': 2.95}\n",
            "{'loss': 0.0322, 'grad_norm': 0.04041978344321251, 'learning_rate': 6.702586597719384e-07, 'epoch': 2.96}\n",
            "{'loss': 0.0274, 'grad_norm': 0.02835840918123722, 'learning_rate': 4.6548918743033465e-07, 'epoch': 2.97}\n",
            "{'loss': 0.0219, 'grad_norm': 0.026409411802887917, 'learning_rate': 2.9792972446479607e-07, 'epoch': 2.98}\n",
            "{'loss': 0.0151, 'grad_norm': 0.02548924833536148, 'learning_rate': 1.6759275227357095e-07, 'epoch': 2.98}\n",
            "{'loss': 0.0325, 'grad_norm': 0.027638733386993408, 'learning_rate': 7.448797957526621e-08, 'epoch': 2.99}\n",
            "{'loss': 0.0296, 'grad_norm': 0.03656916692852974, 'learning_rate': 1.862234168542587e-08, 'epoch': 3.0}\n",
            "{'train_runtime': 44.0738, 'train_samples_per_second': 17.017, 'train_steps_per_second': 8.508, 'train_loss': 0.08780076293895642, 'epoch': 3.0}\n",
            "100% 375/375 [00:44<00:00,  8.51it/s]\n",
            "Training complete.\n",
            "Model saved to loras/self-edit/training_set_iteration_1/44f52bb0/1\n",
            "Training on 69 examples for 3 epochs, lr: 0.01\n",
            "No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n",
            "Starting training...\n",
            "{'loss': 3.1439, 'grad_norm': 1.834293246269226, 'learning_rate': 0.0, 'epoch': 0.03}\n",
            "{'loss': 3.1674, 'grad_norm': 1.8317646980285645, 'learning_rate': 0.0009090909090909091, 'epoch': 0.06}\n",
            "{'loss': 1.8162, 'grad_norm': 0.5597311854362488, 'learning_rate': 0.0018181818181818182, 'epoch': 0.09}\n",
            "{'loss': 1.2533, 'grad_norm': 0.9108178615570068, 'learning_rate': 0.002727272727272727, 'epoch': 0.11}\n",
            "{'loss': 1.9457, 'grad_norm': 4.176822185516357, 'learning_rate': 0.0036363636363636364, 'epoch': 0.14}\n",
            "{'loss': 0.7168, 'grad_norm': 1.9196336269378662, 'learning_rate': 0.004545454545454545, 'epoch': 0.17}\n",
            "{'loss': 0.4419, 'grad_norm': 0.5770339965820312, 'learning_rate': 0.005454545454545454, 'epoch': 0.2}\n",
            "{'loss': 0.9352, 'grad_norm': 2.4775688648223877, 'learning_rate': 0.006363636363636364, 'epoch': 0.23}\n",
            "{'loss': 2.1105, 'grad_norm': 10.876291275024414, 'learning_rate': 0.007272727272727273, 'epoch': 0.26}\n",
            "{'loss': 2.4495, 'grad_norm': 12.074249267578125, 'learning_rate': 0.008181818181818182, 'epoch': 0.29}\n",
            "{'loss': 2.4508, 'grad_norm': 7.516407012939453, 'learning_rate': 0.00909090909090909, 'epoch': 0.31}\n",
            "{'loss': 6.2159, 'grad_norm': 9.950382232666016, 'learning_rate': 0.01, 'epoch': 0.34}\n",
            "{'loss': 12.4963, 'grad_norm': 19.697444915771484, 'learning_rate': 0.009997207818651273, 'epoch': 0.37}\n",
            "{'loss': 10.1676, 'grad_norm': 22.467144012451172, 'learning_rate': 0.009988834393115766, 'epoch': 0.4}\n",
            "{'loss': 8.3355, 'grad_norm': 7.040985584259033, 'learning_rate': 0.009974889075442521, 'epoch': 0.43}\n",
            "{'loss': 12.1493, 'grad_norm': 6.676313877105713, 'learning_rate': 0.009955387440773901, 'epoch': 0.46}\n",
            "{'loss': 14.2462, 'grad_norm': 8.587905883789062, 'learning_rate': 0.009930351269950143, 'epoch': 0.49}\n",
            "{'loss': 11.7435, 'grad_norm': 5.094852447509766, 'learning_rate': 0.009899808525182933, 'epoch': 0.51}\n",
            "{'loss': 12.3317, 'grad_norm': 5.072920322418213, 'learning_rate': 0.009863793318825186, 'epoch': 0.54}\n",
            "{'loss': 9.6461, 'grad_norm': 4.340949535369873, 'learning_rate': 0.009822345875271882, 'epoch': 0.57}\n",
            "{'loss': 10.2218, 'grad_norm': 8.808192253112793, 'learning_rate': 0.009775512486034562, 'epoch': 0.6}\n",
            "{'loss': 7.1187, 'grad_norm': 2.7480015754699707, 'learning_rate': 0.009723345458039594, 'epoch': 0.63}\n",
            "{'loss': 7.3246, 'grad_norm': 3.0742101669311523, 'learning_rate': 0.009665903055208014, 'epoch': 0.66}\n",
            "{'loss': 5.6183, 'grad_norm': 1.3982791900634766, 'learning_rate': 0.009603249433382144, 'epoch': 0.69}\n",
            "{'loss': 5.6022, 'grad_norm': 3.117464303970337, 'learning_rate': 0.009535454568671704, 'epoch': 0.71}\n",
            "{'loss': 5.43, 'grad_norm': 2.1136364936828613, 'learning_rate': 0.009462594179299406, 'epoch': 0.74}\n",
            "{'loss': 4.5947, 'grad_norm': 1.2292388677597046, 'learning_rate': 0.009384749641033358, 'epoch': 0.77}\n",
            "{'loss': 5.254, 'grad_norm': 4.367128849029541, 'learning_rate': 0.009302007896300698, 'epoch': 0.8}\n",
            "{'loss': 4.5137, 'grad_norm': 1.8834378719329834, 'learning_rate': 0.009214461357083986, 'epoch': 0.83}\n",
            "{'loss': 4.649, 'grad_norm': 1.6330510377883911, 'learning_rate': 0.009122207801708802, 'epoch': 0.86}\n",
            "{'loss': 4.5292, 'grad_norm': 1.373759150505066, 'learning_rate': 0.009025350265637815, 'epoch': 0.89}\n",
            "{'loss': 3.9368, 'grad_norm': 0.7215747833251953, 'learning_rate': 0.008923996926393306, 'epoch': 0.91}\n",
            "{'loss': 4.3112, 'grad_norm': 2.148259401321411, 'learning_rate': 0.00881826098273666, 'epoch': 0.94}\n",
            "{'loss': 4.2498, 'grad_norm': 1.862680196762085, 'learning_rate': 0.00870826052823979, 'epoch': 0.97}\n",
            "{'loss': 3.7486, 'grad_norm': 0.6956131458282471, 'learning_rate': 0.008594118419389648, 'epoch': 1.0}\n",
            "{'loss': 3.8433, 'grad_norm': 1.3882986307144165, 'learning_rate': 0.008475962138373212, 'epoch': 1.03}\n",
            "{'loss': 3.4495, 'grad_norm': 3.8618791103363037, 'learning_rate': 0.008353923650696118, 'epoch': 1.06}\n",
            "{'loss': 3.2625, 'grad_norm': 0.48619329929351807, 'learning_rate': 0.008228139257794012, 'epoch': 1.09}\n",
            "{'loss': 3.1007, 'grad_norm': 0.5962636470794678, 'learning_rate': 0.008098749444801224, 'epoch': 1.11}\n",
            "{'loss': 3.1313, 'grad_norm': 0.8288416266441345, 'learning_rate': 0.007965898723646777, 'epoch': 1.14}\n",
            "{'loss': 2.9387, 'grad_norm': 0.46840140223503113, 'learning_rate': 0.007829735471652976, 'epoch': 1.17}\n",
            "{'loss': 3.0258, 'grad_norm': 0.5511458516120911, 'learning_rate': 0.007690411765816863, 'epoch': 1.2}\n",
            "{'loss': 2.8203, 'grad_norm': 0.4894210994243622, 'learning_rate': 0.007548083212959588, 'epoch': 1.23}\n",
            "{'loss': 2.6843, 'grad_norm': 0.3800387978553772, 'learning_rate': 0.007402908775933419, 'epoch': 1.26}\n",
            "{'loss': 2.6728, 'grad_norm': 0.5231489539146423, 'learning_rate': 0.0072550505960805095, 'epoch': 1.29}\n",
            "{'loss': 2.5452, 'grad_norm': 0.22223706543445587, 'learning_rate': 0.007104673812141676, 'epoch': 1.31}\n",
            "{'loss': 2.591, 'grad_norm': 0.5486931204795837, 'learning_rate': 0.006951946375817474, 'epoch': 1.34}\n",
            "{'loss': 2.4467, 'grad_norm': 0.19970369338989258, 'learning_rate': 0.0067970388641875636, 'epoch': 1.37}\n",
            "{'loss': 2.4413, 'grad_norm': 0.28671810030937195, 'learning_rate': 0.006640124289197845, 'epoch': 1.4}\n",
            "{'loss': 2.424, 'grad_norm': 0.31037354469299316, 'learning_rate': 0.00648137790442817, 'epoch': 1.43}\n",
            "{'loss': 2.3696, 'grad_norm': 0.2799389660358429, 'learning_rate': 0.006320977009356431, 'epoch': 1.46}\n",
            "{'loss': 2.2631, 'grad_norm': 0.2540833055973053, 'learning_rate': 0.006159100751337642, 'epoch': 1.49}\n",
            "{'loss': 2.2426, 'grad_norm': 0.2787499725818634, 'learning_rate': 0.00599592992551918, 'epoch': 1.51}\n",
            "{'loss': 2.206, 'grad_norm': 0.27488335967063904, 'learning_rate': 0.005831646772915651, 'epoch': 1.54}\n",
            "{'loss': 2.1673, 'grad_norm': 0.25279271602630615, 'learning_rate': 0.005666434776868895, 'epoch': 1.57}\n",
            "{'loss': 2.0967, 'grad_norm': 0.160618394613266, 'learning_rate': 0.0055004784581204925, 'epoch': 1.6}\n",
            "{'loss': 2.0804, 'grad_norm': 0.35764041543006897, 'learning_rate': 0.005333963168725609, 'epoch': 1.63}\n",
            "{'loss': 2.1498, 'grad_norm': 0.506625235080719, 'learning_rate': 0.005167074885038373, 'epoch': 1.66}\n",
            "{'loss': 2.0581, 'grad_norm': 0.2272278517484665, 'learning_rate': 0.005, 'epoch': 1.69}\n",
            "{'loss': 1.9703, 'grad_norm': 0.28427034616470337, 'learning_rate': 0.004832925114961629, 'epoch': 1.71}\n",
            "{'loss': 1.9155, 'grad_norm': 0.22619719803333282, 'learning_rate': 0.004666036831274392, 'epoch': 1.74}\n",
            "{'loss': 1.8959, 'grad_norm': 0.1550586223602295, 'learning_rate': 0.0044995215418795085, 'epoch': 1.77}\n",
            "{'loss': 1.8474, 'grad_norm': 0.17788302898406982, 'learning_rate': 0.0043335652231311075, 'epoch': 1.8}\n",
            "{'loss': 1.8938, 'grad_norm': 0.581294059753418, 'learning_rate': 0.00416835322708435, 'epoch': 1.83}\n",
            "{'loss': 1.8767, 'grad_norm': 0.2828125059604645, 'learning_rate': 0.004004070074480821, 'epoch': 1.86}\n",
            "{'loss': 1.881, 'grad_norm': 0.33534908294677734, 'learning_rate': 0.0038408992486623585, 'epoch': 1.89}\n",
            "{'loss': 1.8071, 'grad_norm': 0.2363390475511551, 'learning_rate': 0.0036790229906435703, 'epoch': 1.91}\n",
            "{'loss': 1.694, 'grad_norm': 0.16167792677879333, 'learning_rate': 0.0035186220955718307, 'epoch': 1.94}\n",
            "{'loss': 1.7466, 'grad_norm': 0.9718676209449768, 'learning_rate': 0.0033598757108021546, 'epoch': 1.97}\n",
            "{'loss': 1.7117, 'grad_norm': 0.1699577420949936, 'learning_rate': 0.0032029611358124366, 'epoch': 2.0}\n",
            "{'loss': 1.7626, 'grad_norm': 0.4184488356113434, 'learning_rate': 0.003048053624182526, 'epoch': 2.03}\n",
            "{'loss': 1.9006, 'grad_norm': 0.9284495115280151, 'learning_rate': 0.002895326187858326, 'epoch': 2.06}\n",
            "{'loss': 1.7635, 'grad_norm': 0.8325744867324829, 'learning_rate': 0.00274494940391949, 'epoch': 2.09}\n",
            "{'loss': 1.792, 'grad_norm': 0.7887871861457825, 'learning_rate': 0.002597091224066581, 'epoch': 2.11}\n",
            "{'loss': 1.6873, 'grad_norm': 0.26587164402008057, 'learning_rate': 0.0024519167870404126, 'epoch': 2.14}\n",
            "{'loss': 1.6361, 'grad_norm': 0.4472965598106384, 'learning_rate': 0.002309588234183137, 'epoch': 2.17}\n",
            "{'loss': 1.597, 'grad_norm': 0.3384530544281006, 'learning_rate': 0.0021702645283470236, 'epoch': 2.2}\n",
            "{'loss': 1.5898, 'grad_norm': 0.20694392919540405, 'learning_rate': 0.002034101276353224, 'epoch': 2.23}\n",
            "{'loss': 1.6548, 'grad_norm': 0.21657207608222961, 'learning_rate': 0.0019012505551987762, 'epoch': 2.26}\n",
            "{'loss': 1.5776, 'grad_norm': 0.27534452080726624, 'learning_rate': 0.001771860742205988, 'epoch': 2.29}\n",
            "{'loss': 1.5336, 'grad_norm': 0.18927018344402313, 'learning_rate': 0.0016460763493038838, 'epoch': 2.31}\n",
            "{'loss': 1.5308, 'grad_norm': 0.11659244447946548, 'learning_rate': 0.0015240378616267886, 'epoch': 2.34}\n",
            "{'loss': 1.5573, 'grad_norm': 0.324895441532135, 'learning_rate': 0.0014058815806103542, 'epoch': 2.37}\n",
            "{'loss': 1.5355, 'grad_norm': 0.18719758093357086, 'learning_rate': 0.0012917394717602121, 'epoch': 2.4}\n",
            "{'loss': 1.5233, 'grad_norm': 0.13628485798835754, 'learning_rate': 0.0011817390172633403, 'epoch': 2.43}\n",
            "{'loss': 1.4787, 'grad_norm': 0.40326446294784546, 'learning_rate': 0.001076003073606695, 'epoch': 2.46}\n",
            "{'loss': 1.463, 'grad_norm': 0.16189953684806824, 'learning_rate': 0.0009746497343621857, 'epoch': 2.49}\n",
            "{'loss': 1.4644, 'grad_norm': 0.1480732262134552, 'learning_rate': 0.0008777921982911996, 'epoch': 2.51}\n",
            "{'loss': 1.5213, 'grad_norm': 0.12807968258857727, 'learning_rate': 0.0007855386429160149, 'epoch': 2.54}\n",
            "{'loss': 1.4327, 'grad_norm': 0.09407147020101547, 'learning_rate': 0.0006979921036993042, 'epoch': 2.57}\n",
            "{'loss': 1.4387, 'grad_norm': 0.3195261061191559, 'learning_rate': 0.0006152503589666425, 'epoch': 2.6}\n",
            "{'loss': 1.4691, 'grad_norm': 0.18040943145751953, 'learning_rate': 0.0005374058207005944, 'epoch': 2.63}\n",
            "{'loss': 1.4271, 'grad_norm': 0.23542940616607666, 'learning_rate': 0.0004645454313282965, 'epoch': 2.66}\n",
            "{'loss': 1.4153, 'grad_norm': 0.19768968224525452, 'learning_rate': 0.0003967505666178556, 'epoch': 2.69}\n",
            "{'loss': 1.417, 'grad_norm': 0.13706183433532715, 'learning_rate': 0.00033409694479198725, 'epoch': 2.71}\n",
            "{'loss': 1.4106, 'grad_norm': 0.29888564348220825, 'learning_rate': 0.0002766545419604066, 'epoch': 2.74}\n",
            "{'loss': 1.411, 'grad_norm': 0.2566491365432739, 'learning_rate': 0.00022448751396543788, 'epoch': 2.77}\n",
            "{'loss': 1.3997, 'grad_norm': 0.10276810824871063, 'learning_rate': 0.00017765412472811772, 'epoch': 2.8}\n",
            "{'loss': 1.4352, 'grad_norm': 0.09567371010780334, 'learning_rate': 0.0001362066811748147, 'epoch': 2.83}\n",
            "{'loss': 1.3985, 'grad_norm': 0.16135989129543304, 'learning_rate': 0.00010019147481706626, 'epoch': 2.86}\n",
            "{'loss': 1.3938, 'grad_norm': 0.14338691532611847, 'learning_rate': 6.964873004985716e-05, 'epoch': 2.89}\n",
            "{'loss': 1.3974, 'grad_norm': 0.13032491505146027, 'learning_rate': 4.4612559226099855e-05, 'epoch': 2.91}\n",
            "{'loss': 1.3925, 'grad_norm': 0.12543751299381256, 'learning_rate': 2.511092455747932e-05, 'epoch': 2.94}\n",
            "{'loss': 1.4302, 'grad_norm': 0.07035163789987564, 'learning_rate': 1.116560688423418e-05, 'epoch': 2.97}\n",
            "{'loss': 1.3964, 'grad_norm': 0.08144263923168182, 'learning_rate': 2.792181348726941e-06, 'epoch': 3.0}\n",
            "{'train_runtime': 12.5345, 'train_samples_per_second': 16.514, 'train_steps_per_second': 8.377, 'train_loss': 3.193817510207494, 'epoch': 3.0}\n",
            "100% 105/105 [00:12<00:00,  8.38it/s]\n",
            "Training complete.\n",
            "Model saved to loras/self-edit/training_set_iteration_1/44f52bb0/2\n",
            "Skipping training for task 44f52bb0 because the number of steps is greater than 375\n",
            "Training on 250 examples for 0 epochs, lr: 0.01\n",
            "No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n",
            "Starting training...\n",
            "{'train_runtime': 0.0021, 'train_samples_per_second': 0.0, 'train_steps_per_second': 0.0, 'train_loss': 0.0, 'epoch': 0}\n",
            "0it [00:00, ?it/s]\n",
            "Training complete.\n",
            "Model saved to loras/self-edit/training_set_iteration_1/44f52bb0/3\n",
            "Training on 250 examples for 3 epochs, lr: 0.001\n",
            "No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n",
            "Starting training...\n",
            "{'loss': 6.5668, 'grad_norm': 8.890090942382812, 'learning_rate': 0.0, 'epoch': 0.01}\n",
            "{'loss': 4.3306, 'grad_norm': 4.448681831359863, 'learning_rate': 9.090909090909092e-05, 'epoch': 0.02}\n",
            "{'loss': 6.6392, 'grad_norm': 11.848304748535156, 'learning_rate': 0.00018181818181818183, 'epoch': 0.02}\n",
            "{'loss': 1.482, 'grad_norm': 4.397609710693359, 'learning_rate': 0.00027272727272727274, 'epoch': 0.03}\n",
            "{'loss': 1.7099, 'grad_norm': 11.67520523071289, 'learning_rate': 0.00036363636363636367, 'epoch': 0.04}\n",
            "{'loss': 0.9195, 'grad_norm': 0.3379319906234741, 'learning_rate': 0.00045454545454545455, 'epoch': 0.05}\n",
            "{'loss': 0.7591, 'grad_norm': 0.30280986428260803, 'learning_rate': 0.0005454545454545455, 'epoch': 0.06}\n",
            "{'loss': 0.7849, 'grad_norm': 0.3104189336299896, 'learning_rate': 0.0006363636363636364, 'epoch': 0.06}\n",
            "{'loss': 0.6039, 'grad_norm': 0.30617809295654297, 'learning_rate': 0.0007272727272727273, 'epoch': 0.07}\n",
            "{'loss': 0.5163, 'grad_norm': 0.23823416233062744, 'learning_rate': 0.0008181818181818183, 'epoch': 0.08}\n",
            "{'loss': 0.4596, 'grad_norm': 0.17987948656082153, 'learning_rate': 0.0009090909090909091, 'epoch': 0.09}\n",
            "{'loss': 0.3759, 'grad_norm': 0.17979492247104645, 'learning_rate': 0.001, 'epoch': 0.1}\n",
            "{'loss': 0.2679, 'grad_norm': 0.15187402069568634, 'learning_rate': 0.0009999813776583146, 'epoch': 0.1}\n",
            "{'loss': 0.2189, 'grad_norm': 0.16218900680541992, 'learning_rate': 0.0009999255120204248, 'epoch': 0.11}\n",
            "{'loss': 0.1496, 'grad_norm': 0.14840151369571686, 'learning_rate': 0.0009998324072477264, 'epoch': 0.12}\n",
            "{'loss': 0.1771, 'grad_norm': 0.31980863213539124, 'learning_rate': 0.0009997020702755353, 'epoch': 0.13}\n",
            "{'loss': 0.1454, 'grad_norm': 0.13559116423130035, 'learning_rate': 0.0009995345108125698, 'epoch': 0.14}\n",
            "{'loss': 0.127, 'grad_norm': 0.1041744127869606, 'learning_rate': 0.0009993297413402281, 'epoch': 0.14}\n",
            "{'loss': 0.1522, 'grad_norm': 0.11677390336990356, 'learning_rate': 0.0009990877771116587, 'epoch': 0.15}\n",
            "{'loss': 0.1337, 'grad_norm': 0.0947609692811966, 'learning_rate': 0.0009988086361506238, 'epoch': 0.16}\n",
            "{'loss': 0.1448, 'grad_norm': 0.11917059868574142, 'learning_rate': 0.0009984923392501567, 'epoch': 0.17}\n",
            "{'loss': 0.1329, 'grad_norm': 0.08169567584991455, 'learning_rate': 0.0009981389099710132, 'epoch': 0.18}\n",
            "{'loss': 0.13, 'grad_norm': 0.06360872834920883, 'learning_rate': 0.0009977483746399167, 'epoch': 0.18}\n",
            "{'loss': 0.126, 'grad_norm': 0.09153623878955841, 'learning_rate': 0.0009973207623475964, 'epoch': 0.19}\n",
            "{'loss': 0.1185, 'grad_norm': 0.0793445035815239, 'learning_rate': 0.0009968561049466214, 'epoch': 0.2}\n",
            "{'loss': 0.115, 'grad_norm': 0.058116938918828964, 'learning_rate': 0.000996354437049027, 'epoch': 0.21}\n",
            "{'loss': 0.096, 'grad_norm': 0.05792315676808357, 'learning_rate': 0.0009958157960237375, 'epoch': 0.22}\n",
            "{'loss': 0.1366, 'grad_norm': 0.08827297389507294, 'learning_rate': 0.0009952402219937815, 'epoch': 0.22}\n",
            "{'loss': 0.1051, 'grad_norm': 0.08888133615255356, 'learning_rate': 0.0009946277578333045, 'epoch': 0.23}\n",
            "{'loss': 0.0962, 'grad_norm': 0.057858072221279144, 'learning_rate': 0.0009939784491643732, 'epoch': 0.24}\n",
            "{'loss': 0.0926, 'grad_norm': 0.04723859950900078, 'learning_rate': 0.0009932923443535797, 'epoch': 0.25}\n",
            "{'loss': 0.134, 'grad_norm': 0.11625194549560547, 'learning_rate': 0.000992569494508437, 'epoch': 0.26}\n",
            "{'loss': 0.1114, 'grad_norm': 0.06695763766765594, 'learning_rate': 0.0009918099534735718, 'epoch': 0.26}\n",
            "{'loss': 0.0774, 'grad_norm': 0.05339040607213974, 'learning_rate': 0.0009910137778267152, 'epoch': 0.27}\n",
            "{'loss': 0.1086, 'grad_norm': 0.10672057420015335, 'learning_rate': 0.0009901810268744867, 'epoch': 0.28}\n",
            "{'loss': 0.0969, 'grad_norm': 0.07188645005226135, 'learning_rate': 0.0009893117626479776, 'epoch': 0.29}\n",
            "{'loss': 0.104, 'grad_norm': 0.10777654498815536, 'learning_rate': 0.0009884060498981295, 'epoch': 0.3}\n",
            "{'loss': 0.0808, 'grad_norm': 0.10406265407800674, 'learning_rate': 0.0009874639560909118, 'epoch': 0.3}\n",
            "{'loss': 0.0932, 'grad_norm': 0.08442365378141403, 'learning_rate': 0.0009864855514022954, 'epoch': 0.31}\n",
            "{'loss': 0.0826, 'grad_norm': 0.059818293899297714, 'learning_rate': 0.000985470908713026, 'epoch': 0.32}\n",
            "{'loss': 0.0933, 'grad_norm': 0.11604998260736465, 'learning_rate': 0.0009844201036031952, 'epoch': 0.33}\n",
            "{'loss': 0.0661, 'grad_norm': 0.06129786744713783, 'learning_rate': 0.0009833332143466098, 'epoch': 0.34}\n",
            "{'loss': 0.0678, 'grad_norm': 0.06638533622026443, 'learning_rate': 0.0009822103219049626, 'epoch': 0.34}\n",
            "{'loss': 0.0649, 'grad_norm': 0.05816659331321716, 'learning_rate': 0.0009810515099218002, 'epoch': 0.35}\n",
            "{'loss': 0.0742, 'grad_norm': 0.05169341713190079, 'learning_rate': 0.0009798568647162937, 'epoch': 0.36}\n",
            "{'loss': 0.0812, 'grad_norm': 0.08923465013504028, 'learning_rate': 0.000978626475276808, 'epoch': 0.37}\n",
            "{'loss': 0.0636, 'grad_norm': 0.06260570138692856, 'learning_rate': 0.0009773604332542728, 'epoch': 0.38}\n",
            "{'loss': 0.0639, 'grad_norm': 0.06564529240131378, 'learning_rate': 0.0009760588329553571, 'epoch': 0.38}\n",
            "{'loss': 0.0752, 'grad_norm': 0.07973990589380264, 'learning_rate': 0.0009747217713354427, 'epoch': 0.39}\n",
            "{'loss': 0.0509, 'grad_norm': 0.05696415901184082, 'learning_rate': 0.000973349347991403, 'epoch': 0.4}\n",
            "{'loss': 0.0539, 'grad_norm': 0.09319144487380981, 'learning_rate': 0.0009719416651541838, 'epoch': 0.41}\n",
            "{'loss': 0.0778, 'grad_norm': 0.18139441311359406, 'learning_rate': 0.0009704988276811882, 'epoch': 0.42}\n",
            "{'loss': 0.0731, 'grad_norm': 0.06508009135723114, 'learning_rate': 0.000969020943048466, 'epoch': 0.42}\n",
            "{'loss': 0.0753, 'grad_norm': 0.07033617049455643, 'learning_rate': 0.0009675081213427075, 'epoch': 0.43}\n",
            "{'loss': 0.0617, 'grad_norm': 0.052457988262176514, 'learning_rate': 0.0009659604752530434, 'epoch': 0.44}\n",
            "{'loss': 0.0723, 'grad_norm': 0.06998639553785324, 'learning_rate': 0.0009643781200626511, 'epoch': 0.45}\n",
            "{'loss': 0.0759, 'grad_norm': 0.08066931366920471, 'learning_rate': 0.0009627611736401667, 'epoch': 0.46}\n",
            "{'loss': 0.0666, 'grad_norm': 0.06310440599918365, 'learning_rate': 0.0009611097564309052, 'epoch': 0.46}\n",
            "{'loss': 0.0729, 'grad_norm': 0.04564864560961723, 'learning_rate': 0.0009594239914478886, 'epoch': 0.47}\n",
            "{'loss': 0.0594, 'grad_norm': 0.0382809042930603, 'learning_rate': 0.0009577040042626832, 'epoch': 0.48}\n",
            "{'loss': 0.0825, 'grad_norm': 0.05847657844424248, 'learning_rate': 0.0009559499229960451, 'epoch': 0.49}\n",
            "{'loss': 0.0947, 'grad_norm': 0.07297345995903015, 'learning_rate': 0.000954161878308377, 'epoch': 0.5}\n",
            "{'loss': 0.0553, 'grad_norm': 0.061944834887981415, 'learning_rate': 0.0009523400033899956, 'epoch': 0.5}\n",
            "{'loss': 0.0754, 'grad_norm': 0.05732598900794983, 'learning_rate': 0.0009504844339512095, 'epoch': 0.51}\n",
            "{'loss': 0.06, 'grad_norm': 0.05792471393942833, 'learning_rate': 0.0009485953082122116, 'epoch': 0.52}\n",
            "{'loss': 0.0468, 'grad_norm': 0.03199945390224457, 'learning_rate': 0.0009466727668927816, 'epoch': 0.53}\n",
            "{'loss': 0.0708, 'grad_norm': 0.0958695039153099, 'learning_rate': 0.000944716953201805, 'epoch': 0.54}\n",
            "{'loss': 0.0625, 'grad_norm': 0.06058388948440552, 'learning_rate': 0.0009427280128266049, 'epoch': 0.54}\n",
            "{'loss': 0.0596, 'grad_norm': 0.045336902141571045, 'learning_rate': 0.0009407060939220907, 'epoch': 0.55}\n",
            "{'loss': 0.0561, 'grad_norm': 0.05547672510147095, 'learning_rate': 0.000938651347099721, 'epoch': 0.56}\n",
            "{'loss': 0.0471, 'grad_norm': 0.044429317116737366, 'learning_rate': 0.0009365639254162854, 'epoch': 0.57}\n",
            "{'loss': 0.0505, 'grad_norm': 0.051864657551050186, 'learning_rate': 0.0009344439843625034, 'epoch': 0.58}\n",
            "{'loss': 0.0449, 'grad_norm': 0.03634204342961311, 'learning_rate': 0.0009322916818514413, 'epoch': 0.58}\n",
            "{'loss': 0.0565, 'grad_norm': 0.04628315940499306, 'learning_rate': 0.0009301071782067504, 'epoch': 0.59}\n",
            "{'loss': 0.0638, 'grad_norm': 0.05462010204792023, 'learning_rate': 0.0009278906361507238, 'epoch': 0.6}\n",
            "{'loss': 0.0599, 'grad_norm': 0.07283031195402145, 'learning_rate': 0.0009256422207921756, 'epoch': 0.61}\n",
            "{'loss': 0.0536, 'grad_norm': 0.05211856588721275, 'learning_rate': 0.0009233620996141421, 'epoch': 0.62}\n",
            "{'loss': 0.0698, 'grad_norm': 0.14495132863521576, 'learning_rate': 0.0009210504424614059, 'epoch': 0.62}\n",
            "{'loss': 0.063, 'grad_norm': 0.04240652173757553, 'learning_rate': 0.0009187074215278444, 'epoch': 0.63}\n",
            "{'loss': 0.0787, 'grad_norm': 0.09207549691200256, 'learning_rate': 0.0009163332113436032, 'epoch': 0.64}\n",
            "{'loss': 0.0521, 'grad_norm': 0.14125874638557434, 'learning_rate': 0.0009139279887620955, 'epoch': 0.65}\n",
            "{'loss': 0.0585, 'grad_norm': 0.039883099496364594, 'learning_rate': 0.0009114919329468282, 'epoch': 0.66}\n",
            "{'loss': 0.0624, 'grad_norm': 0.04917548596858978, 'learning_rate': 0.0009090252253580565, 'epoch': 0.66}\n",
            "{'loss': 0.0642, 'grad_norm': 0.08011213690042496, 'learning_rate': 0.0009065280497392663, 'epoch': 0.67}\n",
            "{'loss': 0.0602, 'grad_norm': 0.05265232175588608, 'learning_rate': 0.0009040005921034883, 'epoch': 0.68}\n",
            "{'loss': 0.0674, 'grad_norm': 0.09286648780107498, 'learning_rate': 0.0009014430407194413, 'epoch': 0.69}\n",
            "{'loss': 0.0794, 'grad_norm': 0.27199316024780273, 'learning_rate': 0.0008988555860975081, 'epoch': 0.7}\n",
            "{'loss': 0.0706, 'grad_norm': 0.05988914519548416, 'learning_rate': 0.0008962384209755452, 'epoch': 0.7}\n",
            "{'loss': 0.0686, 'grad_norm': 0.0762036144733429, 'learning_rate': 0.000893591740304525, 'epoch': 0.71}\n",
            "{'loss': 0.0657, 'grad_norm': 0.035372696816921234, 'learning_rate': 0.000890915741234015, 'epoch': 0.72}\n",
            "{'loss': 0.0656, 'grad_norm': 0.13354557752609253, 'learning_rate': 0.0008882106230974909, 'epoch': 0.73}\n",
            "{'loss': 0.0738, 'grad_norm': 0.07960839569568634, 'learning_rate': 0.0008854765873974899, 'epoch': 0.74}\n",
            "{'loss': 0.0756, 'grad_norm': 0.13739405572414398, 'learning_rate': 0.0008827138377905998, 'epoch': 0.74}\n",
            "{'loss': 0.0742, 'grad_norm': 0.0847102478146553, 'learning_rate': 0.0008799225800722895, 'epoch': 0.75}\n",
            "{'loss': 0.0645, 'grad_norm': 0.050683725625276566, 'learning_rate': 0.0008771030221615785, 'epoch': 0.76}\n",
            "{'loss': 0.0704, 'grad_norm': 0.06638678908348083, 'learning_rate': 0.0008742553740855505, 'epoch': 0.77}\n",
            "{'loss': 0.0662, 'grad_norm': 0.06347129493951797, 'learning_rate': 0.0008713798479637072, 'epoch': 0.78}\n",
            "{'loss': 0.0585, 'grad_norm': 0.03911193087697029, 'learning_rate': 0.0008684766579921683, 'epoch': 0.78}\n",
            "{'loss': 0.0689, 'grad_norm': 0.0771368145942688, 'learning_rate': 0.0008655460204277166, 'epoch': 0.79}\n",
            "{'loss': 0.0655, 'grad_norm': 0.07724755257368088, 'learning_rate': 0.0008625881535716883, 'epoch': 0.8}\n",
            "{'loss': 0.0685, 'grad_norm': 0.050959426909685135, 'learning_rate': 0.0008596032777537123, 'epoch': 0.81}\n",
            "{'loss': 0.0583, 'grad_norm': 0.04880626127123833, 'learning_rate': 0.0008565916153152981, 'epoch': 0.82}\n",
            "{'loss': 0.063, 'grad_norm': 0.04924210160970688, 'learning_rate': 0.0008535533905932737, 'epoch': 0.82}\n",
            "{'loss': 0.06, 'grad_norm': 0.04343198984861374, 'learning_rate': 0.0008504888299030747, 'epoch': 0.83}\n",
            "{'loss': 0.0796, 'grad_norm': 0.08190211653709412, 'learning_rate': 0.0008473981615218862, 'epoch': 0.84}\n",
            "{'loss': 0.0782, 'grad_norm': 0.10325666517019272, 'learning_rate': 0.0008442816156716386, 'epoch': 0.85}\n",
            "{'loss': 0.05, 'grad_norm': 0.03040517307817936, 'learning_rate': 0.0008411394245018588, 'epoch': 0.86}\n",
            "{'loss': 0.0596, 'grad_norm': 0.06402479112148285, 'learning_rate': 0.0008379718220723773, 'epoch': 0.86}\n",
            "{'loss': 0.0803, 'grad_norm': 0.0998738631606102, 'learning_rate': 0.0008347790443358929, 'epoch': 0.87}\n",
            "{'loss': 0.0532, 'grad_norm': 0.04131901264190674, 'learning_rate': 0.0008315613291203976, 'epoch': 0.88}\n",
            "{'loss': 0.055, 'grad_norm': 0.04606776311993599, 'learning_rate': 0.0008283189161114601, 'epoch': 0.89}\n",
            "{'loss': 0.0557, 'grad_norm': 0.036268383264541626, 'learning_rate': 0.000825052046834372, 'epoch': 0.9}\n",
            "{'loss': 0.0604, 'grad_norm': 0.05814606696367264, 'learning_rate': 0.0008217609646361573, 'epoch': 0.9}\n",
            "{'loss': 0.0535, 'grad_norm': 0.042712777853012085, 'learning_rate': 0.0008184459146674447, 'epoch': 0.91}\n",
            "{'loss': 0.0623, 'grad_norm': 0.08847568929195404, 'learning_rate': 0.0008151071438642068, 'epoch': 0.92}\n",
            "{'loss': 0.0696, 'grad_norm': 0.07390084117650986, 'learning_rate': 0.0008117449009293668, 'epoch': 0.93}\n",
            "{'loss': 0.0584, 'grad_norm': 0.04446151480078697, 'learning_rate': 0.0008083594363142716, 'epoch': 0.94}\n",
            "{'loss': 0.066, 'grad_norm': 0.11089371889829636, 'learning_rate': 0.0008049510022000364, 'epoch': 0.94}\n",
            "{'loss': 0.0506, 'grad_norm': 0.07105576992034912, 'learning_rate': 0.0008015198524787601, 'epoch': 0.95}\n",
            "{'loss': 0.0664, 'grad_norm': 0.07457523792982101, 'learning_rate': 0.0007980662427346127, 'epoch': 0.96}\n",
            "{'loss': 0.0686, 'grad_norm': 0.06293962150812149, 'learning_rate': 0.0007945904302247968, 'epoch': 0.97}\n",
            "{'loss': 0.0559, 'grad_norm': 0.05429079011082649, 'learning_rate': 0.0007910926738603854, 'epoch': 0.98}\n",
            "{'loss': 0.0519, 'grad_norm': 0.047922804951667786, 'learning_rate': 0.0007875732341870349, 'epoch': 0.98}\n",
            "{'loss': 0.0521, 'grad_norm': 0.04712970182299614, 'learning_rate': 0.0007840323733655779, 'epoch': 0.99}\n",
            "{'loss': 0.0615, 'grad_norm': 0.052215397357940674, 'learning_rate': 0.0007804703551524948, 'epoch': 1.0}\n",
            "{'loss': 0.0561, 'grad_norm': 0.07333454489707947, 'learning_rate': 0.0007768874448802665, 'epoch': 1.01}\n",
            "{'loss': 0.0442, 'grad_norm': 0.03950399532914162, 'learning_rate': 0.0007732839094376105, 'epoch': 1.02}\n",
            "{'loss': 0.055, 'grad_norm': 0.168256938457489, 'learning_rate': 0.0007696600172495997, 'epoch': 1.02}\n",
            "{'loss': 0.061, 'grad_norm': 0.057814471423625946, 'learning_rate': 0.0007660160382576683, 'epoch': 1.03}\n",
            "{'loss': 0.0532, 'grad_norm': 0.04047168791294098, 'learning_rate': 0.000762352243899504, 'epoch': 1.04}\n",
            "{'loss': 0.0568, 'grad_norm': 0.09424597769975662, 'learning_rate': 0.0007586689070888284, 'epoch': 1.05}\n",
            "{'loss': 0.0531, 'grad_norm': 0.06654936820268631, 'learning_rate': 0.000754966302195068, 'epoch': 1.06}\n",
            "{'loss': 0.053, 'grad_norm': 0.04168760031461716, 'learning_rate': 0.0007512447050229165, 'epoch': 1.06}\n",
            "{'loss': 0.0592, 'grad_norm': 0.06749086081981659, 'learning_rate': 0.0007475043927917907, 'epoch': 1.07}\n",
            "{'loss': 0.0543, 'grad_norm': 0.036580365151166916, 'learning_rate': 0.00074374564411518, 'epoch': 1.08}\n",
            "{'loss': 0.0575, 'grad_norm': 0.04981640726327896, 'learning_rate': 0.0007399687389798933, 'epoch': 1.09}\n",
            "{'loss': 0.0533, 'grad_norm': 0.04566359147429466, 'learning_rate': 0.0007361739587252019, 'epoch': 1.1}\n",
            "{'loss': 0.0505, 'grad_norm': 0.033874087035655975, 'learning_rate': 0.0007323615860218843, 'epoch': 1.1}\n",
            "{'loss': 0.054, 'grad_norm': 0.04992533102631569, 'learning_rate': 0.000728531904851169, 'epoch': 1.11}\n",
            "{'loss': 0.0499, 'grad_norm': 0.040763530880212784, 'learning_rate': 0.0007246852004835807, 'epoch': 1.12}\n",
            "{'loss': 0.0532, 'grad_norm': 0.03957958146929741, 'learning_rate': 0.0007208217594576922, 'epoch': 1.13}\n",
            "{'loss': 0.0448, 'grad_norm': 0.04876643419265747, 'learning_rate': 0.0007169418695587791, 'epoch': 1.14}\n",
            "{'loss': 0.0315, 'grad_norm': 0.027054766193032265, 'learning_rate': 0.0007130458197973828, 'epoch': 1.14}\n",
            "{'loss': 0.0583, 'grad_norm': 0.19757753610610962, 'learning_rate': 0.0007091339003877826, 'epoch': 1.15}\n",
            "{'loss': 0.0607, 'grad_norm': 0.05420999228954315, 'learning_rate': 0.0007052064027263785, 'epoch': 1.16}\n",
            "{'loss': 0.0478, 'grad_norm': 0.040168263018131256, 'learning_rate': 0.0007012636193699837, 'epoch': 1.17}\n",
            "{'loss': 0.0321, 'grad_norm': 0.028058473020792007, 'learning_rate': 0.0006973058440140341, 'epoch': 1.18}\n",
            "{'loss': 0.0548, 'grad_norm': 0.044476840645074844, 'learning_rate': 0.0006933333714707094, 'epoch': 1.18}\n",
            "{'loss': 0.0404, 'grad_norm': 0.0429546944797039, 'learning_rate': 0.0006893464976469738, 'epoch': 1.19}\n",
            "{'loss': 0.0581, 'grad_norm': 0.08543533831834793, 'learning_rate': 0.0006853455195225339, 'epoch': 1.2}\n",
            "{'loss': 0.0512, 'grad_norm': 0.0471656434237957, 'learning_rate': 0.000681330735127716, 'epoch': 1.21}\n",
            "{'loss': 0.0466, 'grad_norm': 0.0444478876888752, 'learning_rate': 0.0006773024435212678, 'epoch': 1.22}\n",
            "{'loss': 0.0424, 'grad_norm': 0.049573589116334915, 'learning_rate': 0.00067326094476808, 'epoch': 1.22}\n",
            "{'loss': 0.0445, 'grad_norm': 0.04766153171658516, 'learning_rate': 0.0006692065399168352, 'epoch': 1.23}\n",
            "{'loss': 0.0423, 'grad_norm': 0.04784350469708443, 'learning_rate': 0.0006651395309775837, 'epoch': 1.24}\n",
            "{'loss': 0.041, 'grad_norm': 0.03766358643770218, 'learning_rate': 0.0006610602208992453, 'epoch': 1.25}\n",
            "{'loss': 0.0564, 'grad_norm': 0.1004902645945549, 'learning_rate': 0.000656968913547045, 'epoch': 1.26}\n",
            "{'loss': 0.0524, 'grad_norm': 0.044712599366903305, 'learning_rate': 0.0006528659136798764, 'epoch': 1.26}\n",
            "{'loss': 0.0513, 'grad_norm': 0.06343511492013931, 'learning_rate': 0.0006487515269276015, 'epoch': 1.27}\n",
            "{'loss': 0.0528, 'grad_norm': 0.05907348543405533, 'learning_rate': 0.0006446260597682839, 'epoch': 1.28}\n",
            "{'loss': 0.0398, 'grad_norm': 0.03692011162638664, 'learning_rate': 0.0006404898195053597, 'epoch': 1.29}\n",
            "{'loss': 0.0337, 'grad_norm': 0.058206647634506226, 'learning_rate': 0.0006363431142447468, 'epoch': 1.3}\n",
            "{'loss': 0.0446, 'grad_norm': 0.03465976193547249, 'learning_rate': 0.0006321862528718945, 'epoch': 1.3}\n",
            "{'loss': 0.0326, 'grad_norm': 0.03858516365289688, 'learning_rate': 0.0006280195450287736, 'epoch': 1.31}\n",
            "{'loss': 0.0426, 'grad_norm': 0.08519250154495239, 'learning_rate': 0.000623843301090813, 'epoch': 1.32}\n",
            "{'loss': 0.0526, 'grad_norm': 0.05500468239188194, 'learning_rate': 0.0006196578321437789, 'epoch': 1.33}\n",
            "{'loss': 0.0353, 'grad_norm': 0.0384315550327301, 'learning_rate': 0.0006154634499606029, 'epoch': 1.34}\n",
            "{'loss': 0.0572, 'grad_norm': 0.047925595194101334, 'learning_rate': 0.0006112604669781572, 'epoch': 1.34}\n",
            "{'loss': 0.0371, 'grad_norm': 0.04137617349624634, 'learning_rate': 0.000607049196273983, 'epoch': 1.35}\n",
            "{'loss': 0.056, 'grad_norm': 0.05264974385499954, 'learning_rate': 0.0006028299515429683, 'epoch': 1.36}\n",
            "{'loss': 0.0389, 'grad_norm': 0.05654532462358475, 'learning_rate': 0.0005986030470739811, 'epoch': 1.37}\n",
            "{'loss': 0.0386, 'grad_norm': 0.03761108219623566, 'learning_rate': 0.0005943687977264583, 'epoch': 1.38}\n",
            "{'loss': 0.0577, 'grad_norm': 0.04212188348174095, 'learning_rate': 0.000590127518906953, 'epoch': 1.38}\n",
            "{'loss': 0.0386, 'grad_norm': 0.03573325276374817, 'learning_rate': 0.0005858795265456381, 'epoch': 1.39}\n",
            "{'loss': 0.0362, 'grad_norm': 0.039756424725055695, 'learning_rate': 0.0005816251370727748, 'epoch': 1.4}\n",
            "{'loss': 0.0529, 'grad_norm': 0.05472506210207939, 'learning_rate': 0.0005773646673951406, 'epoch': 1.41}\n",
            "{'loss': 0.0462, 'grad_norm': 0.04107716679573059, 'learning_rate': 0.0005730984348724242, 'epoch': 1.42}\n",
            "{'loss': 0.0575, 'grad_norm': 0.0436159186065197, 'learning_rate': 0.0005688267572935842, 'epoch': 1.42}\n",
            "{'loss': 0.0374, 'grad_norm': 0.03491548076272011, 'learning_rate': 0.0005645499528531784, 'epoch': 1.43}\n",
            "{'loss': 0.0443, 'grad_norm': 0.035896144807338715, 'learning_rate': 0.0005602683401276614, 'epoch': 1.44}\n",
            "{'loss': 0.0402, 'grad_norm': 0.033680837601423264, 'learning_rate': 0.0005559822380516539, 'epoch': 1.45}\n",
            "{'loss': 0.0613, 'grad_norm': 0.04591073840856552, 'learning_rate': 0.000551691965894185, 'epoch': 1.46}\n",
            "{'loss': 0.0435, 'grad_norm': 0.046540193259716034, 'learning_rate': 0.0005473978432349112, 'epoch': 1.46}\n",
            "{'loss': 0.041, 'grad_norm': 0.033971432596445084, 'learning_rate': 0.0005431001899403097, 'epoch': 1.47}\n",
            "{'loss': 0.0557, 'grad_norm': 0.05215369164943695, 'learning_rate': 0.0005387993261398532, 'epoch': 1.48}\n",
            "{'loss': 0.0414, 'grad_norm': 0.039931800216436386, 'learning_rate': 0.0005344955722021623, 'epoch': 1.49}\n",
            "{'loss': 0.0425, 'grad_norm': 0.03964249789714813, 'learning_rate': 0.0005301892487111431, 'epoch': 1.5}\n",
            "{'loss': 0.0714, 'grad_norm': 0.06479328870773315, 'learning_rate': 0.0005258806764421047, 'epoch': 1.5}\n",
            "{'loss': 0.0482, 'grad_norm': 0.038743484765291214, 'learning_rate': 0.0005215701763378673, 'epoch': 1.51}\n",
            "{'loss': 0.0587, 'grad_norm': 0.07577639818191528, 'learning_rate': 0.0005172580694848541, 'epoch': 1.52}\n",
            "{'loss': 0.0429, 'grad_norm': 0.055277857929468155, 'learning_rate': 0.0005129446770891738, 'epoch': 1.53}\n",
            "{'loss': 0.0529, 'grad_norm': 0.0443989634513855, 'learning_rate': 0.0005086303204526943, 'epoch': 1.54}\n",
            "{'loss': 0.0542, 'grad_norm': 0.036857932806015015, 'learning_rate': 0.0005043153209491095, 'epoch': 1.54}\n",
            "{'loss': 0.0414, 'grad_norm': 0.03661992400884628, 'learning_rate': 0.0005, 'epoch': 1.55}\n",
            "{'loss': 0.0486, 'grad_norm': 0.03673894330859184, 'learning_rate': 0.0004956846790508906, 'epoch': 1.56}\n",
            "{'loss': 0.0473, 'grad_norm': 0.03894142806529999, 'learning_rate': 0.0004913696795473058, 'epoch': 1.57}\n",
            "{'loss': 0.0478, 'grad_norm': 0.03432160243391991, 'learning_rate': 0.0004870553229108264, 'epoch': 1.58}\n",
            "{'loss': 0.0501, 'grad_norm': 0.030702494084835052, 'learning_rate': 0.0004827419305151461, 'epoch': 1.58}\n",
            "{'loss': 0.041, 'grad_norm': 0.03493306040763855, 'learning_rate': 0.00047842982366213274, 'epoch': 1.59}\n",
            "{'loss': 0.0512, 'grad_norm': 0.055043552070856094, 'learning_rate': 0.0004741193235578952, 'epoch': 1.6}\n",
            "{'loss': 0.0461, 'grad_norm': 0.033859942108392715, 'learning_rate': 0.0004698107512888569, 'epoch': 1.61}\n",
            "{'loss': 0.0455, 'grad_norm': 0.04546093940734863, 'learning_rate': 0.0004655044277978375, 'epoch': 1.62}\n",
            "{'loss': 0.0322, 'grad_norm': 0.0420212484896183, 'learning_rate': 0.0004612006738601469, 'epoch': 1.62}\n",
            "{'loss': 0.0533, 'grad_norm': 0.05508868023753166, 'learning_rate': 0.00045689981005969026, 'epoch': 1.63}\n",
            "{'loss': 0.0531, 'grad_norm': 0.0631251335144043, 'learning_rate': 0.00045260215676508895, 'epoch': 1.64}\n",
            "{'loss': 0.0397, 'grad_norm': 0.03828788548707962, 'learning_rate': 0.000448308034105815, 'epoch': 1.65}\n",
            "{'loss': 0.0496, 'grad_norm': 0.043340325355529785, 'learning_rate': 0.0004440177619483461, 'epoch': 1.66}\n",
            "{'loss': 0.0467, 'grad_norm': 0.04825986549258232, 'learning_rate': 0.00043973165987233853, 'epoch': 1.66}\n",
            "{'loss': 0.0464, 'grad_norm': 0.044674988836050034, 'learning_rate': 0.0004354500471468217, 'epoch': 1.67}\n",
            "{'loss': 0.0502, 'grad_norm': 0.028010284528136253, 'learning_rate': 0.00043117324270641603, 'epoch': 1.68}\n",
            "{'loss': 0.0424, 'grad_norm': 0.03870075196027756, 'learning_rate': 0.00042690156512757607, 'epoch': 1.69}\n",
            "{'loss': 0.0425, 'grad_norm': 0.0419188067317009, 'learning_rate': 0.0004226353326048593, 'epoch': 1.7}\n",
            "{'loss': 0.0436, 'grad_norm': 0.032158706337213516, 'learning_rate': 0.00041837486292722534, 'epoch': 1.7}\n",
            "{'loss': 0.0441, 'grad_norm': 0.024322878569364548, 'learning_rate': 0.00041412047345436195, 'epoch': 1.71}\n",
            "{'loss': 0.0455, 'grad_norm': 0.03137834742665291, 'learning_rate': 0.00040987248109304716, 'epoch': 1.72}\n",
            "{'loss': 0.0495, 'grad_norm': 0.0281643345952034, 'learning_rate': 0.0004056312022735417, 'epoch': 1.73}\n",
            "{'loss': 0.0452, 'grad_norm': 0.039540063589811325, 'learning_rate': 0.000401396952926019, 'epoch': 1.74}\n",
            "{'loss': 0.0412, 'grad_norm': 0.03597315400838852, 'learning_rate': 0.00039717004845703176, 'epoch': 1.74}\n",
            "{'loss': 0.0395, 'grad_norm': 0.03946660831570625, 'learning_rate': 0.000392950803726017, 'epoch': 1.75}\n",
            "{'loss': 0.048, 'grad_norm': 0.03444269299507141, 'learning_rate': 0.00038873953302184284, 'epoch': 1.76}\n",
            "{'loss': 0.0344, 'grad_norm': 0.02816377393901348, 'learning_rate': 0.0003845365500393974, 'epoch': 1.77}\n",
            "{'loss': 0.0465, 'grad_norm': 0.0345056988298893, 'learning_rate': 0.00038034216785622126, 'epoch': 1.78}\n",
            "{'loss': 0.0409, 'grad_norm': 0.04389720782637596, 'learning_rate': 0.00037615669890918703, 'epoch': 1.78}\n",
            "{'loss': 0.0424, 'grad_norm': 0.034151341766119, 'learning_rate': 0.00037198045497122644, 'epoch': 1.79}\n",
            "{'loss': 0.034, 'grad_norm': 0.04050048813223839, 'learning_rate': 0.00036781374712810557, 'epoch': 1.8}\n",
            "{'loss': 0.0377, 'grad_norm': 0.039708975702524185, 'learning_rate': 0.0003636568857552531, 'epoch': 1.81}\n",
            "{'loss': 0.0451, 'grad_norm': 0.03546380251646042, 'learning_rate': 0.0003595101804946404, 'epoch': 1.82}\n",
            "{'loss': 0.0307, 'grad_norm': 0.03718210756778717, 'learning_rate': 0.0003553739402317162, 'epoch': 1.82}\n",
            "{'loss': 0.0406, 'grad_norm': 0.05370194464921951, 'learning_rate': 0.0003512484730723986, 'epoch': 1.83}\n",
            "{'loss': 0.034, 'grad_norm': 0.047304365783929825, 'learning_rate': 0.00034713408632012366, 'epoch': 1.84}\n",
            "{'loss': 0.0461, 'grad_norm': 0.02891392819583416, 'learning_rate': 0.00034303108645295497, 'epoch': 1.85}\n",
            "{'loss': 0.0567, 'grad_norm': 0.05437769368290901, 'learning_rate': 0.0003389397791007548, 'epoch': 1.86}\n",
            "{'loss': 0.0418, 'grad_norm': 0.03609451279044151, 'learning_rate': 0.00033486046902241664, 'epoch': 1.86}\n",
            "{'loss': 0.0396, 'grad_norm': 0.03616045042872429, 'learning_rate': 0.0003307934600831648, 'epoch': 1.87}\n",
            "{'loss': 0.0517, 'grad_norm': 0.053148772567510605, 'learning_rate': 0.00032673905523192, 'epoch': 1.88}\n",
            "{'loss': 0.0527, 'grad_norm': 0.05686890333890915, 'learning_rate': 0.00032269755647873217, 'epoch': 1.89}\n",
            "{'loss': 0.0356, 'grad_norm': 0.034066926687955856, 'learning_rate': 0.000318669264872284, 'epoch': 1.9}\n",
            "{'loss': 0.0323, 'grad_norm': 0.05445777252316475, 'learning_rate': 0.00031465448047746623, 'epoch': 1.9}\n",
            "{'loss': 0.0309, 'grad_norm': 0.03271027281880379, 'learning_rate': 0.0003106535023530262, 'epoch': 1.91}\n",
            "{'loss': 0.0496, 'grad_norm': 0.07345530390739441, 'learning_rate': 0.0003066666285292906, 'epoch': 1.92}\n",
            "{'loss': 0.0601, 'grad_norm': 0.09671907126903534, 'learning_rate': 0.000302694155985966, 'epoch': 1.93}\n",
            "{'loss': 0.0358, 'grad_norm': 0.035808075219392776, 'learning_rate': 0.0002987363806300163, 'epoch': 1.94}\n",
            "{'loss': 0.0354, 'grad_norm': 0.03167637065052986, 'learning_rate': 0.0002947935972736217, 'epoch': 1.94}\n",
            "{'loss': 0.0387, 'grad_norm': 0.04328719526529312, 'learning_rate': 0.00029086609961221754, 'epoch': 1.95}\n",
            "{'loss': 0.039, 'grad_norm': 0.038029931485652924, 'learning_rate': 0.00028695418020261755, 'epoch': 1.96}\n",
            "{'loss': 0.0412, 'grad_norm': 0.036957573145627975, 'learning_rate': 0.00028305813044122096, 'epoch': 1.97}\n",
            "{'loss': 0.0387, 'grad_norm': 0.044611044228076935, 'learning_rate': 0.00027917824054230785, 'epoch': 1.98}\n",
            "{'loss': 0.0416, 'grad_norm': 0.03189873322844505, 'learning_rate': 0.00027531479951641924, 'epoch': 1.98}\n",
            "{'loss': 0.0265, 'grad_norm': 0.03055497258901596, 'learning_rate': 0.0002714680951488312, 'epoch': 1.99}\n",
            "{'loss': 0.0381, 'grad_norm': 0.03654169663786888, 'learning_rate': 0.00026763841397811573, 'epoch': 2.0}\n",
            "{'loss': 0.0494, 'grad_norm': 0.03974291309714317, 'learning_rate': 0.00026382604127479813, 'epoch': 2.01}\n",
            "{'loss': 0.0371, 'grad_norm': 0.027995053678750992, 'learning_rate': 0.00026003126102010693, 'epoch': 2.02}\n",
            "{'loss': 0.0312, 'grad_norm': 0.07141757011413574, 'learning_rate': 0.0002562543558848202, 'epoch': 2.02}\n",
            "{'loss': 0.0457, 'grad_norm': 0.03522847965359688, 'learning_rate': 0.0002524956072082093, 'epoch': 2.03}\n",
            "{'loss': 0.039, 'grad_norm': 0.030550967901945114, 'learning_rate': 0.00024875529497708353, 'epoch': 2.04}\n",
            "{'loss': 0.0311, 'grad_norm': 0.03051622025668621, 'learning_rate': 0.0002450336978049322, 'epoch': 2.05}\n",
            "{'loss': 0.04, 'grad_norm': 0.03316711634397507, 'learning_rate': 0.00024133109291117155, 'epoch': 2.06}\n",
            "{'loss': 0.0324, 'grad_norm': 0.02955913357436657, 'learning_rate': 0.000237647756100496, 'epoch': 2.06}\n",
            "{'loss': 0.0426, 'grad_norm': 0.05402504652738571, 'learning_rate': 0.00023398396174233177, 'epoch': 2.07}\n",
            "{'loss': 0.0323, 'grad_norm': 0.033476315438747406, 'learning_rate': 0.00023033998275040046, 'epoch': 2.08}\n",
            "{'loss': 0.0385, 'grad_norm': 0.029603246599435806, 'learning_rate': 0.0002267160905623895, 'epoch': 2.09}\n",
            "{'loss': 0.0314, 'grad_norm': 0.03295491263270378, 'learning_rate': 0.00022311255511973344, 'epoch': 2.1}\n",
            "{'loss': 0.0303, 'grad_norm': 0.030413160100579262, 'learning_rate': 0.00021952964484750527, 'epoch': 2.1}\n",
            "{'loss': 0.0274, 'grad_norm': 0.031201720237731934, 'learning_rate': 0.00021596762663442215, 'epoch': 2.11}\n",
            "{'loss': 0.0358, 'grad_norm': 0.04603208974003792, 'learning_rate': 0.00021242676581296528, 'epoch': 2.12}\n",
            "{'loss': 0.0359, 'grad_norm': 0.03290943056344986, 'learning_rate': 0.00020890732613961478, 'epoch': 2.13}\n",
            "{'loss': 0.0306, 'grad_norm': 0.035510022193193436, 'learning_rate': 0.00020540956977520319, 'epoch': 2.14}\n",
            "{'loss': 0.0244, 'grad_norm': 0.03385875001549721, 'learning_rate': 0.00020193375726538737, 'epoch': 2.14}\n",
            "{'loss': 0.0264, 'grad_norm': 0.04878466948866844, 'learning_rate': 0.00019848014752123978, 'epoch': 2.15}\n",
            "{'loss': 0.0261, 'grad_norm': 0.04622068628668785, 'learning_rate': 0.00019504899779996355, 'epoch': 2.16}\n",
            "{'loss': 0.0301, 'grad_norm': 0.044807158410549164, 'learning_rate': 0.00019164056368572847, 'epoch': 2.17}\n",
            "{'loss': 0.0392, 'grad_norm': 0.04640183970332146, 'learning_rate': 0.00018825509907063325, 'epoch': 2.18}\n",
            "{'loss': 0.0295, 'grad_norm': 0.05063808336853981, 'learning_rate': 0.00018489285613579326, 'epoch': 2.18}\n",
            "{'loss': 0.0231, 'grad_norm': 0.0734526664018631, 'learning_rate': 0.0001815540853325555, 'epoch': 2.19}\n",
            "{'loss': 0.0322, 'grad_norm': 0.03991352394223213, 'learning_rate': 0.00017823903536384262, 'epoch': 2.2}\n",
            "{'loss': 0.0216, 'grad_norm': 0.05259087681770325, 'learning_rate': 0.0001749479531656279, 'epoch': 2.21}\n",
            "{'loss': 0.0364, 'grad_norm': 0.04196673259139061, 'learning_rate': 0.00017168108388853997, 'epoch': 2.22}\n",
            "{'loss': 0.028, 'grad_norm': 0.03969010338187218, 'learning_rate': 0.00016843867087960252, 'epoch': 2.22}\n",
            "{'loss': 0.0325, 'grad_norm': 0.051858849823474884, 'learning_rate': 0.00016522095566410728, 'epoch': 2.23}\n",
            "{'loss': 0.0492, 'grad_norm': 0.055599141865968704, 'learning_rate': 0.00016202817792762282, 'epoch': 2.24}\n",
            "{'loss': 0.0378, 'grad_norm': 0.035889845341444016, 'learning_rate': 0.0001588605754981413, 'epoch': 2.25}\n",
            "{'loss': 0.0249, 'grad_norm': 0.04459167644381523, 'learning_rate': 0.00015571838432836137, 'epoch': 2.26}\n",
            "{'loss': 0.0355, 'grad_norm': 0.06741165369749069, 'learning_rate': 0.00015260183847811383, 'epoch': 2.26}\n",
            "{'loss': 0.0259, 'grad_norm': 0.061957333236932755, 'learning_rate': 0.00014951117009692527, 'epoch': 2.27}\n",
            "{'loss': 0.0309, 'grad_norm': 0.039632026106119156, 'learning_rate': 0.00014644660940672628, 'epoch': 2.28}\n",
            "{'loss': 0.032, 'grad_norm': 0.033144064247608185, 'learning_rate': 0.00014340838468470196, 'epoch': 2.29}\n",
            "{'loss': 0.0355, 'grad_norm': 0.03485057130455971, 'learning_rate': 0.00014039672224628786, 'epoch': 2.3}\n",
            "{'loss': 0.0293, 'grad_norm': 0.040577974170446396, 'learning_rate': 0.0001374118464283119, 'epoch': 2.3}\n",
            "{'loss': 0.0243, 'grad_norm': 0.03624517470598221, 'learning_rate': 0.0001344539795722834, 'epoch': 2.31}\n",
            "{'loss': 0.0321, 'grad_norm': 0.05690853297710419, 'learning_rate': 0.00013152334200783168, 'epoch': 2.32}\n",
            "{'loss': 0.0321, 'grad_norm': 0.03850225359201431, 'learning_rate': 0.00012862015203629273, 'epoch': 2.33}\n",
            "{'loss': 0.0205, 'grad_norm': 0.029630793258547783, 'learning_rate': 0.0001257446259144494, 'epoch': 2.34}\n",
            "{'loss': 0.028, 'grad_norm': 0.04721957817673683, 'learning_rate': 0.0001228969778384214, 'epoch': 2.34}\n",
            "{'loss': 0.0414, 'grad_norm': 0.03964687138795853, 'learning_rate': 0.00012007741992771066, 'epoch': 2.35}\n",
            "{'loss': 0.0337, 'grad_norm': 0.036301132291555405, 'learning_rate': 0.0001172861622094003, 'epoch': 2.36}\n",
            "{'loss': 0.0322, 'grad_norm': 0.03257938101887703, 'learning_rate': 0.0001145234126025102, 'epoch': 2.37}\n",
            "{'loss': 0.0317, 'grad_norm': 0.047556303441524506, 'learning_rate': 0.00011178937690250917, 'epoch': 2.38}\n",
            "{'loss': 0.0367, 'grad_norm': 0.030055036768317223, 'learning_rate': 0.0001090842587659851, 'epoch': 2.38}\n",
            "{'loss': 0.0226, 'grad_norm': 0.03539092093706131, 'learning_rate': 0.00010640825969547497, 'epoch': 2.39}\n",
            "{'loss': 0.0214, 'grad_norm': 0.029811015352606773, 'learning_rate': 0.00010376157902445487, 'epoch': 2.4}\n",
            "{'loss': 0.0456, 'grad_norm': 0.04759199917316437, 'learning_rate': 0.00010114441390249201, 'epoch': 2.41}\n",
            "{'loss': 0.0333, 'grad_norm': 0.033406879752874374, 'learning_rate': 9.85569592805588e-05, 'epoch': 2.42}\n",
            "{'loss': 0.0472, 'grad_norm': 0.051825232803821564, 'learning_rate': 9.599940789651179e-05, 'epoch': 2.42}\n",
            "{'loss': 0.0293, 'grad_norm': 0.10199974477291107, 'learning_rate': 9.347195026073368e-05, 'epoch': 2.43}\n",
            "{'loss': 0.0224, 'grad_norm': 0.03930080682039261, 'learning_rate': 9.09747746419436e-05, 'epoch': 2.44}\n",
            "{'loss': 0.0163, 'grad_norm': 0.03391662985086441, 'learning_rate': 8.850806705317183e-05, 'epoch': 2.45}\n",
            "{'loss': 0.0402, 'grad_norm': 0.0582161583006382, 'learning_rate': 8.60720112379046e-05, 'epoch': 2.46}\n",
            "{'loss': 0.0399, 'grad_norm': 0.039824649691581726, 'learning_rate': 8.366678865639687e-05, 'epoch': 2.46}\n",
            "{'loss': 0.0302, 'grad_norm': 0.059837084263563156, 'learning_rate': 8.129257847215571e-05, 'epoch': 2.47}\n",
            "{'loss': 0.0314, 'grad_norm': 0.03153708949685097, 'learning_rate': 7.894955753859412e-05, 'epoch': 2.48}\n",
            "{'loss': 0.0316, 'grad_norm': 0.041394297033548355, 'learning_rate': 7.663790038585794e-05, 'epoch': 2.49}\n",
            "{'loss': 0.0326, 'grad_norm': 0.03910892829298973, 'learning_rate': 7.435777920782444e-05, 'epoch': 2.5}\n",
            "{'loss': 0.0377, 'grad_norm': 0.058874450623989105, 'learning_rate': 7.21093638492763e-05, 'epoch': 2.5}\n",
            "{'loss': 0.0321, 'grad_norm': 0.03324953094124794, 'learning_rate': 6.989282179324962e-05, 'epoch': 2.51}\n",
            "{'loss': 0.0321, 'grad_norm': 0.06944064050912857, 'learning_rate': 6.770831814855882e-05, 'epoch': 2.52}\n",
            "{'loss': 0.0276, 'grad_norm': 0.03968706354498863, 'learning_rate': 6.555601563749674e-05, 'epoch': 2.53}\n",
            "{'loss': 0.0271, 'grad_norm': 0.02668226882815361, 'learning_rate': 6.343607458371459e-05, 'epoch': 2.54}\n",
            "{'loss': 0.0334, 'grad_norm': 0.04419029504060745, 'learning_rate': 6.134865290027902e-05, 'epoch': 2.54}\n",
            "{'loss': 0.0295, 'grad_norm': 0.032325707376003265, 'learning_rate': 5.92939060779093e-05, 'epoch': 2.55}\n",
            "{'loss': 0.0251, 'grad_norm': 0.03723257780075073, 'learning_rate': 5.72719871733951e-05, 'epoch': 2.56}\n",
            "{'loss': 0.0199, 'grad_norm': 0.025891633704304695, 'learning_rate': 5.5283046798195126e-05, 'epoch': 2.57}\n",
            "{'loss': 0.0286, 'grad_norm': 0.02966310642659664, 'learning_rate': 5.3327233107218545e-05, 'epoch': 2.58}\n",
            "{'loss': 0.0374, 'grad_norm': 0.035289790481328964, 'learning_rate': 5.140469178778845e-05, 'epoch': 2.58}\n",
            "{'loss': 0.0323, 'grad_norm': 0.03966504707932472, 'learning_rate': 4.9515566048790485e-05, 'epoch': 2.59}\n",
            "{'loss': 0.0322, 'grad_norm': 0.035645630210638046, 'learning_rate': 4.765999661000442e-05, 'epoch': 2.6}\n",
            "{'loss': 0.0323, 'grad_norm': 0.044849902391433716, 'learning_rate': 4.583812169162299e-05, 'epoch': 2.61}\n",
            "{'loss': 0.0177, 'grad_norm': 0.03622175380587578, 'learning_rate': 4.405007700395497e-05, 'epoch': 2.62}\n",
            "{'loss': 0.0359, 'grad_norm': 0.03652917593717575, 'learning_rate': 4.2295995737316854e-05, 'epoch': 2.62}\n",
            "{'loss': 0.0347, 'grad_norm': 0.042443204671144485, 'learning_rate': 4.057600855211141e-05, 'epoch': 2.63}\n",
            "{'loss': 0.0349, 'grad_norm': 0.03410777449607849, 'learning_rate': 3.8890243569094874e-05, 'epoch': 2.64}\n",
            "{'loss': 0.0359, 'grad_norm': 0.04232357069849968, 'learning_rate': 3.7238826359833275e-05, 'epoch': 2.65}\n",
            "{'loss': 0.0257, 'grad_norm': 0.03963012248277664, 'learning_rate': 3.562187993734883e-05, 'epoch': 2.66}\n",
            "{'loss': 0.0248, 'grad_norm': 0.03429357334971428, 'learning_rate': 3.40395247469566e-05, 'epoch': 2.66}\n",
            "{'loss': 0.0314, 'grad_norm': 0.03263593837618828, 'learning_rate': 3.249187865729264e-05, 'epoch': 2.67}\n",
            "{'loss': 0.0417, 'grad_norm': 0.048605069518089294, 'learning_rate': 3.097905695153408e-05, 'epoch': 2.68}\n",
            "{'loss': 0.0289, 'grad_norm': 0.02838309481739998, 'learning_rate': 2.9501172318811832e-05, 'epoch': 2.69}\n",
            "{'loss': 0.0294, 'grad_norm': 0.034721165895462036, 'learning_rate': 2.8058334845816213e-05, 'epoch': 2.7}\n",
            "{'loss': 0.0285, 'grad_norm': 0.03237992525100708, 'learning_rate': 2.6650652008597063e-05, 'epoch': 2.7}\n",
            "{'loss': 0.0292, 'grad_norm': 0.030596934258937836, 'learning_rate': 2.527822866455731e-05, 'epoch': 2.71}\n",
            "{'loss': 0.0357, 'grad_norm': 0.04262203723192215, 'learning_rate': 2.3941167044642943e-05, 'epoch': 2.72}\n",
            "{'loss': 0.0389, 'grad_norm': 0.042519938200712204, 'learning_rate': 2.2639566745727203e-05, 'epoch': 2.73}\n",
            "{'loss': 0.0387, 'grad_norm': 0.059611134231090546, 'learning_rate': 2.137352472319215e-05, 'epoch': 2.74}\n",
            "{'loss': 0.046, 'grad_norm': 0.047522593289613724, 'learning_rate': 2.0143135283706258e-05, 'epoch': 2.74}\n",
            "{'loss': 0.0179, 'grad_norm': 0.02699573151767254, 'learning_rate': 1.8948490078199765e-05, 'epoch': 2.75}\n",
            "{'loss': 0.0294, 'grad_norm': 0.029312606900930405, 'learning_rate': 1.7789678095037452e-05, 'epoch': 2.76}\n",
            "{'loss': 0.0425, 'grad_norm': 0.043723348528146744, 'learning_rate': 1.6666785653390248e-05, 'epoch': 2.77}\n",
            "{'loss': 0.0303, 'grad_norm': 0.03584948927164078, 'learning_rate': 1.557989639680496e-05, 'epoch': 2.78}\n",
            "{'loss': 0.0333, 'grad_norm': 0.03798068314790726, 'learning_rate': 1.4529091286973995e-05, 'epoch': 2.78}\n",
            "{'loss': 0.0249, 'grad_norm': 0.023617517203092575, 'learning_rate': 1.351444859770462e-05, 'epoch': 2.79}\n",
            "{'loss': 0.0359, 'grad_norm': 0.03473097085952759, 'learning_rate': 1.2536043909088191e-05, 'epoch': 2.8}\n",
            "{'loss': 0.0335, 'grad_norm': 0.042349088937044144, 'learning_rate': 1.159395010187042e-05, 'epoch': 2.81}\n",
            "{'loss': 0.0233, 'grad_norm': 0.03487386927008629, 'learning_rate': 1.0688237352022346e-05, 'epoch': 2.82}\n",
            "{'loss': 0.0239, 'grad_norm': 0.04879769682884216, 'learning_rate': 9.818973125513276e-06, 'epoch': 2.82}\n",
            "{'loss': 0.0324, 'grad_norm': 0.04820479825139046, 'learning_rate': 8.986222173284874e-06, 'epoch': 2.83}\n",
            "{'loss': 0.0397, 'grad_norm': 0.044714249670505524, 'learning_rate': 8.190046526428241e-06, 'epoch': 2.84}\n",
            "{'loss': 0.025, 'grad_norm': 0.05244148150086403, 'learning_rate': 7.4305054915631e-06, 'epoch': 2.85}\n",
            "{'loss': 0.0443, 'grad_norm': 0.036039985716342926, 'learning_rate': 6.7076556464202296e-06, 'epoch': 2.86}\n",
            "{'loss': 0.0314, 'grad_norm': 0.03446660190820694, 'learning_rate': 6.021550835626777e-06, 'epoch': 2.86}\n",
            "{'loss': 0.028, 'grad_norm': 0.03772633895277977, 'learning_rate': 5.372242166695684e-06, 'epoch': 2.87}\n",
            "{'loss': 0.0318, 'grad_norm': 0.04099378362298012, 'learning_rate': 4.759778006218407e-06, 'epoch': 2.88}\n",
            "{'loss': 0.0357, 'grad_norm': 0.04879966750741005, 'learning_rate': 4.184203976262513e-06, 'epoch': 2.89}\n",
            "{'loss': 0.0376, 'grad_norm': 0.034306518733501434, 'learning_rate': 3.645562950973014e-06, 'epoch': 2.9}\n",
            "{'loss': 0.0373, 'grad_norm': 0.044518519192934036, 'learning_rate': 3.143895053378698e-06, 'epoch': 2.9}\n",
            "{'loss': 0.0401, 'grad_norm': 0.03912017494440079, 'learning_rate': 2.6792376524036878e-06, 'epoch': 2.91}\n",
            "{'loss': 0.0332, 'grad_norm': 0.03865116089582443, 'learning_rate': 2.251625360083387e-06, 'epoch': 2.92}\n",
            "{'loss': 0.0353, 'grad_norm': 0.038070011883974075, 'learning_rate': 1.8610900289867672e-06, 'epoch': 2.93}\n",
            "{'loss': 0.0257, 'grad_norm': 0.026863543316721916, 'learning_rate': 1.5076607498433204e-06, 'epoch': 2.94}\n",
            "{'loss': 0.0216, 'grad_norm': 0.029654446989297867, 'learning_rate': 1.1913638493762368e-06, 'epoch': 2.94}\n",
            "{'loss': 0.0334, 'grad_norm': 0.048987168818712234, 'learning_rate': 9.12222888341252e-07, 'epoch': 2.95}\n",
            "{'loss': 0.0431, 'grad_norm': 0.050574224442243576, 'learning_rate': 6.702586597719384e-07, 'epoch': 2.96}\n",
            "{'loss': 0.0277, 'grad_norm': 0.02943294867873192, 'learning_rate': 4.6548918743033465e-07, 'epoch': 2.97}\n",
            "{'loss': 0.0323, 'grad_norm': 0.0369720533490181, 'learning_rate': 2.9792972446479607e-07, 'epoch': 2.98}\n",
            "{'loss': 0.0405, 'grad_norm': 0.03887569531798363, 'learning_rate': 1.6759275227357095e-07, 'epoch': 2.98}\n",
            "{'loss': 0.0339, 'grad_norm': 0.057731930166482925, 'learning_rate': 7.448797957526621e-08, 'epoch': 2.99}\n",
            "{'loss': 0.0349, 'grad_norm': 0.048006486147642136, 'learning_rate': 1.862234168542587e-08, 'epoch': 3.0}\n",
            "{'train_runtime': 44.2244, 'train_samples_per_second': 16.959, 'train_steps_per_second': 8.479, 'train_loss': 0.11737491583824158, 'epoch': 3.0}\n",
            "100% 375/375 [00:44<00:00,  8.48it/s]\n",
            "Training complete.\n",
            "Model saved to loras/self-edit/training_set_iteration_1/44f52bb0/4\n",
            "Training on 69 examples for 5 epochs, lr: 0.001\n",
            "No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n",
            "Starting training...\n",
            "{'loss': 6.6941, 'grad_norm': 11.339813232421875, 'learning_rate': 0.0, 'epoch': 0.03}\n",
            "{'loss': 6.8252, 'grad_norm': 11.315876007080078, 'learning_rate': 9.090909090909092e-05, 'epoch': 0.06}\n",
            "{'loss': 6.0556, 'grad_norm': 12.349905014038086, 'learning_rate': 0.00018181818181818183, 'epoch': 0.09}\n",
            "{'loss': 1.4519, 'grad_norm': 3.6504242420196533, 'learning_rate': 0.00027272727272727274, 'epoch': 0.11}\n",
            "{'loss': 0.6818, 'grad_norm': 1.2637577056884766, 'learning_rate': 0.00036363636363636367, 'epoch': 0.14}\n",
            "{'loss': 0.4071, 'grad_norm': 2.2131054401397705, 'learning_rate': 0.00045454545454545455, 'epoch': 0.17}\n",
            "{'loss': 0.113, 'grad_norm': 1.1232469081878662, 'learning_rate': 0.0005454545454545455, 'epoch': 0.2}\n",
            "{'loss': 0.1004, 'grad_norm': 0.3740110397338867, 'learning_rate': 0.0006363636363636364, 'epoch': 0.23}\n",
            "{'loss': 0.0227, 'grad_norm': 0.1348138153553009, 'learning_rate': 0.0007272727272727273, 'epoch': 0.26}\n",
            "{'loss': 0.0492, 'grad_norm': 0.14663457870483398, 'learning_rate': 0.0008181818181818183, 'epoch': 0.29}\n",
            "{'loss': 0.0357, 'grad_norm': 0.27964508533477783, 'learning_rate': 0.0009090909090909091, 'epoch': 0.31}\n",
            "{'loss': 0.0401, 'grad_norm': 0.16521485149860382, 'learning_rate': 0.001, 'epoch': 0.34}\n",
            "{'loss': 0.0303, 'grad_norm': 0.053430311381816864, 'learning_rate': 0.0009999082642158973, 'epoch': 0.37}\n",
            "{'loss': 0.0209, 'grad_norm': 0.0708312913775444, 'learning_rate': 0.0009996330905254049, 'epoch': 0.4}\n",
            "{'loss': 0.0369, 'grad_norm': 0.1300911009311676, 'learning_rate': 0.0009991745799016205, 'epoch': 0.43}\n",
            "{'loss': 0.0261, 'grad_norm': 0.04996860772371292, 'learning_rate': 0.0009985329005918703, 'epoch': 0.46}\n",
            "{'loss': 0.0143, 'grad_norm': 0.04884251579642296, 'learning_rate': 0.0009977082880559724, 'epoch': 0.49}\n",
            "{'loss': 0.0057, 'grad_norm': 0.02661534957587719, 'learning_rate': 0.0009967010448798375, 'epoch': 0.51}\n",
            "{'loss': 0.0572, 'grad_norm': 0.21468693017959595, 'learning_rate': 0.0009955115406644357, 'epoch': 0.54}\n",
            "{'loss': 0.0039, 'grad_norm': 0.021841222420334816, 'learning_rate': 0.0009941402118901744, 'epoch': 0.57}\n",
            "{'loss': 0.0514, 'grad_norm': 0.10006262362003326, 'learning_rate': 0.000992587561756735, 'epoch': 0.6}\n",
            "{'loss': 0.1079, 'grad_norm': 0.21663697063922882, 'learning_rate': 0.0009908541599984275, 'epoch': 0.63}\n",
            "{'loss': 0.0118, 'grad_norm': 0.03835202008485794, 'learning_rate': 0.0009889406426751297, 'epoch': 0.66}\n",
            "{'loss': 0.0225, 'grad_norm': 0.02848745882511139, 'learning_rate': 0.0009868477119388895, 'epoch': 0.69}\n",
            "{'loss': 0.0285, 'grad_norm': 0.04131988063454628, 'learning_rate': 0.0009845761357762759, 'epoch': 0.71}\n",
            "{'loss': 0.0289, 'grad_norm': 0.03581172227859497, 'learning_rate': 0.0009821267477265706, 'epoch': 0.74}\n",
            "{'loss': 0.0175, 'grad_norm': 0.09697157889604568, 'learning_rate': 0.0009795004465759066, 'epoch': 0.77}\n",
            "{'loss': 0.0771, 'grad_norm': 0.2749280035495758, 'learning_rate': 0.0009766981960274653, 'epoch': 0.8}\n",
            "{'loss': 0.0164, 'grad_norm': 0.031172633171081543, 'learning_rate': 0.0009737210243478522, 'epoch': 0.83}\n",
            "{'loss': 0.0294, 'grad_norm': 0.12748275697231293, 'learning_rate': 0.0009705700239897808, 'epoch': 0.86}\n",
            "{'loss': 0.0227, 'grad_norm': 0.024726536124944687, 'learning_rate': 0.0009672463511912055, 'epoch': 0.89}\n",
            "{'loss': 0.0349, 'grad_norm': 0.05937858670949936, 'learning_rate': 0.0009637512255510475, 'epoch': 0.91}\n",
            "{'loss': 0.0476, 'grad_norm': 0.16746880114078522, 'learning_rate': 0.0009600859295816708, 'epoch': 0.94}\n",
            "{'loss': 0.0335, 'grad_norm': 0.07393065840005875, 'learning_rate': 0.000956251808238275, 'epoch': 0.97}\n",
            "{'loss': 0.0039, 'grad_norm': 0.032833389937877655, 'learning_rate': 0.0009522502684253709, 'epoch': 1.0}\n",
            "{'loss': 0.0359, 'grad_norm': 0.16392533481121063, 'learning_rate': 0.0009480827784805278, 'epoch': 1.03}\n",
            "{'loss': 0.0234, 'grad_norm': 0.1055835708975792, 'learning_rate': 0.0009437508676355772, 'epoch': 1.06}\n",
            "{'loss': 0.0418, 'grad_norm': 0.12122384458780289, 'learning_rate': 0.0009392561254554713, 'epoch': 1.09}\n",
            "{'loss': 0.0195, 'grad_norm': 0.11446134746074677, 'learning_rate': 0.0009346002012550026, 'epoch': 1.11}\n",
            "{'loss': 0.0098, 'grad_norm': 0.03488030284643173, 'learning_rate': 0.0009297848034936007, 'epoch': 1.14}\n",
            "{'loss': 0.0032, 'grad_norm': 0.019750718027353287, 'learning_rate': 0.0009248116991484227, 'epoch': 1.17}\n",
            "{'loss': 0.0354, 'grad_norm': 0.25105020403862, 'learning_rate': 0.0009196827130659751, 'epoch': 1.2}\n",
            "{'loss': 0.0045, 'grad_norm': 0.020605111494660378, 'learning_rate': 0.0009143997272924974, 'epoch': 1.23}\n",
            "{'loss': 0.015, 'grad_norm': 0.07641597092151642, 'learning_rate': 0.0009089646803833589, 'epoch': 1.26}\n",
            "{'loss': 0.0142, 'grad_norm': 0.07184284180402756, 'learning_rate': 0.0009033795666917191, 'epoch': 1.29}\n",
            "{'loss': 0.0691, 'grad_norm': 0.09576120227575302, 'learning_rate': 0.0008976464356367133, 'epoch': 1.31}\n",
            "{'loss': 0.0009, 'grad_norm': 0.0055640218779444695, 'learning_rate': 0.0008917673909514322, 'epoch': 1.34}\n",
            "{'loss': 0.0171, 'grad_norm': 0.07227296382188797, 'learning_rate': 0.0008857445899109715, 'epoch': 1.37}\n",
            "{'loss': 0.0277, 'grad_norm': 0.04337158054113388, 'learning_rate': 0.0008795802425408352, 'epoch': 1.4}\n",
            "{'loss': 0.0239, 'grad_norm': 0.08866160362958908, 'learning_rate': 0.0008732766108059813, 'epoch': 1.43}\n",
            "{'loss': 0.01, 'grad_norm': 0.04081122577190399, 'learning_rate': 0.0008668360077808093, 'epoch': 1.46}\n",
            "{'loss': 0.0383, 'grad_norm': 0.13816329836845398, 'learning_rate': 0.0008602607968003935, 'epoch': 1.49}\n",
            "{'loss': 0.0171, 'grad_norm': 0.06205664947628975, 'learning_rate': 0.0008535533905932737, 'epoch': 1.51}\n",
            "{'loss': 0.0098, 'grad_norm': 0.060746125876903534, 'learning_rate': 0.0008467162503961209, 'epoch': 1.54}\n",
            "{'loss': 0.0244, 'grad_norm': 0.08533920347690582, 'learning_rate': 0.0008397518850506028, 'epoch': 1.57}\n",
            "{'loss': 0.0096, 'grad_norm': 0.06997639685869217, 'learning_rate': 0.0008326628500827827, 'epoch': 1.6}\n",
            "{'loss': 0.0056, 'grad_norm': 0.024100562557578087, 'learning_rate': 0.0008254517467653857, 'epoch': 1.63}\n",
            "{'loss': 0.003, 'grad_norm': 0.01852523349225521, 'learning_rate': 0.00081812122116328, 'epoch': 1.66}\n",
            "{'loss': 0.0075, 'grad_norm': 0.058045510202646255, 'learning_rate': 0.0008106739631625217, 'epoch': 1.69}\n",
            "{'loss': 0.0043, 'grad_norm': 0.03702105954289436, 'learning_rate': 0.000803112705483319, 'epoch': 1.71}\n",
            "{'loss': 0.0002, 'grad_norm': 0.0014629210345447063, 'learning_rate': 0.0007954402226772804, 'epoch': 1.74}\n",
            "{'loss': 0.0003, 'grad_norm': 0.0026798106264322996, 'learning_rate': 0.0007876593301093103, 'epoch': 1.77}\n",
            "{'loss': 0.0157, 'grad_norm': 0.17228063941001892, 'learning_rate': 0.0007797728829245321, 'epoch': 1.8}\n",
            "{'loss': 0.0003, 'grad_norm': 0.003636466572061181, 'learning_rate': 0.0007717837750006106, 'epoch': 1.83}\n",
            "{'loss': 0.0007, 'grad_norm': 0.011526915244758129, 'learning_rate': 0.0007636949378858647, 'epoch': 1.86}\n",
            "{'loss': 0.0022, 'grad_norm': 0.05223257094621658, 'learning_rate': 0.0007555093397235552, 'epoch': 1.89}\n",
            "{'loss': 0.0002, 'grad_norm': 0.0020742325577884912, 'learning_rate': 0.0007472299841627451, 'epoch': 1.91}\n",
            "{'loss': 0.0, 'grad_norm': 0.0002530034107621759, 'learning_rate': 0.0007388599092561315, 'epoch': 1.94}\n",
            "{'loss': 0.0, 'grad_norm': 0.00018507208733353764, 'learning_rate': 0.0007304021863452525, 'epoch': 1.97}\n",
            "{'loss': 0.0, 'grad_norm': 0.00012976628204341978, 'learning_rate': 0.0007218599189334799, 'epoch': 2.0}\n",
            "{'loss': 0.0, 'grad_norm': 0.00023984497238416225, 'learning_rate': 0.0007132362415472099, 'epoch': 2.03}\n",
            "{'loss': 0.0, 'grad_norm': 0.0003021833545062691, 'learning_rate': 0.00070453431858567, 'epoch': 2.06}\n",
            "{'loss': 0.0006, 'grad_norm': 0.03552431985735893, 'learning_rate': 0.0006957573431597646, 'epoch': 2.09}\n",
            "{'loss': 0.0, 'grad_norm': 0.000573073688428849, 'learning_rate': 0.0006869085359203844, 'epoch': 2.11}\n",
            "{'loss': 0.0, 'grad_norm': 0.0006503385957330465, 'learning_rate': 0.0006779911438766117, 'epoch': 2.14}\n",
            "{'loss': 0.0, 'grad_norm': 8.666361827636138e-05, 'learning_rate': 0.0006690084392042513, 'epoch': 2.17}\n",
            "{'loss': 0.0965, 'grad_norm': 1.1962677240371704, 'learning_rate': 0.0006599637180451295, 'epoch': 2.2}\n",
            "{'loss': 0.0002, 'grad_norm': 0.004114036913961172, 'learning_rate': 0.0006508602992975963, 'epoch': 2.23}\n",
            "{'loss': 0.0458, 'grad_norm': 0.7899152636528015, 'learning_rate': 0.0006417015233986786, 'epoch': 2.26}\n",
            "{'loss': 0.0001, 'grad_norm': 0.0024059205316007137, 'learning_rate': 0.000632490751098331, 'epoch': 2.29}\n",
            "{'loss': 0.0023, 'grad_norm': 0.057113081216812134, 'learning_rate': 0.0006232313622262297, 'epoch': 2.31}\n",
            "{'loss': 0.0021, 'grad_norm': 0.04596448689699173, 'learning_rate': 0.0006139267544515689, 'epoch': 2.34}\n",
            "{'loss': 0.0, 'grad_norm': 0.000619918224401772, 'learning_rate': 0.0006045803420363084, 'epoch': 2.37}\n",
            "{'loss': 0.001, 'grad_norm': 0.0163270253688097, 'learning_rate': 0.0005951955545823342, 'epoch': 2.4}\n",
            "{'loss': 0.0364, 'grad_norm': 0.8027248978614807, 'learning_rate': 0.0005857758357729892, 'epoch': 2.43}\n",
            "{'loss': 0.0137, 'grad_norm': 0.30700308084487915, 'learning_rate': 0.0005763246421094373, 'epoch': 2.46}\n",
            "{'loss': 0.0015, 'grad_norm': 0.015999674797058105, 'learning_rate': 0.0005668454416423242, 'epoch': 2.49}\n",
            "{'loss': 0.0114, 'grad_norm': 0.23051489889621735, 'learning_rate': 0.0005573417126992003, 'epoch': 2.51}\n",
            "{'loss': 0.0019, 'grad_norm': 0.019301239401102066, 'learning_rate': 0.0005478169426081711, 'epoch': 2.54}\n",
            "{'loss': 0.012, 'grad_norm': 0.1902589499950409, 'learning_rate': 0.0005382746264182479, 'epoch': 2.57}\n",
            "{'loss': 0.0202, 'grad_norm': 0.35553157329559326, 'learning_rate': 0.0005287182656168618, 'epoch': 2.6}\n",
            "{'loss': 0.0008, 'grad_norm': 0.0217002984136343, 'learning_rate': 0.0005191513668450177, 'epoch': 2.63}\n",
            "{'loss': 0.001, 'grad_norm': 0.030174216255545616, 'learning_rate': 0.0005095774406105571, 'epoch': 2.66}\n",
            "{'loss': 0.0034, 'grad_norm': 0.10898227244615555, 'learning_rate': 0.0005, 'epoch': 2.69}\n",
            "{'loss': 0.0001, 'grad_norm': 0.0007109901634976268, 'learning_rate': 0.000490422559389443, 'epoch': 2.71}\n",
            "{'loss': 0.0001, 'grad_norm': 0.0029849382117390633, 'learning_rate': 0.00048084863315498236, 'epoch': 2.74}\n",
            "{'loss': 0.0007, 'grad_norm': 0.017552608624100685, 'learning_rate': 0.0004712817343831384, 'epoch': 2.77}\n",
            "{'loss': 0.0003, 'grad_norm': 0.0043048737570643425, 'learning_rate': 0.00046172537358175214, 'epoch': 2.8}\n",
            "{'loss': 0.0003, 'grad_norm': 0.0039572324603796005, 'learning_rate': 0.0004521830573918289, 'epoch': 2.83}\n",
            "{'loss': 0.0002, 'grad_norm': 0.012077861465513706, 'learning_rate': 0.0004426582873007998, 'epoch': 2.86}\n",
            "{'loss': 0.0142, 'grad_norm': 0.4815751314163208, 'learning_rate': 0.00043315455835767574, 'epoch': 2.89}\n",
            "{'loss': 0.0001, 'grad_norm': 0.0013399907620623708, 'learning_rate': 0.0004236753578905627, 'epoch': 2.91}\n",
            "{'loss': 0.0002, 'grad_norm': 0.005118970759212971, 'learning_rate': 0.0004142241642270108, 'epoch': 2.94}\n",
            "{'loss': 0.0007, 'grad_norm': 0.020306825637817383, 'learning_rate': 0.00040480444541766573, 'epoch': 2.97}\n",
            "{'loss': 0.0002, 'grad_norm': 0.007201912347227335, 'learning_rate': 0.00039541965796369177, 'epoch': 3.0}\n",
            "{'loss': 0.0002, 'grad_norm': 0.00504577299579978, 'learning_rate': 0.0003860732455484313, 'epoch': 3.03}\n",
            "{'loss': 0.0009, 'grad_norm': 0.017418228089809418, 'learning_rate': 0.0003767686377737705, 'epoch': 3.06}\n",
            "{'loss': 0.0001, 'grad_norm': 0.003685588715597987, 'learning_rate': 0.00036750924890166926, 'epoch': 3.09}\n",
            "{'loss': 0.0026, 'grad_norm': 0.27713409066200256, 'learning_rate': 0.00035829847660132146, 'epoch': 3.11}\n",
            "{'loss': 0.0611, 'grad_norm': 0.24625790119171143, 'learning_rate': 0.00034913970070240386, 'epoch': 3.14}\n",
            "{'loss': 0.0321, 'grad_norm': 0.3074536919593811, 'learning_rate': 0.0003400362819548706, 'epoch': 3.17}\n",
            "{'loss': 0.0002, 'grad_norm': 0.004128326196223497, 'learning_rate': 0.0003309915607957487, 'epoch': 3.2}\n",
            "{'loss': 0.0042, 'grad_norm': 0.12149883806705475, 'learning_rate': 0.0003220088561233884, 'epoch': 3.23}\n",
            "{'loss': 0.0004, 'grad_norm': 0.01123074907809496, 'learning_rate': 0.00031309146407961565, 'epoch': 3.26}\n",
            "{'loss': 0.0066, 'grad_norm': 0.14790943264961243, 'learning_rate': 0.00030424265684023555, 'epoch': 3.29}\n",
            "{'loss': 0.0015, 'grad_norm': 0.023743389174342155, 'learning_rate': 0.00029546568141433004, 'epoch': 3.31}\n",
            "{'loss': 0.0001, 'grad_norm': 0.0021222257055342197, 'learning_rate': 0.00028676375845279015, 'epoch': 3.34}\n",
            "{'loss': 0.0016, 'grad_norm': 0.022913355380296707, 'learning_rate': 0.0002781400810665201, 'epoch': 3.37}\n",
            "{'loss': 0.0008, 'grad_norm': 0.008768105879426003, 'learning_rate': 0.0002695978136547476, 'epoch': 3.4}\n",
            "{'loss': 0.0009, 'grad_norm': 0.010444661602377892, 'learning_rate': 0.00026114009074386846, 'epoch': 3.43}\n",
            "{'loss': 0.0001, 'grad_norm': 0.0011685609351843596, 'learning_rate': 0.0002527700158372548, 'epoch': 3.46}\n",
            "{'loss': 0.0001, 'grad_norm': 0.0010868650861084461, 'learning_rate': 0.0002444906602764447, 'epoch': 3.49}\n",
            "{'loss': 0.0001, 'grad_norm': 0.0025468613021075726, 'learning_rate': 0.0002363050621141354, 'epoch': 3.51}\n",
            "{'loss': 0.0002, 'grad_norm': 0.0022927226964384317, 'learning_rate': 0.00022821622499938948, 'epoch': 3.54}\n",
            "{'loss': 0.0002, 'grad_norm': 0.006178271025419235, 'learning_rate': 0.000220227117075468, 'epoch': 3.57}\n",
            "{'loss': 0.0004, 'grad_norm': 0.005360270384699106, 'learning_rate': 0.00021234066989068973, 'epoch': 3.6}\n",
            "{'loss': 0.0002, 'grad_norm': 0.0019417253788560629, 'learning_rate': 0.0002045597773227199, 'epoch': 3.63}\n",
            "{'loss': 0.0001, 'grad_norm': 0.001135277678258717, 'learning_rate': 0.00019688729451668114, 'epoch': 3.66}\n",
            "{'loss': 0.0004, 'grad_norm': 0.006020629778504372, 'learning_rate': 0.00018932603683747857, 'epoch': 3.69}\n",
            "{'loss': 0.0129, 'grad_norm': 0.360895037651062, 'learning_rate': 0.00018187877883672022, 'epoch': 3.71}\n",
            "{'loss': 0.0005, 'grad_norm': 0.006877567619085312, 'learning_rate': 0.0001745482532346145, 'epoch': 3.74}\n",
            "{'loss': 0.0007, 'grad_norm': 0.009235811419785023, 'learning_rate': 0.00016733714991721738, 'epoch': 3.77}\n",
            "{'loss': 0.0001, 'grad_norm': 0.001443934510461986, 'learning_rate': 0.00016024811494939724, 'epoch': 3.8}\n",
            "{'loss': 0.0002, 'grad_norm': 0.003220612183213234, 'learning_rate': 0.0001532837496038792, 'epoch': 3.83}\n",
            "{'loss': 0.0003, 'grad_norm': 0.00391404889523983, 'learning_rate': 0.00014644660940672628, 'epoch': 3.86}\n",
            "{'loss': 0.0007, 'grad_norm': 0.01163340825587511, 'learning_rate': 0.00013973920319960653, 'epoch': 3.89}\n",
            "{'loss': 0.0, 'grad_norm': 0.00018997510778717697, 'learning_rate': 0.00013316399221919073, 'epoch': 3.91}\n",
            "{'loss': 0.0001, 'grad_norm': 0.0011855829507112503, 'learning_rate': 0.00012672338919401865, 'epoch': 3.94}\n",
            "{'loss': 0.0001, 'grad_norm': 0.0013177295913919806, 'learning_rate': 0.00012041975745916473, 'epoch': 3.97}\n",
            "{'loss': 0.005, 'grad_norm': 0.07421711087226868, 'learning_rate': 0.00011425541008902851, 'epoch': 4.0}\n",
            "{'loss': 0.0001, 'grad_norm': 0.0020388399716466665, 'learning_rate': 0.0001082326090485679, 'epoch': 4.03}\n",
            "{'loss': 0.0, 'grad_norm': 0.00031917350133880973, 'learning_rate': 0.00010235356436328675, 'epoch': 4.06}\n",
            "{'loss': 0.0001, 'grad_norm': 0.0012667917180806398, 'learning_rate': 9.662043330828085e-05, 'epoch': 4.09}\n",
            "{'loss': 0.0006, 'grad_norm': 0.009626515209674835, 'learning_rate': 9.103531961664119e-05, 'epoch': 4.11}\n",
            "{'loss': 0.0001, 'grad_norm': 0.0006938019068911672, 'learning_rate': 8.560027270750276e-05, 'epoch': 4.14}\n",
            "{'loss': 0.0002, 'grad_norm': 0.002962929429486394, 'learning_rate': 8.031728693402501e-05, 'epoch': 4.17}\n",
            "{'loss': 0.0001, 'grad_norm': 0.0013038311153650284, 'learning_rate': 7.518830085157735e-05, 'epoch': 4.2}\n",
            "{'loss': 0.0002, 'grad_norm': 0.0027594210114330053, 'learning_rate': 7.021519650639951e-05, 'epoch': 4.23}\n",
            "{'loss': 0.0, 'grad_norm': 0.00014664616901427507, 'learning_rate': 6.539979874499746e-05, 'epoch': 4.26}\n",
            "{'loss': 0.0, 'grad_norm': 0.0005308634717948735, 'learning_rate': 6.07438745445289e-05, 'epoch': 4.29}\n",
            "{'loss': 0.0, 'grad_norm': 0.000552379759028554, 'learning_rate': 5.624913236442286e-05, 'epoch': 4.31}\n",
            "{'loss': 0.0001, 'grad_norm': 0.002174626337364316, 'learning_rate': 5.191722151947226e-05, 'epoch': 4.34}\n",
            "{'loss': 0.0001, 'grad_norm': 0.002190812723711133, 'learning_rate': 4.77497315746292e-05, 'epoch': 4.37}\n",
            "{'loss': 0.0001, 'grad_norm': 0.0008867969154380262, 'learning_rate': 4.374819176172501e-05, 'epoch': 4.4}\n",
            "{'loss': 0.0, 'grad_norm': 0.00011884595005540177, 'learning_rate': 3.991407041832912e-05, 'epoch': 4.43}\n",
            "{'loss': 0.0001, 'grad_norm': 0.0009698267676867545, 'learning_rate': 3.624877444895269e-05, 'epoch': 4.46}\n",
            "{'loss': 0.0001, 'grad_norm': 0.0011085763107985258, 'learning_rate': 3.27536488087945e-05, 'epoch': 4.49}\n",
            "{'loss': 0.0, 'grad_norm': 0.00018509775691200048, 'learning_rate': 2.9429976010219238e-05, 'epoch': 4.51}\n",
            "{'loss': 0.0001, 'grad_norm': 0.0016375536797568202, 'learning_rate': 2.6278975652147873e-05, 'epoch': 4.54}\n",
            "{'loss': 0.0, 'grad_norm': 0.0006652119336649776, 'learning_rate': 2.330180397253473e-05, 'epoch': 4.57}\n",
            "{'loss': 0.0, 'grad_norm': 0.0003724061534740031, 'learning_rate': 2.0499553424093487e-05, 'epoch': 4.6}\n",
            "{'loss': 0.0, 'grad_norm': 0.0008831003797240555, 'learning_rate': 1.787325227342951e-05, 'epoch': 4.63}\n",
            "{'loss': 0.0, 'grad_norm': 0.0006665500113740563, 'learning_rate': 1.542386422372405e-05, 'epoch': 4.66}\n",
            "{'loss': 0.0001, 'grad_norm': 0.0016023399075493217, 'learning_rate': 1.3152288061110518e-05, 'epoch': 4.69}\n",
            "{'loss': 0.0003, 'grad_norm': 0.005688850302249193, 'learning_rate': 1.1059357324870456e-05, 'epoch': 4.71}\n",
            "{'loss': 0.0, 'grad_norm': 0.00013511984434444457, 'learning_rate': 9.145840001572536e-06, 'epoch': 4.74}\n",
            "{'loss': 0.0001, 'grad_norm': 0.0007715389365330338, 'learning_rate': 7.41243824326504e-06, 'epoch': 4.77}\n",
            "{'loss': 0.0, 'grad_norm': 0.00016964567475952208, 'learning_rate': 5.859788109825792e-06, 'epoch': 4.8}\n",
            "{'loss': 0.0, 'grad_norm': 0.0005362782976590097, 'learning_rate': 4.48845933556441e-06, 'epoch': 4.83}\n",
            "{'loss': 0.0, 'grad_norm': 0.00036587592330761254, 'learning_rate': 3.2989551201624833e-06, 'epoch': 4.86}\n",
            "{'loss': 0.0001, 'grad_norm': 0.0007611276232637465, 'learning_rate': 2.2917119440275524e-06, 'epoch': 4.89}\n",
            "{'loss': 0.0, 'grad_norm': 0.00011626307241385803, 'learning_rate': 1.4670994081297795e-06, 'epoch': 4.91}\n",
            "{'loss': 0.0001, 'grad_norm': 0.00149394606705755, 'learning_rate': 8.254200983794369e-07, 'epoch': 4.94}\n",
            "{'loss': 0.0001, 'grad_norm': 0.0005151019431650639, 'learning_rate': 3.669094745950008e-07, 'epoch': 4.97}\n",
            "{'loss': 0.0005, 'grad_norm': 0.008168202824890614, 'learning_rate': 9.17357841028199e-08, 'epoch': 5.0}\n",
            "{'train_runtime': 20.3493, 'train_samples_per_second': 16.954, 'train_steps_per_second': 8.6, 'train_loss': 0.13773456188561664, 'epoch': 5.0}\n",
            "100% 175/175 [00:20<00:00,  8.60it/s]\n",
            "Training complete.\n",
            "Model saved to loras/self-edit/training_set_iteration_1/44f52bb0/5\n",
            "Skipping training for task 44f52bb0 because the number of steps is greater than 375\n",
            "Training on 250 examples for 0 epochs, lr: 0.01\n",
            "No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n",
            "Starting training...\n",
            "{'train_runtime': 0.0021, 'train_samples_per_second': 0.0, 'train_steps_per_second': 0.0, 'train_loss': 0.0, 'epoch': 0}\n",
            "0it [00:00, ?it/s]\n",
            "Training complete.\n",
            "Model saved to loras/self-edit/training_set_iteration_1/44f52bb0/6\n",
            "Skipping training for task 44f52bb0 because the training strategy is not valid\n",
            "Training on 250 examples for 0 epochs, lr: 0.001\n",
            "No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n",
            "Starting training...\n",
            "{'train_runtime': 0.0022, 'train_samples_per_second': 0.0, 'train_steps_per_second': 0.0, 'train_loss': 0.0, 'epoch': 0}\n",
            "0it [00:00, ?it/s]\n",
            "Training complete.\n",
            "Model saved to loras/self-edit/training_set_iteration_1/44f52bb0/7\n",
            "Training on 250 examples for 3 epochs, lr: 0.001\n",
            "No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n",
            "Starting training...\n",
            "{'loss': 6.4353, 'grad_norm': 8.187479019165039, 'learning_rate': 0.0, 'epoch': 0.01}\n",
            "{'loss': 7.3391, 'grad_norm': 10.42506217956543, 'learning_rate': 9.090909090909092e-05, 'epoch': 0.02}\n",
            "{'loss': 5.3564, 'grad_norm': 8.036905288696289, 'learning_rate': 0.00018181818181818183, 'epoch': 0.02}\n",
            "{'loss': 1.5843, 'grad_norm': 5.967859745025635, 'learning_rate': 0.00027272727272727274, 'epoch': 0.03}\n",
            "{'loss': 2.0006, 'grad_norm': 16.405548095703125, 'learning_rate': 0.00036363636363636367, 'epoch': 0.04}\n",
            "{'loss': 0.8793, 'grad_norm': 0.3358604907989502, 'learning_rate': 0.00045454545454545455, 'epoch': 0.05}\n",
            "{'loss': 0.8596, 'grad_norm': 0.3229503035545349, 'learning_rate': 0.0005454545454545455, 'epoch': 0.06}\n",
            "{'loss': 0.6808, 'grad_norm': 0.28216275572776794, 'learning_rate': 0.0006363636363636364, 'epoch': 0.06}\n",
            "{'loss': 0.6141, 'grad_norm': 0.29211145639419556, 'learning_rate': 0.0007272727272727273, 'epoch': 0.07}\n",
            "{'loss': 0.4944, 'grad_norm': 0.171980619430542, 'learning_rate': 0.0008181818181818183, 'epoch': 0.08}\n",
            "{'loss': 0.4293, 'grad_norm': 0.13637018203735352, 'learning_rate': 0.0009090909090909091, 'epoch': 0.09}\n",
            "{'loss': 0.3327, 'grad_norm': 0.13709284365177155, 'learning_rate': 0.001, 'epoch': 0.1}\n",
            "{'loss': 0.2874, 'grad_norm': 0.1393599808216095, 'learning_rate': 0.0009999813776583146, 'epoch': 0.1}\n",
            "{'loss': 0.221, 'grad_norm': 0.18005971610546112, 'learning_rate': 0.0009999255120204248, 'epoch': 0.11}\n",
            "{'loss': 0.179, 'grad_norm': 0.15313680469989777, 'learning_rate': 0.0009998324072477264, 'epoch': 0.12}\n",
            "{'loss': 0.1312, 'grad_norm': 0.1340731978416443, 'learning_rate': 0.0009997020702755353, 'epoch': 0.13}\n",
            "{'loss': 0.1334, 'grad_norm': 0.10394982248544693, 'learning_rate': 0.0009995345108125698, 'epoch': 0.14}\n",
            "{'loss': 0.1098, 'grad_norm': 0.0684162825345993, 'learning_rate': 0.0009993297413402281, 'epoch': 0.14}\n",
            "{'loss': 0.1241, 'grad_norm': 0.08169537037611008, 'learning_rate': 0.0009990877771116587, 'epoch': 0.15}\n",
            "{'loss': 0.1287, 'grad_norm': 0.073919877409935, 'learning_rate': 0.0009988086361506238, 'epoch': 0.16}\n",
            "{'loss': 0.1219, 'grad_norm': 0.06719519942998886, 'learning_rate': 0.0009984923392501567, 'epoch': 0.17}\n",
            "{'loss': 0.1346, 'grad_norm': 0.10940880328416824, 'learning_rate': 0.0009981389099710132, 'epoch': 0.18}\n",
            "{'loss': 0.133, 'grad_norm': 0.09848558157682419, 'learning_rate': 0.0009977483746399167, 'epoch': 0.18}\n",
            "{'loss': 0.14, 'grad_norm': 0.2432851940393448, 'learning_rate': 0.0009973207623475964, 'epoch': 0.19}\n",
            "{'loss': 0.1035, 'grad_norm': 0.06489790976047516, 'learning_rate': 0.0009968561049466214, 'epoch': 0.2}\n",
            "{'loss': 0.1201, 'grad_norm': 0.13527114689350128, 'learning_rate': 0.000996354437049027, 'epoch': 0.21}\n",
            "{'loss': 0.1002, 'grad_norm': 0.07591785490512848, 'learning_rate': 0.0009958157960237375, 'epoch': 0.22}\n",
            "{'loss': 0.1094, 'grad_norm': 0.07899286597967148, 'learning_rate': 0.0009952402219937815, 'epoch': 0.22}\n",
            "{'loss': 0.1175, 'grad_norm': 0.16169939935207367, 'learning_rate': 0.0009946277578333045, 'epoch': 0.23}\n",
            "{'loss': 0.1068, 'grad_norm': 0.11031583696603775, 'learning_rate': 0.0009939784491643732, 'epoch': 0.24}\n",
            "{'loss': 0.1176, 'grad_norm': 0.11733529716730118, 'learning_rate': 0.0009932923443535797, 'epoch': 0.25}\n",
            "{'loss': 0.1015, 'grad_norm': 0.11282974481582642, 'learning_rate': 0.000992569494508437, 'epoch': 0.26}\n",
            "{'loss': 0.0975, 'grad_norm': 0.06924989074468613, 'learning_rate': 0.0009918099534735718, 'epoch': 0.26}\n",
            "{'loss': 0.0798, 'grad_norm': 0.05816936865448952, 'learning_rate': 0.0009910137778267152, 'epoch': 0.27}\n",
            "{'loss': 0.0943, 'grad_norm': 0.0891496017575264, 'learning_rate': 0.0009901810268744867, 'epoch': 0.28}\n",
            "{'loss': 0.1126, 'grad_norm': 0.11501823365688324, 'learning_rate': 0.0009893117626479776, 'epoch': 0.29}\n",
            "{'loss': 0.1105, 'grad_norm': 0.11247923225164413, 'learning_rate': 0.0009884060498981295, 'epoch': 0.3}\n",
            "{'loss': 0.0586, 'grad_norm': 0.07164870947599411, 'learning_rate': 0.0009874639560909118, 'epoch': 0.3}\n",
            "{'loss': 0.0837, 'grad_norm': 0.07036145776510239, 'learning_rate': 0.0009864855514022954, 'epoch': 0.31}\n",
            "{'loss': 0.0618, 'grad_norm': 0.0631142109632492, 'learning_rate': 0.000985470908713026, 'epoch': 0.32}\n",
            "{'loss': 0.0751, 'grad_norm': 0.10206697881221771, 'learning_rate': 0.0009844201036031952, 'epoch': 0.33}\n",
            "{'loss': 0.0506, 'grad_norm': 0.05233136937022209, 'learning_rate': 0.0009833332143466098, 'epoch': 0.34}\n",
            "{'loss': 0.0555, 'grad_norm': 0.0701182633638382, 'learning_rate': 0.0009822103219049626, 'epoch': 0.34}\n",
            "{'loss': 0.0697, 'grad_norm': 0.060911789536476135, 'learning_rate': 0.0009810515099218002, 'epoch': 0.35}\n",
            "{'loss': 0.0777, 'grad_norm': 0.09317123144865036, 'learning_rate': 0.0009798568647162937, 'epoch': 0.36}\n",
            "{'loss': 0.0803, 'grad_norm': 0.0838671624660492, 'learning_rate': 0.000978626475276808, 'epoch': 0.37}\n",
            "{'loss': 0.0888, 'grad_norm': 0.0858718603849411, 'learning_rate': 0.0009773604332542728, 'epoch': 0.38}\n",
            "{'loss': 0.0634, 'grad_norm': 0.05616137757897377, 'learning_rate': 0.0009760588329553571, 'epoch': 0.38}\n",
            "{'loss': 0.0516, 'grad_norm': 0.04405461996793747, 'learning_rate': 0.0009747217713354427, 'epoch': 0.39}\n",
            "{'loss': 0.0556, 'grad_norm': 0.054374661296606064, 'learning_rate': 0.000973349347991403, 'epoch': 0.4}\n",
            "{'loss': 0.0635, 'grad_norm': 0.07891424745321274, 'learning_rate': 0.0009719416651541838, 'epoch': 0.41}\n",
            "{'loss': 0.0539, 'grad_norm': 0.04524233192205429, 'learning_rate': 0.0009704988276811882, 'epoch': 0.42}\n",
            "{'loss': 0.0686, 'grad_norm': 0.07460973411798477, 'learning_rate': 0.000969020943048466, 'epoch': 0.42}\n",
            "{'loss': 0.0647, 'grad_norm': 0.0664907917380333, 'learning_rate': 0.0009675081213427075, 'epoch': 0.43}\n",
            "{'loss': 0.0576, 'grad_norm': 0.03811126947402954, 'learning_rate': 0.0009659604752530434, 'epoch': 0.44}\n",
            "{'loss': 0.0489, 'grad_norm': 0.04329093173146248, 'learning_rate': 0.0009643781200626511, 'epoch': 0.45}\n",
            "{'loss': 0.0653, 'grad_norm': 0.06069236993789673, 'learning_rate': 0.0009627611736401667, 'epoch': 0.46}\n",
            "{'loss': 0.0516, 'grad_norm': 0.05092349648475647, 'learning_rate': 0.0009611097564309052, 'epoch': 0.46}\n",
            "{'loss': 0.0523, 'grad_norm': 0.050163835287094116, 'learning_rate': 0.0009594239914478886, 'epoch': 0.47}\n",
            "{'loss': 0.0432, 'grad_norm': 0.05356219410896301, 'learning_rate': 0.0009577040042626832, 'epoch': 0.48}\n",
            "{'loss': 0.0434, 'grad_norm': 0.07730886340141296, 'learning_rate': 0.0009559499229960451, 'epoch': 0.49}\n",
            "{'loss': 0.0552, 'grad_norm': 0.052049484103918076, 'learning_rate': 0.000954161878308377, 'epoch': 0.5}\n",
            "{'loss': 0.038, 'grad_norm': 0.05146652087569237, 'learning_rate': 0.0009523400033899956, 'epoch': 0.5}\n",
            "{'loss': 0.075, 'grad_norm': 0.06885405629873276, 'learning_rate': 0.0009504844339512095, 'epoch': 0.51}\n",
            "{'loss': 0.0384, 'grad_norm': 0.054153699427843094, 'learning_rate': 0.0009485953082122116, 'epoch': 0.52}\n",
            "{'loss': 0.0625, 'grad_norm': 0.0633581280708313, 'learning_rate': 0.0009466727668927816, 'epoch': 0.53}\n",
            "{'loss': 0.0472, 'grad_norm': 0.040453724563121796, 'learning_rate': 0.000944716953201805, 'epoch': 0.54}\n",
            "{'loss': 0.064, 'grad_norm': 0.07820862531661987, 'learning_rate': 0.0009427280128266049, 'epoch': 0.54}\n",
            "{'loss': 0.0529, 'grad_norm': 0.05009399726986885, 'learning_rate': 0.0009407060939220907, 'epoch': 0.55}\n",
            "{'loss': 0.0762, 'grad_norm': 0.1403377652168274, 'learning_rate': 0.000938651347099721, 'epoch': 0.56}\n",
            "{'loss': 0.0438, 'grad_norm': 0.042768511921167374, 'learning_rate': 0.0009365639254162854, 'epoch': 0.57}\n",
            "{'loss': 0.0614, 'grad_norm': 0.054746415466070175, 'learning_rate': 0.0009344439843625034, 'epoch': 0.58}\n",
            "{'loss': 0.0538, 'grad_norm': 0.06170625984668732, 'learning_rate': 0.0009322916818514413, 'epoch': 0.58}\n",
            "{'loss': 0.073, 'grad_norm': 0.06368308514356613, 'learning_rate': 0.0009301071782067504, 'epoch': 0.59}\n",
            "{'loss': 0.0381, 'grad_norm': 0.06326077878475189, 'learning_rate': 0.0009278906361507238, 'epoch': 0.6}\n",
            "{'loss': 0.0494, 'grad_norm': 0.034456025809049606, 'learning_rate': 0.0009256422207921756, 'epoch': 0.61}\n",
            "{'loss': 0.0467, 'grad_norm': 0.07791034877300262, 'learning_rate': 0.0009233620996141421, 'epoch': 0.62}\n",
            "{'loss': 0.0673, 'grad_norm': 0.07156506180763245, 'learning_rate': 0.0009210504424614059, 'epoch': 0.62}\n",
            "{'loss': 0.0668, 'grad_norm': 0.11054836213588715, 'learning_rate': 0.0009187074215278444, 'epoch': 0.63}\n",
            "{'loss': 0.0551, 'grad_norm': 0.037490714341402054, 'learning_rate': 0.0009163332113436032, 'epoch': 0.64}\n",
            "{'loss': 0.0594, 'grad_norm': 0.0514536015689373, 'learning_rate': 0.0009139279887620955, 'epoch': 0.65}\n",
            "{'loss': 0.0694, 'grad_norm': 0.07011479139328003, 'learning_rate': 0.0009114919329468282, 'epoch': 0.66}\n",
            "{'loss': 0.0535, 'grad_norm': 0.05870535969734192, 'learning_rate': 0.0009090252253580565, 'epoch': 0.66}\n",
            "{'loss': 0.0618, 'grad_norm': 0.09022962301969528, 'learning_rate': 0.0009065280497392663, 'epoch': 0.67}\n",
            "{'loss': 0.0674, 'grad_norm': 0.047538526356220245, 'learning_rate': 0.0009040005921034883, 'epoch': 0.68}\n",
            "{'loss': 0.0561, 'grad_norm': 0.16418392956256866, 'learning_rate': 0.0009014430407194413, 'epoch': 0.69}\n",
            "{'loss': 0.056, 'grad_norm': 0.05036355182528496, 'learning_rate': 0.0008988555860975081, 'epoch': 0.7}\n",
            "{'loss': 0.0524, 'grad_norm': 0.048305802047252655, 'learning_rate': 0.0008962384209755452, 'epoch': 0.7}\n",
            "{'loss': 0.0533, 'grad_norm': 0.036153025925159454, 'learning_rate': 0.000893591740304525, 'epoch': 0.71}\n",
            "{'loss': 0.0368, 'grad_norm': 0.08975598216056824, 'learning_rate': 0.000890915741234015, 'epoch': 0.72}\n",
            "{'loss': 0.0686, 'grad_norm': 0.10682711005210876, 'learning_rate': 0.0008882106230974909, 'epoch': 0.73}\n",
            "{'loss': 0.0399, 'grad_norm': 0.054108332842588425, 'learning_rate': 0.0008854765873974899, 'epoch': 0.74}\n",
            "{'loss': 0.0691, 'grad_norm': 0.06793468445539474, 'learning_rate': 0.0008827138377905998, 'epoch': 0.74}\n",
            "{'loss': 0.0289, 'grad_norm': 0.07052214443683624, 'learning_rate': 0.0008799225800722895, 'epoch': 0.75}\n",
            "{'loss': 0.057, 'grad_norm': 0.05749228596687317, 'learning_rate': 0.0008771030221615785, 'epoch': 0.76}\n",
            "{'loss': 0.0474, 'grad_norm': 0.05186938866972923, 'learning_rate': 0.0008742553740855505, 'epoch': 0.77}\n",
            "{'loss': 0.0448, 'grad_norm': 0.06445690244436264, 'learning_rate': 0.0008713798479637072, 'epoch': 0.78}\n",
            "{'loss': 0.0521, 'grad_norm': 0.10377197712659836, 'learning_rate': 0.0008684766579921683, 'epoch': 0.78}\n",
            "{'loss': 0.0327, 'grad_norm': 0.06276014447212219, 'learning_rate': 0.0008655460204277166, 'epoch': 0.79}\n",
            "{'loss': 0.0339, 'grad_norm': 0.06084465980529785, 'learning_rate': 0.0008625881535716883, 'epoch': 0.8}\n",
            "{'loss': 0.0571, 'grad_norm': 0.07588757574558258, 'learning_rate': 0.0008596032777537123, 'epoch': 0.81}\n",
            "{'loss': 0.0324, 'grad_norm': 0.04290685057640076, 'learning_rate': 0.0008565916153152981, 'epoch': 0.82}\n",
            "{'loss': 0.0556, 'grad_norm': 0.07847394794225693, 'learning_rate': 0.0008535533905932737, 'epoch': 0.82}\n",
            "{'loss': 0.0557, 'grad_norm': 0.10205499827861786, 'learning_rate': 0.0008504888299030747, 'epoch': 0.83}\n",
            "{'loss': 0.0511, 'grad_norm': 0.06796681880950928, 'learning_rate': 0.0008473981615218862, 'epoch': 0.84}\n",
            "{'loss': 0.0661, 'grad_norm': 0.05654938891530037, 'learning_rate': 0.0008442816156716386, 'epoch': 0.85}\n",
            "{'loss': 0.049, 'grad_norm': 0.03711695969104767, 'learning_rate': 0.0008411394245018588, 'epoch': 0.86}\n",
            "{'loss': 0.0361, 'grad_norm': 0.03468453139066696, 'learning_rate': 0.0008379718220723773, 'epoch': 0.86}\n",
            "{'loss': 0.0538, 'grad_norm': 0.04438013210892677, 'learning_rate': 0.0008347790443358929, 'epoch': 0.87}\n",
            "{'loss': 0.0565, 'grad_norm': 0.07876331359148026, 'learning_rate': 0.0008315613291203976, 'epoch': 0.88}\n",
            "{'loss': 0.0399, 'grad_norm': 0.04074312001466751, 'learning_rate': 0.0008283189161114601, 'epoch': 0.89}\n",
            "{'loss': 0.0508, 'grad_norm': 0.05475936830043793, 'learning_rate': 0.000825052046834372, 'epoch': 0.9}\n",
            "{'loss': 0.0357, 'grad_norm': 0.046091873198747635, 'learning_rate': 0.0008217609646361573, 'epoch': 0.9}\n",
            "{'loss': 0.0725, 'grad_norm': 0.126611590385437, 'learning_rate': 0.0008184459146674447, 'epoch': 0.91}\n",
            "{'loss': 0.0251, 'grad_norm': 0.022592835128307343, 'learning_rate': 0.0008151071438642068, 'epoch': 0.92}\n",
            "{'loss': 0.0576, 'grad_norm': 0.03669044375419617, 'learning_rate': 0.0008117449009293668, 'epoch': 0.93}\n",
            "{'loss': 0.0679, 'grad_norm': 0.0931018516421318, 'learning_rate': 0.0008083594363142716, 'epoch': 0.94}\n",
            "{'loss': 0.0439, 'grad_norm': 0.03233902156352997, 'learning_rate': 0.0008049510022000364, 'epoch': 0.94}\n",
            "{'loss': 0.0538, 'grad_norm': 0.0401553213596344, 'learning_rate': 0.0008015198524787601, 'epoch': 0.95}\n",
            "{'loss': 0.0521, 'grad_norm': 0.04673796147108078, 'learning_rate': 0.0007980662427346127, 'epoch': 0.96}\n",
            "{'loss': 0.0561, 'grad_norm': 0.039442889392375946, 'learning_rate': 0.0007945904302247968, 'epoch': 0.97}\n",
            "{'loss': 0.0523, 'grad_norm': 0.052333369851112366, 'learning_rate': 0.0007910926738603854, 'epoch': 0.98}\n",
            "{'loss': 0.059, 'grad_norm': 0.051441363990306854, 'learning_rate': 0.0007875732341870349, 'epoch': 0.98}\n",
            "{'loss': 0.0559, 'grad_norm': 0.05735618993639946, 'learning_rate': 0.0007840323733655779, 'epoch': 0.99}\n",
            "{'loss': 0.0451, 'grad_norm': 0.0466839075088501, 'learning_rate': 0.0007804703551524948, 'epoch': 1.0}\n",
            "{'loss': 0.0376, 'grad_norm': 0.05901319906115532, 'learning_rate': 0.0007768874448802665, 'epoch': 1.01}\n",
            "{'loss': 0.0439, 'grad_norm': 0.04966767504811287, 'learning_rate': 0.0007732839094376105, 'epoch': 1.02}\n",
            "{'loss': 0.0428, 'grad_norm': 0.05196954682469368, 'learning_rate': 0.0007696600172495997, 'epoch': 1.02}\n",
            "{'loss': 0.0569, 'grad_norm': 0.07021516561508179, 'learning_rate': 0.0007660160382576683, 'epoch': 1.03}\n",
            "{'loss': 0.0298, 'grad_norm': 0.16560232639312744, 'learning_rate': 0.000762352243899504, 'epoch': 1.04}\n",
            "{'loss': 0.0326, 'grad_norm': 0.046727005392313004, 'learning_rate': 0.0007586689070888284, 'epoch': 1.05}\n",
            "{'loss': 0.0405, 'grad_norm': 0.03964654356241226, 'learning_rate': 0.000754966302195068, 'epoch': 1.06}\n",
            "{'loss': 0.0379, 'grad_norm': 0.05522680655121803, 'learning_rate': 0.0007512447050229165, 'epoch': 1.06}\n",
            "{'loss': 0.0512, 'grad_norm': 0.07106033712625504, 'learning_rate': 0.0007475043927917907, 'epoch': 1.07}\n",
            "{'loss': 0.0373, 'grad_norm': 0.04642587527632713, 'learning_rate': 0.00074374564411518, 'epoch': 1.08}\n",
            "{'loss': 0.047, 'grad_norm': 0.1410573124885559, 'learning_rate': 0.0007399687389798933, 'epoch': 1.09}\n",
            "{'loss': 0.0293, 'grad_norm': 0.06026257574558258, 'learning_rate': 0.0007361739587252019, 'epoch': 1.1}\n",
            "{'loss': 0.048, 'grad_norm': 0.09162076562643051, 'learning_rate': 0.0007323615860218843, 'epoch': 1.1}\n",
            "{'loss': 0.0357, 'grad_norm': 0.03231770545244217, 'learning_rate': 0.000728531904851169, 'epoch': 1.11}\n",
            "{'loss': 0.0391, 'grad_norm': 0.04077267274260521, 'learning_rate': 0.0007246852004835807, 'epoch': 1.12}\n",
            "{'loss': 0.0435, 'grad_norm': 0.055413082242012024, 'learning_rate': 0.0007208217594576922, 'epoch': 1.13}\n",
            "{'loss': 0.0445, 'grad_norm': 0.044799577444791794, 'learning_rate': 0.0007169418695587791, 'epoch': 1.14}\n",
            "{'loss': 0.0372, 'grad_norm': 0.052891846746206284, 'learning_rate': 0.0007130458197973828, 'epoch': 1.14}\n",
            "{'loss': 0.0669, 'grad_norm': 0.08759047091007233, 'learning_rate': 0.0007091339003877826, 'epoch': 1.15}\n",
            "{'loss': 0.0719, 'grad_norm': 0.12210818380117416, 'learning_rate': 0.0007052064027263785, 'epoch': 1.16}\n",
            "{'loss': 0.0519, 'grad_norm': 0.043972283601760864, 'learning_rate': 0.0007012636193699837, 'epoch': 1.17}\n",
            "{'loss': 0.0462, 'grad_norm': 0.05408276990056038, 'learning_rate': 0.0006973058440140341, 'epoch': 1.18}\n",
            "{'loss': 0.0543, 'grad_norm': 0.069672130048275, 'learning_rate': 0.0006933333714707094, 'epoch': 1.18}\n",
            "{'loss': 0.0431, 'grad_norm': 0.03220219910144806, 'learning_rate': 0.0006893464976469738, 'epoch': 1.19}\n",
            "{'loss': 0.0408, 'grad_norm': 0.029539283365011215, 'learning_rate': 0.0006853455195225339, 'epoch': 1.2}\n",
            "{'loss': 0.0432, 'grad_norm': 0.041417136788368225, 'learning_rate': 0.000681330735127716, 'epoch': 1.21}\n",
            "{'loss': 0.0347, 'grad_norm': 0.040675658732652664, 'learning_rate': 0.0006773024435212678, 'epoch': 1.22}\n",
            "{'loss': 0.0416, 'grad_norm': 0.037404865026474, 'learning_rate': 0.00067326094476808, 'epoch': 1.22}\n",
            "{'loss': 0.0416, 'grad_norm': 0.053447555750608444, 'learning_rate': 0.0006692065399168352, 'epoch': 1.23}\n",
            "{'loss': 0.0364, 'grad_norm': 0.10640616714954376, 'learning_rate': 0.0006651395309775837, 'epoch': 1.24}\n",
            "{'loss': 0.0399, 'grad_norm': 0.061076436191797256, 'learning_rate': 0.0006610602208992453, 'epoch': 1.25}\n",
            "{'loss': 0.0448, 'grad_norm': 0.050297390669584274, 'learning_rate': 0.000656968913547045, 'epoch': 1.26}\n",
            "{'loss': 0.0242, 'grad_norm': 0.08029159158468246, 'learning_rate': 0.0006528659136798764, 'epoch': 1.26}\n",
            "{'loss': 0.0468, 'grad_norm': 0.1836344450712204, 'learning_rate': 0.0006487515269276015, 'epoch': 1.27}\n",
            "{'loss': 0.0219, 'grad_norm': 0.030408458784222603, 'learning_rate': 0.0006446260597682839, 'epoch': 1.28}\n",
            "{'loss': 0.038, 'grad_norm': 0.07627809047698975, 'learning_rate': 0.0006404898195053597, 'epoch': 1.29}\n",
            "{'loss': 0.0488, 'grad_norm': 0.07152841240167618, 'learning_rate': 0.0006363431142447468, 'epoch': 1.3}\n",
            "{'loss': 0.0594, 'grad_norm': 0.11661340296268463, 'learning_rate': 0.0006321862528718945, 'epoch': 1.3}\n",
            "{'loss': 0.0531, 'grad_norm': 0.24125660955905914, 'learning_rate': 0.0006280195450287736, 'epoch': 1.31}\n",
            "{'loss': 0.0328, 'grad_norm': 0.05721820145845413, 'learning_rate': 0.000623843301090813, 'epoch': 1.32}\n",
            "{'loss': 0.0476, 'grad_norm': 0.0549873523414135, 'learning_rate': 0.0006196578321437789, 'epoch': 1.33}\n",
            "{'loss': 0.0489, 'grad_norm': 0.04698871076107025, 'learning_rate': 0.0006154634499606029, 'epoch': 1.34}\n",
            "{'loss': 0.049, 'grad_norm': 0.045918695628643036, 'learning_rate': 0.0006112604669781572, 'epoch': 1.34}\n",
            "{'loss': 0.0354, 'grad_norm': 0.04504638910293579, 'learning_rate': 0.000607049196273983, 'epoch': 1.35}\n",
            "{'loss': 0.0411, 'grad_norm': 0.058732401579618454, 'learning_rate': 0.0006028299515429683, 'epoch': 1.36}\n",
            "{'loss': 0.0622, 'grad_norm': 0.13308432698249817, 'learning_rate': 0.0005986030470739811, 'epoch': 1.37}\n",
            "{'loss': 0.0458, 'grad_norm': 0.05175914987921715, 'learning_rate': 0.0005943687977264583, 'epoch': 1.38}\n",
            "{'loss': 0.0489, 'grad_norm': 0.04104534909129143, 'learning_rate': 0.000590127518906953, 'epoch': 1.38}\n",
            "{'loss': 0.0426, 'grad_norm': 0.13445556163787842, 'learning_rate': 0.0005858795265456381, 'epoch': 1.39}\n",
            "{'loss': 0.0334, 'grad_norm': 0.037619832903146744, 'learning_rate': 0.0005816251370727748, 'epoch': 1.4}\n",
            "{'loss': 0.0438, 'grad_norm': 0.04670042172074318, 'learning_rate': 0.0005773646673951406, 'epoch': 1.41}\n",
            "{'loss': 0.0403, 'grad_norm': 0.03712339699268341, 'learning_rate': 0.0005730984348724242, 'epoch': 1.42}\n",
            "{'loss': 0.0383, 'grad_norm': 0.04940091446042061, 'learning_rate': 0.0005688267572935842, 'epoch': 1.42}\n",
            "{'loss': 0.0357, 'grad_norm': 0.08531784266233444, 'learning_rate': 0.0005645499528531784, 'epoch': 1.43}\n",
            "{'loss': 0.0275, 'grad_norm': 0.02326400764286518, 'learning_rate': 0.0005602683401276614, 'epoch': 1.44}\n",
            "{'loss': 0.0467, 'grad_norm': 0.08881024271249771, 'learning_rate': 0.0005559822380516539, 'epoch': 1.45}\n",
            "{'loss': 0.0365, 'grad_norm': 0.0482880100607872, 'learning_rate': 0.000551691965894185, 'epoch': 1.46}\n",
            "{'loss': 0.0349, 'grad_norm': 0.04056223854422569, 'learning_rate': 0.0005473978432349112, 'epoch': 1.46}\n",
            "{'loss': 0.0488, 'grad_norm': 0.14302320778369904, 'learning_rate': 0.0005431001899403097, 'epoch': 1.47}\n",
            "{'loss': 0.0483, 'grad_norm': 0.05603222921490669, 'learning_rate': 0.0005387993261398532, 'epoch': 1.48}\n",
            "{'loss': 0.0304, 'grad_norm': 0.030970726162195206, 'learning_rate': 0.0005344955722021623, 'epoch': 1.49}\n",
            "{'loss': 0.03, 'grad_norm': 0.043485160917043686, 'learning_rate': 0.0005301892487111431, 'epoch': 1.5}\n",
            "{'loss': 0.0547, 'grad_norm': 0.13127237558364868, 'learning_rate': 0.0005258806764421047, 'epoch': 1.5}\n",
            "{'loss': 0.0377, 'grad_norm': 0.03752408176660538, 'learning_rate': 0.0005215701763378673, 'epoch': 1.51}\n",
            "{'loss': 0.0389, 'grad_norm': 0.041396938264369965, 'learning_rate': 0.0005172580694848541, 'epoch': 1.52}\n",
            "{'loss': 0.0504, 'grad_norm': 0.03653258830308914, 'learning_rate': 0.0005129446770891738, 'epoch': 1.53}\n",
            "{'loss': 0.0402, 'grad_norm': 0.05721680447459221, 'learning_rate': 0.0005086303204526943, 'epoch': 1.54}\n",
            "{'loss': 0.0484, 'grad_norm': 0.04772607609629631, 'learning_rate': 0.0005043153209491095, 'epoch': 1.54}\n",
            "{'loss': 0.0537, 'grad_norm': 0.048515431582927704, 'learning_rate': 0.0005, 'epoch': 1.55}\n",
            "{'loss': 0.0365, 'grad_norm': 0.03802875056862831, 'learning_rate': 0.0004956846790508906, 'epoch': 1.56}\n",
            "{'loss': 0.0392, 'grad_norm': 0.0377754308283329, 'learning_rate': 0.0004913696795473058, 'epoch': 1.57}\n",
            "{'loss': 0.0315, 'grad_norm': 0.05002933368086815, 'learning_rate': 0.0004870553229108264, 'epoch': 1.58}\n",
            "{'loss': 0.0312, 'grad_norm': 0.04672148823738098, 'learning_rate': 0.0004827419305151461, 'epoch': 1.58}\n",
            "{'loss': 0.0303, 'grad_norm': 0.025401858612895012, 'learning_rate': 0.00047842982366213274, 'epoch': 1.59}\n",
            "{'loss': 0.0459, 'grad_norm': 0.044744823127985, 'learning_rate': 0.0004741193235578952, 'epoch': 1.6}\n",
            "{'loss': 0.0329, 'grad_norm': 0.03807080164551735, 'learning_rate': 0.0004698107512888569, 'epoch': 1.61}\n",
            "{'loss': 0.0326, 'grad_norm': 0.04178893566131592, 'learning_rate': 0.0004655044277978375, 'epoch': 1.62}\n",
            "{'loss': 0.047, 'grad_norm': 0.055117812007665634, 'learning_rate': 0.0004612006738601469, 'epoch': 1.62}\n",
            "{'loss': 0.0295, 'grad_norm': 0.04399175941944122, 'learning_rate': 0.00045689981005969026, 'epoch': 1.63}\n",
            "{'loss': 0.0326, 'grad_norm': 0.06506015360355377, 'learning_rate': 0.00045260215676508895, 'epoch': 1.64}\n",
            "{'loss': 0.0334, 'grad_norm': 0.039216384291648865, 'learning_rate': 0.000448308034105815, 'epoch': 1.65}\n",
            "{'loss': 0.0359, 'grad_norm': 0.06083261966705322, 'learning_rate': 0.0004440177619483461, 'epoch': 1.66}\n",
            "{'loss': 0.0168, 'grad_norm': 0.0337691493332386, 'learning_rate': 0.00043973165987233853, 'epoch': 1.66}\n",
            "{'loss': 0.0267, 'grad_norm': 0.040644362568855286, 'learning_rate': 0.0004354500471468217, 'epoch': 1.67}\n",
            "{'loss': 0.0486, 'grad_norm': 0.0689459964632988, 'learning_rate': 0.00043117324270641603, 'epoch': 1.68}\n",
            "{'loss': 0.03, 'grad_norm': 0.0514342337846756, 'learning_rate': 0.00042690156512757607, 'epoch': 1.69}\n",
            "{'loss': 0.0493, 'grad_norm': 0.057581428438425064, 'learning_rate': 0.0004226353326048593, 'epoch': 1.7}\n",
            "{'loss': 0.0349, 'grad_norm': 0.04632614925503731, 'learning_rate': 0.00041837486292722534, 'epoch': 1.7}\n",
            "{'loss': 0.0369, 'grad_norm': 0.0437270887196064, 'learning_rate': 0.00041412047345436195, 'epoch': 1.71}\n",
            "{'loss': 0.0461, 'grad_norm': 0.04986424744129181, 'learning_rate': 0.00040987248109304716, 'epoch': 1.72}\n",
            "{'loss': 0.0234, 'grad_norm': 0.02444041706621647, 'learning_rate': 0.0004056312022735417, 'epoch': 1.73}\n",
            "{'loss': 0.0247, 'grad_norm': 0.03743939474225044, 'learning_rate': 0.000401396952926019, 'epoch': 1.74}\n",
            "{'loss': 0.0457, 'grad_norm': 0.03948085382580757, 'learning_rate': 0.00039717004845703176, 'epoch': 1.74}\n",
            "{'loss': 0.039, 'grad_norm': 0.035986024886369705, 'learning_rate': 0.000392950803726017, 'epoch': 1.75}\n",
            "{'loss': 0.0335, 'grad_norm': 0.05723090097308159, 'learning_rate': 0.00038873953302184284, 'epoch': 1.76}\n",
            "{'loss': 0.0387, 'grad_norm': 0.04261310026049614, 'learning_rate': 0.0003845365500393974, 'epoch': 1.77}\n",
            "{'loss': 0.0453, 'grad_norm': 0.04257415235042572, 'learning_rate': 0.00038034216785622126, 'epoch': 1.78}\n",
            "{'loss': 0.0412, 'grad_norm': 0.04454883560538292, 'learning_rate': 0.00037615669890918703, 'epoch': 1.78}\n",
            "{'loss': 0.0332, 'grad_norm': 0.05547394976019859, 'learning_rate': 0.00037198045497122644, 'epoch': 1.79}\n",
            "{'loss': 0.0423, 'grad_norm': 0.051169298589229584, 'learning_rate': 0.00036781374712810557, 'epoch': 1.8}\n",
            "{'loss': 0.0424, 'grad_norm': 0.03167324140667915, 'learning_rate': 0.0003636568857552531, 'epoch': 1.81}\n",
            "{'loss': 0.0543, 'grad_norm': 0.044345926493406296, 'learning_rate': 0.0003595101804946404, 'epoch': 1.82}\n",
            "{'loss': 0.0335, 'grad_norm': 0.03177952766418457, 'learning_rate': 0.0003553739402317162, 'epoch': 1.82}\n",
            "{'loss': 0.0291, 'grad_norm': 0.02951555699110031, 'learning_rate': 0.0003512484730723986, 'epoch': 1.83}\n",
            "{'loss': 0.0368, 'grad_norm': 0.0386277474462986, 'learning_rate': 0.00034713408632012366, 'epoch': 1.84}\n",
            "{'loss': 0.0507, 'grad_norm': 0.03832504525780678, 'learning_rate': 0.00034303108645295497, 'epoch': 1.85}\n",
            "{'loss': 0.034, 'grad_norm': 0.032829754054546356, 'learning_rate': 0.0003389397791007548, 'epoch': 1.86}\n",
            "{'loss': 0.0493, 'grad_norm': 0.04113253578543663, 'learning_rate': 0.00033486046902241664, 'epoch': 1.86}\n",
            "{'loss': 0.0339, 'grad_norm': 0.02857469767332077, 'learning_rate': 0.0003307934600831648, 'epoch': 1.87}\n",
            "{'loss': 0.0412, 'grad_norm': 0.0299285389482975, 'learning_rate': 0.00032673905523192, 'epoch': 1.88}\n",
            "{'loss': 0.0375, 'grad_norm': 0.05188323184847832, 'learning_rate': 0.00032269755647873217, 'epoch': 1.89}\n",
            "{'loss': 0.044, 'grad_norm': 0.0327397882938385, 'learning_rate': 0.000318669264872284, 'epoch': 1.9}\n",
            "{'loss': 0.0298, 'grad_norm': 0.02737896703183651, 'learning_rate': 0.00031465448047746623, 'epoch': 1.9}\n",
            "{'loss': 0.0374, 'grad_norm': 0.041014134883880615, 'learning_rate': 0.0003106535023530262, 'epoch': 1.91}\n",
            "{'loss': 0.0284, 'grad_norm': 0.03452008590102196, 'learning_rate': 0.0003066666285292906, 'epoch': 1.92}\n",
            "{'loss': 0.0495, 'grad_norm': 0.056598272174596786, 'learning_rate': 0.000302694155985966, 'epoch': 1.93}\n",
            "{'loss': 0.0224, 'grad_norm': 0.03443177044391632, 'learning_rate': 0.0002987363806300163, 'epoch': 1.94}\n",
            "{'loss': 0.0341, 'grad_norm': 0.030169714242219925, 'learning_rate': 0.0002947935972736217, 'epoch': 1.94}\n",
            "{'loss': 0.035, 'grad_norm': 0.04342286288738251, 'learning_rate': 0.00029086609961221754, 'epoch': 1.95}\n",
            "{'loss': 0.0184, 'grad_norm': 0.01957802288234234, 'learning_rate': 0.00028695418020261755, 'epoch': 1.96}\n",
            "{'loss': 0.0283, 'grad_norm': 0.031050359830260277, 'learning_rate': 0.00028305813044122096, 'epoch': 1.97}\n",
            "{'loss': 0.0315, 'grad_norm': 0.0370163694024086, 'learning_rate': 0.00027917824054230785, 'epoch': 1.98}\n",
            "{'loss': 0.02, 'grad_norm': 0.024627506732940674, 'learning_rate': 0.00027531479951641924, 'epoch': 1.98}\n",
            "{'loss': 0.0316, 'grad_norm': 0.03866590932011604, 'learning_rate': 0.0002714680951488312, 'epoch': 1.99}\n",
            "{'loss': 0.028, 'grad_norm': 0.026490529999136925, 'learning_rate': 0.00026763841397811573, 'epoch': 2.0}\n",
            "{'loss': 0.0203, 'grad_norm': 0.036256927996873856, 'learning_rate': 0.00026382604127479813, 'epoch': 2.01}\n",
            "{'loss': 0.0183, 'grad_norm': 0.02904612384736538, 'learning_rate': 0.00026003126102010693, 'epoch': 2.02}\n",
            "{'loss': 0.0258, 'grad_norm': 0.024440327659249306, 'learning_rate': 0.0002562543558848202, 'epoch': 2.02}\n",
            "{'loss': 0.0414, 'grad_norm': 0.03641558066010475, 'learning_rate': 0.0002524956072082093, 'epoch': 2.03}\n",
            "{'loss': 0.0375, 'grad_norm': 0.026990270242094994, 'learning_rate': 0.00024875529497708353, 'epoch': 2.04}\n",
            "{'loss': 0.0202, 'grad_norm': 0.034012675285339355, 'learning_rate': 0.0002450336978049322, 'epoch': 2.05}\n",
            "{'loss': 0.0319, 'grad_norm': 0.028018593788146973, 'learning_rate': 0.00024133109291117155, 'epoch': 2.06}\n",
            "{'loss': 0.0338, 'grad_norm': 0.03882759064435959, 'learning_rate': 0.000237647756100496, 'epoch': 2.06}\n",
            "{'loss': 0.049, 'grad_norm': 0.048601184040308, 'learning_rate': 0.00023398396174233177, 'epoch': 2.07}\n",
            "{'loss': 0.0347, 'grad_norm': 0.04080729931592941, 'learning_rate': 0.00023033998275040046, 'epoch': 2.08}\n",
            "{'loss': 0.026, 'grad_norm': 0.03053305484354496, 'learning_rate': 0.0002267160905623895, 'epoch': 2.09}\n",
            "{'loss': 0.0251, 'grad_norm': 0.02604052983224392, 'learning_rate': 0.00022311255511973344, 'epoch': 2.1}\n",
            "{'loss': 0.0308, 'grad_norm': 0.029196497052907944, 'learning_rate': 0.00021952964484750527, 'epoch': 2.1}\n",
            "{'loss': 0.0191, 'grad_norm': 0.04219074919819832, 'learning_rate': 0.00021596762663442215, 'epoch': 2.11}\n",
            "{'loss': 0.0316, 'grad_norm': 0.03096199780702591, 'learning_rate': 0.00021242676581296528, 'epoch': 2.12}\n",
            "{'loss': 0.0291, 'grad_norm': 0.03700026497244835, 'learning_rate': 0.00020890732613961478, 'epoch': 2.13}\n",
            "{'loss': 0.0341, 'grad_norm': 0.03608762472867966, 'learning_rate': 0.00020540956977520319, 'epoch': 2.14}\n",
            "{'loss': 0.0354, 'grad_norm': 0.04656161740422249, 'learning_rate': 0.00020193375726538737, 'epoch': 2.14}\n",
            "{'loss': 0.0298, 'grad_norm': 0.02969164028763771, 'learning_rate': 0.00019848014752123978, 'epoch': 2.15}\n",
            "{'loss': 0.0271, 'grad_norm': 0.030373310670256615, 'learning_rate': 0.00019504899779996355, 'epoch': 2.16}\n",
            "{'loss': 0.0289, 'grad_norm': 0.03347080200910568, 'learning_rate': 0.00019164056368572847, 'epoch': 2.17}\n",
            "{'loss': 0.0177, 'grad_norm': 0.020473835989832878, 'learning_rate': 0.00018825509907063325, 'epoch': 2.18}\n",
            "{'loss': 0.0329, 'grad_norm': 0.03773994743824005, 'learning_rate': 0.00018489285613579326, 'epoch': 2.18}\n",
            "{'loss': 0.0291, 'grad_norm': 0.027583476155996323, 'learning_rate': 0.0001815540853325555, 'epoch': 2.19}\n",
            "{'loss': 0.0328, 'grad_norm': 0.0297941192984581, 'learning_rate': 0.00017823903536384262, 'epoch': 2.2}\n",
            "{'loss': 0.0186, 'grad_norm': 0.027036603540182114, 'learning_rate': 0.0001749479531656279, 'epoch': 2.21}\n",
            "{'loss': 0.0325, 'grad_norm': 0.03682677820324898, 'learning_rate': 0.00017168108388853997, 'epoch': 2.22}\n",
            "{'loss': 0.0319, 'grad_norm': 0.04440343752503395, 'learning_rate': 0.00016843867087960252, 'epoch': 2.22}\n",
            "{'loss': 0.0339, 'grad_norm': 0.039221011102199554, 'learning_rate': 0.00016522095566410728, 'epoch': 2.23}\n",
            "{'loss': 0.0384, 'grad_norm': 0.04126869514584541, 'learning_rate': 0.00016202817792762282, 'epoch': 2.24}\n",
            "{'loss': 0.0281, 'grad_norm': 0.0312130618840456, 'learning_rate': 0.0001588605754981413, 'epoch': 2.25}\n",
            "{'loss': 0.0185, 'grad_norm': 0.041247446089982986, 'learning_rate': 0.00015571838432836137, 'epoch': 2.26}\n",
            "{'loss': 0.0249, 'grad_norm': 0.023947851732373238, 'learning_rate': 0.00015260183847811383, 'epoch': 2.26}\n",
            "{'loss': 0.0319, 'grad_norm': 0.042030610144138336, 'learning_rate': 0.00014951117009692527, 'epoch': 2.27}\n",
            "{'loss': 0.0298, 'grad_norm': 0.034706320613622665, 'learning_rate': 0.00014644660940672628, 'epoch': 2.28}\n",
            "{'loss': 0.02, 'grad_norm': 0.027489103376865387, 'learning_rate': 0.00014340838468470196, 'epoch': 2.29}\n",
            "{'loss': 0.0197, 'grad_norm': 0.03186450153589249, 'learning_rate': 0.00014039672224628786, 'epoch': 2.3}\n",
            "{'loss': 0.0198, 'grad_norm': 0.027041804045438766, 'learning_rate': 0.0001374118464283119, 'epoch': 2.3}\n",
            "{'loss': 0.0185, 'grad_norm': 0.03153156489133835, 'learning_rate': 0.0001344539795722834, 'epoch': 2.31}\n",
            "{'loss': 0.0412, 'grad_norm': 0.03861706331372261, 'learning_rate': 0.00013152334200783168, 'epoch': 2.32}\n",
            "{'loss': 0.029, 'grad_norm': 0.0330401174724102, 'learning_rate': 0.00012862015203629273, 'epoch': 2.33}\n",
            "{'loss': 0.0397, 'grad_norm': 0.06801000982522964, 'learning_rate': 0.0001257446259144494, 'epoch': 2.34}\n",
            "{'loss': 0.0224, 'grad_norm': 0.08805183321237564, 'learning_rate': 0.0001228969778384214, 'epoch': 2.34}\n",
            "{'loss': 0.0389, 'grad_norm': 0.03222260996699333, 'learning_rate': 0.00012007741992771066, 'epoch': 2.35}\n",
            "{'loss': 0.0253, 'grad_norm': 0.023934876546263695, 'learning_rate': 0.0001172861622094003, 'epoch': 2.36}\n",
            "{'loss': 0.0215, 'grad_norm': 0.026592141017317772, 'learning_rate': 0.0001145234126025102, 'epoch': 2.37}\n",
            "{'loss': 0.0243, 'grad_norm': 0.03620787337422371, 'learning_rate': 0.00011178937690250917, 'epoch': 2.38}\n",
            "{'loss': 0.0339, 'grad_norm': 0.04021698608994484, 'learning_rate': 0.0001090842587659851, 'epoch': 2.38}\n",
            "{'loss': 0.0365, 'grad_norm': 0.04347776249051094, 'learning_rate': 0.00010640825969547497, 'epoch': 2.39}\n",
            "{'loss': 0.0319, 'grad_norm': 0.03946700319647789, 'learning_rate': 0.00010376157902445487, 'epoch': 2.4}\n",
            "{'loss': 0.0398, 'grad_norm': 0.05181034654378891, 'learning_rate': 0.00010114441390249201, 'epoch': 2.41}\n",
            "{'loss': 0.035, 'grad_norm': 0.07097385078668594, 'learning_rate': 9.85569592805588e-05, 'epoch': 2.42}\n",
            "{'loss': 0.0361, 'grad_norm': 0.042611293494701385, 'learning_rate': 9.599940789651179e-05, 'epoch': 2.42}\n",
            "{'loss': 0.0157, 'grad_norm': 0.029062459245324135, 'learning_rate': 9.347195026073368e-05, 'epoch': 2.43}\n",
            "{'loss': 0.024, 'grad_norm': 0.027510741725564003, 'learning_rate': 9.09747746419436e-05, 'epoch': 2.44}\n",
            "{'loss': 0.0375, 'grad_norm': 0.05760161206126213, 'learning_rate': 8.850806705317183e-05, 'epoch': 2.45}\n",
            "{'loss': 0.0223, 'grad_norm': 0.027518033981323242, 'learning_rate': 8.60720112379046e-05, 'epoch': 2.46}\n",
            "{'loss': 0.0238, 'grad_norm': 0.030814073979854584, 'learning_rate': 8.366678865639687e-05, 'epoch': 2.46}\n",
            "{'loss': 0.0289, 'grad_norm': 0.03128257021307945, 'learning_rate': 8.129257847215571e-05, 'epoch': 2.47}\n",
            "{'loss': 0.0229, 'grad_norm': 0.023433789610862732, 'learning_rate': 7.894955753859412e-05, 'epoch': 2.48}\n",
            "{'loss': 0.0184, 'grad_norm': 0.022908972576260567, 'learning_rate': 7.663790038585794e-05, 'epoch': 2.49}\n",
            "{'loss': 0.0204, 'grad_norm': 0.031505804508924484, 'learning_rate': 7.435777920782444e-05, 'epoch': 2.5}\n",
            "{'loss': 0.0233, 'grad_norm': 0.0321318618953228, 'learning_rate': 7.21093638492763e-05, 'epoch': 2.5}\n",
            "{'loss': 0.0326, 'grad_norm': 0.031403377652168274, 'learning_rate': 6.989282179324962e-05, 'epoch': 2.51}\n",
            "{'loss': 0.0263, 'grad_norm': 0.043009668588638306, 'learning_rate': 6.770831814855882e-05, 'epoch': 2.52}\n",
            "{'loss': 0.023, 'grad_norm': 0.025703957304358482, 'learning_rate': 6.555601563749674e-05, 'epoch': 2.53}\n",
            "{'loss': 0.0311, 'grad_norm': 0.025598373264074326, 'learning_rate': 6.343607458371459e-05, 'epoch': 2.54}\n",
            "{'loss': 0.0259, 'grad_norm': 0.03003784455358982, 'learning_rate': 6.134865290027902e-05, 'epoch': 2.54}\n",
            "{'loss': 0.0257, 'grad_norm': 0.03158452361822128, 'learning_rate': 5.92939060779093e-05, 'epoch': 2.55}\n",
            "{'loss': 0.0343, 'grad_norm': 0.03973223268985748, 'learning_rate': 5.72719871733951e-05, 'epoch': 2.56}\n",
            "{'loss': 0.0294, 'grad_norm': 0.029808254912495613, 'learning_rate': 5.5283046798195126e-05, 'epoch': 2.57}\n",
            "{'loss': 0.0311, 'grad_norm': 0.03670147433876991, 'learning_rate': 5.3327233107218545e-05, 'epoch': 2.58}\n",
            "{'loss': 0.0216, 'grad_norm': 0.028499824926257133, 'learning_rate': 5.140469178778845e-05, 'epoch': 2.58}\n",
            "{'loss': 0.0239, 'grad_norm': 0.028760066255927086, 'learning_rate': 4.9515566048790485e-05, 'epoch': 2.59}\n",
            "{'loss': 0.0272, 'grad_norm': 0.03434065729379654, 'learning_rate': 4.765999661000442e-05, 'epoch': 2.6}\n",
            "{'loss': 0.0187, 'grad_norm': 0.05325676500797272, 'learning_rate': 4.583812169162299e-05, 'epoch': 2.61}\n",
            "{'loss': 0.0229, 'grad_norm': 0.040101557970047, 'learning_rate': 4.405007700395497e-05, 'epoch': 2.62}\n",
            "{'loss': 0.0273, 'grad_norm': 0.029146524146199226, 'learning_rate': 4.2295995737316854e-05, 'epoch': 2.62}\n",
            "{'loss': 0.0257, 'grad_norm': 0.03620205819606781, 'learning_rate': 4.057600855211141e-05, 'epoch': 2.63}\n",
            "{'loss': 0.0242, 'grad_norm': 0.02896435186266899, 'learning_rate': 3.8890243569094874e-05, 'epoch': 2.64}\n",
            "{'loss': 0.0272, 'grad_norm': 0.026549339294433594, 'learning_rate': 3.7238826359833275e-05, 'epoch': 2.65}\n",
            "{'loss': 0.0173, 'grad_norm': 0.022975295782089233, 'learning_rate': 3.562187993734883e-05, 'epoch': 2.66}\n",
            "{'loss': 0.0236, 'grad_norm': 0.02038446068763733, 'learning_rate': 3.40395247469566e-05, 'epoch': 2.66}\n",
            "{'loss': 0.0304, 'grad_norm': 0.044094596058130264, 'learning_rate': 3.249187865729264e-05, 'epoch': 2.67}\n",
            "{'loss': 0.0336, 'grad_norm': 0.03891411051154137, 'learning_rate': 3.097905695153408e-05, 'epoch': 2.68}\n",
            "{'loss': 0.0211, 'grad_norm': 0.034223198890686035, 'learning_rate': 2.9501172318811832e-05, 'epoch': 2.69}\n",
            "{'loss': 0.0343, 'grad_norm': 0.05323373153805733, 'learning_rate': 2.8058334845816213e-05, 'epoch': 2.7}\n",
            "{'loss': 0.0334, 'grad_norm': 0.03278797119855881, 'learning_rate': 2.6650652008597063e-05, 'epoch': 2.7}\n",
            "{'loss': 0.0307, 'grad_norm': 0.0420958586037159, 'learning_rate': 2.527822866455731e-05, 'epoch': 2.71}\n",
            "{'loss': 0.0267, 'grad_norm': 0.037485431879758835, 'learning_rate': 2.3941167044642943e-05, 'epoch': 2.72}\n",
            "{'loss': 0.0207, 'grad_norm': 0.04063955694437027, 'learning_rate': 2.2639566745727203e-05, 'epoch': 2.73}\n",
            "{'loss': 0.0225, 'grad_norm': 0.024305056780576706, 'learning_rate': 2.137352472319215e-05, 'epoch': 2.74}\n",
            "{'loss': 0.0228, 'grad_norm': 0.04295208305120468, 'learning_rate': 2.0143135283706258e-05, 'epoch': 2.74}\n",
            "{'loss': 0.0252, 'grad_norm': 0.03127511590719223, 'learning_rate': 1.8948490078199765e-05, 'epoch': 2.75}\n",
            "{'loss': 0.0232, 'grad_norm': 0.03486558794975281, 'learning_rate': 1.7789678095037452e-05, 'epoch': 2.76}\n",
            "{'loss': 0.0291, 'grad_norm': 0.03685503453016281, 'learning_rate': 1.6666785653390248e-05, 'epoch': 2.77}\n",
            "{'loss': 0.0272, 'grad_norm': 0.03320532292127609, 'learning_rate': 1.557989639680496e-05, 'epoch': 2.78}\n",
            "{'loss': 0.0344, 'grad_norm': 0.0519925095140934, 'learning_rate': 1.4529091286973995e-05, 'epoch': 2.78}\n",
            "{'loss': 0.0178, 'grad_norm': 0.024164482951164246, 'learning_rate': 1.351444859770462e-05, 'epoch': 2.79}\n",
            "{'loss': 0.0323, 'grad_norm': 0.035757195204496384, 'learning_rate': 1.2536043909088191e-05, 'epoch': 2.8}\n",
            "{'loss': 0.0236, 'grad_norm': 0.023634128272533417, 'learning_rate': 1.159395010187042e-05, 'epoch': 2.81}\n",
            "{'loss': 0.0223, 'grad_norm': 0.027395328506827354, 'learning_rate': 1.0688237352022346e-05, 'epoch': 2.82}\n",
            "{'loss': 0.0396, 'grad_norm': 0.05092823505401611, 'learning_rate': 9.818973125513276e-06, 'epoch': 2.82}\n",
            "{'loss': 0.0374, 'grad_norm': 0.03231015428900719, 'learning_rate': 8.986222173284874e-06, 'epoch': 2.83}\n",
            "{'loss': 0.02, 'grad_norm': 0.04631926864385605, 'learning_rate': 8.190046526428241e-06, 'epoch': 2.84}\n",
            "{'loss': 0.0339, 'grad_norm': 0.04226686432957649, 'learning_rate': 7.4305054915631e-06, 'epoch': 2.85}\n",
            "{'loss': 0.0248, 'grad_norm': 0.036789558827877045, 'learning_rate': 6.7076556464202296e-06, 'epoch': 2.86}\n",
            "{'loss': 0.0237, 'grad_norm': 0.02690046653151512, 'learning_rate': 6.021550835626777e-06, 'epoch': 2.86}\n",
            "{'loss': 0.0252, 'grad_norm': 0.030722569674253464, 'learning_rate': 5.372242166695684e-06, 'epoch': 2.87}\n",
            "{'loss': 0.0231, 'grad_norm': 0.046401165425777435, 'learning_rate': 4.759778006218407e-06, 'epoch': 2.88}\n",
            "{'loss': 0.019, 'grad_norm': 0.030263369902968407, 'learning_rate': 4.184203976262513e-06, 'epoch': 2.89}\n",
            "{'loss': 0.0226, 'grad_norm': 0.024940237402915955, 'learning_rate': 3.645562950973014e-06, 'epoch': 2.9}\n",
            "{'loss': 0.0382, 'grad_norm': 0.04362626001238823, 'learning_rate': 3.143895053378698e-06, 'epoch': 2.9}\n",
            "{'loss': 0.0332, 'grad_norm': 0.03739291429519653, 'learning_rate': 2.6792376524036878e-06, 'epoch': 2.91}\n",
            "{'loss': 0.0153, 'grad_norm': 0.03318875655531883, 'learning_rate': 2.251625360083387e-06, 'epoch': 2.92}\n",
            "{'loss': 0.023, 'grad_norm': 0.021679582074284554, 'learning_rate': 1.8610900289867672e-06, 'epoch': 2.93}\n",
            "{'loss': 0.0194, 'grad_norm': 0.04056745022535324, 'learning_rate': 1.5076607498433204e-06, 'epoch': 2.94}\n",
            "{'loss': 0.027, 'grad_norm': 0.037574756890535355, 'learning_rate': 1.1913638493762368e-06, 'epoch': 2.94}\n",
            "{'loss': 0.0148, 'grad_norm': 0.023768246173858643, 'learning_rate': 9.12222888341252e-07, 'epoch': 2.95}\n",
            "{'loss': 0.0215, 'grad_norm': 0.037296753376722336, 'learning_rate': 6.702586597719384e-07, 'epoch': 2.96}\n",
            "{'loss': 0.0197, 'grad_norm': 0.02035488933324814, 'learning_rate': 4.6548918743033465e-07, 'epoch': 2.97}\n",
            "{'loss': 0.0319, 'grad_norm': 0.03540831059217453, 'learning_rate': 2.9792972446479607e-07, 'epoch': 2.98}\n",
            "{'loss': 0.0248, 'grad_norm': 0.037138681858778, 'learning_rate': 1.6759275227357095e-07, 'epoch': 2.98}\n",
            "{'loss': 0.0356, 'grad_norm': 0.03849172964692116, 'learning_rate': 7.448797957526621e-08, 'epoch': 2.99}\n",
            "{'loss': 0.0335, 'grad_norm': 0.03985955938696861, 'learning_rate': 1.862234168542587e-08, 'epoch': 3.0}\n",
            "{'train_runtime': 44.1536, 'train_samples_per_second': 16.986, 'train_steps_per_second': 8.493, 'train_loss': 0.11595967997858922, 'epoch': 3.0}\n",
            "100% 375/375 [00:44<00:00,  8.49it/s]\n",
            "Training complete.\n",
            "Model saved to loras/self-edit/training_set_iteration_1/44f52bb0/8\n",
            "Skipping training for task 44f52bb0 because the number of steps is greater than 375\n",
            "Training on 250 examples for 0 epochs, lr: 0.001\n",
            "No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n",
            "Starting training...\n",
            "{'train_runtime': 0.0024, 'train_samples_per_second': 0.0, 'train_steps_per_second': 0.0, 'train_loss': 0.0, 'epoch': 0}\n",
            "0it [00:00, ?it/s]\n",
            "Training complete.\n",
            "Model saved to loras/self-edit/training_set_iteration_1/44f52bb0/9\n",
            "Training on 250 examples for 2 epochs, lr: 0.01\n",
            "No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n",
            "Starting training...\n",
            "{'loss': 6.9911, 'grad_norm': 9.771469116210938, 'learning_rate': 0.0, 'epoch': 0.01}\n",
            "{'loss': 7.3822, 'grad_norm': 10.278796195983887, 'learning_rate': 0.0009090909090909091, 'epoch': 0.02}\n",
            "{'loss': 1.6532, 'grad_norm': 5.435969829559326, 'learning_rate': 0.0018181818181818182, 'epoch': 0.02}\n",
            "{'loss': 3.6412, 'grad_norm': 10.192765235900879, 'learning_rate': 0.002727272727272727, 'epoch': 0.03}\n",
            "{'loss': 1.56, 'grad_norm': 1.5538699626922607, 'learning_rate': 0.0036363636363636364, 'epoch': 0.04}\n",
            "{'loss': 1.2763, 'grad_norm': 7.029184818267822, 'learning_rate': 0.004545454545454545, 'epoch': 0.05}\n",
            "{'loss': 0.9441, 'grad_norm': 0.729439377784729, 'learning_rate': 0.005454545454545454, 'epoch': 0.06}\n",
            "{'loss': 0.7183, 'grad_norm': 0.7367910146713257, 'learning_rate': 0.006363636363636364, 'epoch': 0.06}\n",
            "{'loss': 0.9659, 'grad_norm': 2.915821075439453, 'learning_rate': 0.007272727272727273, 'epoch': 0.07}\n",
            "{'loss': 0.9525, 'grad_norm': 2.9963300228118896, 'learning_rate': 0.008181818181818182, 'epoch': 0.08}\n",
            "{'loss': 0.8868, 'grad_norm': 2.9358971118927, 'learning_rate': 0.00909090909090909, 'epoch': 0.09}\n",
            "{'loss': 6.2457, 'grad_norm': 11.650004386901855, 'learning_rate': 0.01, 'epoch': 0.1}\n",
            "{'loss': 17.9948, 'grad_norm': 24.006580352783203, 'learning_rate': 0.009999568045802217, 'epoch': 0.1}\n",
            "{'loss': 8.2819, 'grad_norm': 13.97367000579834, 'learning_rate': 0.00999827225784264, 'epoch': 0.11}\n",
            "{'loss': 10.0854, 'grad_norm': 8.513440132141113, 'learning_rate': 0.009996112860009688, 'epoch': 0.12}\n",
            "{'loss': 7.2906, 'grad_norm': 7.278249263763428, 'learning_rate': 0.009993090225407742, 'epoch': 0.13}\n",
            "{'loss': 4.7624, 'grad_norm': 1.8629119396209717, 'learning_rate': 0.009989204876292688, 'epoch': 0.14}\n",
            "{'loss': 15.2685, 'grad_norm': 88.10034942626953, 'learning_rate': 0.009984457483981668, 'epoch': 0.14}\n",
            "{'loss': 10.8189, 'grad_norm': 5.310937881469727, 'learning_rate': 0.009978848868737098, 'epoch': 0.15}\n",
            "{'loss': 7.4729, 'grad_norm': 6.272401332855225, 'learning_rate': 0.009972379999624935, 'epoch': 0.16}\n",
            "{'loss': 5.0081, 'grad_norm': 1.5755668878555298, 'learning_rate': 0.00996505199434725, 'epoch': 0.17}\n",
            "{'loss': 5.5428, 'grad_norm': 2.5353658199310303, 'learning_rate': 0.009956866119049095, 'epoch': 0.18}\n",
            "{'loss': 6.0338, 'grad_norm': 18.83528709411621, 'learning_rate': 0.009947823788099752, 'epoch': 0.18}\n",
            "{'loss': 3.7751, 'grad_norm': 20.435504913330078, 'learning_rate': 0.009937926563848344, 'epoch': 0.19}\n",
            "{'loss': 4.5159, 'grad_norm': 5.138482570648193, 'learning_rate': 0.009927176156353898, 'epoch': 0.2}\n",
            "{'loss': 4.294, 'grad_norm': 1.1088948249816895, 'learning_rate': 0.00991557442308987, 'epoch': 0.21}\n",
            "{'loss': 3.3824, 'grad_norm': 0.867260754108429, 'learning_rate': 0.009903123368623215, 'epoch': 0.22}\n",
            "{'loss': 5.4761, 'grad_norm': 3.8492021560668945, 'learning_rate': 0.00988982514426803, 'epoch': 0.22}\n",
            "{'loss': 2.8388, 'grad_norm': 1.7140781879425049, 'learning_rate': 0.009875682047713847, 'epoch': 0.23}\n",
            "{'loss': 4.1543, 'grad_norm': 2.834256172180176, 'learning_rate': 0.009860696522628639, 'epoch': 0.24}\n",
            "{'loss': 2.4175, 'grad_norm': 0.3036355972290039, 'learning_rate': 0.00984487115823659, 'epoch': 0.25}\n",
            "{'loss': 2.9515, 'grad_norm': 0.49005770683288574, 'learning_rate': 0.009828208688870734, 'epoch': 0.26}\n",
            "{'loss': 2.8881, 'grad_norm': 0.4147189259529114, 'learning_rate': 0.009810711993500506, 'epoch': 0.26}\n",
            "{'loss': 2.4695, 'grad_norm': 0.29781442880630493, 'learning_rate': 0.009792384095234313, 'epoch': 0.27}\n",
            "{'loss': 2.9637, 'grad_norm': 0.5019187927246094, 'learning_rate': 0.009773228160797188, 'epoch': 0.28}\n",
            "{'loss': 2.4063, 'grad_norm': 1.2764264345169067, 'learning_rate': 0.009753247499983648, 'epoch': 0.29}\n",
            "{'loss': 4.5263, 'grad_norm': 13.226632118225098, 'learning_rate': 0.009732445565085823, 'epoch': 0.3}\n",
            "{'loss': 5.194, 'grad_norm': 1.4865821599960327, 'learning_rate': 0.009710825950296948, 'epoch': 0.3}\n",
            "{'loss': 2.8625, 'grad_norm': 0.6238022446632385, 'learning_rate': 0.009688392391090372, 'epoch': 0.31}\n",
            "{'loss': 3.1389, 'grad_norm': 1.2689449787139893, 'learning_rate': 0.009665148763574122, 'epoch': 0.32}\n",
            "{'loss': 2.6327, 'grad_norm': 0.4317198693752289, 'learning_rate': 0.00964109908382119, 'epoch': 0.33}\n",
            "{'loss': 2.3905, 'grad_norm': 0.5397903919219971, 'learning_rate': 0.009616247507175622, 'epoch': 0.34}\n",
            "{'loss': 2.4504, 'grad_norm': 0.5439559817314148, 'learning_rate': 0.009590598327534562, 'epoch': 0.34}\n",
            "{'loss': 2.1591, 'grad_norm': 0.3538060486316681, 'learning_rate': 0.009564155976606339, 'epoch': 0.35}\n",
            "{'loss': 1.9914, 'grad_norm': 0.36699652671813965, 'learning_rate': 0.009536925023144741, 'epoch': 0.36}\n",
            "{'loss': 2.2278, 'grad_norm': 0.4767640233039856, 'learning_rate': 0.009508910172159634, 'epoch': 0.37}\n",
            "{'loss': 1.9047, 'grad_norm': 0.23821505904197693, 'learning_rate': 0.009480116264104011, 'epoch': 0.38}\n",
            "{'loss': 1.9385, 'grad_norm': 0.31491103768348694, 'learning_rate': 0.009450548274037653, 'epoch': 0.38}\n",
            "{'loss': 1.7436, 'grad_norm': 0.34786003828048706, 'learning_rate': 0.009420211310767533, 'epoch': 0.39}\n",
            "{'loss': 2.4758, 'grad_norm': 0.34318387508392334, 'learning_rate': 0.009389110615965103, 'epoch': 0.4}\n",
            "{'loss': 1.9716, 'grad_norm': 0.36139440536499023, 'learning_rate': 0.00935725156326063, 'epoch': 0.41}\n",
            "{'loss': 1.8608, 'grad_norm': 0.18008244037628174, 'learning_rate': 0.009324639657314742, 'epoch': 0.42}\n",
            "{'loss': 1.9258, 'grad_norm': 0.165630504488945, 'learning_rate': 0.009291280532867301, 'epoch': 0.42}\n",
            "{'loss': 2.1812, 'grad_norm': 0.28481215238571167, 'learning_rate': 0.009257179953763846, 'epoch': 0.43}\n",
            "{'loss': 2.3872, 'grad_norm': 0.4480505585670471, 'learning_rate': 0.009222343811959693, 'epoch': 0.44}\n",
            "{'loss': 2.0202, 'grad_norm': 0.3475911617279053, 'learning_rate': 0.009186778126501916, 'epoch': 0.45}\n",
            "{'loss': 1.8176, 'grad_norm': 0.31122133135795593, 'learning_rate': 0.009150489042489367, 'epoch': 0.46}\n",
            "{'loss': 1.8229, 'grad_norm': 0.2298748940229416, 'learning_rate': 0.009113482830010917, 'epoch': 0.46}\n",
            "{'loss': 2.2694, 'grad_norm': 0.42417702078819275, 'learning_rate': 0.009075765883062093, 'epoch': 0.47}\n",
            "{'loss': 1.888, 'grad_norm': 0.16303479671478271, 'learning_rate': 0.009037344718440322, 'epoch': 0.48}\n",
            "{'loss': 2.4557, 'grad_norm': 0.2505008578300476, 'learning_rate': 0.008998225974618938, 'epoch': 0.49}\n",
            "{'loss': 1.8485, 'grad_norm': 0.2132996767759323, 'learning_rate': 0.008958416410600188, 'epoch': 0.5}\n",
            "{'loss': 1.5873, 'grad_norm': 0.20100414752960205, 'learning_rate': 0.008917922904747385, 'epoch': 0.5}\n",
            "{'loss': 2.2317, 'grad_norm': 0.25545910000801086, 'learning_rate': 0.008876752453596462, 'epoch': 0.51}\n",
            "{'loss': 1.464, 'grad_norm': 0.07482758909463882, 'learning_rate': 0.008834912170647101, 'epoch': 0.52}\n",
            "{'loss': 2.2416, 'grad_norm': 0.33309662342071533, 'learning_rate': 0.008792409285133642, 'epoch': 0.53}\n",
            "{'loss': 1.5502, 'grad_norm': 0.163528710603714, 'learning_rate': 0.008749251140776015, 'epoch': 0.54}\n",
            "{'loss': 1.4888, 'grad_norm': 0.18690787255764008, 'learning_rate': 0.008705445194510868, 'epoch': 0.54}\n",
            "{'loss': 1.7111, 'grad_norm': 0.1770063042640686, 'learning_rate': 0.00866099901520315, 'epoch': 0.55}\n",
            "{'loss': 1.6177, 'grad_norm': 0.09008864313364029, 'learning_rate': 0.008615920282338355, 'epoch': 0.56}\n",
            "{'loss': 1.9042, 'grad_norm': 0.12193349003791809, 'learning_rate': 0.008570216784695637, 'epoch': 0.57}\n",
            "{'loss': 1.5755, 'grad_norm': 0.10696209222078323, 'learning_rate': 0.00852389641900206, 'epoch': 0.58}\n",
            "{'loss': 1.9825, 'grad_norm': 0.24696296453475952, 'learning_rate': 0.008476967188568187, 'epoch': 0.58}\n",
            "{'loss': 1.4907, 'grad_norm': 0.1621401011943817, 'learning_rate': 0.008429437201905253, 'epoch': 0.59}\n",
            "{'loss': 1.6171, 'grad_norm': 0.12260551005601883, 'learning_rate': 0.00838131467132416, 'epoch': 0.6}\n",
            "{'loss': 1.7737, 'grad_norm': 0.17121009528636932, 'learning_rate': 0.008332607911516545, 'epoch': 0.61}\n",
            "{'loss': 1.4157, 'grad_norm': 0.09975531697273254, 'learning_rate': 0.008283325338118153, 'epoch': 0.62}\n",
            "{'loss': 1.9444, 'grad_norm': 0.18582944571971893, 'learning_rate': 0.008233475466254764, 'epoch': 0.62}\n",
            "{'loss': 1.8159, 'grad_norm': 0.15773651003837585, 'learning_rate': 0.008183066909070946, 'epoch': 0.63}\n",
            "{'loss': 1.3961, 'grad_norm': 0.07268090546131134, 'learning_rate': 0.008132108376241847, 'epoch': 0.64}\n",
            "{'loss': 1.8449, 'grad_norm': 0.28211328387260437, 'learning_rate': 0.00808060867246834, 'epoch': 0.65}\n",
            "{'loss': 1.3502, 'grad_norm': 0.15484623610973358, 'learning_rate': 0.00802857669595571, 'epoch': 0.66}\n",
            "{'loss': 2.083, 'grad_norm': 0.19733218848705292, 'learning_rate': 0.007976021436876231, 'epoch': 0.66}\n",
            "{'loss': 1.593, 'grad_norm': 0.05721154063940048, 'learning_rate': 0.007922951975815811, 'epoch': 0.67}\n",
            "{'loss': 1.9214, 'grad_norm': 0.20019415020942688, 'learning_rate': 0.007869377482205042, 'epoch': 0.68}\n",
            "{'loss': 1.8591, 'grad_norm': 0.1441441774368286, 'learning_rate': 0.007815307212734888, 'epoch': 0.69}\n",
            "{'loss': 1.8557, 'grad_norm': 0.12209909409284592, 'learning_rate': 0.007760750509757298, 'epoch': 0.7}\n",
            "{'loss': 2.4484, 'grad_norm': 0.16319581866264343, 'learning_rate': 0.007705716799671019, 'epoch': 0.7}\n",
            "{'loss': 1.7305, 'grad_norm': 0.12299221009016037, 'learning_rate': 0.007650215591292888, 'epoch': 0.71}\n",
            "{'loss': 1.5202, 'grad_norm': 0.11351588368415833, 'learning_rate': 0.007594256474214882, 'epoch': 0.72}\n",
            "{'loss': 2.1369, 'grad_norm': 0.21469174325466156, 'learning_rate': 0.007537849117147212, 'epoch': 0.73}\n",
            "{'loss': 1.5122, 'grad_norm': 0.22660066187381744, 'learning_rate': 0.007481003266247744, 'epoch': 0.74}\n",
            "{'loss': 1.3187, 'grad_norm': 0.11340237408876419, 'learning_rate': 0.007423728743438048, 'epoch': 0.74}\n",
            "{'loss': 1.9557, 'grad_norm': 0.39331623911857605, 'learning_rate': 0.007366035444706346, 'epoch': 0.75}\n",
            "{'loss': 1.4529, 'grad_norm': 0.28636717796325684, 'learning_rate': 0.007307933338397667, 'epoch': 0.76}\n",
            "{'loss': 1.5501, 'grad_norm': 0.2683330178260803, 'learning_rate': 0.007249432463491498, 'epoch': 0.77}\n",
            "{'loss': 1.3153, 'grad_norm': 0.10518820583820343, 'learning_rate': 0.007190542927867234, 'epoch': 0.78}\n",
            "{'loss': 2.1983, 'grad_norm': 0.5508949756622314, 'learning_rate': 0.007131274906557725, 'epoch': 0.78}\n",
            "{'loss': 1.8744, 'grad_norm': 0.16095736622810364, 'learning_rate': 0.007071638639991207, 'epoch': 0.79}\n",
            "{'loss': 1.7408, 'grad_norm': 0.47805315256118774, 'learning_rate': 0.007011644432221957, 'epoch': 0.8}\n",
            "{'loss': 1.9237, 'grad_norm': 0.15075819194316864, 'learning_rate': 0.0069513026491499295, 'epoch': 0.81}\n",
            "{'loss': 1.3462, 'grad_norm': 0.19077283143997192, 'learning_rate': 0.0068906237167297235, 'epoch': 0.82}\n",
            "{'loss': 2.2082, 'grad_norm': 0.4919222593307495, 'learning_rate': 0.006829618119169168, 'epoch': 0.82}\n",
            "{'loss': 1.4901, 'grad_norm': 0.13660944998264313, 'learning_rate': 0.006768296397117848, 'epoch': 0.83}\n",
            "{'loss': 2.1425, 'grad_norm': 0.34602808952331543, 'learning_rate': 0.0067066691458458625, 'epoch': 0.84}\n",
            "{'loss': 1.8666, 'grad_norm': 0.37638750672340393, 'learning_rate': 0.0066447470134131685, 'epoch': 0.85}\n",
            "{'loss': 1.6933, 'grad_norm': 0.2144889086484909, 'learning_rate': 0.006582540698829781, 'epoch': 0.86}\n",
            "{'loss': 1.6681, 'grad_norm': 0.1344323605298996, 'learning_rate': 0.006520060950207185, 'epoch': 0.86}\n",
            "{'loss': 1.5468, 'grad_norm': 0.26569536328315735, 'learning_rate': 0.006457318562901257, 'epoch': 0.87}\n",
            "{'loss': 1.4297, 'grad_norm': 0.17814837396144867, 'learning_rate': 0.006394324377647027, 'epoch': 0.88}\n",
            "{'loss': 1.5259, 'grad_norm': 0.13332076370716095, 'learning_rate': 0.006331089278685599, 'epoch': 0.89}\n",
            "{'loss': 1.6626, 'grad_norm': 0.17551544308662415, 'learning_rate': 0.006267624191883551, 'epoch': 0.9}\n",
            "{'loss': 1.5182, 'grad_norm': 0.11846532672643661, 'learning_rate': 0.006203940082845145, 'epoch': 0.9}\n",
            "{'loss': 1.9292, 'grad_norm': 0.3796271085739136, 'learning_rate': 0.006140047955017672, 'epoch': 0.91}\n",
            "{'loss': 1.6213, 'grad_norm': 0.13310576975345612, 'learning_rate': 0.006075958847790262, 'epoch': 0.92}\n",
            "{'loss': 1.4628, 'grad_norm': 0.21590176224708557, 'learning_rate': 0.006011683834586473, 'epoch': 0.93}\n",
            "{'loss': 1.5225, 'grad_norm': 0.15697941184043884, 'learning_rate': 0.005947234020951014, 'epoch': 0.94}\n",
            "{'loss': 1.685, 'grad_norm': 0.1706940233707428, 'learning_rate': 0.005882620542630901, 'epoch': 0.94}\n",
            "{'loss': 1.4644, 'grad_norm': 0.08194613456726074, 'learning_rate': 0.0058178545636514145, 'epoch': 0.95}\n",
            "{'loss': 1.7154, 'grad_norm': 0.16109515726566315, 'learning_rate': 0.005752947274387147, 'epoch': 0.96}\n",
            "{'loss': 1.5783, 'grad_norm': 0.11549605429172516, 'learning_rate': 0.0056879098896285285, 'epoch': 0.97}\n",
            "{'loss': 1.7848, 'grad_norm': 0.16306790709495544, 'learning_rate': 0.005622753646644102, 'epoch': 0.98}\n",
            "{'loss': 1.3521, 'grad_norm': 0.19082297384738922, 'learning_rate': 0.005557489803238933, 'epoch': 0.98}\n",
            "{'loss': 1.3079, 'grad_norm': 0.09515364468097687, 'learning_rate': 0.005492129635809473, 'epoch': 0.99}\n",
            "{'loss': 1.3427, 'grad_norm': 0.0910460501909256, 'learning_rate': 0.005426684437395197, 'epoch': 1.0}\n",
            "{'loss': 1.3458, 'grad_norm': 0.15064840018749237, 'learning_rate': 0.005361165515727374, 'epoch': 1.01}\n",
            "{'loss': 1.6394, 'grad_norm': 0.19808685779571533, 'learning_rate': 0.005295584191275308, 'epoch': 1.02}\n",
            "{'loss': 1.6022, 'grad_norm': 0.2239605039358139, 'learning_rate': 0.005229951795290353, 'epoch': 1.02}\n",
            "{'loss': 1.1768, 'grad_norm': 0.09603608399629593, 'learning_rate': 0.0051642796678480945, 'epoch': 1.03}\n",
            "{'loss': 2.107, 'grad_norm': 0.277700811624527, 'learning_rate': 0.005098579155888979, 'epoch': 1.04}\n",
            "{'loss': 1.2585, 'grad_norm': 0.11823077499866486, 'learning_rate': 0.005032861611257783, 'epoch': 1.05}\n",
            "{'loss': 1.4491, 'grad_norm': 0.22906087338924408, 'learning_rate': 0.0049671383887422175, 'epoch': 1.06}\n",
            "{'loss': 1.3111, 'grad_norm': 0.08400629460811615, 'learning_rate': 0.004901420844111021, 'epoch': 1.06}\n",
            "{'loss': 1.3843, 'grad_norm': 0.07735791057348251, 'learning_rate': 0.004835720332151907, 'epoch': 1.07}\n",
            "{'loss': 2.1452, 'grad_norm': 0.5838475823402405, 'learning_rate': 0.0047700482047096475, 'epoch': 1.08}\n",
            "{'loss': 1.3654, 'grad_norm': 0.14199525117874146, 'learning_rate': 0.004704415808724692, 'epoch': 1.09}\n",
            "{'loss': 1.4268, 'grad_norm': 0.2531030476093292, 'learning_rate': 0.004638834484272627, 'epoch': 1.1}\n",
            "{'loss': 1.5284, 'grad_norm': 0.27993786334991455, 'learning_rate': 0.0045733155626048036, 'epoch': 1.1}\n",
            "{'loss': 1.6826, 'grad_norm': 0.14136937260627747, 'learning_rate': 0.004507870364190527, 'epoch': 1.11}\n",
            "{'loss': 2.1004, 'grad_norm': 0.4525739252567291, 'learning_rate': 0.004442510196761068, 'epoch': 1.12}\n",
            "{'loss': 1.3713, 'grad_norm': 0.2423679679632187, 'learning_rate': 0.004377246353355899, 'epoch': 1.13}\n",
            "{'loss': 1.4516, 'grad_norm': 0.2275800108909607, 'learning_rate': 0.004312090110371473, 'epoch': 1.14}\n",
            "{'loss': 1.5217, 'grad_norm': 0.1834600567817688, 'learning_rate': 0.004247052725612852, 'epoch': 1.14}\n",
            "{'loss': 1.2505, 'grad_norm': 0.10249084234237671, 'learning_rate': 0.0041821454363485866, 'epoch': 1.15}\n",
            "{'loss': 1.201, 'grad_norm': 0.07734212279319763, 'learning_rate': 0.004117379457369099, 'epoch': 1.16}\n",
            "{'loss': 1.1219, 'grad_norm': 0.0919632837176323, 'learning_rate': 0.004052765979048986, 'epoch': 1.17}\n",
            "{'loss': 1.6595, 'grad_norm': 0.2523796558380127, 'learning_rate': 0.003988316165413527, 'epoch': 1.18}\n",
            "{'loss': 1.3718, 'grad_norm': 0.18522867560386658, 'learning_rate': 0.003924041152209738, 'epoch': 1.18}\n",
            "{'loss': 1.1255, 'grad_norm': 0.0888029932975769, 'learning_rate': 0.003859952044982329, 'epoch': 1.19}\n",
            "{'loss': 1.2072, 'grad_norm': 0.1810339093208313, 'learning_rate': 0.003796059917154857, 'epoch': 1.2}\n",
            "{'loss': 1.4201, 'grad_norm': 0.26397040486335754, 'learning_rate': 0.0037323758081164505, 'epoch': 1.21}\n",
            "{'loss': 1.3837, 'grad_norm': 0.14101363718509674, 'learning_rate': 0.0036689107213144024, 'epoch': 1.22}\n",
            "{'loss': 1.1559, 'grad_norm': 0.22291116416454315, 'learning_rate': 0.003605675622352973, 'epoch': 1.22}\n",
            "{'loss': 1.3855, 'grad_norm': 0.1154131144285202, 'learning_rate': 0.003542681437098745, 'epoch': 1.23}\n",
            "{'loss': 1.2586, 'grad_norm': 0.13655561208724976, 'learning_rate': 0.003479939049792817, 'epoch': 1.24}\n",
            "{'loss': 1.1819, 'grad_norm': 0.1107647493481636, 'learning_rate': 0.0034174593011702193, 'epoch': 1.25}\n",
            "{'loss': 1.1951, 'grad_norm': 0.0985335111618042, 'learning_rate': 0.003355252986586832, 'epoch': 1.26}\n",
            "{'loss': 1.2213, 'grad_norm': 0.08371588587760925, 'learning_rate': 0.0032933308541541364, 'epoch': 1.26}\n",
            "{'loss': 1.2421, 'grad_norm': 0.1578356921672821, 'learning_rate': 0.0032317036028821525, 'epoch': 1.27}\n",
            "{'loss': 1.1471, 'grad_norm': 0.10338863730430603, 'learning_rate': 0.0031703818808308326, 'epoch': 1.28}\n",
            "{'loss': 1.1098, 'grad_norm': 0.08354584872722626, 'learning_rate': 0.003109376283270277, 'epoch': 1.29}\n",
            "{'loss': 1.0579, 'grad_norm': 0.13561712205410004, 'learning_rate': 0.0030486973508500725, 'epoch': 1.3}\n",
            "{'loss': 1.0852, 'grad_norm': 0.12695468962192535, 'learning_rate': 0.0029883555677780427, 'epoch': 1.3}\n",
            "{'loss': 1.2975, 'grad_norm': 0.1725899875164032, 'learning_rate': 0.002928361360008793, 'epoch': 1.31}\n",
            "{'loss': 1.1777, 'grad_norm': 0.08559330552816391, 'learning_rate': 0.002868725093442277, 'epoch': 1.32}\n",
            "{'loss': 1.0409, 'grad_norm': 0.08340710401535034, 'learning_rate': 0.002809457072132766, 'epoch': 1.33}\n",
            "{'loss': 2.0501, 'grad_norm': 0.6824268698692322, 'learning_rate': 0.0027505675365085036, 'epoch': 1.34}\n",
            "{'loss': 1.2085, 'grad_norm': 0.09268508851528168, 'learning_rate': 0.0026920666616023327, 'epoch': 1.34}\n",
            "{'loss': 1.2911, 'grad_norm': 0.25145307183265686, 'learning_rate': 0.0026339645552936534, 'epoch': 1.35}\n",
            "{'loss': 1.0465, 'grad_norm': 0.202217698097229, 'learning_rate': 0.002576271256561953, 'epoch': 1.36}\n",
            "{'loss': 1.5955, 'grad_norm': 0.36227715015411377, 'learning_rate': 0.002518996733752257, 'epoch': 1.37}\n",
            "{'loss': 1.087, 'grad_norm': 0.1668640673160553, 'learning_rate': 0.00246215088285279, 'epoch': 1.38}\n",
            "{'loss': 1.0317, 'grad_norm': 0.12806439399719238, 'learning_rate': 0.0024057435257851174, 'epoch': 1.38}\n",
            "{'loss': 1.0551, 'grad_norm': 0.08419438451528549, 'learning_rate': 0.0023497844087071117, 'epoch': 1.39}\n",
            "{'loss': 1.5797, 'grad_norm': 0.2790844440460205, 'learning_rate': 0.002294283200328982, 'epoch': 1.4}\n",
            "{'loss': 1.0439, 'grad_norm': 0.07610172033309937, 'learning_rate': 0.0022392494902427023, 'epoch': 1.41}\n",
            "{'loss': 1.6722, 'grad_norm': 0.39330193400382996, 'learning_rate': 0.0021846927872651136, 'epoch': 1.42}\n",
            "{'loss': 1.0935, 'grad_norm': 0.12666650116443634, 'learning_rate': 0.0021306225177949584, 'epoch': 1.42}\n",
            "{'loss': 1.4616, 'grad_norm': 0.1990528702735901, 'learning_rate': 0.00207704802418419, 'epoch': 1.43}\n",
            "{'loss': 1.4552, 'grad_norm': 0.21533946692943573, 'learning_rate': 0.0020239785631237708, 'epoch': 1.44}\n",
            "{'loss': 1.0218, 'grad_norm': 0.16031228005886078, 'learning_rate': 0.0019714233040442914, 'epoch': 1.45}\n",
            "{'loss': 1.3109, 'grad_norm': 0.250806599855423, 'learning_rate': 0.0019193913275316627, 'epoch': 1.46}\n",
            "{'loss': 1.4973, 'grad_norm': 0.19624869525432587, 'learning_rate': 0.0018678916237581523, 'epoch': 1.46}\n",
            "{'loss': 1.4494, 'grad_norm': 0.20008668303489685, 'learning_rate': 0.0018169330909290548, 'epoch': 1.47}\n",
            "{'loss': 1.3498, 'grad_norm': 0.17619773745536804, 'learning_rate': 0.0017665245337452368, 'epoch': 1.48}\n",
            "{'loss': 1.4755, 'grad_norm': 0.27012938261032104, 'learning_rate': 0.001716674661881848, 'epoch': 1.49}\n",
            "{'loss': 0.943, 'grad_norm': 0.04713810235261917, 'learning_rate': 0.001667392088483456, 'epoch': 1.5}\n",
            "{'loss': 1.0274, 'grad_norm': 0.09416361153125763, 'learning_rate': 0.0016186853286758397, 'epoch': 1.5}\n",
            "{'loss': 1.0122, 'grad_norm': 0.08956407755613327, 'learning_rate': 0.0015705627980947467, 'epoch': 1.51}\n",
            "{'loss': 1.2781, 'grad_norm': 0.190860316157341, 'learning_rate': 0.0015230328114318127, 'epoch': 1.52}\n",
            "{'loss': 1.5123, 'grad_norm': 0.2500455677509308, 'learning_rate': 0.0014761035809979395, 'epoch': 1.53}\n",
            "{'loss': 1.1858, 'grad_norm': 0.1453714370727539, 'learning_rate': 0.0014297832153043655, 'epoch': 1.54}\n",
            "{'loss': 1.0096, 'grad_norm': 0.09139315783977509, 'learning_rate': 0.0013840797176616466, 'epoch': 1.54}\n",
            "{'loss': 1.0141, 'grad_norm': 0.09415064752101898, 'learning_rate': 0.0013390009847968503, 'epoch': 1.55}\n",
            "{'loss': 1.1616, 'grad_norm': 0.12280789762735367, 'learning_rate': 0.001294554805489132, 'epoch': 1.56}\n",
            "{'loss': 1.3736, 'grad_norm': 0.11583112925291061, 'learning_rate': 0.0012507488592239846, 'epoch': 1.57}\n",
            "{'loss': 0.9691, 'grad_norm': 0.06820449978113174, 'learning_rate': 0.0012075907148663579, 'epoch': 1.58}\n",
            "{'loss': 0.9645, 'grad_norm': 0.05919980630278587, 'learning_rate': 0.0011650878293528993, 'epoch': 1.58}\n",
            "{'loss': 1.1653, 'grad_norm': 0.08048020303249359, 'learning_rate': 0.0011232475464035385, 'epoch': 1.59}\n",
            "{'loss': 0.9661, 'grad_norm': 0.0478300042450428, 'learning_rate': 0.0010820770952526153, 'epoch': 1.6}\n",
            "{'loss': 0.9988, 'grad_norm': 0.04365411400794983, 'learning_rate': 0.0010415835893998115, 'epoch': 1.61}\n",
            "{'loss': 1.0694, 'grad_norm': 0.11685065925121307, 'learning_rate': 0.001001774025381061, 'epoch': 1.62}\n",
            "{'loss': 1.0356, 'grad_norm': 0.12217476963996887, 'learning_rate': 0.000962655281559679, 'epoch': 1.62}\n",
            "{'loss': 0.9809, 'grad_norm': 0.04767444357275963, 'learning_rate': 0.0009242341169379076, 'epoch': 1.63}\n",
            "{'loss': 1.4715, 'grad_norm': 0.2644435465335846, 'learning_rate': 0.0008865171699890834, 'epoch': 1.64}\n",
            "{'loss': 1.5824, 'grad_norm': 0.18216091394424438, 'learning_rate': 0.000849510957510633, 'epoch': 1.65}\n",
            "{'loss': 1.2279, 'grad_norm': 0.15084756910800934, 'learning_rate': 0.0008132218734980851, 'epoch': 1.66}\n",
            "{'loss': 0.9578, 'grad_norm': 0.09248103946447372, 'learning_rate': 0.0007776561880403071, 'epoch': 1.66}\n",
            "{'loss': 1.0211, 'grad_norm': 0.08512499928474426, 'learning_rate': 0.000742820046236154, 'epoch': 1.67}\n",
            "{'loss': 0.9567, 'grad_norm': 0.10860118269920349, 'learning_rate': 0.0007087194671326985, 'epoch': 1.68}\n",
            "{'loss': 0.9511, 'grad_norm': 0.10957557708024979, 'learning_rate': 0.0006753603426852589, 'epoch': 1.69}\n",
            "{'loss': 0.941, 'grad_norm': 0.09801250696182251, 'learning_rate': 0.0006427484367393699, 'epoch': 1.7}\n",
            "{'loss': 1.0338, 'grad_norm': 0.05564352497458458, 'learning_rate': 0.0006108893840348995, 'epoch': 1.7}\n",
            "{'loss': 1.2435, 'grad_norm': 0.12205320596694946, 'learning_rate': 0.0005797886892324694, 'epoch': 1.71}\n",
            "{'loss': 1.3821, 'grad_norm': 0.1677977442741394, 'learning_rate': 0.0005494517259623477, 'epoch': 1.72}\n",
            "{'loss': 0.9435, 'grad_norm': 0.10672388225793839, 'learning_rate': 0.0005198837358959902, 'epoch': 1.73}\n",
            "{'loss': 1.2995, 'grad_norm': 0.1626676321029663, 'learning_rate': 0.0004910898278403669, 'epoch': 1.74}\n",
            "{'loss': 1.17, 'grad_norm': 0.12148647010326385, 'learning_rate': 0.0004630749768552589, 'epoch': 1.74}\n",
            "{'loss': 1.1559, 'grad_norm': 0.20069555938243866, 'learning_rate': 0.0004358440233936617, 'epoch': 1.75}\n",
            "{'loss': 1.4592, 'grad_norm': 0.18836359679698944, 'learning_rate': 0.0004094016724654359, 'epoch': 1.76}\n",
            "{'loss': 0.977, 'grad_norm': 0.06467670202255249, 'learning_rate': 0.0003837524928243774, 'epoch': 1.77}\n",
            "{'loss': 1.0725, 'grad_norm': 0.09395858645439148, 'learning_rate': 0.0003589009161788104, 'epoch': 1.78}\n",
            "{'loss': 1.0519, 'grad_norm': 0.07436898350715637, 'learning_rate': 0.00033485123642587654, 'epoch': 1.78}\n",
            "{'loss': 1.0272, 'grad_norm': 0.05340339615941048, 'learning_rate': 0.0003116076089096265, 'epoch': 1.79}\n",
            "{'loss': 1.0817, 'grad_norm': 0.0907367393374443, 'learning_rate': 0.0002891740497030509, 'epoch': 1.8}\n",
            "{'loss': 1.0872, 'grad_norm': 0.10018724948167801, 'learning_rate': 0.00026755443491417784, 'epoch': 1.81}\n",
            "{'loss': 1.2766, 'grad_norm': 0.13773635029792786, 'learning_rate': 0.0002467525000163523, 'epoch': 1.82}\n",
            "{'loss': 1.195, 'grad_norm': 0.07583130896091461, 'learning_rate': 0.0002267718392028134, 'epoch': 1.82}\n",
            "{'loss': 1.1053, 'grad_norm': 0.11390545219182968, 'learning_rate': 0.00020761590476568893, 'epoch': 1.83}\n",
            "{'loss': 1.2799, 'grad_norm': 0.11489523947238922, 'learning_rate': 0.0001892880064994934, 'epoch': 1.84}\n",
            "{'loss': 0.9222, 'grad_norm': 0.09033989161252975, 'learning_rate': 0.00017179131112926628, 'epoch': 1.85}\n",
            "{'loss': 1.3529, 'grad_norm': 0.13105638325214386, 'learning_rate': 0.00015512884176341059, 'epoch': 1.86}\n",
            "{'loss': 1.4186, 'grad_norm': 0.11579344421625137, 'learning_rate': 0.00013930347737136194, 'epoch': 1.86}\n",
            "{'loss': 1.1835, 'grad_norm': 0.08092766255140305, 'learning_rate': 0.00012431795228615372, 'epoch': 1.87}\n",
            "{'loss': 1.1945, 'grad_norm': 0.10496640205383301, 'learning_rate': 0.0001101748557319715, 'epoch': 1.88}\n",
            "{'loss': 1.4562, 'grad_norm': 0.15897375345230103, 'learning_rate': 9.687663137678604e-05, 'epoch': 1.89}\n",
            "{'loss': 1.0296, 'grad_norm': 0.06188002601265907, 'learning_rate': 8.442557691013042e-05, 'epoch': 1.9}\n",
            "{'loss': 1.2025, 'grad_norm': 0.11094681918621063, 'learning_rate': 7.282384364610206e-05, 'epoch': 1.9}\n",
            "{'loss': 0.9967, 'grad_norm': 0.0957873985171318, 'learning_rate': 6.207343615165562e-05, 'epoch': 1.91}\n",
            "{'loss': 1.0753, 'grad_norm': 0.1445811688899994, 'learning_rate': 5.217621190024779e-05, 'epoch': 1.92}\n",
            "{'loss': 1.5302, 'grad_norm': 0.18725444376468658, 'learning_rate': 4.31338809509052e-05, 'epoch': 1.93}\n",
            "{'loss': 1.0503, 'grad_norm': 0.11923225224018097, 'learning_rate': 3.494800565275125e-05, 'epoch': 1.94}\n",
            "{'loss': 1.0685, 'grad_norm': 0.12341301143169403, 'learning_rate': 2.7620000375064847e-05, 'epoch': 1.94}\n",
            "{'loss': 1.2019, 'grad_norm': 0.11567004770040512, 'learning_rate': 2.1151131262902577e-05, 'epoch': 1.95}\n",
            "{'loss': 1.3271, 'grad_norm': 0.12050873786211014, 'learning_rate': 1.5542516018332008e-05, 'epoch': 1.96}\n",
            "{'loss': 1.2314, 'grad_norm': 0.07890855520963669, 'learning_rate': 1.0795123707312281e-05, 'epoch': 1.97}\n",
            "{'loss': 0.983, 'grad_norm': 0.08201278746128082, 'learning_rate': 6.909774592258056e-06, 'epoch': 1.98}\n",
            "{'loss': 1.0985, 'grad_norm': 0.053034182637929916, 'learning_rate': 3.887139990313426e-06, 'epoch': 1.98}\n",
            "{'loss': 1.0359, 'grad_norm': 0.06279123574495316, 'learning_rate': 1.7277421573608233e-06, 'epoch': 1.99}\n",
            "{'loss': 0.9492, 'grad_norm': 0.09939412772655487, 'learning_rate': 4.319541977831909e-07, 'epoch': 2.0}\n",
            "{'train_runtime': 29.8857, 'train_samples_per_second': 16.73, 'train_steps_per_second': 8.365, 'train_loss': 2.0044892392158506, 'epoch': 2.0}\n",
            "100% 250/250 [00:29<00:00,  8.37it/s]\n",
            "Training complete.\n",
            "Model saved to loras/self-edit/training_set_iteration_1/44f52bb0/10\n",
            "Skipping training for task 44f52bb0 because the number of steps is greater than 375\n",
            "Training on 250 examples for 0 epochs, lr: 1.0\n",
            "No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n",
            "Starting training...\n",
            "{'train_runtime': 0.0021, 'train_samples_per_second': 0.0, 'train_steps_per_second': 0.0, 'train_loss': 0.0, 'epoch': 0}\n",
            "0it [00:00, ?it/s]\n",
            "Training complete.\n",
            "Model saved to loras/self-edit/training_set_iteration_1/44f52bb0/11\n",
            "Training on 250 examples for 3 epochs, lr: 0.01\n",
            "No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n",
            "Starting training...\n",
            "{'loss': 6.4988, 'grad_norm': 9.142213821411133, 'learning_rate': 0.0, 'epoch': 0.01}\n",
            "{'loss': 6.592, 'grad_norm': 8.51971435546875, 'learning_rate': 0.0009090909090909091, 'epoch': 0.02}\n",
            "{'loss': 2.9253, 'grad_norm': 15.519278526306152, 'learning_rate': 0.0018181818181818182, 'epoch': 0.02}\n",
            "{'loss': 2.8122, 'grad_norm': 8.420727729797363, 'learning_rate': 0.002727272727272727, 'epoch': 0.03}\n",
            "{'loss': 1.681, 'grad_norm': 1.6244306564331055, 'learning_rate': 0.0036363636363636364, 'epoch': 0.04}\n",
            "{'loss': 1.0062, 'grad_norm': 0.9231923818588257, 'learning_rate': 0.004545454545454545, 'epoch': 0.05}\n",
            "{'loss': 0.8565, 'grad_norm': 0.5810914635658264, 'learning_rate': 0.005454545454545454, 'epoch': 0.06}\n",
            "{'loss': 0.5736, 'grad_norm': 0.5669565200805664, 'learning_rate': 0.006363636363636364, 'epoch': 0.06}\n",
            "{'loss': 0.4284, 'grad_norm': 0.7021042704582214, 'learning_rate': 0.007272727272727273, 'epoch': 0.07}\n",
            "{'loss': 0.5619, 'grad_norm': 1.193932294845581, 'learning_rate': 0.008181818181818182, 'epoch': 0.08}\n",
            "{'loss': 4.519, 'grad_norm': 24.248291015625, 'learning_rate': 0.00909090909090909, 'epoch': 0.09}\n",
            "{'loss': 3.6508, 'grad_norm': 14.936417579650879, 'learning_rate': 0.01, 'epoch': 0.1}\n",
            "{'loss': 10.0658, 'grad_norm': 10.260392189025879, 'learning_rate': 0.009999813776583147, 'epoch': 0.1}\n",
            "{'loss': 12.6818, 'grad_norm': 13.28750228881836, 'learning_rate': 0.009999255120204246, 'epoch': 0.11}\n",
            "{'loss': 10.7886, 'grad_norm': 16.91120147705078, 'learning_rate': 0.009998324072477265, 'epoch': 0.12}\n",
            "{'loss': 6.2615, 'grad_norm': 12.452122688293457, 'learning_rate': 0.009997020702755353, 'epoch': 0.13}\n",
            "{'loss': 12.1836, 'grad_norm': 22.997716903686523, 'learning_rate': 0.009995345108125697, 'epoch': 0.14}\n",
            "{'loss': 6.4765, 'grad_norm': 3.5015926361083984, 'learning_rate': 0.009993297413402281, 'epoch': 0.14}\n",
            "{'loss': 4.9339, 'grad_norm': 6.524250507354736, 'learning_rate': 0.009990877771116588, 'epoch': 0.15}\n",
            "{'loss': 7.9978, 'grad_norm': 82.36446380615234, 'learning_rate': 0.009988086361506238, 'epoch': 0.16}\n",
            "{'loss': 6.7393, 'grad_norm': 1.503544569015503, 'learning_rate': 0.009984923392501567, 'epoch': 0.17}\n",
            "{'loss': 12.8171, 'grad_norm': 4.463413238525391, 'learning_rate': 0.009981389099710133, 'epoch': 0.18}\n",
            "{'loss': 6.0866, 'grad_norm': 1.9313204288482666, 'learning_rate': 0.009977483746399167, 'epoch': 0.18}\n",
            "{'loss': 9.4337, 'grad_norm': 4.778341293334961, 'learning_rate': 0.009973207623475963, 'epoch': 0.19}\n",
            "{'loss': 6.3719, 'grad_norm': 2.074522018432617, 'learning_rate': 0.009968561049466213, 'epoch': 0.2}\n",
            "{'loss': 7.8555, 'grad_norm': 3.1961209774017334, 'learning_rate': 0.00996354437049027, 'epoch': 0.21}\n",
            "{'loss': 5.6021, 'grad_norm': 2.2822320461273193, 'learning_rate': 0.009958157960237374, 'epoch': 0.22}\n",
            "{'loss': 3.5192, 'grad_norm': 0.8041736483573914, 'learning_rate': 0.009952402219937815, 'epoch': 0.22}\n",
            "{'loss': 5.2619, 'grad_norm': 2.0185012817382812, 'learning_rate': 0.009946277578333045, 'epoch': 0.23}\n",
            "{'loss': 3.5657, 'grad_norm': 0.8726524710655212, 'learning_rate': 0.009939784491643733, 'epoch': 0.24}\n",
            "{'loss': 5.6112, 'grad_norm': 3.308342218399048, 'learning_rate': 0.009932923443535798, 'epoch': 0.25}\n",
            "{'loss': 5.3927, 'grad_norm': 2.6282660961151123, 'learning_rate': 0.009925694945084369, 'epoch': 0.26}\n",
            "{'loss': 4.7894, 'grad_norm': 1.8228940963745117, 'learning_rate': 0.009918099534735719, 'epoch': 0.26}\n",
            "{'loss': 3.8989, 'grad_norm': 0.936780571937561, 'learning_rate': 0.009910137778267152, 'epoch': 0.27}\n",
            "{'loss': 6.1683, 'grad_norm': 11.063911437988281, 'learning_rate': 0.009901810268744867, 'epoch': 0.28}\n",
            "{'loss': 4.7638, 'grad_norm': 1.6629170179367065, 'learning_rate': 0.009893117626479776, 'epoch': 0.29}\n",
            "{'loss': 4.0352, 'grad_norm': 1.7254184484481812, 'learning_rate': 0.009884060498981296, 'epoch': 0.3}\n",
            "{'loss': 8.3896, 'grad_norm': 3.4086132049560547, 'learning_rate': 0.009874639560909117, 'epoch': 0.3}\n",
            "{'loss': 4.7155, 'grad_norm': 2.0094316005706787, 'learning_rate': 0.009864855514022955, 'epoch': 0.31}\n",
            "{'loss': 3.6112, 'grad_norm': 1.0332527160644531, 'learning_rate': 0.009854709087130261, 'epoch': 0.32}\n",
            "{'loss': 3.1355, 'grad_norm': 1.1841840744018555, 'learning_rate': 0.00984420103603195, 'epoch': 0.33}\n",
            "{'loss': 3.2543, 'grad_norm': 1.0428115129470825, 'learning_rate': 0.009833332143466099, 'epoch': 0.34}\n",
            "{'loss': 2.4951, 'grad_norm': 0.4760359823703766, 'learning_rate': 0.009822103219049624, 'epoch': 0.34}\n",
            "{'loss': 2.6526, 'grad_norm': 0.4276353418827057, 'learning_rate': 0.009810515099218002, 'epoch': 0.35}\n",
            "{'loss': 2.8963, 'grad_norm': 0.5704933404922485, 'learning_rate': 0.009798568647162938, 'epoch': 0.36}\n",
            "{'loss': 2.85, 'grad_norm': 0.5934405326843262, 'learning_rate': 0.00978626475276808, 'epoch': 0.37}\n",
            "{'loss': 2.8546, 'grad_norm': 0.5048477649688721, 'learning_rate': 0.009773604332542728, 'epoch': 0.38}\n",
            "{'loss': 2.5354, 'grad_norm': 0.21109525859355927, 'learning_rate': 0.00976058832955357, 'epoch': 0.38}\n",
            "{'loss': 3.1481, 'grad_norm': 0.8056002259254456, 'learning_rate': 0.009747217713354427, 'epoch': 0.39}\n",
            "{'loss': 3.0001, 'grad_norm': 0.6070672869682312, 'learning_rate': 0.009733493479914031, 'epoch': 0.4}\n",
            "{'loss': 2.1246, 'grad_norm': 0.21735768020153046, 'learning_rate': 0.009719416651541838, 'epoch': 0.41}\n",
            "{'loss': 2.641, 'grad_norm': 0.45080599188804626, 'learning_rate': 0.009704988276811882, 'epoch': 0.42}\n",
            "{'loss': 2.5069, 'grad_norm': 0.39129456877708435, 'learning_rate': 0.00969020943048466, 'epoch': 0.42}\n",
            "{'loss': 2.7407, 'grad_norm': 0.44251084327697754, 'learning_rate': 0.009675081213427075, 'epoch': 0.43}\n",
            "{'loss': 2.5381, 'grad_norm': 0.989641547203064, 'learning_rate': 0.009659604752530434, 'epoch': 0.44}\n",
            "{'loss': 2.3629, 'grad_norm': 0.45592132210731506, 'learning_rate': 0.00964378120062651, 'epoch': 0.45}\n",
            "{'loss': 2.0214, 'grad_norm': 0.36713141202926636, 'learning_rate': 0.009627611736401667, 'epoch': 0.46}\n",
            "{'loss': 2.8212, 'grad_norm': 0.46188434958457947, 'learning_rate': 0.009611097564309053, 'epoch': 0.46}\n",
            "{'loss': 2.4725, 'grad_norm': 0.23498448729515076, 'learning_rate': 0.009594239914478886, 'epoch': 0.47}\n",
            "{'loss': 2.6759, 'grad_norm': 0.41712313890457153, 'learning_rate': 0.009577040042626833, 'epoch': 0.48}\n",
            "{'loss': 2.674, 'grad_norm': 0.847949206829071, 'learning_rate': 0.00955949922996045, 'epoch': 0.49}\n",
            "{'loss': 2.2363, 'grad_norm': 0.21753674745559692, 'learning_rate': 0.00954161878308377, 'epoch': 0.5}\n",
            "{'loss': 1.9003, 'grad_norm': 0.19055618345737457, 'learning_rate': 0.009523400033899955, 'epoch': 0.5}\n",
            "{'loss': 1.9497, 'grad_norm': 0.3092682957649231, 'learning_rate': 0.009504844339512096, 'epoch': 0.51}\n",
            "{'loss': 1.6622, 'grad_norm': 0.17396096885204315, 'learning_rate': 0.009485953082122116, 'epoch': 0.52}\n",
            "{'loss': 2.2902, 'grad_norm': 0.3139495253562927, 'learning_rate': 0.009466727668927815, 'epoch': 0.53}\n",
            "{'loss': 1.6697, 'grad_norm': 0.10543626546859741, 'learning_rate': 0.00944716953201805, 'epoch': 0.54}\n",
            "{'loss': 2.5881, 'grad_norm': 0.30371150374412537, 'learning_rate': 0.009427280128266049, 'epoch': 0.54}\n",
            "{'loss': 1.9728, 'grad_norm': 0.16511572897434235, 'learning_rate': 0.009407060939220908, 'epoch': 0.55}\n",
            "{'loss': 2.3074, 'grad_norm': 0.24664048850536346, 'learning_rate': 0.00938651347099721, 'epoch': 0.56}\n",
            "{'loss': 1.6628, 'grad_norm': 0.16311316192150116, 'learning_rate': 0.009365639254162854, 'epoch': 0.57}\n",
            "{'loss': 2.3271, 'grad_norm': 0.16421803832054138, 'learning_rate': 0.009344439843625034, 'epoch': 0.58}\n",
            "{'loss': 1.8786, 'grad_norm': 0.2463364452123642, 'learning_rate': 0.009322916818514413, 'epoch': 0.58}\n",
            "{'loss': 2.6913, 'grad_norm': 0.19186724722385406, 'learning_rate': 0.009301071782067504, 'epoch': 0.59}\n",
            "{'loss': 1.566, 'grad_norm': 0.1311759501695633, 'learning_rate': 0.009278906361507237, 'epoch': 0.6}\n",
            "{'loss': 1.9231, 'grad_norm': 0.10080257803201675, 'learning_rate': 0.009256422207921756, 'epoch': 0.61}\n",
            "{'loss': 2.1523, 'grad_norm': 0.2408764809370041, 'learning_rate': 0.00923362099614142, 'epoch': 0.62}\n",
            "{'loss': 2.3906, 'grad_norm': 0.30729934573173523, 'learning_rate': 0.009210504424614059, 'epoch': 0.62}\n",
            "{'loss': 2.2008, 'grad_norm': 0.15635912120342255, 'learning_rate': 0.009187074215278444, 'epoch': 0.63}\n",
            "{'loss': 2.1729, 'grad_norm': 0.17279133200645447, 'learning_rate': 0.009163332113436031, 'epoch': 0.64}\n",
            "{'loss': 1.634, 'grad_norm': 0.15958352386951447, 'learning_rate': 0.009139279887620954, 'epoch': 0.65}\n",
            "{'loss': 1.6896, 'grad_norm': 0.17347313463687897, 'learning_rate': 0.009114919329468282, 'epoch': 0.66}\n",
            "{'loss': 1.4778, 'grad_norm': 0.15721535682678223, 'learning_rate': 0.009090252253580565, 'epoch': 0.66}\n",
            "{'loss': 1.5654, 'grad_norm': 0.1107865497469902, 'learning_rate': 0.009065280497392662, 'epoch': 0.67}\n",
            "{'loss': 1.5559, 'grad_norm': 0.1165071353316307, 'learning_rate': 0.009040005921034882, 'epoch': 0.68}\n",
            "{'loss': 2.0162, 'grad_norm': 0.29728636145591736, 'learning_rate': 0.009014430407194412, 'epoch': 0.69}\n",
            "{'loss': 2.4904, 'grad_norm': 0.3112890124320984, 'learning_rate': 0.008988555860975082, 'epoch': 0.7}\n",
            "{'loss': 1.4669, 'grad_norm': 0.16094069182872772, 'learning_rate': 0.008962384209755451, 'epoch': 0.7}\n",
            "{'loss': 1.7886, 'grad_norm': 0.26286646723747253, 'learning_rate': 0.00893591740304525, 'epoch': 0.71}\n",
            "{'loss': 1.688, 'grad_norm': 0.6883965134620667, 'learning_rate': 0.008909157412340149, 'epoch': 0.72}\n",
            "{'loss': 1.7142, 'grad_norm': 0.16457226872444153, 'learning_rate': 0.008882106230974908, 'epoch': 0.73}\n",
            "{'loss': 1.7501, 'grad_norm': 0.1691862940788269, 'learning_rate': 0.008854765873974898, 'epoch': 0.74}\n",
            "{'loss': 1.3003, 'grad_norm': 0.08399832993745804, 'learning_rate': 0.008827138377905998, 'epoch': 0.74}\n",
            "{'loss': 1.3781, 'grad_norm': 0.12774935364723206, 'learning_rate': 0.008799225800722895, 'epoch': 0.75}\n",
            "{'loss': 1.2296, 'grad_norm': 0.07183591276407242, 'learning_rate': 0.008771030221615786, 'epoch': 0.76}\n",
            "{'loss': 1.738, 'grad_norm': 0.2252676635980606, 'learning_rate': 0.008742553740855506, 'epoch': 0.77}\n",
            "{'loss': 1.2162, 'grad_norm': 0.08245387673377991, 'learning_rate': 0.008713798479637071, 'epoch': 0.78}\n",
            "{'loss': 1.6802, 'grad_norm': 0.1491672694683075, 'learning_rate': 0.008684766579921684, 'epoch': 0.78}\n",
            "{'loss': 1.6712, 'grad_norm': 0.1341421753168106, 'learning_rate': 0.008655460204277167, 'epoch': 0.79}\n",
            "{'loss': 1.6761, 'grad_norm': 0.13163147866725922, 'learning_rate': 0.008625881535716882, 'epoch': 0.8}\n",
            "{'loss': 1.518, 'grad_norm': 0.12318636476993561, 'learning_rate': 0.008596032777537123, 'epoch': 0.81}\n",
            "{'loss': 1.3211, 'grad_norm': 0.09474507719278336, 'learning_rate': 0.008565916153152981, 'epoch': 0.82}\n",
            "{'loss': 1.5862, 'grad_norm': 0.13605967164039612, 'learning_rate': 0.008535533905932738, 'epoch': 0.82}\n",
            "{'loss': 1.5557, 'grad_norm': 0.1505492776632309, 'learning_rate': 0.008504888299030747, 'epoch': 0.83}\n",
            "{'loss': 1.3496, 'grad_norm': 0.14742568135261536, 'learning_rate': 0.008473981615218862, 'epoch': 0.84}\n",
            "{'loss': 1.3494, 'grad_norm': 0.12628409266471863, 'learning_rate': 0.008442816156716385, 'epoch': 0.85}\n",
            "{'loss': 1.2245, 'grad_norm': 0.09355810284614563, 'learning_rate': 0.008411394245018588, 'epoch': 0.86}\n",
            "{'loss': 1.4401, 'grad_norm': 0.07941421866416931, 'learning_rate': 0.008379718220723772, 'epoch': 0.86}\n",
            "{'loss': 1.9346, 'grad_norm': 0.19547007977962494, 'learning_rate': 0.008347790443358928, 'epoch': 0.87}\n",
            "{'loss': 1.2391, 'grad_norm': 0.12164583057165146, 'learning_rate': 0.008315613291203975, 'epoch': 0.88}\n",
            "{'loss': 1.6116, 'grad_norm': 0.14191222190856934, 'learning_rate': 0.0082831891611146, 'epoch': 0.89}\n",
            "{'loss': 1.4425, 'grad_norm': 0.09367936849594116, 'learning_rate': 0.00825052046834372, 'epoch': 0.9}\n",
            "{'loss': 1.523, 'grad_norm': 19.795621871948242, 'learning_rate': 0.008217609646361573, 'epoch': 0.9}\n",
            "{'loss': 1.4975, 'grad_norm': 0.17432992160320282, 'learning_rate': 0.008184459146674447, 'epoch': 0.91}\n",
            "{'loss': 1.5803, 'grad_norm': 0.2249353677034378, 'learning_rate': 0.008151071438642068, 'epoch': 0.92}\n",
            "{'loss': 1.1063, 'grad_norm': 0.1346787065267563, 'learning_rate': 0.008117449009293669, 'epoch': 0.93}\n",
            "{'loss': 1.1197, 'grad_norm': 0.06746533513069153, 'learning_rate': 0.008083594363142717, 'epoch': 0.94}\n",
            "{'loss': 1.3343, 'grad_norm': 0.13435061275959015, 'learning_rate': 0.008049510022000364, 'epoch': 0.94}\n",
            "{'loss': 1.4115, 'grad_norm': 0.134739488363266, 'learning_rate': 0.008015198524787602, 'epoch': 0.95}\n",
            "{'loss': 1.3091, 'grad_norm': 0.11749458312988281, 'learning_rate': 0.007980662427346127, 'epoch': 0.96}\n",
            "{'loss': 1.0042, 'grad_norm': 0.40772008895874023, 'learning_rate': 0.007945904302247968, 'epoch': 0.97}\n",
            "{'loss': 1.29, 'grad_norm': 0.17378824949264526, 'learning_rate': 0.007910926738603854, 'epoch': 0.98}\n",
            "{'loss': 1.2126, 'grad_norm': 13.992315292358398, 'learning_rate': 0.007875732341870348, 'epoch': 0.98}\n",
            "{'loss': 1.2743, 'grad_norm': 0.2392120510339737, 'learning_rate': 0.007840323733655778, 'epoch': 0.99}\n",
            "{'loss': 1.4726, 'grad_norm': 0.20445166528224945, 'learning_rate': 0.007804703551524948, 'epoch': 1.0}\n",
            "{'loss': 0.9518, 'grad_norm': 0.09476666897535324, 'learning_rate': 0.0077688744488026654, 'epoch': 1.01}\n",
            "{'loss': 1.075, 'grad_norm': 0.09308250993490219, 'learning_rate': 0.007732839094376105, 'epoch': 1.02}\n",
            "{'loss': 1.0257, 'grad_norm': 0.11795223504304886, 'learning_rate': 0.007696600172495996, 'epoch': 1.02}\n",
            "{'loss': 1.4021, 'grad_norm': 178.87796020507812, 'learning_rate': 0.007660160382576683, 'epoch': 1.03}\n",
            "{'loss': 1.0917, 'grad_norm': 1.7435344457626343, 'learning_rate': 0.00762352243899504, 'epoch': 1.04}\n",
            "{'loss': 1.3229, 'grad_norm': 0.15075670182704926, 'learning_rate': 0.007586689070888284, 'epoch': 1.05}\n",
            "{'loss': 1.4794, 'grad_norm': 0.14118684828281403, 'learning_rate': 0.00754966302195068, 'epoch': 1.06}\n",
            "{'loss': 1.176, 'grad_norm': 0.13016237318515778, 'learning_rate': 0.007512447050229166, 'epoch': 1.06}\n",
            "{'loss': 1.677, 'grad_norm': 0.15842926502227783, 'learning_rate': 0.007475043927917907, 'epoch': 1.07}\n",
            "{'loss': 1.2307, 'grad_norm': 0.0762416198849678, 'learning_rate': 0.007437456441151799, 'epoch': 1.08}\n",
            "{'loss': 1.3952, 'grad_norm': 0.13828043639659882, 'learning_rate': 0.007399687389798932, 'epoch': 1.09}\n",
            "{'loss': 1.1922, 'grad_norm': 0.07334353029727936, 'learning_rate': 0.007361739587252019, 'epoch': 1.1}\n",
            "{'loss': 1.1755, 'grad_norm': 0.11099925637245178, 'learning_rate': 0.007323615860218843, 'epoch': 1.1}\n",
            "{'loss': 1.4395, 'grad_norm': 0.1627846509218216, 'learning_rate': 0.00728531904851169, 'epoch': 1.11}\n",
            "{'loss': 1.3813, 'grad_norm': 0.12845806777477264, 'learning_rate': 0.007246852004835807, 'epoch': 1.12}\n",
            "{'loss': 1.8458, 'grad_norm': 0.24206677079200745, 'learning_rate': 0.007208217594576923, 'epoch': 1.13}\n",
            "{'loss': 0.9638, 'grad_norm': 0.10254469513893127, 'learning_rate': 0.007169418695587791, 'epoch': 1.14}\n",
            "{'loss': 0.9397, 'grad_norm': 0.10473142564296722, 'learning_rate': 0.007130458197973828, 'epoch': 1.14}\n",
            "{'loss': 1.4684, 'grad_norm': 0.4374011754989624, 'learning_rate': 0.0070913390038778255, 'epoch': 1.15}\n",
            "{'loss': 1.0616, 'grad_norm': 0.14689621329307556, 'learning_rate': 0.007052064027263785, 'epoch': 1.16}\n",
            "{'loss': 1.2706, 'grad_norm': 0.2584379017353058, 'learning_rate': 0.0070126361936998375, 'epoch': 1.17}\n",
            "{'loss': 1.5392, 'grad_norm': 0.21929733455181122, 'learning_rate': 0.006973058440140341, 'epoch': 1.18}\n",
            "{'loss': 1.1892, 'grad_norm': 0.17481406033039093, 'learning_rate': 0.006933333714707094, 'epoch': 1.18}\n",
            "{'loss': 1.337, 'grad_norm': 0.2856665253639221, 'learning_rate': 0.006893464976469739, 'epoch': 1.19}\n",
            "{'loss': 1.3047, 'grad_norm': 0.27819889783859253, 'learning_rate': 0.006853455195225339, 'epoch': 1.2}\n",
            "{'loss': 0.9489, 'grad_norm': 1.2139290571212769, 'learning_rate': 0.00681330735127716, 'epoch': 1.21}\n",
            "{'loss': 1.6216, 'grad_norm': 107.90110778808594, 'learning_rate': 0.006773024435212678, 'epoch': 1.22}\n",
            "{'loss': 2.8269, 'grad_norm': 0.9523695707321167, 'learning_rate': 0.0067326094476808, 'epoch': 1.22}\n",
            "{'loss': 1.652, 'grad_norm': 0.5099508166313171, 'learning_rate': 0.0066920653991683525, 'epoch': 1.23}\n",
            "{'loss': 1.6192, 'grad_norm': 0.27483120560646057, 'learning_rate': 0.006651395309775836, 'epoch': 1.24}\n",
            "{'loss': 1.6245, 'grad_norm': 0.8721780776977539, 'learning_rate': 0.006610602208992454, 'epoch': 1.25}\n",
            "{'loss': 1.9978, 'grad_norm': 0.4165269136428833, 'learning_rate': 0.00656968913547045, 'epoch': 1.26}\n",
            "{'loss': 1.5164, 'grad_norm': 0.23877884447574615, 'learning_rate': 0.006528659136798765, 'epoch': 1.26}\n",
            "{'loss': 1.7491, 'grad_norm': 0.29388317465782166, 'learning_rate': 0.006487515269276016, 'epoch': 1.27}\n",
            "{'loss': 2.0148, 'grad_norm': 0.3356831669807434, 'learning_rate': 0.0064462605976828395, 'epoch': 1.28}\n",
            "{'loss': 1.6219, 'grad_norm': 0.1938524693250656, 'learning_rate': 0.0064048981950535966, 'epoch': 1.29}\n",
            "{'loss': 1.9361, 'grad_norm': 0.36227649450302124, 'learning_rate': 0.006363431142447469, 'epoch': 1.3}\n",
            "{'loss': 1.7663, 'grad_norm': 0.3499893546104431, 'learning_rate': 0.006321862528718945, 'epoch': 1.3}\n",
            "{'loss': 1.5588, 'grad_norm': 0.14847497642040253, 'learning_rate': 0.006280195450287736, 'epoch': 1.31}\n",
            "{'loss': 1.2658, 'grad_norm': 0.13277877867221832, 'learning_rate': 0.00623843301090813, 'epoch': 1.32}\n",
            "{'loss': 1.1171, 'grad_norm': 0.1252344697713852, 'learning_rate': 0.006196578321437789, 'epoch': 1.33}\n",
            "{'loss': 1.5048, 'grad_norm': 0.3793337643146515, 'learning_rate': 0.006154634499606029, 'epoch': 1.34}\n",
            "{'loss': 1.3428, 'grad_norm': 0.1371183693408966, 'learning_rate': 0.006112604669781572, 'epoch': 1.34}\n",
            "{'loss': 1.4986, 'grad_norm': 0.22319285571575165, 'learning_rate': 0.0060704919627398305, 'epoch': 1.35}\n",
            "{'loss': 1.6049, 'grad_norm': 0.154438316822052, 'learning_rate': 0.006028299515429682, 'epoch': 1.36}\n",
            "{'loss': 1.5448, 'grad_norm': 0.166267991065979, 'learning_rate': 0.005986030470739811, 'epoch': 1.37}\n",
            "{'loss': 1.4707, 'grad_norm': 0.1836378276348114, 'learning_rate': 0.005943687977264584, 'epoch': 1.38}\n",
            "{'loss': 1.591, 'grad_norm': 0.6133033633232117, 'learning_rate': 0.005901275189069529, 'epoch': 1.38}\n",
            "{'loss': 1.1423, 'grad_norm': 0.07467767596244812, 'learning_rate': 0.005858795265456382, 'epoch': 1.39}\n",
            "{'loss': 1.2982, 'grad_norm': 0.12106061726808548, 'learning_rate': 0.005816251370727748, 'epoch': 1.4}\n",
            "{'loss': 1.4573, 'grad_norm': 0.25875553488731384, 'learning_rate': 0.005773646673951406, 'epoch': 1.41}\n",
            "{'loss': 1.0814, 'grad_norm': 0.11466676741838455, 'learning_rate': 0.005730984348724242, 'epoch': 1.42}\n",
            "{'loss': 1.7909, 'grad_norm': 0.2589062452316284, 'learning_rate': 0.005688267572935842, 'epoch': 1.42}\n",
            "{'loss': 1.4664, 'grad_norm': 0.08831588923931122, 'learning_rate': 0.005645499528531784, 'epoch': 1.43}\n",
            "{'loss': 1.4471, 'grad_norm': 0.14705735445022583, 'learning_rate': 0.005602683401276615, 'epoch': 1.44}\n",
            "{'loss': 1.1727, 'grad_norm': 0.13406318426132202, 'learning_rate': 0.005559822380516539, 'epoch': 1.45}\n",
            "{'loss': 1.4584, 'grad_norm': 0.1409139782190323, 'learning_rate': 0.00551691965894185, 'epoch': 1.46}\n",
            "{'loss': 1.5292, 'grad_norm': 0.1411210149526596, 'learning_rate': 0.005473978432349111, 'epoch': 1.46}\n",
            "{'loss': 1.5707, 'grad_norm': 0.16600358486175537, 'learning_rate': 0.0054310018994030975, 'epoch': 1.47}\n",
            "{'loss': 1.1463, 'grad_norm': 0.10810965299606323, 'learning_rate': 0.005387993261398532, 'epoch': 1.48}\n",
            "{'loss': 1.3712, 'grad_norm': 0.09982263296842575, 'learning_rate': 0.005344955722021624, 'epoch': 1.49}\n",
            "{'loss': 1.3327, 'grad_norm': 0.1272372603416443, 'learning_rate': 0.00530189248711143, 'epoch': 1.5}\n",
            "{'loss': 1.1141, 'grad_norm': 0.08822020143270493, 'learning_rate': 0.005258806764421048, 'epoch': 1.5}\n",
            "{'loss': 1.3026, 'grad_norm': 0.1290988177061081, 'learning_rate': 0.005215701763378673, 'epoch': 1.51}\n",
            "{'loss': 1.3982, 'grad_norm': 0.13484309613704681, 'learning_rate': 0.005172580694848541, 'epoch': 1.52}\n",
            "{'loss': 1.0758, 'grad_norm': 0.13041138648986816, 'learning_rate': 0.005129446770891738, 'epoch': 1.53}\n",
            "{'loss': 1.2808, 'grad_norm': 0.10481028258800507, 'learning_rate': 0.0050863032045269435, 'epoch': 1.54}\n",
            "{'loss': 1.6167, 'grad_norm': 0.1731864959001541, 'learning_rate': 0.0050431532094910945, 'epoch': 1.54}\n",
            "{'loss': 1.0872, 'grad_norm': 0.041086576879024506, 'learning_rate': 0.005, 'epoch': 1.55}\n",
            "{'loss': 1.0575, 'grad_norm': 0.12382468581199646, 'learning_rate': 0.004956846790508906, 'epoch': 1.56}\n",
            "{'loss': 1.5516, 'grad_norm': 0.1548830270767212, 'learning_rate': 0.004913696795473058, 'epoch': 1.57}\n",
            "{'loss': 1.0718, 'grad_norm': 0.08657210320234299, 'learning_rate': 0.004870553229108264, 'epoch': 1.58}\n",
            "{'loss': 1.3339, 'grad_norm': 0.08856405317783356, 'learning_rate': 0.004827419305151461, 'epoch': 1.58}\n",
            "{'loss': 1.4927, 'grad_norm': 0.1373809576034546, 'learning_rate': 0.004784298236621327, 'epoch': 1.59}\n",
            "{'loss': 1.1376, 'grad_norm': 0.10040365904569626, 'learning_rate': 0.0047411932355789525, 'epoch': 1.6}\n",
            "{'loss': 1.1857, 'grad_norm': 0.08987448364496231, 'learning_rate': 0.004698107512888569, 'epoch': 1.61}\n",
            "{'loss': 1.0299, 'grad_norm': 0.05647148936986923, 'learning_rate': 0.004655044277978375, 'epoch': 1.62}\n",
            "{'loss': 1.0164, 'grad_norm': 0.08327003568410873, 'learning_rate': 0.004612006738601469, 'epoch': 1.62}\n",
            "{'loss': 1.0044, 'grad_norm': 0.05981960520148277, 'learning_rate': 0.004568998100596903, 'epoch': 1.63}\n",
            "{'loss': 1.2556, 'grad_norm': 0.10081823915243149, 'learning_rate': 0.004526021567650889, 'epoch': 1.64}\n",
            "{'loss': 1.0823, 'grad_norm': 0.08369375765323639, 'learning_rate': 0.00448308034105815, 'epoch': 1.65}\n",
            "{'loss': 1.6078, 'grad_norm': 0.2087361216545105, 'learning_rate': 0.004440177619483461, 'epoch': 1.66}\n",
            "{'loss': 1.049, 'grad_norm': 0.06595998257398605, 'learning_rate': 0.004397316598723385, 'epoch': 1.66}\n",
            "{'loss': 1.205, 'grad_norm': 0.07019983977079391, 'learning_rate': 0.004354500471468217, 'epoch': 1.67}\n",
            "{'loss': 1.2681, 'grad_norm': 0.09790714085102081, 'learning_rate': 0.00431173242706416, 'epoch': 1.68}\n",
            "{'loss': 1.3515, 'grad_norm': 0.12991905212402344, 'learning_rate': 0.004269015651275761, 'epoch': 1.69}\n",
            "{'loss': 1.3577, 'grad_norm': 0.08479947596788406, 'learning_rate': 0.004226353326048593, 'epoch': 1.7}\n",
            "{'loss': 1.1304, 'grad_norm': 0.11993483453989029, 'learning_rate': 0.004183748629272253, 'epoch': 1.7}\n",
            "{'loss': 1.221, 'grad_norm': 0.07596245408058167, 'learning_rate': 0.004141204734543619, 'epoch': 1.71}\n",
            "{'loss': 1.2128, 'grad_norm': 0.08431336283683777, 'learning_rate': 0.004098724810930472, 'epoch': 1.72}\n",
            "{'loss': 1.2567, 'grad_norm': 0.09405959397554398, 'learning_rate': 0.004056312022735417, 'epoch': 1.73}\n",
            "{'loss': 1.3035, 'grad_norm': 0.12666825950145721, 'learning_rate': 0.00401396952926019, 'epoch': 1.74}\n",
            "{'loss': 1.2733, 'grad_norm': 0.10618884861469269, 'learning_rate': 0.003971700484570318, 'epoch': 1.74}\n",
            "{'loss': 1.0102, 'grad_norm': 0.15346485376358032, 'learning_rate': 0.00392950803726017, 'epoch': 1.75}\n",
            "{'loss': 1.3617, 'grad_norm': 7.265966415405273, 'learning_rate': 0.003887395330218428, 'epoch': 1.76}\n",
            "{'loss': 1.191, 'grad_norm': 0.09639807045459747, 'learning_rate': 0.0038453655003939735, 'epoch': 1.77}\n",
            "{'loss': 1.2886, 'grad_norm': 0.1020798608660698, 'learning_rate': 0.003803421678562213, 'epoch': 1.78}\n",
            "{'loss': 1.0573, 'grad_norm': 0.07932451367378235, 'learning_rate': 0.00376156698909187, 'epoch': 1.78}\n",
            "{'loss': 1.1716, 'grad_norm': 0.09011251479387283, 'learning_rate': 0.0037198045497122646, 'epoch': 1.79}\n",
            "{'loss': 0.8862, 'grad_norm': 0.05879553407430649, 'learning_rate': 0.0036781374712810556, 'epoch': 1.8}\n",
            "{'loss': 0.8817, 'grad_norm': 0.06178160011768341, 'learning_rate': 0.0036365688575525313, 'epoch': 1.81}\n",
            "{'loss': 0.9524, 'grad_norm': 0.08168283104896545, 'learning_rate': 0.003595101804946404, 'epoch': 1.82}\n",
            "{'loss': 1.1673, 'grad_norm': 0.1315920054912567, 'learning_rate': 0.003553739402317162, 'epoch': 1.82}\n",
            "{'loss': 1.331, 'grad_norm': 0.18701566755771637, 'learning_rate': 0.003512484730723986, 'epoch': 1.83}\n",
            "{'loss': 1.4541, 'grad_norm': 0.1737537831068039, 'learning_rate': 0.0034713408632012365, 'epoch': 1.84}\n",
            "{'loss': 0.9767, 'grad_norm': 0.10659024864435196, 'learning_rate': 0.00343031086452955, 'epoch': 1.85}\n",
            "{'loss': 0.9781, 'grad_norm': 0.10683514922857285, 'learning_rate': 0.003389397791007548, 'epoch': 1.86}\n",
            "{'loss': 1.1876, 'grad_norm': 0.0926322191953659, 'learning_rate': 0.0033486046902241663, 'epoch': 1.86}\n",
            "{'loss': 0.9175, 'grad_norm': 0.07309431582689285, 'learning_rate': 0.003307934600831648, 'epoch': 1.87}\n",
            "{'loss': 1.2693, 'grad_norm': 0.1423080414533615, 'learning_rate': 0.0032673905523191997, 'epoch': 1.88}\n",
            "{'loss': 1.058, 'grad_norm': 0.09539561718702316, 'learning_rate': 0.0032269755647873215, 'epoch': 1.89}\n",
            "{'loss': 1.009, 'grad_norm': 0.08814951032400131, 'learning_rate': 0.00318669264872284, 'epoch': 1.9}\n",
            "{'loss': 1.5057, 'grad_norm': 0.17020221054553986, 'learning_rate': 0.0031465448047746625, 'epoch': 1.9}\n",
            "{'loss': 1.2042, 'grad_norm': 0.10404788702726364, 'learning_rate': 0.003106535023530262, 'epoch': 1.91}\n",
            "{'loss': 1.0095, 'grad_norm': 0.11845269799232483, 'learning_rate': 0.003066666285292906, 'epoch': 1.92}\n",
            "{'loss': 0.9483, 'grad_norm': 0.08275680989027023, 'learning_rate': 0.00302694155985966, 'epoch': 1.93}\n",
            "{'loss': 0.873, 'grad_norm': 0.10437247902154922, 'learning_rate': 0.0029873638063001627, 'epoch': 1.94}\n",
            "{'loss': 1.3808, 'grad_norm': 0.14041000604629517, 'learning_rate': 0.002947935972736217, 'epoch': 1.94}\n",
            "{'loss': 1.3056, 'grad_norm': 0.13052372634410858, 'learning_rate': 0.0029086609961221756, 'epoch': 1.95}\n",
            "{'loss': 1.004, 'grad_norm': 0.09124238044023514, 'learning_rate': 0.0028695418020261753, 'epoch': 1.96}\n",
            "{'loss': 1.0224, 'grad_norm': 0.07063409686088562, 'learning_rate': 0.00283058130441221, 'epoch': 1.97}\n",
            "{'loss': 0.884, 'grad_norm': 0.05841197445988655, 'learning_rate': 0.0027917824054230784, 'epoch': 1.98}\n",
            "{'loss': 0.8852, 'grad_norm': 0.07686309516429901, 'learning_rate': 0.0027531479951641924, 'epoch': 1.98}\n",
            "{'loss': 1.5172, 'grad_norm': 0.23087219893932343, 'learning_rate': 0.002714680951488312, 'epoch': 1.99}\n",
            "{'loss': 1.2179, 'grad_norm': 0.12130007147789001, 'learning_rate': 0.002676384139781157, 'epoch': 2.0}\n",
            "{'loss': 1.2714, 'grad_norm': 0.11994995176792145, 'learning_rate': 0.0026382604127479815, 'epoch': 2.01}\n",
            "{'loss': 1.2291, 'grad_norm': 0.1408471018075943, 'learning_rate': 0.0026003126102010694, 'epoch': 2.02}\n",
            "{'loss': 1.7755, 'grad_norm': 0.2326047271490097, 'learning_rate': 0.0025625435588482017, 'epoch': 2.02}\n",
            "{'loss': 1.0882, 'grad_norm': 0.09847817569971085, 'learning_rate': 0.002524956072082093, 'epoch': 2.03}\n",
            "{'loss': 1.2114, 'grad_norm': 0.08822347968816757, 'learning_rate': 0.0024875529497708354, 'epoch': 2.04}\n",
            "{'loss': 1.6284, 'grad_norm': 0.3156183362007141, 'learning_rate': 0.0024503369780493217, 'epoch': 2.05}\n",
            "{'loss': 1.3647, 'grad_norm': 0.15297769010066986, 'learning_rate': 0.0024133109291117156, 'epoch': 2.06}\n",
            "{'loss': 1.3293, 'grad_norm': 0.11935514211654663, 'learning_rate': 0.00237647756100496, 'epoch': 2.06}\n",
            "{'loss': 0.9199, 'grad_norm': 0.12389899045228958, 'learning_rate': 0.0023398396174233176, 'epoch': 2.07}\n",
            "{'loss': 1.1983, 'grad_norm': 0.1562298685312271, 'learning_rate': 0.002303399827504005, 'epoch': 2.08}\n",
            "{'loss': 1.2202, 'grad_norm': 0.1250312477350235, 'learning_rate': 0.002267160905623895, 'epoch': 2.09}\n",
            "{'loss': 0.991, 'grad_norm': 0.09281904995441437, 'learning_rate': 0.0022311255511973343, 'epoch': 2.1}\n",
            "{'loss': 1.0937, 'grad_norm': 0.1282176524400711, 'learning_rate': 0.0021952964484750525, 'epoch': 2.1}\n",
            "{'loss': 1.5688, 'grad_norm': 0.3805394768714905, 'learning_rate': 0.0021596762663442215, 'epoch': 2.11}\n",
            "{'loss': 1.2587, 'grad_norm': 177.40145874023438, 'learning_rate': 0.0021242676581296528, 'epoch': 2.12}\n",
            "{'loss': 0.9929, 'grad_norm': 0.08891143649816513, 'learning_rate': 0.0020890732613961477, 'epoch': 2.13}\n",
            "{'loss': 0.8825, 'grad_norm': 0.11173858493566513, 'learning_rate': 0.002054095697752032, 'epoch': 2.14}\n",
            "{'loss': 1.4176, 'grad_norm': 0.14872656762599945, 'learning_rate': 0.002019337572653874, 'epoch': 2.14}\n",
            "{'loss': 1.2505, 'grad_norm': 0.4719172716140747, 'learning_rate': 0.0019848014752123977, 'epoch': 2.15}\n",
            "{'loss': 1.3193, 'grad_norm': 0.14014878869056702, 'learning_rate': 0.0019504899779996354, 'epoch': 2.16}\n",
            "{'loss': 1.4259, 'grad_norm': 0.18756695091724396, 'learning_rate': 0.0019164056368572847, 'epoch': 2.17}\n",
            "{'loss': 1.0518, 'grad_norm': 0.09054730087518692, 'learning_rate': 0.0018825509907063327, 'epoch': 2.18}\n",
            "{'loss': 1.1342, 'grad_norm': 0.07966970652341843, 'learning_rate': 0.0018489285613579327, 'epoch': 2.18}\n",
            "{'loss': 1.2313, 'grad_norm': 0.2543489336967468, 'learning_rate': 0.0018155408533255552, 'epoch': 2.19}\n",
            "{'loss': 1.7087, 'grad_norm': 0.42967352271080017, 'learning_rate': 0.001782390353638426, 'epoch': 2.2}\n",
            "{'loss': 0.8459, 'grad_norm': 2.670149326324463, 'learning_rate': 0.0017494795316562789, 'epoch': 2.21}\n",
            "{'loss': 1.1054, 'grad_norm': 0.10843338072299957, 'learning_rate': 0.0017168108388853998, 'epoch': 2.22}\n",
            "{'loss': 1.2376, 'grad_norm': 0.1528419852256775, 'learning_rate': 0.001684386708796025, 'epoch': 2.22}\n",
            "{'loss': 1.412, 'grad_norm': 8.861498832702637, 'learning_rate': 0.0016522095566410728, 'epoch': 2.23}\n",
            "{'loss': 1.1499, 'grad_norm': 4.496862411499023, 'learning_rate': 0.001620281779276228, 'epoch': 2.24}\n",
            "{'loss': 1.2492, 'grad_norm': 0.19062112271785736, 'learning_rate': 0.0015886057549814132, 'epoch': 2.25}\n",
            "{'loss': 1.2044, 'grad_norm': 0.20160837471485138, 'learning_rate': 0.001557183843283614, 'epoch': 2.26}\n",
            "{'loss': 1.4262, 'grad_norm': 0.19744306802749634, 'learning_rate': 0.0015260183847811382, 'epoch': 2.26}\n",
            "{'loss': 1.4747, 'grad_norm': 0.17752017080783844, 'learning_rate': 0.0014951117009692528, 'epoch': 2.27}\n",
            "{'loss': 1.2763, 'grad_norm': 0.16364921629428864, 'learning_rate': 0.0014644660940672626, 'epoch': 2.28}\n",
            "{'loss': 1.273, 'grad_norm': 0.47186070680618286, 'learning_rate': 0.0014340838468470197, 'epoch': 2.29}\n",
            "{'loss': 0.8832, 'grad_norm': 0.08947062492370605, 'learning_rate': 0.0014039672224628785, 'epoch': 2.3}\n",
            "{'loss': 1.096, 'grad_norm': 1.147817850112915, 'learning_rate': 0.001374118464283119, 'epoch': 2.3}\n",
            "{'loss': 0.9621, 'grad_norm': 0.11305788904428482, 'learning_rate': 0.0013445397957228338, 'epoch': 2.31}\n",
            "{'loss': 1.3375, 'grad_norm': 0.22585873305797577, 'learning_rate': 0.0013152334200783166, 'epoch': 2.32}\n",
            "{'loss': 1.1287, 'grad_norm': 0.12723830342292786, 'learning_rate': 0.0012862015203629273, 'epoch': 2.33}\n",
            "{'loss': 0.9628, 'grad_norm': 0.09552621841430664, 'learning_rate': 0.001257446259144494, 'epoch': 2.34}\n",
            "{'loss': 1.2704, 'grad_norm': 0.1188267171382904, 'learning_rate': 0.0012289697783842142, 'epoch': 2.34}\n",
            "{'loss': 0.9304, 'grad_norm': 0.0994890108704567, 'learning_rate': 0.0012007741992771065, 'epoch': 2.35}\n",
            "{'loss': 1.2392, 'grad_norm': 0.10944676399230957, 'learning_rate': 0.0011728616220940031, 'epoch': 2.36}\n",
            "{'loss': 1.068, 'grad_norm': 0.12917277216911316, 'learning_rate': 0.001145234126025102, 'epoch': 2.37}\n",
            "{'loss': 0.9289, 'grad_norm': 0.18576398491859436, 'learning_rate': 0.0011178937690250917, 'epoch': 2.38}\n",
            "{'loss': 1.0325, 'grad_norm': 0.10560856759548187, 'learning_rate': 0.001090842587659851, 'epoch': 2.38}\n",
            "{'loss': 1.2766, 'grad_norm': 0.13840210437774658, 'learning_rate': 0.0010640825969547496, 'epoch': 2.39}\n",
            "{'loss': 0.9887, 'grad_norm': 0.08531602472066879, 'learning_rate': 0.0010376157902445488, 'epoch': 2.4}\n",
            "{'loss': 1.0093, 'grad_norm': 0.08077937364578247, 'learning_rate': 0.00101144413902492, 'epoch': 2.41}\n",
            "{'loss': 1.0141, 'grad_norm': 0.0810733437538147, 'learning_rate': 0.000985569592805588, 'epoch': 2.42}\n",
            "{'loss': 1.3664, 'grad_norm': 0.16858074069023132, 'learning_rate': 0.0009599940789651179, 'epoch': 2.42}\n",
            "{'loss': 0.9791, 'grad_norm': 0.09317480772733688, 'learning_rate': 0.0009347195026073368, 'epoch': 2.43}\n",
            "{'loss': 0.9774, 'grad_norm': 0.1984272599220276, 'learning_rate': 0.000909747746419436, 'epoch': 2.44}\n",
            "{'loss': 0.9904, 'grad_norm': 0.050586529076099396, 'learning_rate': 0.0008850806705317183, 'epoch': 2.45}\n",
            "{'loss': 1.0503, 'grad_norm': 0.12576529383659363, 'learning_rate': 0.0008607201123790459, 'epoch': 2.46}\n",
            "{'loss': 1.4954, 'grad_norm': 0.24953225255012512, 'learning_rate': 0.0008366678865639688, 'epoch': 2.46}\n",
            "{'loss': 1.3446, 'grad_norm': 0.16312843561172485, 'learning_rate': 0.0008129257847215571, 'epoch': 2.47}\n",
            "{'loss': 1.4802, 'grad_norm': 0.14592157304286957, 'learning_rate': 0.0007894955753859412, 'epoch': 2.48}\n",
            "{'loss': 0.9266, 'grad_norm': 0.0663493424654007, 'learning_rate': 0.0007663790038585794, 'epoch': 2.49}\n",
            "{'loss': 0.8459, 'grad_norm': 0.09180983155965805, 'learning_rate': 0.0007435777920782444, 'epoch': 2.5}\n",
            "{'loss': 1.2606, 'grad_norm': 0.09955795854330063, 'learning_rate': 0.000721093638492763, 'epoch': 2.5}\n",
            "{'loss': 1.1433, 'grad_norm': 0.07924604415893555, 'learning_rate': 0.0006989282179324963, 'epoch': 2.51}\n",
            "{'loss': 1.3573, 'grad_norm': 0.14879748225212097, 'learning_rate': 0.0006770831814855883, 'epoch': 2.52}\n",
            "{'loss': 1.3542, 'grad_norm': 0.13358834385871887, 'learning_rate': 0.0006555601563749675, 'epoch': 2.53}\n",
            "{'loss': 0.8746, 'grad_norm': 0.09814238548278809, 'learning_rate': 0.0006343607458371459, 'epoch': 2.54}\n",
            "{'loss': 1.1192, 'grad_norm': 0.09111044555902481, 'learning_rate': 0.0006134865290027902, 'epoch': 2.54}\n",
            "{'loss': 0.8767, 'grad_norm': 0.09031590819358826, 'learning_rate': 0.000592939060779093, 'epoch': 2.55}\n",
            "{'loss': 1.0939, 'grad_norm': 0.06754850596189499, 'learning_rate': 0.000572719871733951, 'epoch': 2.56}\n",
            "{'loss': 1.435, 'grad_norm': 0.1541367620229721, 'learning_rate': 0.0005528304679819513, 'epoch': 2.57}\n",
            "{'loss': 1.0318, 'grad_norm': 0.08477511256933212, 'learning_rate': 0.0005332723310721854, 'epoch': 2.58}\n",
            "{'loss': 0.955, 'grad_norm': 0.060350436717271805, 'learning_rate': 0.0005140469178778845, 'epoch': 2.58}\n",
            "{'loss': 1.1161, 'grad_norm': 0.07306379824876785, 'learning_rate': 0.0004951556604879049, 'epoch': 2.59}\n",
            "{'loss': 1.2235, 'grad_norm': 0.1050894483923912, 'learning_rate': 0.00047659996610004417, 'epoch': 2.6}\n",
            "{'loss': 0.8917, 'grad_norm': 0.07317274808883667, 'learning_rate': 0.00045838121691622993, 'epoch': 2.61}\n",
            "{'loss': 1.3715, 'grad_norm': 0.15393130481243134, 'learning_rate': 0.0004405007700395497, 'epoch': 2.62}\n",
            "{'loss': 1.5054, 'grad_norm': 0.19144052267074585, 'learning_rate': 0.0004229599573731685, 'epoch': 2.62}\n",
            "{'loss': 1.291, 'grad_norm': 0.1174929291009903, 'learning_rate': 0.0004057600855211141, 'epoch': 2.63}\n",
            "{'loss': 1.6543, 'grad_norm': 0.16579705476760864, 'learning_rate': 0.00038890243569094876, 'epoch': 2.64}\n",
            "{'loss': 1.2339, 'grad_norm': 0.09200238436460495, 'learning_rate': 0.0003723882635983328, 'epoch': 2.65}\n",
            "{'loss': 1.2075, 'grad_norm': 0.12186486274003983, 'learning_rate': 0.00035621879937348835, 'epoch': 2.66}\n",
            "{'loss': 0.9369, 'grad_norm': 0.058278366923332214, 'learning_rate': 0.00034039524746956595, 'epoch': 2.66}\n",
            "{'loss': 1.4439, 'grad_norm': 0.11745348572731018, 'learning_rate': 0.0003249187865729264, 'epoch': 2.67}\n",
            "{'loss': 0.8559, 'grad_norm': 0.08682592213153839, 'learning_rate': 0.0003097905695153408, 'epoch': 2.68}\n",
            "{'loss': 1.292, 'grad_norm': 0.228194922208786, 'learning_rate': 0.0002950117231881183, 'epoch': 2.69}\n",
            "{'loss': 1.0554, 'grad_norm': 0.1183585673570633, 'learning_rate': 0.0002805833484581621, 'epoch': 2.7}\n",
            "{'loss': 1.044, 'grad_norm': 0.12158146500587463, 'learning_rate': 0.00026650652008597067, 'epoch': 2.7}\n",
            "{'loss': 1.0644, 'grad_norm': 0.0676962211728096, 'learning_rate': 0.0002527822866455731, 'epoch': 2.71}\n",
            "{'loss': 1.1015, 'grad_norm': 0.0394001379609108, 'learning_rate': 0.00023941167044642941, 'epoch': 2.72}\n",
            "{'loss': 1.0967, 'grad_norm': 0.0709061250090599, 'learning_rate': 0.00022639566745727202, 'epoch': 2.73}\n",
            "{'loss': 1.184, 'grad_norm': 0.0773094892501831, 'learning_rate': 0.0002137352472319215, 'epoch': 2.74}\n",
            "{'loss': 0.9843, 'grad_norm': 0.056820765137672424, 'learning_rate': 0.0002014313528370626, 'epoch': 2.74}\n",
            "{'loss': 1.0756, 'grad_norm': 0.06323190778493881, 'learning_rate': 0.00018948490078199765, 'epoch': 2.75}\n",
            "{'loss': 0.9831, 'grad_norm': 0.04796939715743065, 'learning_rate': 0.00017789678095037452, 'epoch': 2.76}\n",
            "{'loss': 0.892, 'grad_norm': 0.0754011943936348, 'learning_rate': 0.0001666678565339025, 'epoch': 2.77}\n",
            "{'loss': 1.0606, 'grad_norm': 0.05732749402523041, 'learning_rate': 0.0001557989639680496, 'epoch': 2.78}\n",
            "{'loss': 1.0169, 'grad_norm': 0.06286615878343582, 'learning_rate': 0.00014529091286973994, 'epoch': 2.78}\n",
            "{'loss': 1.4776, 'grad_norm': 0.1234203577041626, 'learning_rate': 0.0001351444859770462, 'epoch': 2.79}\n",
            "{'loss': 1.1572, 'grad_norm': 0.09762445837259293, 'learning_rate': 0.0001253604390908819, 'epoch': 2.8}\n",
            "{'loss': 0.8188, 'grad_norm': 0.06516449898481369, 'learning_rate': 0.0001159395010187042, 'epoch': 2.81}\n",
            "{'loss': 1.0772, 'grad_norm': 0.07120287418365479, 'learning_rate': 0.00010688237352022346, 'epoch': 2.82}\n",
            "{'loss': 0.8499, 'grad_norm': 0.06857658922672272, 'learning_rate': 9.818973125513276e-05, 'epoch': 2.82}\n",
            "{'loss': 1.1526, 'grad_norm': 0.08229845017194748, 'learning_rate': 8.986222173284874e-05, 'epoch': 2.83}\n",
            "{'loss': 0.8135, 'grad_norm': 0.06141533702611923, 'learning_rate': 8.190046526428241e-05, 'epoch': 2.84}\n",
            "{'loss': 1.1073, 'grad_norm': 0.07504568994045258, 'learning_rate': 7.4305054915631e-05, 'epoch': 2.85}\n",
            "{'loss': 0.9688, 'grad_norm': 0.05963665246963501, 'learning_rate': 6.707655646420229e-05, 'epoch': 2.86}\n",
            "{'loss': 0.8933, 'grad_norm': 0.08631359785795212, 'learning_rate': 6.0215508356267765e-05, 'epoch': 2.86}\n",
            "{'loss': 0.8981, 'grad_norm': 0.05005689710378647, 'learning_rate': 5.372242166695684e-05, 'epoch': 2.87}\n",
            "{'loss': 1.0294, 'grad_norm': 0.10074619203805923, 'learning_rate': 4.759778006218407e-05, 'epoch': 2.88}\n",
            "{'loss': 0.9597, 'grad_norm': 0.08263187110424042, 'learning_rate': 4.184203976262513e-05, 'epoch': 2.89}\n",
            "{'loss': 1.2464, 'grad_norm': 0.06862936913967133, 'learning_rate': 3.645562950973014e-05, 'epoch': 2.9}\n",
            "{'loss': 1.043, 'grad_norm': 0.09660420566797256, 'learning_rate': 3.143895053378698e-05, 'epoch': 2.9}\n",
            "{'loss': 1.3498, 'grad_norm': 0.15441258251667023, 'learning_rate': 2.6792376524036878e-05, 'epoch': 2.91}\n",
            "{'loss': 1.1921, 'grad_norm': 0.12690630555152893, 'learning_rate': 2.2516253600833868e-05, 'epoch': 2.92}\n",
            "{'loss': 1.2389, 'grad_norm': 0.12114376574754715, 'learning_rate': 1.8610900289867673e-05, 'epoch': 2.93}\n",
            "{'loss': 0.844, 'grad_norm': 0.05977192521095276, 'learning_rate': 1.5076607498433204e-05, 'epoch': 2.94}\n",
            "{'loss': 0.8499, 'grad_norm': 0.06583402305841446, 'learning_rate': 1.1913638493762369e-05, 'epoch': 2.94}\n",
            "{'loss': 1.1092, 'grad_norm': 0.0537530891597271, 'learning_rate': 9.12222888341252e-06, 'epoch': 2.95}\n",
            "{'loss': 1.0389, 'grad_norm': 0.06626278907060623, 'learning_rate': 6.702586597719385e-06, 'epoch': 2.96}\n",
            "{'loss': 1.2113, 'grad_norm': 0.08569840341806412, 'learning_rate': 4.654891874303346e-06, 'epoch': 2.97}\n",
            "{'loss': 1.4925, 'grad_norm': 0.14206019043922424, 'learning_rate': 2.9792972446479605e-06, 'epoch': 2.98}\n",
            "{'loss': 1.2199, 'grad_norm': 0.12266506254673004, 'learning_rate': 1.6759275227357095e-06, 'epoch': 2.98}\n",
            "{'loss': 0.9738, 'grad_norm': 0.07133270800113678, 'learning_rate': 7.448797957526621e-07, 'epoch': 2.99}\n",
            "{'loss': 1.709, 'grad_norm': 0.2512997090816498, 'learning_rate': 1.862234168542587e-07, 'epoch': 3.0}\n",
            "{'train_runtime': 44.5129, 'train_samples_per_second': 16.849, 'train_steps_per_second': 8.425, 'train_loss': 1.847852011124293, 'epoch': 3.0}\n",
            "100% 375/375 [00:44<00:00,  8.42it/s]\n",
            "Training complete.\n",
            "Model saved to loras/self-edit/training_set_iteration_1/44f52bb0/12\n",
            "Skipping training for task 44f52bb0 because the number of steps is greater than 375\n",
            "Training on 250 examples for 0 epochs, lr: 0.01\n",
            "No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n",
            "Starting training...\n",
            "{'train_runtime': 0.0022, 'train_samples_per_second': 0.0, 'train_steps_per_second': 0.0, 'train_loss': 0.0, 'epoch': 0}\n",
            "0it [00:00, ?it/s]\n",
            "Training complete.\n",
            "Model saved to loras/self-edit/training_set_iteration_1/44f52bb0/13\n",
            "Training on 250 examples for 3 epochs, lr: 0.01\n",
            "No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n",
            "Starting training...\n",
            "{'loss': 6.4988, 'grad_norm': 9.142213821411133, 'learning_rate': 0.0, 'epoch': 0.01}\n",
            "{'loss': 6.592, 'grad_norm': 8.51971435546875, 'learning_rate': 0.0009090909090909091, 'epoch': 0.02}\n",
            "{'loss': 2.9253, 'grad_norm': 15.519278526306152, 'learning_rate': 0.0018181818181818182, 'epoch': 0.02}\n",
            "{'loss': 2.8122, 'grad_norm': 8.420727729797363, 'learning_rate': 0.002727272727272727, 'epoch': 0.03}\n",
            "{'loss': 1.681, 'grad_norm': 1.6244306564331055, 'learning_rate': 0.0036363636363636364, 'epoch': 0.04}\n",
            "{'loss': 1.0062, 'grad_norm': 0.9231923818588257, 'learning_rate': 0.004545454545454545, 'epoch': 0.05}\n",
            "{'loss': 0.8565, 'grad_norm': 0.5810914635658264, 'learning_rate': 0.005454545454545454, 'epoch': 0.06}\n",
            "{'loss': 0.5736, 'grad_norm': 0.5669565200805664, 'learning_rate': 0.006363636363636364, 'epoch': 0.06}\n",
            "{'loss': 0.4284, 'grad_norm': 0.7021042704582214, 'learning_rate': 0.007272727272727273, 'epoch': 0.07}\n",
            "{'loss': 0.5619, 'grad_norm': 1.193932294845581, 'learning_rate': 0.008181818181818182, 'epoch': 0.08}\n",
            "{'loss': 4.519, 'grad_norm': 24.248291015625, 'learning_rate': 0.00909090909090909, 'epoch': 0.09}\n",
            "{'loss': 3.6508, 'grad_norm': 14.936417579650879, 'learning_rate': 0.01, 'epoch': 0.1}\n",
            "{'loss': 10.0658, 'grad_norm': 10.260392189025879, 'learning_rate': 0.009999813776583147, 'epoch': 0.1}\n",
            "{'loss': 12.6818, 'grad_norm': 13.28750228881836, 'learning_rate': 0.009999255120204246, 'epoch': 0.11}\n",
            "{'loss': 10.7886, 'grad_norm': 16.91120147705078, 'learning_rate': 0.009998324072477265, 'epoch': 0.12}\n",
            "{'loss': 6.2615, 'grad_norm': 12.452122688293457, 'learning_rate': 0.009997020702755353, 'epoch': 0.13}\n",
            "{'loss': 12.1836, 'grad_norm': 22.997716903686523, 'learning_rate': 0.009995345108125697, 'epoch': 0.14}\n",
            "{'loss': 6.4765, 'grad_norm': 3.5015926361083984, 'learning_rate': 0.009993297413402281, 'epoch': 0.14}\n",
            "{'loss': 4.9339, 'grad_norm': 6.524250507354736, 'learning_rate': 0.009990877771116588, 'epoch': 0.15}\n",
            "{'loss': 7.9978, 'grad_norm': 82.36446380615234, 'learning_rate': 0.009988086361506238, 'epoch': 0.16}\n",
            "{'loss': 6.7393, 'grad_norm': 1.503544569015503, 'learning_rate': 0.009984923392501567, 'epoch': 0.17}\n",
            "{'loss': 12.8171, 'grad_norm': 4.463413238525391, 'learning_rate': 0.009981389099710133, 'epoch': 0.18}\n",
            "{'loss': 6.0866, 'grad_norm': 1.9313204288482666, 'learning_rate': 0.009977483746399167, 'epoch': 0.18}\n",
            "{'loss': 9.4337, 'grad_norm': 4.778341293334961, 'learning_rate': 0.009973207623475963, 'epoch': 0.19}\n",
            "{'loss': 6.3719, 'grad_norm': 2.074522018432617, 'learning_rate': 0.009968561049466213, 'epoch': 0.2}\n",
            "{'loss': 7.8555, 'grad_norm': 3.1961209774017334, 'learning_rate': 0.00996354437049027, 'epoch': 0.21}\n",
            "{'loss': 5.6021, 'grad_norm': 2.2822320461273193, 'learning_rate': 0.009958157960237374, 'epoch': 0.22}\n",
            "{'loss': 3.5192, 'grad_norm': 0.8041736483573914, 'learning_rate': 0.009952402219937815, 'epoch': 0.22}\n",
            "{'loss': 5.2619, 'grad_norm': 2.0185012817382812, 'learning_rate': 0.009946277578333045, 'epoch': 0.23}\n",
            "{'loss': 3.5657, 'grad_norm': 0.8726524710655212, 'learning_rate': 0.009939784491643733, 'epoch': 0.24}\n",
            "{'loss': 5.6112, 'grad_norm': 3.308342218399048, 'learning_rate': 0.009932923443535798, 'epoch': 0.25}\n",
            "{'loss': 5.3927, 'grad_norm': 2.6282660961151123, 'learning_rate': 0.009925694945084369, 'epoch': 0.26}\n",
            "{'loss': 4.7894, 'grad_norm': 1.8228940963745117, 'learning_rate': 0.009918099534735719, 'epoch': 0.26}\n",
            "{'loss': 3.8989, 'grad_norm': 0.936780571937561, 'learning_rate': 0.009910137778267152, 'epoch': 0.27}\n",
            "{'loss': 6.1683, 'grad_norm': 11.063960075378418, 'learning_rate': 0.009901810268744867, 'epoch': 0.28}\n",
            "{'loss': 4.7633, 'grad_norm': 1.6628655195236206, 'learning_rate': 0.009893117626479776, 'epoch': 0.29}\n",
            "{'loss': 4.0355, 'grad_norm': 1.7252835035324097, 'learning_rate': 0.009884060498981296, 'epoch': 0.3}\n",
            "{'loss': 8.3903, 'grad_norm': 3.408626079559326, 'learning_rate': 0.009874639560909117, 'epoch': 0.3}\n",
            "{'loss': 4.7158, 'grad_norm': 2.0095055103302, 'learning_rate': 0.009864855514022955, 'epoch': 0.31}\n",
            "{'loss': 3.6111, 'grad_norm': 1.0333929061889648, 'learning_rate': 0.009854709087130261, 'epoch': 0.32}\n",
            "{'loss': 3.1355, 'grad_norm': 1.1843522787094116, 'learning_rate': 0.00984420103603195, 'epoch': 0.33}\n",
            "{'loss': 3.2555, 'grad_norm': 1.0429831743240356, 'learning_rate': 0.009833332143466099, 'epoch': 0.34}\n",
            "{'loss': 2.4954, 'grad_norm': 0.47597700357437134, 'learning_rate': 0.009822103219049624, 'epoch': 0.34}\n",
            "{'loss': 2.6527, 'grad_norm': 0.42761194705963135, 'learning_rate': 0.009810515099218002, 'epoch': 0.35}\n",
            "{'loss': 2.8954, 'grad_norm': 0.5701567530632019, 'learning_rate': 0.009798568647162938, 'epoch': 0.36}\n",
            "{'loss': 2.8499, 'grad_norm': 0.5933230519294739, 'learning_rate': 0.00978626475276808, 'epoch': 0.37}\n",
            "{'loss': 2.8549, 'grad_norm': 0.5048755407333374, 'learning_rate': 0.009773604332542728, 'epoch': 0.38}\n",
            "{'loss': 2.5348, 'grad_norm': 0.210918590426445, 'learning_rate': 0.00976058832955357, 'epoch': 0.38}\n",
            "{'loss': 3.147, 'grad_norm': 0.8037245273590088, 'learning_rate': 0.009747217713354427, 'epoch': 0.39}\n",
            "{'loss': 2.9995, 'grad_norm': 0.606017529964447, 'learning_rate': 0.009733493479914031, 'epoch': 0.4}\n",
            "{'loss': 2.1215, 'grad_norm': 0.21807387471199036, 'learning_rate': 0.009719416651541838, 'epoch': 0.41}\n",
            "{'loss': 2.6298, 'grad_norm': 0.4480663537979126, 'learning_rate': 0.009704988276811882, 'epoch': 0.42}\n",
            "{'loss': 2.4963, 'grad_norm': 0.3887389898300171, 'learning_rate': 0.00969020943048466, 'epoch': 0.42}\n",
            "{'loss': 2.7314, 'grad_norm': 0.4395742416381836, 'learning_rate': 0.009675081213427075, 'epoch': 0.43}\n",
            "{'loss': 2.5381, 'grad_norm': 0.3199671804904938, 'learning_rate': 0.009659604752530434, 'epoch': 0.44}\n",
            "{'loss': 2.3327, 'grad_norm': 0.8773059248924255, 'learning_rate': 0.00964378120062651, 'epoch': 0.45}\n",
            "{'loss': 1.9863, 'grad_norm': 0.39415252208709717, 'learning_rate': 0.009627611736401667, 'epoch': 0.46}\n",
            "{'loss': 2.7727, 'grad_norm': 0.4525609016418457, 'learning_rate': 0.009611097564309053, 'epoch': 0.46}\n",
            "{'loss': 2.4152, 'grad_norm': 0.2520235478878021, 'learning_rate': 0.009594239914478886, 'epoch': 0.47}\n",
            "{'loss': 2.6263, 'grad_norm': 0.42066681385040283, 'learning_rate': 0.009577040042626833, 'epoch': 0.48}\n",
            "{'loss': 2.6199, 'grad_norm': 0.42943450808525085, 'learning_rate': 0.00955949922996045, 'epoch': 0.49}\n",
            "{'loss': 2.1791, 'grad_norm': 0.206063911318779, 'learning_rate': 0.00954161878308377, 'epoch': 0.5}\n",
            "{'loss': 1.8233, 'grad_norm': 0.17926591634750366, 'learning_rate': 0.009523400033899955, 'epoch': 0.5}\n",
            "{'loss': 1.8828, 'grad_norm': 0.26186805963516235, 'learning_rate': 0.009504844339512096, 'epoch': 0.51}\n",
            "{'loss': 1.5819, 'grad_norm': 0.18854229152202606, 'learning_rate': 0.009485953082122116, 'epoch': 0.52}\n",
            "{'loss': 2.219, 'grad_norm': 0.29946646094322205, 'learning_rate': 0.009466727668927815, 'epoch': 0.53}\n",
            "{'loss': 1.5775, 'grad_norm': 0.09507421404123306, 'learning_rate': 0.00944716953201805, 'epoch': 0.54}\n",
            "{'loss': 2.5532, 'grad_norm': 0.3256058394908905, 'learning_rate': 0.009427280128266049, 'epoch': 0.54}\n",
            "{'loss': 1.8986, 'grad_norm': 0.1754741668701172, 'learning_rate': 0.009407060939220908, 'epoch': 0.55}\n",
            "{'loss': 2.2489, 'grad_norm': 0.23999692499637604, 'learning_rate': 0.00938651347099721, 'epoch': 0.56}\n",
            "{'loss': 1.5876, 'grad_norm': 0.17447243630886078, 'learning_rate': 0.009365639254162854, 'epoch': 0.57}\n",
            "{'loss': 2.2911, 'grad_norm': 0.20320162177085876, 'learning_rate': 0.009344439843625034, 'epoch': 0.58}\n",
            "{'loss': 1.8193, 'grad_norm': 0.25638502836227417, 'learning_rate': 0.009322916818514413, 'epoch': 0.58}\n",
            "{'loss': 2.6692, 'grad_norm': 0.18705211579799652, 'learning_rate': 0.009301071782067504, 'epoch': 0.59}\n",
            "{'loss': 1.4826, 'grad_norm': 0.1163766011595726, 'learning_rate': 0.009278906361507237, 'epoch': 0.6}\n",
            "{'loss': 1.8642, 'grad_norm': 0.11125088483095169, 'learning_rate': 0.009256422207921756, 'epoch': 0.61}\n",
            "{'loss': 2.1161, 'grad_norm': 0.2688313126564026, 'learning_rate': 0.00923362099614142, 'epoch': 0.62}\n",
            "{'loss': 2.3797, 'grad_norm': 0.3248908817768097, 'learning_rate': 0.009210504424614059, 'epoch': 0.62}\n",
            "{'loss': 2.1868, 'grad_norm': 0.12700830399990082, 'learning_rate': 0.009187074215278444, 'epoch': 0.63}\n",
            "{'loss': 2.1774, 'grad_norm': 0.20333774387836456, 'learning_rate': 0.009163332113436031, 'epoch': 0.64}\n",
            "{'loss': 1.6187, 'grad_norm': 0.18346741795539856, 'learning_rate': 0.009139279887620954, 'epoch': 0.65}\n",
            "{'loss': 1.6821, 'grad_norm': 0.1886167675256729, 'learning_rate': 0.009114919329468282, 'epoch': 0.66}\n",
            "{'loss': 1.454, 'grad_norm': 0.16697907447814941, 'learning_rate': 0.009090252253580565, 'epoch': 0.66}\n",
            "{'loss': 1.5668, 'grad_norm': 0.12171212583780289, 'learning_rate': 0.009065280497392662, 'epoch': 0.67}\n",
            "{'loss': 1.5557, 'grad_norm': 0.10488398373126984, 'learning_rate': 0.009040005921034882, 'epoch': 0.68}\n",
            "{'loss': 2.0857, 'grad_norm': 0.3268325626850128, 'learning_rate': 0.009014430407194412, 'epoch': 0.69}\n",
            "{'loss': 2.5989, 'grad_norm': 0.3354548215866089, 'learning_rate': 0.008988555860975082, 'epoch': 0.7}\n",
            "{'loss': 1.4639, 'grad_norm': 0.4481888711452484, 'learning_rate': 0.008962384209755451, 'epoch': 0.7}\n",
            "{'loss': 1.8427, 'grad_norm': 57.87743377685547, 'learning_rate': 0.00893591740304525, 'epoch': 0.71}\n",
            "{'loss': 1.8043, 'grad_norm': 0.3842860758304596, 'learning_rate': 0.008909157412340149, 'epoch': 0.72}\n",
            "{'loss': 1.8697, 'grad_norm': 0.31801748275756836, 'learning_rate': 0.008882106230974908, 'epoch': 0.73}\n",
            "{'loss': 1.8562, 'grad_norm': 0.15453407168388367, 'learning_rate': 0.008854765873974898, 'epoch': 0.74}\n",
            "{'loss': 1.3776, 'grad_norm': 0.26912298798561096, 'learning_rate': 0.008827138377905998, 'epoch': 0.74}\n",
            "{'loss': 1.4882, 'grad_norm': 0.3123089075088501, 'learning_rate': 0.008799225800722895, 'epoch': 0.75}\n",
            "{'loss': 1.303, 'grad_norm': 0.11988825350999832, 'learning_rate': 0.008771030221615786, 'epoch': 0.76}\n",
            "{'loss': 1.9535, 'grad_norm': 0.378805547952652, 'learning_rate': 0.008742553740855506, 'epoch': 0.77}\n",
            "{'loss': 1.2332, 'grad_norm': 0.05695582553744316, 'learning_rate': 0.008713798479637071, 'epoch': 0.78}\n",
            "{'loss': 1.7959, 'grad_norm': 0.24135813117027283, 'learning_rate': 0.008684766579921684, 'epoch': 0.78}\n",
            "{'loss': 1.8287, 'grad_norm': 0.30212584137916565, 'learning_rate': 0.008655460204277167, 'epoch': 0.79}\n",
            "{'loss': 1.8046, 'grad_norm': 0.20878450572490692, 'learning_rate': 0.008625881535716882, 'epoch': 0.8}\n",
            "{'loss': 1.6166, 'grad_norm': 0.15803714096546173, 'learning_rate': 0.008596032777537123, 'epoch': 0.81}\n",
            "{'loss': 1.4233, 'grad_norm': 0.1755635142326355, 'learning_rate': 0.008565916153152981, 'epoch': 0.82}\n",
            "{'loss': 1.7416, 'grad_norm': 0.25524723529815674, 'learning_rate': 0.008535533905932738, 'epoch': 0.82}\n",
            "{'loss': 1.6242, 'grad_norm': 0.1483713835477829, 'learning_rate': 0.008504888299030747, 'epoch': 0.83}\n",
            "{'loss': 1.4777, 'grad_norm': 0.22259092330932617, 'learning_rate': 0.008473981615218862, 'epoch': 0.84}\n",
            "{'loss': 1.4038, 'grad_norm': 0.11782945692539215, 'learning_rate': 0.008442816156716385, 'epoch': 0.85}\n",
            "{'loss': 1.2613, 'grad_norm': 0.11200372129678726, 'learning_rate': 0.008411394245018588, 'epoch': 0.86}\n",
            "{'loss': 1.5313, 'grad_norm': 0.1956728994846344, 'learning_rate': 0.008379718220723772, 'epoch': 0.86}\n",
            "{'loss': 2.0399, 'grad_norm': 0.2624729871749878, 'learning_rate': 0.008347790443358928, 'epoch': 0.87}\n",
            "{'loss': 1.3488, 'grad_norm': 0.17603714764118195, 'learning_rate': 0.008315613291203975, 'epoch': 0.88}\n",
            "{'loss': 1.783, 'grad_norm': 0.2563600242137909, 'learning_rate': 0.0082831891611146, 'epoch': 0.89}\n",
            "{'loss': 1.5192, 'grad_norm': 0.12876391410827637, 'learning_rate': 0.00825052046834372, 'epoch': 0.9}\n",
            "{'loss': 1.6674, 'grad_norm': 0.30867451429367065, 'learning_rate': 0.008217609646361573, 'epoch': 0.9}\n",
            "{'loss': 1.5476, 'grad_norm': 0.17225484549999237, 'learning_rate': 0.008184459146674447, 'epoch': 0.91}\n",
            "{'loss': 1.622, 'grad_norm': 0.19288156926631927, 'learning_rate': 0.008151071438642068, 'epoch': 0.92}\n",
            "{'loss': 1.1407, 'grad_norm': 1.1391454935073853, 'learning_rate': 0.008117449009293669, 'epoch': 0.93}\n",
            "{'loss': 1.2096, 'grad_norm': 0.12925302982330322, 'learning_rate': 0.008083594363142717, 'epoch': 0.94}\n",
            "{'loss': 1.4915, 'grad_norm': 0.3164893686771393, 'learning_rate': 0.008049510022000364, 'epoch': 0.94}\n",
            "{'loss': 1.5106, 'grad_norm': 7.184718608856201, 'learning_rate': 0.008015198524787602, 'epoch': 0.95}\n",
            "{'loss': 1.4556, 'grad_norm': 0.14499983191490173, 'learning_rate': 0.007980662427346127, 'epoch': 0.96}\n",
            "{'loss': 1.2245, 'grad_norm': 0.17257723212242126, 'learning_rate': 0.007945904302247968, 'epoch': 0.97}\n",
            "{'loss': 1.4841, 'grad_norm': 0.1153319701552391, 'learning_rate': 0.007910926738603854, 'epoch': 0.98}\n",
            "{'loss': 1.4299, 'grad_norm': 0.12344420701265335, 'learning_rate': 0.007875732341870348, 'epoch': 0.98}\n",
            "{'loss': 1.4341, 'grad_norm': 4.197227478027344, 'learning_rate': 0.007840323733655778, 'epoch': 0.99}\n",
            "{'loss': 1.6063, 'grad_norm': 0.132892906665802, 'learning_rate': 0.007804703551524948, 'epoch': 1.0}\n",
            "{'loss': 1.0947, 'grad_norm': 0.08798941224813461, 'learning_rate': 0.0077688744488026654, 'epoch': 1.01}\n",
            "{'loss': 1.2006, 'grad_norm': 0.08384282141923904, 'learning_rate': 0.007732839094376105, 'epoch': 1.02}\n",
            "{'loss': 1.1497, 'grad_norm': 0.10197524726390839, 'learning_rate': 0.007696600172495996, 'epoch': 1.02}\n",
            "{'loss': 1.5694, 'grad_norm': 0.22204208374023438, 'learning_rate': 0.007660160382576683, 'epoch': 1.03}\n",
            "{'loss': 1.1868, 'grad_norm': 0.07881300896406174, 'learning_rate': 0.00762352243899504, 'epoch': 1.04}\n",
            "{'loss': 1.4405, 'grad_norm': 0.17862877249717712, 'learning_rate': 0.007586689070888284, 'epoch': 1.05}\n",
            "{'loss': 1.5808, 'grad_norm': 0.12500445544719696, 'learning_rate': 0.00754966302195068, 'epoch': 1.06}\n",
            "{'loss': 1.2565, 'grad_norm': 0.09258101880550385, 'learning_rate': 0.007512447050229166, 'epoch': 1.06}\n",
            "{'loss': 1.7854, 'grad_norm': 0.18685556948184967, 'learning_rate': 0.007475043927917907, 'epoch': 1.07}\n",
            "{'loss': 1.3305, 'grad_norm': 3.406676769256592, 'learning_rate': 0.007437456441151799, 'epoch': 1.08}\n",
            "{'loss': 1.5271, 'grad_norm': 0.17596502602100372, 'learning_rate': 0.007399687389798932, 'epoch': 1.09}\n",
            "{'loss': 1.3072, 'grad_norm': 0.11790185421705246, 'learning_rate': 0.007361739587252019, 'epoch': 1.1}\n",
            "{'loss': 1.2538, 'grad_norm': 0.21491405367851257, 'learning_rate': 0.007323615860218843, 'epoch': 1.1}\n",
            "{'loss': 1.556, 'grad_norm': 0.4712420701980591, 'learning_rate': 0.00728531904851169, 'epoch': 1.11}\n",
            "{'loss': 1.4648, 'grad_norm': 0.19014044106006622, 'learning_rate': 0.007246852004835807, 'epoch': 1.12}\n",
            "{'loss': 1.9737, 'grad_norm': 0.26640382409095764, 'learning_rate': 0.007208217594576923, 'epoch': 1.13}\n",
            "{'loss': 1.0306, 'grad_norm': 0.1115737333893776, 'learning_rate': 0.007169418695587791, 'epoch': 1.14}\n",
            "{'loss': 1.0213, 'grad_norm': 0.09239844232797623, 'learning_rate': 0.007130458197973828, 'epoch': 1.14}\n",
            "{'loss': 1.5587, 'grad_norm': 0.4088627099990845, 'learning_rate': 0.0070913390038778255, 'epoch': 1.15}\n",
            "{'loss': 1.1126, 'grad_norm': 0.10352103412151337, 'learning_rate': 0.007052064027263785, 'epoch': 1.16}\n",
            "{'loss': 1.2403, 'grad_norm': 0.16905611753463745, 'learning_rate': 0.0070126361936998375, 'epoch': 1.17}\n",
            "{'loss': 1.5487, 'grad_norm': 0.2143883854150772, 'learning_rate': 0.006973058440140341, 'epoch': 1.18}\n",
            "{'loss': 1.1871, 'grad_norm': 32.45980453491211, 'learning_rate': 0.006933333714707094, 'epoch': 1.18}\n",
            "{'loss': 1.398, 'grad_norm': 0.25595733523368835, 'learning_rate': 0.006893464976469739, 'epoch': 1.19}\n",
            "{'loss': 1.3451, 'grad_norm': 0.18393677473068237, 'learning_rate': 0.006853455195225339, 'epoch': 1.2}\n",
            "{'loss': 1.0462, 'grad_norm': 0.12783288955688477, 'learning_rate': 0.00681330735127716, 'epoch': 1.21}\n",
            "{'loss': 1.3443, 'grad_norm': 0.1586320847272873, 'learning_rate': 0.006773024435212678, 'epoch': 1.22}\n",
            "{'loss': 1.4376, 'grad_norm': 0.18195390701293945, 'learning_rate': 0.0067326094476808, 'epoch': 1.22}\n",
            "{'loss': 1.2125, 'grad_norm': 0.08616141974925995, 'learning_rate': 0.0066920653991683525, 'epoch': 1.23}\n",
            "{'loss': 1.4737, 'grad_norm': 0.173284649848938, 'learning_rate': 0.006651395309775836, 'epoch': 1.24}\n",
            "{'loss': 1.0909, 'grad_norm': 0.11234597861766815, 'learning_rate': 0.006610602208992454, 'epoch': 1.25}\n",
            "{'loss': 1.6289, 'grad_norm': 0.2745112478733063, 'learning_rate': 0.00656968913547045, 'epoch': 1.26}\n",
            "{'loss': 1.1707, 'grad_norm': 0.10642760992050171, 'learning_rate': 0.006528659136798765, 'epoch': 1.26}\n",
            "{'loss': 1.3524, 'grad_norm': 1.6615426540374756, 'learning_rate': 0.006487515269276016, 'epoch': 1.27}\n",
            "{'loss': 1.6818, 'grad_norm': 0.444863498210907, 'learning_rate': 0.0064462605976828395, 'epoch': 1.28}\n",
            "{'loss': 1.333, 'grad_norm': 0.12017049640417099, 'learning_rate': 0.0064048981950535966, 'epoch': 1.29}\n",
            "{'loss': 1.5332, 'grad_norm': 0.32752153277397156, 'learning_rate': 0.006363431142447469, 'epoch': 1.3}\n",
            "{'loss': 1.3956, 'grad_norm': 0.15081888437271118, 'learning_rate': 0.006321862528718945, 'epoch': 1.3}\n",
            "{'loss': 1.3382, 'grad_norm': 0.16909456253051758, 'learning_rate': 0.006280195450287736, 'epoch': 1.31}\n",
            "{'loss': 1.1213, 'grad_norm': 0.15976482629776, 'learning_rate': 0.00623843301090813, 'epoch': 1.32}\n",
            "{'loss': 0.942, 'grad_norm': 0.18338331580162048, 'learning_rate': 0.006196578321437789, 'epoch': 1.33}\n",
            "{'loss': 1.1905, 'grad_norm': 0.22176408767700195, 'learning_rate': 0.006154634499606029, 'epoch': 1.34}\n",
            "{'loss': 1.1442, 'grad_norm': 3.659320592880249, 'learning_rate': 0.006112604669781572, 'epoch': 1.34}\n",
            "{'loss': 1.2315, 'grad_norm': 0.14010410010814667, 'learning_rate': 0.0060704919627398305, 'epoch': 1.35}\n",
            "{'loss': 1.4157, 'grad_norm': 0.16862060129642487, 'learning_rate': 0.006028299515429682, 'epoch': 1.36}\n",
            "{'loss': 1.2934, 'grad_norm': 0.17769205570220947, 'learning_rate': 0.005986030470739811, 'epoch': 1.37}\n",
            "{'loss': 1.2345, 'grad_norm': 0.13261254131793976, 'learning_rate': 0.005943687977264584, 'epoch': 1.38}\n",
            "{'loss': 1.299, 'grad_norm': 0.14421331882476807, 'learning_rate': 0.005901275189069529, 'epoch': 1.38}\n",
            "{'loss': 0.9497, 'grad_norm': 0.26353055238723755, 'learning_rate': 0.005858795265456382, 'epoch': 1.39}\n",
            "{'loss': 1.0571, 'grad_norm': 0.08311165124177933, 'learning_rate': 0.005816251370727748, 'epoch': 1.4}\n",
            "{'loss': 1.2167, 'grad_norm': 3.6992347240448, 'learning_rate': 0.005773646673951406, 'epoch': 1.41}\n",
            "{'loss': 0.8728, 'grad_norm': 0.07340521365404129, 'learning_rate': 0.005730984348724242, 'epoch': 1.42}\n",
            "{'loss': 1.5837, 'grad_norm': 0.24309492111206055, 'learning_rate': 0.005688267572935842, 'epoch': 1.42}\n",
            "{'loss': 1.3386, 'grad_norm': 0.18848977982997894, 'learning_rate': 0.005645499528531784, 'epoch': 1.43}\n",
            "{'loss': 1.283, 'grad_norm': 0.1592649221420288, 'learning_rate': 0.005602683401276615, 'epoch': 1.44}\n",
            "{'loss': 0.9894, 'grad_norm': 0.0775114968419075, 'learning_rate': 0.005559822380516539, 'epoch': 1.45}\n",
            "{'loss': 1.325, 'grad_norm': 0.2808308005332947, 'learning_rate': 0.00551691965894185, 'epoch': 1.46}\n",
            "{'loss': 1.3383, 'grad_norm': 0.13587723672389984, 'learning_rate': 0.005473978432349111, 'epoch': 1.46}\n",
            "{'loss': 1.3516, 'grad_norm': 0.17746424674987793, 'learning_rate': 0.0054310018994030975, 'epoch': 1.47}\n",
            "{'loss': 1.0478, 'grad_norm': 0.1411445289850235, 'learning_rate': 0.005387993261398532, 'epoch': 1.48}\n",
            "{'loss': 1.1731, 'grad_norm': 0.0900530070066452, 'learning_rate': 0.005344955722021624, 'epoch': 1.49}\n",
            "{'loss': 1.1626, 'grad_norm': 0.20676366984844208, 'learning_rate': 0.00530189248711143, 'epoch': 1.5}\n",
            "{'loss': 0.9643, 'grad_norm': 0.08493836224079132, 'learning_rate': 0.005258806764421048, 'epoch': 1.5}\n",
            "{'loss': 1.1147, 'grad_norm': 0.22227080166339874, 'learning_rate': 0.005215701763378673, 'epoch': 1.51}\n",
            "{'loss': 1.222, 'grad_norm': 0.14624638855457306, 'learning_rate': 0.005172580694848541, 'epoch': 1.52}\n",
            "{'loss': 0.9607, 'grad_norm': 0.10481858998537064, 'learning_rate': 0.005129446770891738, 'epoch': 1.53}\n",
            "{'loss': 1.0942, 'grad_norm': 0.06083812192082405, 'learning_rate': 0.0050863032045269435, 'epoch': 1.54}\n",
            "{'loss': 1.4401, 'grad_norm': 0.1578284651041031, 'learning_rate': 0.0050431532094910945, 'epoch': 1.54}\n",
            "{'loss': 0.9517, 'grad_norm': 0.07715210318565369, 'learning_rate': 0.005, 'epoch': 1.55}\n",
            "{'loss': 0.926, 'grad_norm': 0.08878683298826218, 'learning_rate': 0.004956846790508906, 'epoch': 1.56}\n",
            "{'loss': 1.3459, 'grad_norm': 0.14534646272659302, 'learning_rate': 0.004913696795473058, 'epoch': 1.57}\n",
            "{'loss': 0.9199, 'grad_norm': 1.531269907951355, 'learning_rate': 0.004870553229108264, 'epoch': 1.58}\n",
            "{'loss': 1.1551, 'grad_norm': 0.059483062475919724, 'learning_rate': 0.004827419305151461, 'epoch': 1.58}\n",
            "{'loss': 1.2964, 'grad_norm': 0.15137171745300293, 'learning_rate': 0.004784298236621327, 'epoch': 1.59}\n",
            "{'loss': 0.9874, 'grad_norm': 0.0992734357714653, 'learning_rate': 0.0047411932355789525, 'epoch': 1.6}\n",
            "{'loss': 1.0308, 'grad_norm': 0.08360402286052704, 'learning_rate': 0.004698107512888569, 'epoch': 1.61}\n",
            "{'loss': 0.8984, 'grad_norm': 0.062299322336912155, 'learning_rate': 0.004655044277978375, 'epoch': 1.62}\n",
            "{'loss': 0.8864, 'grad_norm': 0.058955736458301544, 'learning_rate': 0.004612006738601469, 'epoch': 1.62}\n",
            "{'loss': 0.9059, 'grad_norm': 0.3222075402736664, 'learning_rate': 0.004568998100596903, 'epoch': 1.63}\n",
            "{'loss': 1.1223, 'grad_norm': 0.12158112972974777, 'learning_rate': 0.004526021567650889, 'epoch': 1.64}\n",
            "{'loss': 0.9545, 'grad_norm': 0.09261661022901535, 'learning_rate': 0.00448308034105815, 'epoch': 1.65}\n",
            "{'loss': 1.3814, 'grad_norm': 0.14816878736019135, 'learning_rate': 0.004440177619483461, 'epoch': 1.66}\n",
            "{'loss': 0.933, 'grad_norm': 0.07845781743526459, 'learning_rate': 0.004397316598723385, 'epoch': 1.66}\n",
            "{'loss': 1.0643, 'grad_norm': 0.22858086228370667, 'learning_rate': 0.004354500471468217, 'epoch': 1.67}\n",
            "{'loss': 1.1081, 'grad_norm': 0.12279798090457916, 'learning_rate': 0.00431173242706416, 'epoch': 1.68}\n",
            "{'loss': 1.2423, 'grad_norm': 0.15271537005901337, 'learning_rate': 0.004269015651275761, 'epoch': 1.69}\n",
            "{'loss': 1.2041, 'grad_norm': 0.08593348413705826, 'learning_rate': 0.004226353326048593, 'epoch': 1.7}\n",
            "{'loss': 1.0094, 'grad_norm': 0.10480118542909622, 'learning_rate': 0.004183748629272253, 'epoch': 1.7}\n",
            "{'loss': 1.1002, 'grad_norm': 0.07371977716684341, 'learning_rate': 0.004141204734543619, 'epoch': 1.71}\n",
            "{'loss': 1.067, 'grad_norm': 0.07128334790468216, 'learning_rate': 0.004098724810930472, 'epoch': 1.72}\n",
            "{'loss': 1.1399, 'grad_norm': 0.10011898726224899, 'learning_rate': 0.004056312022735417, 'epoch': 1.73}\n",
            "{'loss': 1.2118, 'grad_norm': 0.15883028507232666, 'learning_rate': 0.00401396952926019, 'epoch': 1.74}\n",
            "{'loss': 1.1091, 'grad_norm': 0.09675373136997223, 'learning_rate': 0.003971700484570318, 'epoch': 1.74}\n",
            "{'loss': 0.8942, 'grad_norm': 0.08487691730260849, 'learning_rate': 0.00392950803726017, 'epoch': 1.75}\n",
            "{'loss': 1.2055, 'grad_norm': 0.1402224749326706, 'learning_rate': 0.003887395330218428, 'epoch': 1.76}\n",
            "{'loss': 1.0282, 'grad_norm': 2.500697612762451, 'learning_rate': 0.0038453655003939735, 'epoch': 1.77}\n",
            "{'loss': 1.1558, 'grad_norm': 0.0959102213382721, 'learning_rate': 0.003803421678562213, 'epoch': 1.78}\n",
            "{'loss': 1.0208, 'grad_norm': 0.07792558521032333, 'learning_rate': 0.00376156698909187, 'epoch': 1.78}\n",
            "{'loss': 1.15, 'grad_norm': 0.10666283220052719, 'learning_rate': 0.0037198045497122646, 'epoch': 1.79}\n",
            "{'loss': 0.9457, 'grad_norm': 0.733232855796814, 'learning_rate': 0.0036781374712810556, 'epoch': 1.8}\n",
            "{'loss': 0.9579, 'grad_norm': 0.07144086062908173, 'learning_rate': 0.0036365688575525313, 'epoch': 1.81}\n",
            "{'loss': 1.0192, 'grad_norm': 0.07756491750478745, 'learning_rate': 0.003595101804946404, 'epoch': 1.82}\n",
            "{'loss': 1.2465, 'grad_norm': 0.1473434567451477, 'learning_rate': 0.003553739402317162, 'epoch': 1.82}\n",
            "{'loss': 1.385, 'grad_norm': 0.19637589156627655, 'learning_rate': 0.003512484730723986, 'epoch': 1.83}\n",
            "{'loss': 1.4387, 'grad_norm': 0.15374156832695007, 'learning_rate': 0.0034713408632012365, 'epoch': 1.84}\n",
            "{'loss': 1.0456, 'grad_norm': 0.10728650540113449, 'learning_rate': 0.00343031086452955, 'epoch': 1.85}\n",
            "{'loss': 1.0448, 'grad_norm': 0.11043140292167664, 'learning_rate': 0.003389397791007548, 'epoch': 1.86}\n",
            "{'loss': 1.1877, 'grad_norm': 2.6860461235046387, 'learning_rate': 0.0033486046902241663, 'epoch': 1.86}\n",
            "{'loss': 0.9985, 'grad_norm': 0.07215390354394913, 'learning_rate': 0.003307934600831648, 'epoch': 1.87}\n",
            "{'loss': 1.3391, 'grad_norm': 0.8869195580482483, 'learning_rate': 0.0032673905523191997, 'epoch': 1.88}\n",
            "{'loss': 1.1775, 'grad_norm': 0.08927500247955322, 'learning_rate': 0.0032269755647873215, 'epoch': 1.89}\n",
            "{'loss': 1.1259, 'grad_norm': 0.07864926755428314, 'learning_rate': 0.00318669264872284, 'epoch': 1.9}\n",
            "{'loss': 1.5315, 'grad_norm': 0.18378190696239471, 'learning_rate': 0.0031465448047746625, 'epoch': 1.9}\n",
            "{'loss': 1.2802, 'grad_norm': 0.1008046418428421, 'learning_rate': 0.003106535023530262, 'epoch': 1.91}\n",
            "{'loss': 1.1006, 'grad_norm': 0.11733227968215942, 'learning_rate': 0.003066666285292906, 'epoch': 1.92}\n",
            "{'loss': 1.0537, 'grad_norm': 0.08540498465299606, 'learning_rate': 0.00302694155985966, 'epoch': 1.93}\n",
            "{'loss': 0.9788, 'grad_norm': 0.12188606709241867, 'learning_rate': 0.0029873638063001627, 'epoch': 1.94}\n",
            "{'loss': 1.4108, 'grad_norm': 0.15658360719680786, 'learning_rate': 0.002947935972736217, 'epoch': 1.94}\n",
            "{'loss': 1.3579, 'grad_norm': 0.22066299617290497, 'learning_rate': 0.0029086609961221756, 'epoch': 1.95}\n",
            "{'loss': 1.0833, 'grad_norm': 0.0878002792596817, 'learning_rate': 0.0028695418020261753, 'epoch': 1.96}\n",
            "{'loss': 1.0792, 'grad_norm': 0.08031846582889557, 'learning_rate': 0.00283058130441221, 'epoch': 1.97}\n",
            "{'loss': 0.9639, 'grad_norm': 0.07987399399280548, 'learning_rate': 0.0027917824054230784, 'epoch': 1.98}\n",
            "{'loss': 0.9507, 'grad_norm': 0.07350581139326096, 'learning_rate': 0.0027531479951641924, 'epoch': 1.98}\n",
            "{'loss': 1.4543, 'grad_norm': 0.19865743815898895, 'learning_rate': 0.002714680951488312, 'epoch': 1.99}\n",
            "{'loss': 1.22, 'grad_norm': 0.11469488590955734, 'learning_rate': 0.002676384139781157, 'epoch': 2.0}\n",
            "{'loss': 1.255, 'grad_norm': 30.348995208740234, 'learning_rate': 0.0026382604127479815, 'epoch': 2.01}\n",
            "{'loss': 1.2167, 'grad_norm': 0.11617309600114822, 'learning_rate': 0.0026003126102010694, 'epoch': 2.02}\n",
            "{'loss': 1.7099, 'grad_norm': 0.21950025856494904, 'learning_rate': 0.0025625435588482017, 'epoch': 2.02}\n",
            "{'loss': 1.1176, 'grad_norm': 0.09177710115909576, 'learning_rate': 0.002524956072082093, 'epoch': 2.03}\n",
            "{'loss': 1.1997, 'grad_norm': 0.4487658143043518, 'learning_rate': 0.0024875529497708354, 'epoch': 2.04}\n",
            "{'loss': 1.5754, 'grad_norm': 0.23286846280097961, 'learning_rate': 0.0024503369780493217, 'epoch': 2.05}\n",
            "{'loss': 1.3305, 'grad_norm': 0.12882064282894135, 'learning_rate': 0.0024133109291117156, 'epoch': 2.06}\n",
            "{'loss': 1.2971, 'grad_norm': 0.5456090569496155, 'learning_rate': 0.00237647756100496, 'epoch': 2.06}\n",
            "{'loss': 0.9311, 'grad_norm': 0.07587684690952301, 'learning_rate': 0.0023398396174233176, 'epoch': 2.07}\n",
            "{'loss': 1.1664, 'grad_norm': 0.1328851580619812, 'learning_rate': 0.002303399827504005, 'epoch': 2.08}\n",
            "{'loss': 1.2018, 'grad_norm': 0.12193845212459564, 'learning_rate': 0.002267160905623895, 'epoch': 2.09}\n",
            "{'loss': 1.0063, 'grad_norm': 0.07490874081850052, 'learning_rate': 0.0022311255511973343, 'epoch': 2.1}\n",
            "{'loss': 1.1009, 'grad_norm': 0.13523858785629272, 'learning_rate': 0.0021952964484750525, 'epoch': 2.1}\n",
            "{'loss': 1.5155, 'grad_norm': 0.3568758964538574, 'learning_rate': 0.0021596762663442215, 'epoch': 2.11}\n",
            "{'loss': 1.2205, 'grad_norm': 0.13702015578746796, 'learning_rate': 0.0021242676581296528, 'epoch': 2.12}\n",
            "{'loss': 1.0145, 'grad_norm': 0.09155572205781937, 'learning_rate': 0.0020890732613961477, 'epoch': 2.13}\n",
            "{'loss': 0.9284, 'grad_norm': 0.6216667294502258, 'learning_rate': 0.002054095697752032, 'epoch': 2.14}\n",
            "{'loss': 1.3768, 'grad_norm': 0.17698435485363007, 'learning_rate': 0.002019337572653874, 'epoch': 2.14}\n",
            "{'loss': 1.1979, 'grad_norm': 0.14402645826339722, 'learning_rate': 0.0019848014752123977, 'epoch': 2.15}\n",
            "{'loss': 1.3092, 'grad_norm': 0.17910389602184296, 'learning_rate': 0.0019504899779996354, 'epoch': 2.16}\n",
            "{'loss': 1.3606, 'grad_norm': 0.08849132061004639, 'learning_rate': 0.0019164056368572847, 'epoch': 2.17}\n",
            "{'loss': 1.0578, 'grad_norm': 0.227132648229599, 'learning_rate': 0.0018825509907063327, 'epoch': 2.18}\n",
            "{'loss': 1.1463, 'grad_norm': 0.14113806188106537, 'learning_rate': 0.0018489285613579327, 'epoch': 2.18}\n",
            "{'loss': 1.1912, 'grad_norm': 0.2691717743873596, 'learning_rate': 0.0018155408533255552, 'epoch': 2.19}\n",
            "{'loss': 1.6862, 'grad_norm': 0.3547048568725586, 'learning_rate': 0.001782390353638426, 'epoch': 2.2}\n",
            "{'loss': 0.8901, 'grad_norm': 0.06488418579101562, 'learning_rate': 0.0017494795316562789, 'epoch': 2.21}\n",
            "{'loss': 1.0849, 'grad_norm': 0.10817094892263412, 'learning_rate': 0.0017168108388853998, 'epoch': 2.22}\n",
            "{'loss': 1.2336, 'grad_norm': 0.16171175241470337, 'learning_rate': 0.001684386708796025, 'epoch': 2.22}\n",
            "{'loss': 1.3225, 'grad_norm': 0.1842440962791443, 'learning_rate': 0.0016522095566410728, 'epoch': 2.23}\n",
            "{'loss': 1.1393, 'grad_norm': 0.1268983781337738, 'learning_rate': 0.001620281779276228, 'epoch': 2.24}\n",
            "{'loss': 1.1798, 'grad_norm': 0.14349977672100067, 'learning_rate': 0.0015886057549814132, 'epoch': 2.25}\n",
            "{'loss': 1.0961, 'grad_norm': 0.055249862372875214, 'learning_rate': 0.001557183843283614, 'epoch': 2.26}\n",
            "{'loss': 1.304, 'grad_norm': 0.19320295751094818, 'learning_rate': 0.0015260183847811382, 'epoch': 2.26}\n",
            "{'loss': 1.3896, 'grad_norm': 0.32436075806617737, 'learning_rate': 0.0014951117009692528, 'epoch': 2.27}\n",
            "{'loss': 1.1814, 'grad_norm': 0.1608804315328598, 'learning_rate': 0.0014644660940672626, 'epoch': 2.28}\n",
            "{'loss': 1.1894, 'grad_norm': 0.15887990593910217, 'learning_rate': 0.0014340838468470197, 'epoch': 2.29}\n",
            "{'loss': 0.8725, 'grad_norm': 0.04687882959842682, 'learning_rate': 0.0014039672224628785, 'epoch': 2.3}\n",
            "{'loss': 1.051, 'grad_norm': 0.10997641831636429, 'learning_rate': 0.001374118464283119, 'epoch': 2.3}\n",
            "{'loss': 0.9246, 'grad_norm': 0.07821907103061676, 'learning_rate': 0.0013445397957228338, 'epoch': 2.31}\n",
            "{'loss': 1.1932, 'grad_norm': 0.1169426366686821, 'learning_rate': 0.0013152334200783166, 'epoch': 2.32}\n",
            "{'loss': 1.0579, 'grad_norm': 0.06504956632852554, 'learning_rate': 0.0012862015203629273, 'epoch': 2.33}\n",
            "{'loss': 0.9341, 'grad_norm': 0.07833447307348251, 'learning_rate': 0.001257446259144494, 'epoch': 2.34}\n",
            "{'loss': 1.175, 'grad_norm': 0.10282792896032333, 'learning_rate': 0.0012289697783842142, 'epoch': 2.34}\n",
            "{'loss': 0.8786, 'grad_norm': 0.047660090029239655, 'learning_rate': 0.0012007741992771065, 'epoch': 2.35}\n",
            "{'loss': 1.1355, 'grad_norm': 0.09003998339176178, 'learning_rate': 0.0011728616220940031, 'epoch': 2.36}\n",
            "{'loss': 0.9877, 'grad_norm': 0.07221020013093948, 'learning_rate': 0.001145234126025102, 'epoch': 2.37}\n",
            "{'loss': 0.8812, 'grad_norm': 0.051896341145038605, 'learning_rate': 0.0011178937690250917, 'epoch': 2.38}\n",
            "{'loss': 0.9598, 'grad_norm': 0.04447289928793907, 'learning_rate': 0.001090842587659851, 'epoch': 2.38}\n",
            "{'loss': 1.168, 'grad_norm': 0.14011362195014954, 'learning_rate': 0.0010640825969547496, 'epoch': 2.39}\n",
            "{'loss': 0.9539, 'grad_norm': 0.060724228620529175, 'learning_rate': 0.0010376157902445488, 'epoch': 2.4}\n",
            "{'loss': 0.9558, 'grad_norm': 0.057448290288448334, 'learning_rate': 0.00101144413902492, 'epoch': 2.41}\n",
            "{'loss': 0.9669, 'grad_norm': 0.06251877546310425, 'learning_rate': 0.000985569592805588, 'epoch': 2.42}\n",
            "{'loss': 1.2259, 'grad_norm': 0.10685867071151733, 'learning_rate': 0.0009599940789651179, 'epoch': 2.42}\n",
            "{'loss': 0.9388, 'grad_norm': 0.03988170996308327, 'learning_rate': 0.0009347195026073368, 'epoch': 2.43}\n",
            "{'loss': 0.9412, 'grad_norm': 0.0398445650935173, 'learning_rate': 0.000909747746419436, 'epoch': 2.44}\n",
            "{'loss': 0.9465, 'grad_norm': 0.05019642785191536, 'learning_rate': 0.0008850806705317183, 'epoch': 2.45}\n",
            "{'loss': 0.9968, 'grad_norm': 0.09925657510757446, 'learning_rate': 0.0008607201123790459, 'epoch': 2.46}\n",
            "{'loss': 1.3212, 'grad_norm': 0.1423395425081253, 'learning_rate': 0.0008366678865639688, 'epoch': 2.46}\n",
            "{'loss': 1.2773, 'grad_norm': 0.17329606413841248, 'learning_rate': 0.0008129257847215571, 'epoch': 2.47}\n",
            "{'loss': 1.3504, 'grad_norm': 0.10512464493513107, 'learning_rate': 0.0007894955753859412, 'epoch': 2.48}\n",
            "{'loss': 0.8961, 'grad_norm': 0.0548570491373539, 'learning_rate': 0.0007663790038585794, 'epoch': 2.49}\n",
            "{'loss': 0.8255, 'grad_norm': 0.05851641297340393, 'learning_rate': 0.0007435777920782444, 'epoch': 2.5}\n",
            "{'loss': 1.163, 'grad_norm': 0.06127471104264259, 'learning_rate': 0.000721093638492763, 'epoch': 2.5}\n",
            "{'loss': 1.0621, 'grad_norm': 0.047714997082948685, 'learning_rate': 0.0006989282179324963, 'epoch': 2.51}\n",
            "{'loss': 1.2957, 'grad_norm': 0.15915443003177643, 'learning_rate': 0.0006770831814855883, 'epoch': 2.52}\n",
            "{'loss': 1.2353, 'grad_norm': 0.09697607904672623, 'learning_rate': 0.0006555601563749675, 'epoch': 2.53}\n",
            "{'loss': 0.8503, 'grad_norm': 0.05805617570877075, 'learning_rate': 0.0006343607458371459, 'epoch': 2.54}\n",
            "{'loss': 1.0661, 'grad_norm': 0.07169007509946823, 'learning_rate': 0.0006134865290027902, 'epoch': 2.54}\n",
            "{'loss': 0.8563, 'grad_norm': 0.05314597859978676, 'learning_rate': 0.000592939060779093, 'epoch': 2.55}\n",
            "{'loss': 1.0297, 'grad_norm': 0.06444835662841797, 'learning_rate': 0.000572719871733951, 'epoch': 2.56}\n",
            "{'loss': 1.3087, 'grad_norm': 0.13832378387451172, 'learning_rate': 0.0005528304679819513, 'epoch': 2.57}\n",
            "{'loss': 1.0088, 'grad_norm': 0.07358046621084213, 'learning_rate': 0.0005332723310721854, 'epoch': 2.58}\n",
            "{'loss': 0.9244, 'grad_norm': 0.03508356213569641, 'learning_rate': 0.0005140469178778845, 'epoch': 2.58}\n",
            "{'loss': 1.0506, 'grad_norm': 0.06046454235911369, 'learning_rate': 0.0004951556604879049, 'epoch': 2.59}\n",
            "{'loss': 1.1463, 'grad_norm': 0.07561247795820236, 'learning_rate': 0.00047659996610004417, 'epoch': 2.6}\n",
            "{'loss': 0.8787, 'grad_norm': 0.04952549189329147, 'learning_rate': 0.00045838121691622993, 'epoch': 2.61}\n",
            "{'loss': 1.3224, 'grad_norm': 0.17613811790943146, 'learning_rate': 0.0004405007700395497, 'epoch': 2.62}\n",
            "{'loss': 1.3576, 'grad_norm': 0.1301908791065216, 'learning_rate': 0.0004229599573731685, 'epoch': 2.62}\n",
            "{'loss': 1.2228, 'grad_norm': 0.12150046974420547, 'learning_rate': 0.0004057600855211141, 'epoch': 2.63}\n",
            "{'loss': 1.5088, 'grad_norm': 0.13846014440059662, 'learning_rate': 0.00038890243569094876, 'epoch': 2.64}\n",
            "{'loss': 1.145, 'grad_norm': 0.0661456435918808, 'learning_rate': 0.0003723882635983328, 'epoch': 2.65}\n",
            "{'loss': 1.1813, 'grad_norm': 0.13680782914161682, 'learning_rate': 0.00035621879937348835, 'epoch': 2.66}\n",
            "{'loss': 0.9121, 'grad_norm': 0.0587473027408123, 'learning_rate': 0.00034039524746956595, 'epoch': 2.66}\n",
            "{'loss': 1.3474, 'grad_norm': 0.11948046833276749, 'learning_rate': 0.0003249187865729264, 'epoch': 2.67}\n",
            "{'loss': 0.8393, 'grad_norm': 0.060900311917066574, 'learning_rate': 0.0003097905695153408, 'epoch': 2.68}\n",
            "{'loss': 1.2146, 'grad_norm': 0.10130162537097931, 'learning_rate': 0.0002950117231881183, 'epoch': 2.69}\n",
            "{'loss': 1.02, 'grad_norm': 0.10455493628978729, 'learning_rate': 0.0002805833484581621, 'epoch': 2.7}\n",
            "{'loss': 1.0094, 'grad_norm': 0.1083792969584465, 'learning_rate': 0.00026650652008597067, 'epoch': 2.7}\n",
            "{'loss': 1.0345, 'grad_norm': 0.06802248954772949, 'learning_rate': 0.0002527822866455731, 'epoch': 2.71}\n",
            "{'loss': 1.0467, 'grad_norm': 0.032900597900152206, 'learning_rate': 0.00023941167044642941, 'epoch': 2.72}\n",
            "{'loss': 1.0525, 'grad_norm': 0.06150107458233833, 'learning_rate': 0.00022639566745727202, 'epoch': 2.73}\n",
            "{'loss': 1.1097, 'grad_norm': 0.07562409341335297, 'learning_rate': 0.0002137352472319215, 'epoch': 2.74}\n",
            "{'loss': 0.9577, 'grad_norm': 0.048718128353357315, 'learning_rate': 0.0002014313528370626, 'epoch': 2.74}\n",
            "{'loss': 1.0252, 'grad_norm': 0.07743325084447861, 'learning_rate': 0.00018948490078199765, 'epoch': 2.75}\n",
            "{'loss': 0.9589, 'grad_norm': 0.04319777339696884, 'learning_rate': 0.00017789678095037452, 'epoch': 2.76}\n",
            "{'loss': 0.8752, 'grad_norm': 0.0464223176240921, 'learning_rate': 0.0001666678565339025, 'epoch': 2.77}\n",
            "{'loss': 1.0159, 'grad_norm': 0.06179346144199371, 'learning_rate': 0.0001557989639680496, 'epoch': 2.78}\n",
            "{'loss': 0.9821, 'grad_norm': 0.044860657304525375, 'learning_rate': 0.00014529091286973994, 'epoch': 2.78}\n",
            "{'loss': 1.3791, 'grad_norm': 0.13959479331970215, 'learning_rate': 0.0001351444859770462, 'epoch': 2.79}\n",
            "{'loss': 1.0924, 'grad_norm': 0.10761059075593948, 'learning_rate': 0.0001253604390908819, 'epoch': 2.8}\n",
            "{'loss': 0.8098, 'grad_norm': 0.04225097969174385, 'learning_rate': 0.0001159395010187042, 'epoch': 2.81}\n",
            "{'loss': 1.0292, 'grad_norm': 0.08631616830825806, 'learning_rate': 0.00010688237352022346, 'epoch': 2.82}\n",
            "{'loss': 0.8432, 'grad_norm': 0.04180319234728813, 'learning_rate': 9.818973125513276e-05, 'epoch': 2.82}\n",
            "{'loss': 1.089, 'grad_norm': 0.0882859155535698, 'learning_rate': 8.986222173284874e-05, 'epoch': 2.83}\n",
            "{'loss': 0.8059, 'grad_norm': 0.04138316214084625, 'learning_rate': 8.190046526428241e-05, 'epoch': 2.84}\n",
            "{'loss': 1.0734, 'grad_norm': 4.636651039123535, 'learning_rate': 7.4305054915631e-05, 'epoch': 2.85}\n",
            "{'loss': 0.9324, 'grad_norm': 0.041514329612255096, 'learning_rate': 6.707655646420229e-05, 'epoch': 2.86}\n",
            "{'loss': 0.8823, 'grad_norm': 0.06756643205881119, 'learning_rate': 6.0215508356267765e-05, 'epoch': 2.86}\n",
            "{'loss': 0.8783, 'grad_norm': 0.04743976518511772, 'learning_rate': 5.372242166695684e-05, 'epoch': 2.87}\n",
            "{'loss': 0.9966, 'grad_norm': 0.09812036901712418, 'learning_rate': 4.759778006218407e-05, 'epoch': 2.88}\n",
            "{'loss': 0.9415, 'grad_norm': 0.06578870117664337, 'learning_rate': 4.184203976262513e-05, 'epoch': 2.89}\n",
            "{'loss': 1.1692, 'grad_norm': 0.07362206280231476, 'learning_rate': 3.645562950973014e-05, 'epoch': 2.9}\n",
            "{'loss': 1.0082, 'grad_norm': 0.09202712029218674, 'learning_rate': 3.143895053378698e-05, 'epoch': 2.9}\n",
            "{'loss': 1.274, 'grad_norm': 0.1725628525018692, 'learning_rate': 2.6792376524036878e-05, 'epoch': 2.91}\n",
            "{'loss': 1.1429, 'grad_norm': 0.13791941106319427, 'learning_rate': 2.2516253600833868e-05, 'epoch': 2.92}\n",
            "{'loss': 1.1827, 'grad_norm': 0.12851496040821075, 'learning_rate': 1.8610900289867673e-05, 'epoch': 2.93}\n",
            "{'loss': 0.836, 'grad_norm': 0.042657580226659775, 'learning_rate': 1.5076607498433204e-05, 'epoch': 2.94}\n",
            "{'loss': 0.8416, 'grad_norm': 0.04181056469678879, 'learning_rate': 1.1913638493762369e-05, 'epoch': 2.94}\n",
            "{'loss': 1.0506, 'grad_norm': 0.05505123361945152, 'learning_rate': 9.12222888341252e-06, 'epoch': 2.95}\n",
            "{'loss': 1.0062, 'grad_norm': 0.06386787444353104, 'learning_rate': 6.702586597719385e-06, 'epoch': 2.96}\n",
            "{'loss': 1.1442, 'grad_norm': 0.08633435517549515, 'learning_rate': 4.654891874303346e-06, 'epoch': 2.97}\n",
            "{'loss': 1.3984, 'grad_norm': 0.1379106640815735, 'learning_rate': 2.9792972446479605e-06, 'epoch': 2.98}\n",
            "{'loss': 1.1591, 'grad_norm': 0.136611208319664, 'learning_rate': 1.6759275227357095e-06, 'epoch': 2.98}\n",
            "{'loss': 0.9413, 'grad_norm': 0.06458910554647446, 'learning_rate': 7.448797957526621e-07, 'epoch': 2.99}\n",
            "{'loss': 1.5966, 'grad_norm': 0.26942989230155945, 'learning_rate': 1.862234168542587e-07, 'epoch': 3.0}\n",
            "{'train_runtime': 44.3983, 'train_samples_per_second': 16.893, 'train_steps_per_second': 8.446, 'train_loss': 1.8087735119660695, 'epoch': 3.0}\n",
            "100% 375/375 [00:44<00:00,  8.45it/s]\n",
            "Training complete.\n",
            "Model saved to loras/self-edit/training_set_iteration_1/44f52bb0/14\n",
            "Training complete. Final configs and indices saved to: loras/self-edit/training_set_iteration_1/final_configs_and_indices.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python /content/SEAL/few-shot/ttt.py"
      ],
      "metadata": {
        "id": "mNzfXwY7Ipqu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "DATA_DIR='/content/SEAL/few-shot/data'\n",
        "TTI_DIR='/content/SEAL/loras/self-edit/training_set_iteration_1'\n",
        "LORA_DIR='/content/SEAL/loras/self-edit/training_set_iteration_1/8d5021e8/14'\n",
        "\n",
        "!python /content/SEAL/few-shot/eval-self-edits.py  \\\n",
        "    --experiment_folder={TTI_DIR} \\\n",
        "    --pretrained_checkpoint=meta-llama/Llama-3.2-1B-Instruct \\\n",
        "    --lora_checkpoints_folder={LORA_DIR} \\\n",
        "    --temperature=0 \\\n",
        "    --n_sample=1 \\\n",
        "    --data_file=/content/SEAL/few-shot/data/arc-agi_training_challenges_filtered_1B_training_set.json \\\n",
        "    --solution_file=/content/SEAL/few-shot/data/arc-agi_evaluation_challenges_filtered_1B_eval_set.json \\\n",
        "    --max_lora_rank=128 \\\n",
        "    --include_n=1 \\\n",
        "    --new_format \\\n",
        "    --num_examples=11 \\\n",
        "    --n_self_edits=15"
      ],
      "metadata": {
        "id": "d2H8z48V8kT_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python /content/SEAL/few-shot/BC-self-edit.py \\\n",
        "    --configs_and_indices=/content/SEAL/loras/self-edit/training_set_iteration_1/final_configs_and_indices.json \\\n",
        "    --results=/content/SEAL/few-shot/final_results.json \\\n",
        "    --model_name=meta-llama/Llama-3.2-1B-Instruct \\\n",
        "    --lora_rank=16 \\\n",
        "    --lora_alpha=16 \\\n",
        "    --num_train_epochs=8 \\\n",
        "    --per_device_train_batch_size=5 \\\n",
        "    --gradient_accumulation_steps=1 \\\n",
        "    --learning_rate=5e-5"
      ],
      "metadata": {
        "id": "o3tBgYc-8l2z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python /content/SEAL/few-shot/self-edit.py  \\\n",
        "    --experiment_name=eval_RL_iteration_1_8_epoch \\\n",
        "    --challenge_file={DATA_DIR}/arc-agi_evaluation_challenges_filtered_1B_eval_set.json \\\n",
        "    --solution_file={DATA_DIR}/arc-agi_evaluation_solutions_filtered_1B_eval_set.json \\\n",
        "    --model_name={LORA_DIR}/self-edit/training_set_iteration_1/RL_trained_model_iteration_1_8_epoch \\\n",
        "    --n_tasks=10 \\\n",
        "    --n_self_edits_per_task=5"
      ],
      "metadata": {
        "id": "vLNLYvf_8qoC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python /content/SEAL/few-shot/eval-self-edits.py \\\n",
        "    --experiment_folder={TTI_DIR}/eval_set_RL_iteration_1_8_epoch \\\n",
        "    --pretrained_checkpoint={LORA_DIR}/self-edit/training_set_iteration_1/RL_trained_model_iteration_1_8_epoch \\\n",
        "    --lora_checkpoints_folder={LORA_DIR}/self-edit/eval_RL_iteration_1_8_epoch \\\n",
        "    --temperature=0 \\\n",
        "    --n_sample=1 \\\n",
        "    --data_file=${DATA_DIR}/arc-agi_evaluation_challenges_filtered_1B_eval_set.json \\\n",
        "    --solution_file=${DATA_DIR}/arc-agi_evaluation_solutions_filtered_1B_eval_set.json \\\n",
        "    --max_lora_rank=128 \\\n",
        "    --include_n=1 \\\n",
        "    --new_format \\\n",
        "    --num_examples=9 \\\n",
        "    --n_self_edits=5"
      ],
      "metadata": {
        "id": "_EpbSLpi8xbb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python /content/SEAL/few-shot/eval-self-edits-baseline.py \\\n",
        "    --experiment_folder=/content/SEAL/tti/eval_base_model \\\n",
        "    --pretrained_checkpoint=meta-llama/Llama-3.2-1B-Instruct \\\n",
        "    --lora_checkpoints_folder=${LORA_DIR}/self-edit/eval_RL_iteration_1_8_epoch \\\n",
        "    --temperature=0 \\\n",
        "    --n_sample=1 \\\n",
        "    --data_file=/content/SEAL/few-shot/data/arc-agi_evaluation_challenges_filtered_1B_eval_set.json \\\n",
        "    --solution_file=/content/SEAL/few-shot/data/arc-agi_evaluation_solutions_filtered_1B_eval_set.json \\\n",
        "    --max_lora_rank=128 \\\n",
        "    --include_n=1 \\\n",
        "    --new_format \\\n",
        "    --num_examples=9"
      ],
      "metadata": {
        "id": "s1O3obS-81ei"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python /content/SEAL/few-shot/self-edit.py \\\n",
        "    --experiment_name=eval_RL_iteration_1 \\\n",
        "    --challenge_file=/content/SEAL/few-shot/data/arc-agi_evaluation_challenges_filtered_1B_eval_set.json \\\n",
        "    --solution_file=/content/SEAL/few-shot/data/arc-agi_evaluation_solutions_filtered_1B_eval_set.json \\\n",
        "    --model_name=${LORA_DIR}/self-edit/training_set_iteration_1/RL_trained_model_iteration_1 \\\n",
        "    --n_tasks=10 \\\n",
        "    --n_self_edits_per_task=5"
      ],
      "metadata": {
        "id": "LVocsW3a86wj"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}