{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100",
      "authorship_tag": "ABX9TyOZogYHlICzg2PXjkroURsT",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/frank-morales2020/Cloud_curious/blob/master/SEAL_DEMO.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://github.com/Continual-Intelligence/SEAL/tree/main"
      ],
      "metadata": {
        "id": "8ELjlTPOQIcc"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rPC9FQyR23cJ"
      },
      "outputs": [],
      "source": [
        "!git clone https://github.com/Continual-Intelligence/SEAL.git\n",
        "%cd SEAL\n",
        "!pip install -r requirements.txt -q\n",
        "!pip install colab-env -q\n",
        "import colab_env"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tuahowyn1Zg7",
        "outputId": "0b9fa71c-3324-4256-d359-76d5b077c084"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Thu Jul  3 10:29:40 2025       \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n",
            "|-----------------------------------------+------------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                        |               MIG M. |\n",
            "|=========================================+========================+======================|\n",
            "|   0  NVIDIA A100-SXM4-40GB          Off |   00000000:00:04.0 Off |                    0 |\n",
            "| N/A   31C    P0             43W /  400W |       0MiB /  40960MiB |      0%      Default |\n",
            "|                                         |                        |             Disabled |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "                                                                                         \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                              |\n",
            "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
            "|        ID   ID                                                               Usage      |\n",
            "|=========================================================================================|\n",
            "|  No running processes found                                                             |\n",
            "+-----------------------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import colab_env\n",
        "import os\n",
        "\n",
        "access_token_write = os.getenv(\"HUGGINGFACE_ACCESS_TOKEN_WRITE\")\n",
        "\n",
        "from huggingface_hub import login\n",
        "\n",
        "login(\n",
        "  token=access_token_write,\n",
        "  add_to_git_credential=True\n",
        ")"
      ],
      "metadata": {
        "id": "r9riExTm6J-9"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!sh /content/SEAL/few-shot/launch.sh"
      ],
      "metadata": {
        "id": "M4-79zgcMRHb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "DATA_DIR='/content/SEAL/few-shot/data'\n",
        "!python /content/SEAL/few-shot/self-edit.py  \\\n",
        "    --experiment_name=training_set_iteration_1 \\\n",
        "    --challenge_file={DATA_DIR}/arc-agi_training_challenges_filtered_1B_training_set.json \\\n",
        "    --solution_file={DATA_DIR}/arc-agi_training_solutions_filtered_1B_training_set.json \\\n",
        "    --model_name=meta-llama/Llama-3.2-1B-Instruct \\\n",
        "    --n_tasks=1 \\\n",
        "    --n_self_edits_per_task=15"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "twKPB5UC30_w",
        "outputId": "a06c2d4d-1f81-4d04-ce7f-fce1b4021eb4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-07-03 10:36:08.479950: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
            "2025-07-03 10:36:08.497782: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1751538968.519379   62479 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1751538968.525991   62479 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2025-07-03 10:36:08.548080: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "INFO 07-03 10:36:12 [__init__.py:244] Automatically detected platform cuda.\n",
            "Phase 1: Generating configs using self-edit model...\n",
            "INFO 07-03 10:36:30 [config.py:823] This model supports multiple tasks: {'generate', 'classify', 'reward', 'embed', 'score'}. Defaulting to 'generate'.\n",
            "INFO 07-03 10:36:30 [config.py:2195] Chunked prefill is enabled with max_num_batched_tokens=8192.\n",
            "WARNING 07-03 10:36:32 [utils.py:2597] We must use the `spawn` multiprocessing start method. Overriding VLLM_WORKER_MULTIPROC_METHOD to 'spawn'. See https://docs.vllm.ai/en/latest/usage/troubleshooting.html#python-multiprocessing for more information. Reason: CUDA is initialized\n",
            "2025-07-03 10:36:37.975947: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1751538997.996813   62753 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1751538998.003195   62753 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "WARNING 07-03 10:36:40 [env_override.py:17] NCCL_CUMEM_ENABLE is set to 0, skipping override. This may increase memory overhead with cudagraph+allreduce: https://github.com/NVIDIA/nccl/issues/1234\n",
            "INFO 07-03 10:36:40 [__init__.py:244] Automatically detected platform cuda.\n",
            "INFO 07-03 10:36:44 [core.py:455] Waiting for init message from front-end.\n",
            "INFO 07-03 10:36:44 [core.py:70] Initializing a V1 LLM engine (v0.9.1) with config: model='meta-llama/Llama-3.2-1B-Instruct', speculative_config=None, tokenizer='meta-llama/Llama-3.2-1B-Instruct', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config={}, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=131072, download_dir=None, load_format=LoadFormat.AUTO, tensor_parallel_size=1, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto,  device_config=cuda, decoding_config=DecodingConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_backend=''), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=meta-llama/Llama-3.2-1B-Instruct, num_scheduler_steps=1, multi_step_stream_outputs=True, enable_prefix_caching=True, chunked_prefill_enabled=True, use_async_output_proc=True, pooler_config=None, compilation_config={\"level\":3,\"debug_dump_path\":\"\",\"cache_dir\":\"\",\"backend\":\"\",\"custom_ops\":[\"none\"],\"splitting_ops\":[\"vllm.unified_attention\",\"vllm.unified_attention_with_output\"],\"use_inductor\":true,\"compile_sizes\":[],\"inductor_compile_config\":{\"enable_auto_functionalized_v2\":false},\"inductor_passes\":{},\"use_cudagraph\":true,\"cudagraph_num_of_warmups\":1,\"cudagraph_capture_sizes\":[512,504,496,488,480,472,464,456,448,440,432,424,416,408,400,392,384,376,368,360,352,344,336,328,320,312,304,296,288,280,272,264,256,248,240,232,224,216,208,200,192,184,176,168,160,152,144,136,128,120,112,104,96,88,80,72,64,56,48,40,32,24,16,8,4,2,1],\"cudagraph_copy_inputs\":false,\"full_cuda_graph\":false,\"max_capture_size\":512,\"local_cache_dir\":null}\n",
            "WARNING 07-03 10:36:45 [utils.py:2737] Methods determine_num_available_blocks,device_config,get_cache_block_size_bytes,initialize_cache not implemented in <vllm.v1.worker.gpu_worker.Worker object at 0x7923b8befa90>\n",
            "INFO 07-03 10:36:45 [parallel_state.py:1065] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0\n",
            "WARNING 07-03 10:36:45 [topk_topp_sampler.py:59] FlashInfer is not available. Falling back to the PyTorch-native implementation of top-p & top-k sampling. For the best performance, please install FlashInfer.\n",
            "INFO 07-03 10:36:45 [gpu_model_runner.py:1595] Starting to load model meta-llama/Llama-3.2-1B-Instruct...\n",
            "INFO 07-03 10:36:46 [gpu_model_runner.py:1600] Loading model from scratch...\n",
            "INFO 07-03 10:36:46 [cuda.py:252] Using Flash Attention backend on V1 engine.\n",
            "INFO 07-03 10:36:46 [weight_utils.py:292] Using model weights format ['*.safetensors']\n",
            "INFO 07-03 10:36:46 [weight_utils.py:345] No model.safetensors.index.json found in remote.\n",
            "Loading safetensors checkpoint shards: 100% 1/1 [00:00<00:00,  1.51it/s]\n",
            "INFO 07-03 10:36:47 [default_loader.py:272] Loading weights took 0.71 seconds\n",
            "INFO 07-03 10:36:48 [gpu_model_runner.py:1624] Model loading took 2.3185 GiB and 1.240163 seconds\n",
            "INFO 07-03 10:36:54 [backends.py:462] Using cache directory: /root/.cache/vllm/torch_compile_cache/3800301869/rank_0_0 for vLLM's torch.compile\n",
            "INFO 07-03 10:36:54 [backends.py:472] Dynamo bytecode transform time: 5.82 s\n",
            "INFO 07-03 10:36:58 [backends.py:135] Directly load the compiled graph(s) for shape None from the cache, took 3.698 s\n",
            "INFO 07-03 10:36:58 [monitor.py:34] torch.compile takes 5.82 s in total\n",
            "INFO 07-03 10:37:00 [gpu_worker.py:227] Available KV cache memory: 32.02 GiB\n",
            "INFO 07-03 10:37:00 [kv_cache_utils.py:715] GPU KV cache size: 1,049,200 tokens\n",
            "INFO 07-03 10:37:00 [kv_cache_utils.py:719] Maximum concurrency for 131,072 tokens per request: 8.00x\n",
            "INFO 07-03 10:37:30 [gpu_model_runner.py:2048] Graph capturing finished in 30 secs, took 0.30 GiB\n",
            "INFO 07-03 10:37:30 [core.py:171] init engine (profile, create kv cache, warmup model) took 41.99 seconds\n",
            "Adding requests: 100% 1/1 [00:00<00:00, 330.65it/s]\n",
            "Processed prompts: 100% 1/1 [00:00<00:00,  2.02it/s, est. speed input: 834.58 toks/s, output: 175.80 toks/s]\n",
            "New config for task 44f52bb0: {'data_generation': {'use_basic_augmentations': False, 'use_size_augmentations': False, 'use_chain_augmentations': False, 'use_repeat_augmentations': False}, 'training': {'strategy': 'train_using_all_tokens', 'learning_rate': 0.01, 'num_train_epochs': 5}}\n",
            "Adding requests: 100% 1/1 [00:00<00:00, 540.50it/s]\n",
            "Processed prompts: 100% 1/1 [00:00<00:00,  2.49it/s, est. speed input: 1029.74 toks/s, output: 216.91 toks/s]\n",
            "New config for task 44f52bb0: {'data_generation': {'use_basic_augmentations': False, 'use_size_augmentations': False, 'use_chain_augmentations': True, 'use_repeat_augmentations': False}, 'training': {'strategy': 'train_using_all_tokens', 'learning_rate': 0.001, 'num_train_epochs': 3}}\n",
            "Adding requests: 100% 1/1 [00:00<00:00, 593.67it/s]\n",
            "Processed prompts: 100% 1/1 [00:00<00:00,  2.12it/s, est. speed input: 875.77 toks/s, output: 237.49 toks/s]\n",
            "New config for task 44f52bb0: {'data_generation': {'use_basic_augmentations': False, 'use_size_augmentations': False, 'use_chain_augmentations': False, 'use_repeat_augmentations': False}, 'training': {'strategy': 'train_using_all_tokens', 'learning_rate': 0.01, 'num_train_epochs': 3, 'use_tfidf': True, 'num_iterations': 100000, 'batch_size': 32}}\n",
            "Adding requests: 100% 1/1 [00:00<00:00, 595.11it/s]\n",
            "Processed prompts: 100% 1/1 [00:00<00:00,  2.64it/s, est. speed input: 1090.88 toks/s, output: 229.79 toks/s]\n",
            "New config for task 44f52bb0: {'data_generation': {'use_basic_augmentations': True, 'use_size_augmentations': False, 'use_chain_augmentations': False, 'use_repeat_augmentations': False}, 'training': {'strategy': 'train_using_all_tokens', 'learning_rate': 0.01, 'num_train_epochs': 5}}\n",
            "Adding requests: 100% 1/1 [00:00<00:00, 594.01it/s]\n",
            "Processed prompts: 100% 1/1 [00:00<00:00,  2.72it/s, est. speed input: 1124.90 toks/s, output: 236.95 toks/s]\n",
            "New config for task 44f52bb0: {'data_generation': {'use_basic_augmentations': True, 'use_size_augmentations': True, 'use_chain_augmentations': True, 'use_repeat_augmentations': False}, 'training': {'strategy': 'train_using_all_tokens', 'learning_rate': 0.001, 'num_train_epochs': 3}}\n",
            "Adding requests: 100% 1/1 [00:00<00:00, 593.42it/s]\n",
            "Processed prompts: 100% 1/1 [00:00<00:00,  2.73it/s, est. speed input: 1128.18 toks/s, output: 237.64 toks/s]\n",
            "New config for task 44f52bb0: {'data_generation': {'use_basic_augmentations': False, 'use_size_augmentations': False, 'use_chain_augmentations': False, 'use_repeat_augmentations': False}, 'training': {'strategy': 'train_using_output_tokens', 'learning_rate': 0.001, 'num_train_epochs': 5}}\n",
            "Adding requests: 100% 1/1 [00:00<00:00, 546.77it/s]\n",
            "Processed prompts: 100% 1/1 [00:00<00:00,  2.53it/s, est. speed input: 1045.30 toks/s, output: 220.19 toks/s]\n",
            "New config for task 44f52bb0: {'data_generation': {'use_basic_augmentations': True, 'use_size_augmentations': False, 'use_chain_augmentations': True, 'use_repeat_augmentations': False}, 'training': {'strategy': 'train_using_all_tokens', 'learning_rate': 0.01, 'num_train_epochs': 5}}\n",
            "Adding requests: 100% 1/1 [00:00<00:00, 595.27it/s]\n",
            "Processed prompts: 100% 1/1 [00:00<00:00,  2.64it/s, est. speed input: 1091.20 toks/s, output: 237.78 toks/s]\n",
            "New config for task 44f52bb0: {'data_generation': {'use_basic_augmentations': 'false', 'use_size_augmentations': 'false', 'use_chain_augmentations': 'false', 'use_repeat_augmentations': 'false'}, 'training': {'strategy': 'stochastic_basic', 'learning_rate': 0.001, 'num_train_epochs': 3}}\n",
            "Adding requests: 100% 1/1 [00:00<00:00, 615.81it/s]\n",
            "Processed prompts: 100% 1/1 [00:00<00:00,  2.68it/s, est. speed input: 1107.39 toks/s, output: 233.26 toks/s]\n",
            "New config for task 44f52bb0: {'data_generation': {'use_basic_augmentations': True, 'use_size_augmentations': True, 'use_chain_augmentations': False, 'use_repeat_augmentations': False}, 'training': {'strategy': 'train_using_all_tokens', 'learning_rate': 0.001, 'num_train_epochs': 3}}\n",
            "Adding requests: 100% 1/1 [00:00<00:00, 621.75it/s]\n",
            "Processed prompts: 100% 1/1 [00:00<00:00,  2.71it/s, est. speed input: 1120.22 toks/s, output: 235.97 toks/s]\n",
            "New config for task 44f52bb0: {'data_generation': {'use_basic_augmentations': False, 'use_size_augmentations': False, 'use_chain_augmentations': True, 'use_repeat_augmentations': False}, 'training': {'strategy': 'train_using_all_tokens', 'learning_rate': 0.001, 'num_train_epochs': 10}}\n",
            "Adding requests: 100% 1/1 [00:00<00:00, 259.81it/s]\n",
            "Processed prompts: 100% 1/1 [00:00<00:00,  2.71it/s, est. speed input: 1121.05 toks/s, output: 236.14 toks/s]\n",
            "New config for task 44f52bb0: {'data_generation': {'use_basic_augmentations': True, 'use_size_augmentations': True, 'use_chain_augmentations': False, 'use_repeat_augmentations': True}, 'training': {'strategy': 'train_using_all_tokens', 'learning_rate': 0.01, 'num_train_epochs': 2}}\n",
            "Adding requests: 100% 1/1 [00:00<00:00, 616.81it/s]\n",
            "Processed prompts: 100% 1/1 [00:00<00:00,  2.71it/s, est. speed input: 1121.00 toks/s, output: 236.13 toks/s]\n",
            "New config for task 44f52bb0: {'data_generation': {'use_basic_augmentations': True, 'use_size_augmentations': True, 'use_chain_augmentations': False, 'use_repeat_augmentations': False}, 'training': {'strategy': 'train_using_all_tokens', 'learning_rate': 1.0, 'num_train_epochs': 5}}\n",
            "Adding requests: 100% 1/1 [00:00<00:00, 617.99it/s]\n",
            "Processed prompts: 100% 1/1 [00:00<00:00,  2.69it/s, est. speed input: 1112.23 toks/s, output: 234.28 toks/s]\n",
            "New config for task 44f52bb0: {'data_generation': {'use_basic_augmentations': True, 'use_size_augmentations': False, 'use_chain_augmentations': True, 'use_repeat_augmentations': True}, 'training': {'strategy': 'train_using_all_tokens', 'learning_rate': 0.01, 'num_train_epochs': 3}}\n",
            "Adding requests: 100% 1/1 [00:00<00:00, 606.29it/s]\n",
            "Processed prompts: 100% 1/1 [00:00<00:00,  2.69it/s, est. speed input: 1110.18 toks/s, output: 233.85 toks/s]\n",
            "New config for task 44f52bb0: {'data_generation': {'use_basic_augmentations': True, 'use_size_augmentations': True, 'use_chain_augmentations': False, 'use_repeat_augmentations': False}, 'training': {'strategy': 'train_using_all_tokens', 'learning_rate': 0.01, 'num_train_epochs': 5}}\n",
            "Adding requests: 100% 1/1 [00:00<00:00, 564.36it/s]\n",
            "Processed prompts: 100% 1/1 [00:00<00:00,  2.32it/s, est. speed input: 958.35 toks/s, output: 201.87 toks/s]\n",
            "New config for task 44f52bb0: {'data_generation': {'use_basic_augmentations': True, 'use_size_augmentations': False, 'use_chain_augmentations': True, 'use_repeat_augmentations': True}, 'training': {'strategy': 'train_using_all_tokens', 'learning_rate': 0.01, 'num_train_epochs': 3}}\n",
            "[rank0]:[W703 10:37:37.554428540 ProcessGroupNCCL.cpp:1476] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())\n",
            "Phase 1 complete.\n",
            "\n",
            "Phase 2: Training models using generated configs...\n",
            "Training on 69 examples for 5 epochs, lr: 0.01\n",
            "No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n",
            "Starting training...\n",
            "{'loss': 3.1439, 'grad_norm': 1.834293246269226, 'learning_rate': 0.0, 'epoch': 0.03}\n",
            "{'loss': 3.1674, 'grad_norm': 1.8317646980285645, 'learning_rate': 0.0009090909090909091, 'epoch': 0.06}\n",
            "{'loss': 1.8162, 'grad_norm': 0.5597311854362488, 'learning_rate': 0.0018181818181818182, 'epoch': 0.09}\n",
            "{'loss': 1.2533, 'grad_norm': 0.9108178615570068, 'learning_rate': 0.002727272727272727, 'epoch': 0.11}\n",
            "{'loss': 1.9457, 'grad_norm': 4.176822185516357, 'learning_rate': 0.0036363636363636364, 'epoch': 0.14}\n",
            "{'loss': 0.7168, 'grad_norm': 1.9196336269378662, 'learning_rate': 0.004545454545454545, 'epoch': 0.17}\n",
            "{'loss': 0.4419, 'grad_norm': 0.5770339965820312, 'learning_rate': 0.005454545454545454, 'epoch': 0.2}\n",
            "{'loss': 0.9352, 'grad_norm': 2.4775688648223877, 'learning_rate': 0.006363636363636364, 'epoch': 0.23}\n",
            "{'loss': 2.1105, 'grad_norm': 10.876291275024414, 'learning_rate': 0.007272727272727273, 'epoch': 0.26}\n",
            "{'loss': 2.4495, 'grad_norm': 12.074249267578125, 'learning_rate': 0.008181818181818182, 'epoch': 0.29}\n",
            "{'loss': 2.4508, 'grad_norm': 7.516407012939453, 'learning_rate': 0.00909090909090909, 'epoch': 0.31}\n",
            "{'loss': 6.2159, 'grad_norm': 9.950382232666016, 'learning_rate': 0.01, 'epoch': 0.34}\n",
            "{'loss': 12.4963, 'grad_norm': 19.697444915771484, 'learning_rate': 0.009999082642158971, 'epoch': 0.37}\n",
            "{'loss': 10.1638, 'grad_norm': 22.669652938842773, 'learning_rate': 0.00999633090525405, 'epoch': 0.4}\n",
            "{'loss': 8.3375, 'grad_norm': 6.9918084144592285, 'learning_rate': 0.009991745799016205, 'epoch': 0.43}\n",
            "{'loss': 12.2938, 'grad_norm': 7.214596271514893, 'learning_rate': 0.009985329005918702, 'epoch': 0.46}\n",
            "{'loss': 13.9115, 'grad_norm': 8.380569458007812, 'learning_rate': 0.009977082880559724, 'epoch': 0.49}\n",
            "{'loss': 11.4104, 'grad_norm': 4.872331142425537, 'learning_rate': 0.009967010448798375, 'epoch': 0.51}\n",
            "{'loss': 9.5446, 'grad_norm': 4.7248029708862305, 'learning_rate': 0.009955115406644356, 'epoch': 0.54}\n",
            "{'loss': 9.106, 'grad_norm': 5.148559093475342, 'learning_rate': 0.009941402118901743, 'epoch': 0.57}\n",
            "{'loss': 8.5194, 'grad_norm': 4.864954471588135, 'learning_rate': 0.00992587561756735, 'epoch': 0.6}\n",
            "{'loss': 7.5527, 'grad_norm': 3.4612040519714355, 'learning_rate': 0.009908541599984276, 'epoch': 0.63}\n",
            "{'loss': 6.3746, 'grad_norm': 2.681631326675415, 'learning_rate': 0.009889406426751296, 'epoch': 0.66}\n",
            "{'loss': 6.3573, 'grad_norm': 1.9358649253845215, 'learning_rate': 0.009868477119388895, 'epoch': 0.69}\n",
            "{'loss': 5.7449, 'grad_norm': 2.1273598670959473, 'learning_rate': 0.009845761357762758, 'epoch': 0.71}\n",
            "{'loss': 5.4136, 'grad_norm': 8.367140769958496, 'learning_rate': 0.009821267477265706, 'epoch': 0.74}\n",
            "{'loss': 5.3816, 'grad_norm': 3.105698585510254, 'learning_rate': 0.009795004465759065, 'epoch': 0.77}\n",
            "{'loss': 5.0068, 'grad_norm': 1.695292353630066, 'learning_rate': 0.009766981960274652, 'epoch': 0.8}\n",
            "{'loss': 4.6219, 'grad_norm': 0.986676812171936, 'learning_rate': 0.009737210243478522, 'epoch': 0.83}\n",
            "{'loss': 4.3846, 'grad_norm': 0.97871333360672, 'learning_rate': 0.009705700239897808, 'epoch': 0.86}\n",
            "{'loss': 4.4818, 'grad_norm': 1.1072497367858887, 'learning_rate': 0.009672463511912055, 'epoch': 0.89}\n",
            "{'loss': 4.4475, 'grad_norm': 1.1389906406402588, 'learning_rate': 0.009637512255510475, 'epoch': 0.91}\n",
            "{'loss': 4.2058, 'grad_norm': 1.1316758394241333, 'learning_rate': 0.009600859295816708, 'epoch': 0.94}\n",
            "{'loss': 4.1269, 'grad_norm': 0.7016121745109558, 'learning_rate': 0.009562518082382749, 'epoch': 0.97}\n",
            "{'loss': 3.8847, 'grad_norm': 0.706536054611206, 'learning_rate': 0.00952250268425371, 'epoch': 1.0}\n",
            "{'loss': 3.6755, 'grad_norm': 0.2775759994983673, 'learning_rate': 0.009480827784805279, 'epoch': 1.03}\n",
            "{'loss': 3.6508, 'grad_norm': 0.5804733633995056, 'learning_rate': 0.009437508676355772, 'epoch': 1.06}\n",
            "{'loss': 3.6972, 'grad_norm': 0.9423337578773499, 'learning_rate': 0.009392561254554713, 'epoch': 1.09}\n",
            "{'loss': 3.5902, 'grad_norm': 0.8675497770309448, 'learning_rate': 0.009346002012550026, 'epoch': 1.11}\n",
            "{'loss': 3.477, 'grad_norm': 0.7091462016105652, 'learning_rate': 0.009297848034936006, 'epoch': 1.14}\n",
            "{'loss': 3.6254, 'grad_norm': 0.8736729025840759, 'learning_rate': 0.009248116991484227, 'epoch': 1.17}\n",
            "{'loss': 3.3697, 'grad_norm': 0.37598517537117004, 'learning_rate': 0.00919682713065975, 'epoch': 1.2}\n",
            "{'loss': 3.4571, 'grad_norm': 1.0033050775527954, 'learning_rate': 0.009143997272924973, 'epoch': 1.23}\n",
            "{'loss': 3.236, 'grad_norm': 0.37300506234169006, 'learning_rate': 0.009089646803833588, 'epoch': 1.26}\n",
            "{'loss': 3.2618, 'grad_norm': 0.6652799248695374, 'learning_rate': 0.00903379566691719, 'epoch': 1.29}\n",
            "{'loss': 3.1311, 'grad_norm': 0.37432244420051575, 'learning_rate': 0.008976464356367134, 'epoch': 1.31}\n",
            "{'loss': 3.1297, 'grad_norm': 0.5881084203720093, 'learning_rate': 0.00891767390951432, 'epoch': 1.34}\n",
            "{'loss': 3.0874, 'grad_norm': 0.37067148089408875, 'learning_rate': 0.008857445899109716, 'epoch': 1.37}\n",
            "{'loss': 3.0682, 'grad_norm': 0.38478565216064453, 'learning_rate': 0.008795802425408353, 'epoch': 1.4}\n",
            "{'loss': 2.9504, 'grad_norm': 0.4953271150588989, 'learning_rate': 0.008732766108059812, 'epoch': 1.43}\n",
            "{'loss': 2.8923, 'grad_norm': 5.767369270324707, 'learning_rate': 0.008668360077808093, 'epoch': 1.46}\n",
            "{'loss': 3.2157, 'grad_norm': 1.1597455739974976, 'learning_rate': 0.008602607968003936, 'epoch': 1.49}\n",
            "{'loss': 2.9478, 'grad_norm': 0.4218854308128357, 'learning_rate': 0.008535533905932738, 'epoch': 1.51}\n",
            "{'loss': 2.8567, 'grad_norm': 0.3611922860145569, 'learning_rate': 0.008467162503961208, 'epoch': 1.54}\n",
            "{'loss': 2.801, 'grad_norm': 0.2951056957244873, 'learning_rate': 0.008397518850506028, 'epoch': 1.57}\n",
            "{'loss': 2.8212, 'grad_norm': 0.32665005326271057, 'learning_rate': 0.008326628500827826, 'epoch': 1.6}\n",
            "{'loss': 2.8513, 'grad_norm': 0.36537790298461914, 'learning_rate': 0.008254517467653858, 'epoch': 1.63}\n",
            "{'loss': 2.8052, 'grad_norm': 0.366021990776062, 'learning_rate': 0.008181212211632798, 'epoch': 1.66}\n",
            "{'loss': 2.6942, 'grad_norm': 0.18329626321792603, 'learning_rate': 0.008106739631625216, 'epoch': 1.69}\n",
            "{'loss': 2.7452, 'grad_norm': 0.3158070147037506, 'learning_rate': 0.00803112705483319, 'epoch': 1.71}\n",
            "{'loss': 2.7316, 'grad_norm': 0.37066149711608887, 'learning_rate': 0.007954402226772803, 'epoch': 1.74}\n",
            "{'loss': 2.6908, 'grad_norm': 0.8363568186759949, 'learning_rate': 0.007876593301093103, 'epoch': 1.77}\n",
            "{'loss': 2.7138, 'grad_norm': 0.33947110176086426, 'learning_rate': 0.007797728829245321, 'epoch': 1.8}\n",
            "{'loss': 2.7334, 'grad_norm': 0.3647868037223816, 'learning_rate': 0.007717837750006106, 'epoch': 1.83}\n",
            "{'loss': 2.7317, 'grad_norm': 0.32030773162841797, 'learning_rate': 0.007636949378858646, 'epoch': 1.86}\n",
            "{'loss': 2.7136, 'grad_norm': 0.33376240730285645, 'learning_rate': 0.0075550933972355514, 'epoch': 1.89}\n",
            "{'loss': 2.599, 'grad_norm': 0.36578187346458435, 'learning_rate': 0.007472299841627451, 'epoch': 1.91}\n",
            "{'loss': 2.593, 'grad_norm': 0.25475117564201355, 'learning_rate': 0.0073885990925613146, 'epoch': 1.94}\n",
            "{'loss': 2.6093, 'grad_norm': 0.25981664657592773, 'learning_rate': 0.007304021863452525, 'epoch': 1.97}\n",
            "{'loss': 2.5699, 'grad_norm': 0.24558775126934052, 'learning_rate': 0.007218599189334799, 'epoch': 2.0}\n",
            "{'loss': 2.5122, 'grad_norm': 0.18896794319152832, 'learning_rate': 0.007132362415472099, 'epoch': 2.03}\n",
            "{'loss': 2.5091, 'grad_norm': 0.15823079645633698, 'learning_rate': 0.007045343185856701, 'epoch': 2.06}\n",
            "{'loss': 2.5367, 'grad_norm': 0.389404296875, 'learning_rate': 0.0069575734315976455, 'epoch': 2.09}\n",
            "{'loss': 2.4774, 'grad_norm': 0.2885155975818634, 'learning_rate': 0.006869085359203844, 'epoch': 2.11}\n",
            "{'loss': 2.4222, 'grad_norm': 0.2529257535934448, 'learning_rate': 0.006779911438766117, 'epoch': 2.14}\n",
            "{'loss': 2.4627, 'grad_norm': 0.311204195022583, 'learning_rate': 0.006690084392042514, 'epoch': 2.17}\n",
            "{'loss': 2.3963, 'grad_norm': 0.25161343812942505, 'learning_rate': 0.006599637180451295, 'epoch': 2.2}\n",
            "{'loss': 2.3575, 'grad_norm': 0.2776014506816864, 'learning_rate': 0.006508602992975962, 'epoch': 2.23}\n",
            "{'loss': 2.2862, 'grad_norm': 0.7198169231414795, 'learning_rate': 0.006417015233986786, 'epoch': 2.26}\n",
            "{'loss': 2.2592, 'grad_norm': 0.17315664887428284, 'learning_rate': 0.00632490751098331, 'epoch': 2.29}\n",
            "{'loss': 2.2074, 'grad_norm': 0.15471212565898895, 'learning_rate': 0.006232313622262297, 'epoch': 2.31}\n",
            "{'loss': 2.1972, 'grad_norm': 0.29056641459465027, 'learning_rate': 0.006139267544515689, 'epoch': 2.34}\n",
            "{'loss': 2.1838, 'grad_norm': 0.26225703954696655, 'learning_rate': 0.006045803420363084, 'epoch': 2.37}\n",
            "{'loss': 2.204, 'grad_norm': 0.4012642800807953, 'learning_rate': 0.005951955545823342, 'epoch': 2.4}\n",
            "{'loss': 2.1592, 'grad_norm': 0.4061194062232971, 'learning_rate': 0.005857758357729892, 'epoch': 2.43}\n",
            "{'loss': 2.0823, 'grad_norm': 0.3005290925502777, 'learning_rate': 0.0057632464210943726, 'epoch': 2.46}\n",
            "{'loss': 2.0743, 'grad_norm': 0.22171685099601746, 'learning_rate': 0.005668454416423242, 'epoch': 2.49}\n",
            "{'loss': 2.039, 'grad_norm': 0.7855501174926758, 'learning_rate': 0.0055734171269920035, 'epoch': 2.51}\n",
            "{'loss': 2.0792, 'grad_norm': 0.9377843141555786, 'learning_rate': 0.005478169426081711, 'epoch': 2.54}\n",
            "{'loss': 1.982, 'grad_norm': 53.58595657348633, 'learning_rate': 0.00538274626418248, 'epoch': 2.57}\n",
            "{'loss': 2.1625, 'grad_norm': 0.4869045913219452, 'learning_rate': 0.005287182656168617, 'epoch': 2.6}\n",
            "{'loss': 2.0521, 'grad_norm': 0.23561373353004456, 'learning_rate': 0.005191513668450177, 'epoch': 2.63}\n",
            "{'loss': 2.0449, 'grad_norm': 0.36150842905044556, 'learning_rate': 0.005095774406105571, 'epoch': 2.66}\n",
            "{'loss': 2.1118, 'grad_norm': 0.77519291639328, 'learning_rate': 0.005, 'epoch': 2.69}\n",
            "{'loss': 1.9557, 'grad_norm': 0.24636414647102356, 'learning_rate': 0.00490422559389443, 'epoch': 2.71}\n",
            "{'loss': 1.9249, 'grad_norm': 1.2258869409561157, 'learning_rate': 0.004808486331549823, 'epoch': 2.74}\n",
            "{'loss': 1.9388, 'grad_norm': 0.3184869885444641, 'learning_rate': 0.004712817343831384, 'epoch': 2.77}\n",
            "{'loss': 1.9312, 'grad_norm': 2.3453221321105957, 'learning_rate': 0.0046172537358175215, 'epoch': 2.8}\n",
            "{'loss': 1.9641, 'grad_norm': 1.3485889434814453, 'learning_rate': 0.004521830573918289, 'epoch': 2.83}\n",
            "{'loss': 1.9611, 'grad_norm': 0.3393351435661316, 'learning_rate': 0.0044265828730079984, 'epoch': 2.86}\n",
            "{'loss': 1.9397, 'grad_norm': 0.3120068609714508, 'learning_rate': 0.004331545583576757, 'epoch': 2.89}\n",
            "{'loss': 1.902, 'grad_norm': 0.18928678333759308, 'learning_rate': 0.004236753578905627, 'epoch': 2.91}\n",
            "{'loss': 1.9199, 'grad_norm': 0.2790687680244446, 'learning_rate': 0.004142241642270108, 'epoch': 2.94}\n",
            "{'loss': 1.9135, 'grad_norm': 0.7729037404060364, 'learning_rate': 0.004048044454176658, 'epoch': 2.97}\n",
            "{'loss': 1.8667, 'grad_norm': 0.2006930410861969, 'learning_rate': 0.0039541965796369176, 'epoch': 3.0}\n",
            "{'loss': 1.8571, 'grad_norm': 0.26996055245399475, 'learning_rate': 0.003860732455484313, 'epoch': 3.03}\n",
            "{'loss': 1.8396, 'grad_norm': 0.25569120049476624, 'learning_rate': 0.0037676863777377054, 'epoch': 3.06}\n",
            "{'loss': 1.8016, 'grad_norm': 0.14673249423503876, 'learning_rate': 0.0036750924890166926, 'epoch': 3.09}\n",
            "{'loss': 1.8313, 'grad_norm': 1.871271014213562, 'learning_rate': 0.0035829847660132147, 'epoch': 3.11}\n",
            "{'loss': 1.7804, 'grad_norm': 0.1430312693119049, 'learning_rate': 0.0034913970070240387, 'epoch': 3.14}\n",
            "{'loss': 1.777, 'grad_norm': 0.135570228099823, 'learning_rate': 0.003400362819548706, 'epoch': 3.17}\n",
            "{'loss': 1.7497, 'grad_norm': 0.13168972730636597, 'learning_rate': 0.003309915607957487, 'epoch': 3.2}\n",
            "{'loss': 1.744, 'grad_norm': 0.13655899465084076, 'learning_rate': 0.0032200885612338843, 'epoch': 3.23}\n",
            "{'loss': 1.7288, 'grad_norm': 0.11626484990119934, 'learning_rate': 0.0031309146407961564, 'epoch': 3.26}\n",
            "{'loss': 1.771, 'grad_norm': 1.2986811399459839, 'learning_rate': 0.0030424265684023555, 'epoch': 3.29}\n",
            " 66% 115/175 [00:14<00:06,  8.97it/s]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python /content/SEAL/few-shot/ttt.py"
      ],
      "metadata": {
        "id": "mNzfXwY7Ipqu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "DATA_DIR='/content/SEAL/few-shot/data'\n",
        "TTI_DIR='/content/SEAL/loras/self-edit/training_set_iteration_1'\n",
        "LORA_DIR='/content/SEAL/loras/self-edit/training_set_iteration_1/8d5021e8/14'\n",
        "\n",
        "!python /content/SEAL/few-shot/eval-self-edits.py  \\\n",
        "    --experiment_folder={TTI_DIR} \\\n",
        "    --pretrained_checkpoint=meta-llama/Llama-3.2-1B-Instruct \\\n",
        "    --lora_checkpoints_folder={LORA_DIR} \\\n",
        "    --temperature=0 \\\n",
        "    --n_sample=1 \\\n",
        "    --data_file=/content/SEAL/few-shot/data/arc-agi_training_challenges_filtered_1B_training_set.json \\\n",
        "    --solution_file=/content/SEAL/few-shot/data/arc-agi_evaluation_challenges_filtered_1B_eval_set.json \\\n",
        "    --max_lora_rank=128 \\\n",
        "    --include_n=1 \\\n",
        "    --new_format \\\n",
        "    --num_examples=11 \\\n",
        "    --n_self_edits=15"
      ],
      "metadata": {
        "id": "d2H8z48V8kT_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python /content/SEAL/few-shot/BC-self-edit.py \\\n",
        "    --configs_and_indices=/content/SEAL/loras/self-edit/training_set_iteration_1/final_configs_and_indices.json \\\n",
        "    --results=/content/SEAL/few-shot/final_results.json \\\n",
        "    --model_name=meta-llama/Llama-3.2-1B-Instruct \\\n",
        "    --lora_rank=16 \\\n",
        "    --lora_alpha=16 \\\n",
        "    --num_train_epochs=8 \\\n",
        "    --per_device_train_batch_size=5 \\\n",
        "    --gradient_accumulation_steps=1 \\\n",
        "    --learning_rate=5e-5"
      ],
      "metadata": {
        "id": "o3tBgYc-8l2z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python /content/SEAL/few-shot/self-edit.py  \\\n",
        "    --experiment_name=eval_RL_iteration_1_8_epoch \\\n",
        "    --challenge_file={DATA_DIR}/arc-agi_evaluation_challenges_filtered_1B_eval_set.json \\\n",
        "    --solution_file={DATA_DIR}/arc-agi_evaluation_solutions_filtered_1B_eval_set.json \\\n",
        "    --model_name={LORA_DIR}/self-edit/training_set_iteration_1/RL_trained_model_iteration_1_8_epoch \\\n",
        "    --n_tasks=10 \\\n",
        "    --n_self_edits_per_task=5"
      ],
      "metadata": {
        "id": "vLNLYvf_8qoC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python /content/SEAL/few-shot/eval-self-edits.py \\\n",
        "    --experiment_folder={TTI_DIR}/eval_set_RL_iteration_1_8_epoch \\\n",
        "    --pretrained_checkpoint={LORA_DIR}/self-edit/training_set_iteration_1/RL_trained_model_iteration_1_8_epoch \\\n",
        "    --lora_checkpoints_folder={LORA_DIR}/self-edit/eval_RL_iteration_1_8_epoch \\\n",
        "    --temperature=0 \\\n",
        "    --n_sample=1 \\\n",
        "    --data_file=${DATA_DIR}/arc-agi_evaluation_challenges_filtered_1B_eval_set.json \\\n",
        "    --solution_file=${DATA_DIR}/arc-agi_evaluation_solutions_filtered_1B_eval_set.json \\\n",
        "    --max_lora_rank=128 \\\n",
        "    --include_n=1 \\\n",
        "    --new_format \\\n",
        "    --num_examples=9 \\\n",
        "    --n_self_edits=5"
      ],
      "metadata": {
        "id": "_EpbSLpi8xbb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python /content/SEAL/few-shot/eval-self-edits-baseline.py \\\n",
        "    --experiment_folder=/content/SEAL/tti/eval_base_model \\\n",
        "    --pretrained_checkpoint=meta-llama/Llama-3.2-1B-Instruct \\\n",
        "    --lora_checkpoints_folder=${LORA_DIR}/self-edit/eval_RL_iteration_1_8_epoch \\\n",
        "    --temperature=0 \\\n",
        "    --n_sample=1 \\\n",
        "    --data_file=/content/SEAL/few-shot/data/arc-agi_evaluation_challenges_filtered_1B_eval_set.json \\\n",
        "    --solution_file=/content/SEAL/few-shot/data/arc-agi_evaluation_solutions_filtered_1B_eval_set.json \\\n",
        "    --max_lora_rank=128 \\\n",
        "    --include_n=1 \\\n",
        "    --new_format \\\n",
        "    --num_examples=9"
      ],
      "metadata": {
        "id": "s1O3obS-81ei"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python /content/SEAL/few-shot/self-edit.py \\\n",
        "    --experiment_name=eval_RL_iteration_1 \\\n",
        "    --challenge_file=/content/SEAL/few-shot/data/arc-agi_evaluation_challenges_filtered_1B_eval_set.json \\\n",
        "    --solution_file=/content/SEAL/few-shot/data/arc-agi_evaluation_solutions_filtered_1B_eval_set.json \\\n",
        "    --model_name=${LORA_DIR}/self-edit/training_set_iteration_1/RL_trained_model_iteration_1 \\\n",
        "    --n_tasks=10 \\\n",
        "    --n_self_edits_per_task=5"
      ],
      "metadata": {
        "id": "LVocsW3a86wj"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}