{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100",
      "authorship_tag": "ABX9TyPeqrY/vqDpaU1bt84Tzncr",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/frank-morales2020/Cloud_curious/blob/master/SEAL_DEMO.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://github.com/Continual-Intelligence/SEAL/tree/main"
      ],
      "metadata": {
        "id": "8ELjlTPOQIcc"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rPC9FQyR23cJ"
      },
      "outputs": [],
      "source": [
        "!git clone https://github.com/Continual-Intelligence/SEAL.git\n",
        "%cd SEAL\n",
        "!pip install -r requirements.txt -q\n",
        "!pip install colab-env -q\n",
        "import colab_env"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import colab_env\n",
        "import os\n",
        "\n",
        "access_token_write = os.getenv(\"HUGGINGFACE_ACCESS_TOKEN_WRITE\")\n",
        "\n",
        "from huggingface_hub import login\n",
        "\n",
        "login(\n",
        "  token=access_token_write,\n",
        "  add_to_git_credential=True\n",
        ")"
      ],
      "metadata": {
        "id": "r9riExTm6J-9"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!sh /content/SEAL/few-shot/launch.sh"
      ],
      "metadata": {
        "id": "M4-79zgcMRHb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "DATA_DIR='/content/SEAL/few-shot/data'\n",
        "!python /content/SEAL/few-shot/self-edit.py  \\\n",
        "    --experiment_name=training_set_iteration_1 \\\n",
        "    --challenge_file={DATA_DIR}/arc-agi_training_challenges_filtered_1B_training_set.json \\\n",
        "    --solution_file={DATA_DIR}/arc-agi_training_solutions_filtered_1B_training_set.json \\\n",
        "    --model_name=meta-llama/Llama-3.2-1B-Instruct \\\n",
        "    --n_tasks=12 \\\n",
        "    --n_self_edits_per_task=15"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "twKPB5UC30_w",
        "outputId": "3f6db7d3-9afc-4f09-baaf-cf66611d68fc"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "{'loss': 0.008, 'grad_norm': 0.017266247421503067, 'learning_rate': 9.410911550880474e-06, 'epoch': 2.86}\n",
            "{'loss': 0.0091, 'grad_norm': 0.017133334651589394, 'learning_rate': 6.541645633054649e-06, 'epoch': 2.89}\n",
            "{'loss': 0.011, 'grad_norm': 0.01525526400655508, 'learning_rate': 4.189949386787462e-06, 'epoch': 2.92}\n",
            "{'loss': 0.0085, 'grad_norm': 0.01685592345893383, 'learning_rate': 2.3582894166930268e-06, 'epoch': 2.94}\n",
            "{'loss': 0.0085, 'grad_norm': 0.019107569009065628, 'learning_rate': 1.0485868811441758e-06, 'epoch': 2.97}\n",
            "{'loss': 0.0092, 'grad_norm': 0.01672017015516758, 'learning_rate': 2.6221547724253336e-07, 'epoch': 3.0}\n",
            "{'train_runtime': 14.3203, 'train_samples_per_second': 15.084, 'train_steps_per_second': 7.542, 'train_loss': 0.2811508280682136, 'epoch': 3.0}\n",
            "100% 108/108 [00:14<00:00,  7.54it/s]\n",
            "Training complete.\n",
            "Model saved to loras/self-edit/training_set_iteration_1/8be77c9e/7\n",
            "Training on 250 examples for 3 epochs, lr: 0.1\n",
            "No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n",
            "Starting training...\n",
            "{'loss': 6.0455, 'grad_norm': 7.652691841125488, 'learning_rate': 0.0, 'epoch': 0.01}\n",
            "{'loss': 4.4883, 'grad_norm': 4.800975799560547, 'learning_rate': 0.009090909090909092, 'epoch': 0.02}\n",
            "{'loss': 4.8574, 'grad_norm': 20.129945755004883, 'learning_rate': 0.018181818181818184, 'epoch': 0.02}\n",
            "{'loss': 11.1649, 'grad_norm': 35.05783462524414, 'learning_rate': 0.02727272727272727, 'epoch': 0.03}\n",
            "{'loss': 37.6678, 'grad_norm': 57.36524200439453, 'learning_rate': 0.03636363636363637, 'epoch': 0.04}\n",
            "{'loss': 35.1134, 'grad_norm': 2.6821389198303223, 'learning_rate': 0.045454545454545456, 'epoch': 0.05}\n",
            "{'loss': 12.7461, 'grad_norm': 1.582136869430542, 'learning_rate': 0.05454545454545454, 'epoch': 0.06}\n",
            "{'loss': 13.5991, 'grad_norm': 25.13669776916504, 'learning_rate': 0.06363636363636364, 'epoch': 0.06}\n",
            "{'loss': 12.3882, 'grad_norm': 1.022977352142334, 'learning_rate': 0.07272727272727274, 'epoch': 0.07}\n",
            "{'loss': 28.0602, 'grad_norm': 1.5079351663589478, 'learning_rate': 0.08181818181818183, 'epoch': 0.08}\n",
            "{'loss': 2.9983, 'grad_norm': 0.22938472032546997, 'learning_rate': 0.09090909090909091, 'epoch': 0.09}\n",
            "{'loss': 7.2079, 'grad_norm': 0.3825397789478302, 'learning_rate': 0.1, 'epoch': 0.1}\n",
            "{'loss': 4.5127, 'grad_norm': 0.30486026406288147, 'learning_rate': 0.09999813776583147, 'epoch': 0.1}\n",
            "{'loss': 4.3068, 'grad_norm': 0.28099581599235535, 'learning_rate': 0.09999255120204248, 'epoch': 0.11}\n",
            "{'loss': 4.8648, 'grad_norm': 0.5451489090919495, 'learning_rate': 0.09998324072477266, 'epoch': 0.12}\n",
            "{'loss': 3.5289, 'grad_norm': 0.2395089566707611, 'learning_rate': 0.09997020702755353, 'epoch': 0.13}\n",
            "{'loss': 4.1572, 'grad_norm': 37.08003616333008, 'learning_rate': 0.09995345108125697, 'epoch': 0.14}\n",
            "{'loss': 3.3724, 'grad_norm': 0.3711232841014862, 'learning_rate': 0.0999329741340228, 'epoch': 0.14}\n",
            "{'loss': 2.9904, 'grad_norm': 1.094894528388977, 'learning_rate': 0.09990877771116588, 'epoch': 0.15}\n",
            "{'loss': 4.505, 'grad_norm': 60.734981536865234, 'learning_rate': 0.09988086361506239, 'epoch': 0.16}\n",
            "{'loss': 5.3374, 'grad_norm': 0.3910323679447174, 'learning_rate': 0.09984923392501567, 'epoch': 0.17}\n",
            "{'loss': 3.8815, 'grad_norm': 0.5031324625015259, 'learning_rate': 0.09981389099710132, 'epoch': 0.18}\n",
            "{'loss': 3.3436, 'grad_norm': 0.2652413845062256, 'learning_rate': 0.09977483746399167, 'epoch': 0.18}\n",
            "{'loss': 3.2754, 'grad_norm': 0.10983424633741379, 'learning_rate': 0.09973207623475965, 'epoch': 0.19}\n",
            "{'loss': 3.2287, 'grad_norm': 0.09717866778373718, 'learning_rate': 0.09968561049466214, 'epoch': 0.2}\n",
            "{'loss': 2.3102, 'grad_norm': 0.23921971023082733, 'learning_rate': 0.0996354437049027, 'epoch': 0.21}\n",
            "{'loss': 3.1678, 'grad_norm': 0.10628654807806015, 'learning_rate': 0.09958157960237375, 'epoch': 0.22}\n",
            "{'loss': 2.3291, 'grad_norm': 0.2548832297325134, 'learning_rate': 0.09952402219937817, 'epoch': 0.22}\n",
            "{'loss': 3.3088, 'grad_norm': 479.4089660644531, 'learning_rate': 0.09946277578333045, 'epoch': 0.23}\n",
            "{'loss': 2.6662, 'grad_norm': 0.09805972129106522, 'learning_rate': 0.09939784491643733, 'epoch': 0.24}\n",
            "{'loss': 3.7965, 'grad_norm': 0.22204822301864624, 'learning_rate': 0.09932923443535797, 'epoch': 0.25}\n",
            "{'loss': 3.2718, 'grad_norm': 0.07663271576166153, 'learning_rate': 0.09925694945084369, 'epoch': 0.26}\n",
            "{'loss': 3.1258, 'grad_norm': 0.2227196991443634, 'learning_rate': 0.09918099534735719, 'epoch': 0.26}\n",
            "{'loss': 3.279, 'grad_norm': 0.15040339529514313, 'learning_rate': 0.09910137778267153, 'epoch': 0.27}\n",
            "{'loss': 2.777, 'grad_norm': 0.20456235110759735, 'learning_rate': 0.09901810268744868, 'epoch': 0.28}\n",
            "{'loss': 2.9392, 'grad_norm': 0.11566001176834106, 'learning_rate': 0.09893117626479776, 'epoch': 0.29}\n",
            "{'loss': 2.3343, 'grad_norm': 0.0688520073890686, 'learning_rate': 0.09884060498981295, 'epoch': 0.3}\n",
            "{'loss': 3.5707, 'grad_norm': 0.14995771646499634, 'learning_rate': 0.09874639560909118, 'epoch': 0.3}\n",
            "{'loss': 2.6449, 'grad_norm': 0.08277498185634613, 'learning_rate': 0.09864855514022955, 'epoch': 0.31}\n",
            "{'loss': 2.9863, 'grad_norm': 0.09392359107732773, 'learning_rate': 0.0985470908713026, 'epoch': 0.32}\n",
            "{'loss': 2.9212, 'grad_norm': 0.30422475934028625, 'learning_rate': 0.09844201036031952, 'epoch': 0.33}\n",
            "{'loss': 3.0192, 'grad_norm': 0.16105936467647552, 'learning_rate': 0.09833332143466099, 'epoch': 0.34}\n",
            "{'loss': 3.6067, 'grad_norm': 0.19972430169582367, 'learning_rate': 0.09822103219049626, 'epoch': 0.34}\n",
            "{'loss': 3.0399, 'grad_norm': 0.10612478107213974, 'learning_rate': 0.09810515099218003, 'epoch': 0.35}\n",
            "{'loss': 2.8382, 'grad_norm': 0.04258151352405548, 'learning_rate': 0.09798568647162938, 'epoch': 0.36}\n",
            "{'loss': 2.8737, 'grad_norm': 0.04810909181833267, 'learning_rate': 0.0978626475276808, 'epoch': 0.37}\n",
            "{'loss': 3.002, 'grad_norm': 0.10986782610416412, 'learning_rate': 0.09773604332542729, 'epoch': 0.38}\n",
            "{'loss': 3.1263, 'grad_norm': 0.09115192294120789, 'learning_rate': 0.09760588329553571, 'epoch': 0.38}\n",
            "{'loss': 2.9492, 'grad_norm': 0.09568830579519272, 'learning_rate': 0.09747217713354428, 'epoch': 0.39}\n",
            "{'loss': 2.6674, 'grad_norm': 0.03596051037311554, 'learning_rate': 0.09733493479914031, 'epoch': 0.4}\n",
            "{'loss': 2.5147, 'grad_norm': 0.14177541434764862, 'learning_rate': 0.09719416651541839, 'epoch': 0.41}\n",
            "{'loss': 2.5162, 'grad_norm': 0.13318847119808197, 'learning_rate': 0.09704988276811882, 'epoch': 0.42}\n",
            "{'loss': 2.0979, 'grad_norm': 0.06386636942625046, 'learning_rate': 0.0969020943048466, 'epoch': 0.42}\n",
            "{'loss': 3.2846, 'grad_norm': 0.15918146073818207, 'learning_rate': 0.09675081213427075, 'epoch': 0.43}\n",
            "{'loss': 2.8527, 'grad_norm': 0.5166903734207153, 'learning_rate': 0.09659604752530435, 'epoch': 0.44}\n",
            "{'loss': 2.7744, 'grad_norm': 0.06866960227489471, 'learning_rate': 0.09643781200626511, 'epoch': 0.45}\n",
            "{'loss': 2.5601, 'grad_norm': 0.030132440850138664, 'learning_rate': 0.09627611736401667, 'epoch': 0.46}\n",
            "{'loss': 2.4689, 'grad_norm': 0.07305753231048584, 'learning_rate': 0.09611097564309053, 'epoch': 0.46}\n",
            "{'loss': 2.4246, 'grad_norm': 0.07254046201705933, 'learning_rate': 0.09594239914478886, 'epoch': 0.47}\n",
            "{'loss': 2.7345, 'grad_norm': 0.02774255909025669, 'learning_rate': 0.09577040042626833, 'epoch': 0.48}\n",
            "{'loss': 2.5191, 'grad_norm': 0.03658417612314224, 'learning_rate': 0.09559499229960451, 'epoch': 0.49}\n",
            "{'loss': 2.6523, 'grad_norm': 0.042083773761987686, 'learning_rate': 0.0954161878308377, 'epoch': 0.5}\n",
            "{'loss': 2.3392, 'grad_norm': 0.03495749086141586, 'learning_rate': 0.09523400033899956, 'epoch': 0.5}\n",
            "{'loss': 2.3616, 'grad_norm': 0.020329570397734642, 'learning_rate': 0.09504844339512096, 'epoch': 0.51}\n",
            "{'loss': 2.6554, 'grad_norm': 0.04760196432471275, 'learning_rate': 0.09485953082122117, 'epoch': 0.52}\n",
            "{'loss': 2.2074, 'grad_norm': 0.07252763956785202, 'learning_rate': 0.09466727668927816, 'epoch': 0.53}\n",
            "{'loss': 2.7788, 'grad_norm': 0.05314268916845322, 'learning_rate': 0.0944716953201805, 'epoch': 0.54}\n",
            "{'loss': 2.0668, 'grad_norm': 0.05263783037662506, 'learning_rate': 0.0942728012826605, 'epoch': 0.54}\n",
            "{'loss': 2.097, 'grad_norm': 0.02917858399450779, 'learning_rate': 0.09407060939220907, 'epoch': 0.55}\n",
            "{'loss': 2.7202, 'grad_norm': 0.10995621979236603, 'learning_rate': 0.0938651347099721, 'epoch': 0.56}\n",
            "{'loss': 2.1493, 'grad_norm': 0.014126324094831944, 'learning_rate': 0.09365639254162855, 'epoch': 0.57}\n",
            "{'loss': 2.6371, 'grad_norm': 0.06563560664653778, 'learning_rate': 0.09344439843625034, 'epoch': 0.58}\n",
            "{'loss': 2.0541, 'grad_norm': 0.10126721858978271, 'learning_rate': 0.09322916818514414, 'epoch': 0.58}\n",
            "{'loss': 2.4482, 'grad_norm': 0.04774952679872513, 'learning_rate': 0.09301071782067505, 'epoch': 0.59}\n",
            "{'loss': 2.6567, 'grad_norm': 0.08727724850177765, 'learning_rate': 0.09278906361507239, 'epoch': 0.6}\n",
            "{'loss': 1.8814, 'grad_norm': 0.08793564885854721, 'learning_rate': 0.09256422207921756, 'epoch': 0.61}\n",
            "{'loss': 3.189, 'grad_norm': 0.10597558319568634, 'learning_rate': 0.09233620996141421, 'epoch': 0.62}\n",
            "{'loss': 2.8622, 'grad_norm': 0.08120544999837875, 'learning_rate': 0.09210504424614059, 'epoch': 0.62}\n",
            "{'loss': 2.0647, 'grad_norm': 0.06306618452072144, 'learning_rate': 0.09187074215278444, 'epoch': 0.63}\n",
            "{'loss': 2.3641, 'grad_norm': 0.041965607553720474, 'learning_rate': 0.09163332113436032, 'epoch': 0.64}\n",
            "{'loss': 1.9111, 'grad_norm': 0.094728983938694, 'learning_rate': 0.09139279887620955, 'epoch': 0.65}\n",
            "{'loss': 2.61, 'grad_norm': 0.05603067949414253, 'learning_rate': 0.09114919329468282, 'epoch': 0.66}\n",
            "{'loss': 2.1489, 'grad_norm': 0.037899892777204514, 'learning_rate': 0.09090252253580565, 'epoch': 0.66}\n",
            "{'loss': 2.673, 'grad_norm': 0.11037140339612961, 'learning_rate': 0.09065280497392664, 'epoch': 0.67}\n",
            "{'loss': 2.8674, 'grad_norm': 0.08284750580787659, 'learning_rate': 0.09040005921034883, 'epoch': 0.68}\n",
            "{'loss': 2.4838, 'grad_norm': 0.07349655032157898, 'learning_rate': 0.09014430407194413, 'epoch': 0.69}\n",
            "{'loss': 2.6031, 'grad_norm': 0.028501782566308975, 'learning_rate': 0.08988555860975082, 'epoch': 0.7}\n",
            "{'loss': 2.8135, 'grad_norm': 0.608971118927002, 'learning_rate': 0.08962384209755453, 'epoch': 0.7}\n",
            "{'loss': 2.5346, 'grad_norm': 0.10772711783647537, 'learning_rate': 0.08935917403045252, 'epoch': 0.71}\n",
            "{'loss': 2.3139, 'grad_norm': 0.26086047291755676, 'learning_rate': 0.0890915741234015, 'epoch': 0.72}\n",
            "{'loss': 2.3094, 'grad_norm': 0.058719269931316376, 'learning_rate': 0.0888210623097491, 'epoch': 0.73}\n",
            "{'loss': 2.25, 'grad_norm': 0.05568862706422806, 'learning_rate': 0.08854765873974899, 'epoch': 0.74}\n",
            "{'loss': 3.5752, 'grad_norm': 0.19410686194896698, 'learning_rate': 0.08827138377905999, 'epoch': 0.74}\n",
            "{'loss': 2.96, 'grad_norm': 0.41941651701927185, 'learning_rate': 0.08799225800722894, 'epoch': 0.75}\n",
            "{'loss': 2.4196, 'grad_norm': 0.28997254371643066, 'learning_rate': 0.08771030221615786, 'epoch': 0.76}\n",
            "{'loss': 3.6416, 'grad_norm': 0.2424771934747696, 'learning_rate': 0.08742553740855506, 'epoch': 0.77}\n",
            "{'loss': 2.8112, 'grad_norm': 0.7647333741188049, 'learning_rate': 0.08713798479637072, 'epoch': 0.78}\n",
            "{'loss': 2.5193, 'grad_norm': 0.05510156601667404, 'learning_rate': 0.08684766579921684, 'epoch': 0.78}\n",
            "{'loss': 1.9917, 'grad_norm': 0.028713418170809746, 'learning_rate': 0.08655460204277166, 'epoch': 0.79}\n",
            "{'loss': 3.1565, 'grad_norm': 0.12363536655902863, 'learning_rate': 0.08625881535716884, 'epoch': 0.8}\n",
            "{'loss': 2.2972, 'grad_norm': 0.06790873408317566, 'learning_rate': 0.08596032777537123, 'epoch': 0.81}\n",
            "{'loss': 4.7561, 'grad_norm': 0.23866556584835052, 'learning_rate': 0.08565916153152982, 'epoch': 0.82}\n",
            "{'loss': 1.9875, 'grad_norm': 0.04039603844285011, 'learning_rate': 0.08535533905932738, 'epoch': 0.82}\n",
            "{'loss': 2.456, 'grad_norm': 0.10234642028808594, 'learning_rate': 0.08504888299030748, 'epoch': 0.83}\n",
            "{'loss': 2.5759, 'grad_norm': 0.07590974867343903, 'learning_rate': 0.08473981615218862, 'epoch': 0.84}\n",
            "{'loss': 2.5208, 'grad_norm': 0.13976944983005524, 'learning_rate': 0.08442816156716386, 'epoch': 0.85}\n",
            "{'loss': 2.8937, 'grad_norm': 0.10621481388807297, 'learning_rate': 0.08411394245018589, 'epoch': 0.86}\n",
            "{'loss': 2.158, 'grad_norm': 0.10215692222118378, 'learning_rate': 0.08379718220723772, 'epoch': 0.86}\n",
            "{'loss': 2.2447, 'grad_norm': 0.231354758143425, 'learning_rate': 0.0834779044335893, 'epoch': 0.87}\n",
            "{'loss': 3.5361, 'grad_norm': 0.16775335371494293, 'learning_rate': 0.08315613291203977, 'epoch': 0.88}\n",
            "{'loss': 3.3479, 'grad_norm': 0.16160941123962402, 'learning_rate': 0.08283189161114601, 'epoch': 0.89}\n",
            "{'loss': 1.8702, 'grad_norm': 1.3300280570983887, 'learning_rate': 0.08250520468343721, 'epoch': 0.9}\n",
            "{'loss': 2.0517, 'grad_norm': 0.5917739272117615, 'learning_rate': 0.08217609646361573, 'epoch': 0.9}\n",
            "{'loss': 2.3185, 'grad_norm': 4.132875919342041, 'learning_rate': 0.08184459146674447, 'epoch': 0.91}\n",
            "{'loss': 2.7734, 'grad_norm': 0.13589775562286377, 'learning_rate': 0.08151071438642069, 'epoch': 0.92}\n",
            "{'loss': 2.6085, 'grad_norm': 0.1369786113500595, 'learning_rate': 0.08117449009293669, 'epoch': 0.93}\n",
            "{'loss': 2.4855, 'grad_norm': 0.056666310876607895, 'learning_rate': 0.08083594363142717, 'epoch': 0.94}\n",
            "{'loss': 2.9099, 'grad_norm': 0.0717952772974968, 'learning_rate': 0.08049510022000364, 'epoch': 0.94}\n",
            "{'loss': 2.7809, 'grad_norm': 0.04866071417927742, 'learning_rate': 0.08015198524787602, 'epoch': 0.95}\n",
            "{'loss': 2.1967, 'grad_norm': 0.08787432312965393, 'learning_rate': 0.07980662427346127, 'epoch': 0.96}\n",
            "{'loss': 1.9136, 'grad_norm': 0.06737615913152695, 'learning_rate': 0.07945904302247969, 'epoch': 0.97}\n",
            "{'loss': 2.2634, 'grad_norm': 0.03363899514079094, 'learning_rate': 0.07910926738603855, 'epoch': 0.98}\n",
            "{'loss': 2.9761, 'grad_norm': 0.1272144913673401, 'learning_rate': 0.07875732341870349, 'epoch': 0.98}\n",
            "{'loss': 2.3284, 'grad_norm': 0.05921373516321182, 'learning_rate': 0.0784032373365578, 'epoch': 0.99}\n",
            "{'loss': 3.5688, 'grad_norm': 0.1639065444469452, 'learning_rate': 0.07804703551524948, 'epoch': 1.0}\n",
            "{'loss': 2.441, 'grad_norm': 0.06422821432352066, 'learning_rate': 0.07768874448802665, 'epoch': 1.01}\n",
            "{'loss': 3.0064, 'grad_norm': 0.12427446246147156, 'learning_rate': 0.07732839094376105, 'epoch': 1.02}\n",
            "{'loss': 2.7558, 'grad_norm': 0.11545941233634949, 'learning_rate': 0.07696600172495997, 'epoch': 1.02}\n",
            "{'loss': 2.7658, 'grad_norm': 0.07309368997812271, 'learning_rate': 0.07660160382576683, 'epoch': 1.03}\n",
            "{'loss': 2.3876, 'grad_norm': 0.12233009189367294, 'learning_rate': 0.0762352243899504, 'epoch': 1.04}\n",
            "{'loss': 2.8208, 'grad_norm': 0.06308339536190033, 'learning_rate': 0.07586689070888285, 'epoch': 1.05}\n",
            "{'loss': 2.3712, 'grad_norm': 0.05810749530792236, 'learning_rate': 0.07549663021950681, 'epoch': 1.06}\n",
            "{'loss': 2.4053, 'grad_norm': 0.07680553942918777, 'learning_rate': 0.07512447050229165, 'epoch': 1.06}\n",
            "{'loss': 2.55, 'grad_norm': 0.07562720030546188, 'learning_rate': 0.07475043927917907, 'epoch': 1.07}\n",
            "{'loss': 2.8286, 'grad_norm': 0.10650027543306351, 'learning_rate': 0.074374564411518, 'epoch': 1.08}\n",
            "{'loss': 1.9117, 'grad_norm': 2.2541372776031494, 'learning_rate': 0.07399687389798933, 'epoch': 1.09}\n",
            "{'loss': 2.3068, 'grad_norm': 0.07793550938367844, 'learning_rate': 0.07361739587252018, 'epoch': 1.1}\n",
            "{'loss': 2.0567, 'grad_norm': 0.24292172491550446, 'learning_rate': 0.07323615860218843, 'epoch': 1.1}\n",
            "{'loss': 2.1294, 'grad_norm': 0.061493001878261566, 'learning_rate': 0.07285319048511689, 'epoch': 1.11}\n",
            "{'loss': 1.8495, 'grad_norm': 0.018444592133164406, 'learning_rate': 0.07246852004835806, 'epoch': 1.12}\n",
            "{'loss': 3.323, 'grad_norm': 0.15203231573104858, 'learning_rate': 0.07208217594576923, 'epoch': 1.13}\n",
            "{'loss': 2.5314, 'grad_norm': 0.07975039631128311, 'learning_rate': 0.07169418695587791, 'epoch': 1.14}\n",
            "{'loss': 2.1302, 'grad_norm': 0.48721417784690857, 'learning_rate': 0.07130458197973828, 'epoch': 1.14}\n",
            "{'loss': 1.9011, 'grad_norm': 0.09345223754644394, 'learning_rate': 0.07091339003877827, 'epoch': 1.15}\n",
            "{'loss': 2.5906, 'grad_norm': 0.04712485522031784, 'learning_rate': 0.07052064027263785, 'epoch': 1.16}\n",
            "{'loss': 2.7138, 'grad_norm': 0.07379575818777084, 'learning_rate': 0.07012636193699838, 'epoch': 1.17}\n",
            "{'loss': 2.5817, 'grad_norm': 0.8486018180847168, 'learning_rate': 0.06973058440140341, 'epoch': 1.18}\n",
            "{'loss': 2.5952, 'grad_norm': 110.13957977294922, 'learning_rate': 0.06933333714707095, 'epoch': 1.18}\n",
            "{'loss': 2.592, 'grad_norm': 0.17967678606510162, 'learning_rate': 0.06893464976469739, 'epoch': 1.19}\n",
            "{'loss': 2.4309, 'grad_norm': 0.045091412961483, 'learning_rate': 0.06853455195225339, 'epoch': 1.2}\n",
            "{'loss': 2.6914, 'grad_norm': 0.05723154544830322, 'learning_rate': 0.0681330735127716, 'epoch': 1.21}\n",
            "{'loss': 2.033, 'grad_norm': 0.03481149673461914, 'learning_rate': 0.06773024435212678, 'epoch': 1.22}\n",
            "{'loss': 2.1483, 'grad_norm': 0.027383927255868912, 'learning_rate': 0.067326094476808, 'epoch': 1.22}\n",
            "{'loss': 2.4578, 'grad_norm': 0.05605950951576233, 'learning_rate': 0.06692065399168352, 'epoch': 1.23}\n",
            "{'loss': 3.2797, 'grad_norm': 0.18092428147792816, 'learning_rate': 0.06651395309775836, 'epoch': 1.24}\n",
            "{'loss': 2.1136, 'grad_norm': 3.062000274658203, 'learning_rate': 0.06610602208992454, 'epoch': 1.25}\n",
            "{'loss': 2.3687, 'grad_norm': 0.0159455556422472, 'learning_rate': 0.06569689135470451, 'epoch': 1.26}\n",
            "{'loss': 2.4879, 'grad_norm': 0.0644545629620552, 'learning_rate': 0.06528659136798765, 'epoch': 1.26}\n",
            "{'loss': 2.405, 'grad_norm': 0.05606822669506073, 'learning_rate': 0.06487515269276016, 'epoch': 1.27}\n",
            "{'loss': 2.6079, 'grad_norm': 0.032919492572546005, 'learning_rate': 0.06446260597682839, 'epoch': 1.28}\n",
            "{'loss': 2.1926, 'grad_norm': 75.17817687988281, 'learning_rate': 0.06404898195053597, 'epoch': 1.29}\n",
            "{'loss': 2.6135, 'grad_norm': 0.023275263607501984, 'learning_rate': 0.06363431142447469, 'epoch': 1.3}\n",
            "{'loss': 2.1514, 'grad_norm': 0.06519079208374023, 'learning_rate': 0.06321862528718945, 'epoch': 1.3}\n",
            "{'loss': 1.834, 'grad_norm': 0.06551402807235718, 'learning_rate': 0.06280195450287736, 'epoch': 1.31}\n",
            "{'loss': 3.1848, 'grad_norm': 0.13619153201580048, 'learning_rate': 0.0623843301090813, 'epoch': 1.32}\n",
            "{'loss': 2.3193, 'grad_norm': 0.03630076348781586, 'learning_rate': 0.061965783214377894, 'epoch': 1.33}\n",
            "{'loss': 1.9348, 'grad_norm': 0.02170266956090927, 'learning_rate': 0.06154634499606029, 'epoch': 1.34}\n",
            "{'loss': 2.8542, 'grad_norm': 0.11269353330135345, 'learning_rate': 0.06112604669781572, 'epoch': 1.34}\n",
            "{'loss': 2.086, 'grad_norm': 0.04561050608754158, 'learning_rate': 0.0607049196273983, 'epoch': 1.35}\n",
            "{'loss': 2.1025, 'grad_norm': 0.06588181853294373, 'learning_rate': 0.06028299515429683, 'epoch': 1.36}\n",
            "{'loss': 2.2433, 'grad_norm': 0.06351125985383987, 'learning_rate': 0.05986030470739811, 'epoch': 1.37}\n",
            "{'loss': 2.3163, 'grad_norm': 0.01899893209338188, 'learning_rate': 0.059436879772645834, 'epoch': 1.38}\n",
            "{'loss': 1.9468, 'grad_norm': 0.17280039191246033, 'learning_rate': 0.0590127518906953, 'epoch': 1.38}\n",
            "{'loss': 2.3028, 'grad_norm': 0.045071281492710114, 'learning_rate': 0.05858795265456382, 'epoch': 1.39}\n",
            "{'loss': 2.3981, 'grad_norm': 0.07113705575466156, 'learning_rate': 0.05816251370727748, 'epoch': 1.4}\n",
            "{'loss': 2.4935, 'grad_norm': 0.07548987120389938, 'learning_rate': 0.05773646673951406, 'epoch': 1.41}\n",
            "{'loss': 1.9475, 'grad_norm': 0.022847875952720642, 'learning_rate': 0.05730984348724242, 'epoch': 1.42}\n",
            "{'loss': 2.0495, 'grad_norm': 0.018156856298446655, 'learning_rate': 0.05688267572935843, 'epoch': 1.42}\n",
            "{'loss': 2.051, 'grad_norm': 0.03525703772902489, 'learning_rate': 0.05645499528531785, 'epoch': 1.43}\n",
            "{'loss': 1.8633, 'grad_norm': 0.11093275249004364, 'learning_rate': 0.05602683401276615, 'epoch': 1.44}\n",
            "{'loss': 2.051, 'grad_norm': 0.036554351449012756, 'learning_rate': 0.055598223805165395, 'epoch': 1.45}\n",
            "{'loss': 2.1173, 'grad_norm': 0.0435955636203289, 'learning_rate': 0.055169196589418504, 'epoch': 1.46}\n",
            "{'loss': 1.8134, 'grad_norm': 0.08504948765039444, 'learning_rate': 0.054739784323491116, 'epoch': 1.46}\n",
            "{'loss': 1.7561, 'grad_norm': 0.027245132252573967, 'learning_rate': 0.05431001899403098, 'epoch': 1.47}\n",
            "{'loss': 2.1505, 'grad_norm': 0.04012395069003105, 'learning_rate': 0.05387993261398532, 'epoch': 1.48}\n",
            "{'loss': 2.1686, 'grad_norm': 0.05435020104050636, 'learning_rate': 0.05344955722021624, 'epoch': 1.49}\n",
            "{'loss': 1.8017, 'grad_norm': 0.06052239611744881, 'learning_rate': 0.05301892487111431, 'epoch': 1.5}\n",
            "{'loss': 1.9777, 'grad_norm': 0.05634856969118118, 'learning_rate': 0.05258806764421048, 'epoch': 1.5}\n",
            "{'loss': 1.9388, 'grad_norm': 0.014874489977955818, 'learning_rate': 0.05215701763378673, 'epoch': 1.51}\n",
            "{'loss': 1.7816, 'grad_norm': 0.14083361625671387, 'learning_rate': 0.051725806948485414, 'epoch': 1.52}\n",
            "{'loss': 1.9059, 'grad_norm': 0.983980655670166, 'learning_rate': 0.05129446770891738, 'epoch': 1.53}\n",
            "{'loss': 1.9645, 'grad_norm': 0.01824497990310192, 'learning_rate': 0.05086303204526943, 'epoch': 1.54}\n",
            "{'loss': 1.5638, 'grad_norm': 0.036702100187540054, 'learning_rate': 0.05043153209491095, 'epoch': 1.54}\n",
            "{'loss': 1.9818, 'grad_norm': 0.020493218675255775, 'learning_rate': 0.05, 'epoch': 1.55}\n",
            "{'loss': 2.6876, 'grad_norm': 0.08001146465539932, 'learning_rate': 0.049568467905089064, 'epoch': 1.56}\n",
            "{'loss': 1.8354, 'grad_norm': 0.018298886716365814, 'learning_rate': 0.049136967954730576, 'epoch': 1.57}\n",
            "{'loss': 1.8497, 'grad_norm': 0.020906247198581696, 'learning_rate': 0.04870553229108264, 'epoch': 1.58}\n",
            "{'loss': 1.7314, 'grad_norm': 0.04371422156691551, 'learning_rate': 0.04827419305151461, 'epoch': 1.58}\n",
            "{'loss': 1.9307, 'grad_norm': 0.024522053077816963, 'learning_rate': 0.047842982366213274, 'epoch': 1.59}\n",
            "{'loss': 1.5482, 'grad_norm': 0.03742218017578125, 'learning_rate': 0.04741193235578953, 'epoch': 1.6}\n",
            "{'loss': 2.0846, 'grad_norm': 0.02231007069349289, 'learning_rate': 0.04698107512888569, 'epoch': 1.61}\n",
            "{'loss': 1.6408, 'grad_norm': 0.00998925045132637, 'learning_rate': 0.046550442779783756, 'epoch': 1.62}\n",
            "{'loss': 1.7189, 'grad_norm': 0.021515248343348503, 'learning_rate': 0.04612006738601469, 'epoch': 1.62}\n",
            "{'loss': 1.8839, 'grad_norm': 0.03938181698322296, 'learning_rate': 0.04568998100596903, 'epoch': 1.63}\n",
            "{'loss': 2.3295, 'grad_norm': 0.05335693433880806, 'learning_rate': 0.0452602156765089, 'epoch': 1.64}\n",
            "{'loss': 1.7391, 'grad_norm': 0.016600366681814194, 'learning_rate': 0.0448308034105815, 'epoch': 1.65}\n",
            "{'loss': 1.7044, 'grad_norm': 0.050037700682878494, 'learning_rate': 0.04440177619483461, 'epoch': 1.66}\n",
            "{'loss': 1.6636, 'grad_norm': 0.049726903438568115, 'learning_rate': 0.04397316598723386, 'epoch': 1.66}\n",
            "{'loss': 1.956, 'grad_norm': 0.026215719059109688, 'learning_rate': 0.04354500471468217, 'epoch': 1.67}\n",
            "{'loss': 1.9337, 'grad_norm': 0.014692943543195724, 'learning_rate': 0.043117324270641605, 'epoch': 1.68}\n",
            "{'loss': 2.0515, 'grad_norm': 0.0215633325278759, 'learning_rate': 0.04269015651275761, 'epoch': 1.69}\n",
            "{'loss': 1.7091, 'grad_norm': 0.028612157329916954, 'learning_rate': 0.04226353326048593, 'epoch': 1.7}\n",
            "{'loss': 1.5261, 'grad_norm': 0.03932511433959007, 'learning_rate': 0.041837486292722534, 'epoch': 1.7}\n",
            "{'loss': 2.7318, 'grad_norm': 0.08939334005117416, 'learning_rate': 0.041412047345436194, 'epoch': 1.71}\n",
            "{'loss': 1.8646, 'grad_norm': 0.02998240292072296, 'learning_rate': 0.040987248109304715, 'epoch': 1.72}\n",
            "{'loss': 2.0871, 'grad_norm': 0.04817362502217293, 'learning_rate': 0.04056312022735417, 'epoch': 1.73}\n",
            "{'loss': 1.5826, 'grad_norm': 0.06111382693052292, 'learning_rate': 0.040139695292601904, 'epoch': 1.74}\n",
            "{'loss': 1.9291, 'grad_norm': 0.01900133118033409, 'learning_rate': 0.039717004845703174, 'epoch': 1.74}\n",
            "{'loss': 1.98, 'grad_norm': 0.016127830371260643, 'learning_rate': 0.0392950803726017, 'epoch': 1.75}\n",
            "{'loss': 1.7235, 'grad_norm': 0.04543444514274597, 'learning_rate': 0.03887395330218429, 'epoch': 1.76}\n",
            "{'loss': 2.1554, 'grad_norm': 0.047026626765728, 'learning_rate': 0.03845365500393974, 'epoch': 1.77}\n",
            "{'loss': 1.9227, 'grad_norm': 0.028577983379364014, 'learning_rate': 0.03803421678562213, 'epoch': 1.78}\n",
            "{'loss': 2.0195, 'grad_norm': 0.01700260490179062, 'learning_rate': 0.037615669890918704, 'epoch': 1.78}\n",
            "{'loss': 1.6629, 'grad_norm': 0.047032084316015244, 'learning_rate': 0.03719804549712265, 'epoch': 1.79}\n",
            "{'loss': 1.5491, 'grad_norm': 0.029245151206851006, 'learning_rate': 0.03678137471281056, 'epoch': 1.8}\n",
            "{'loss': 1.6737, 'grad_norm': 0.023148197680711746, 'learning_rate': 0.036365688575525315, 'epoch': 1.81}\n",
            "{'loss': 1.7056, 'grad_norm': 0.027943890541791916, 'learning_rate': 0.03595101804946404, 'epoch': 1.82}\n",
            "{'loss': 2.0167, 'grad_norm': 0.04350205138325691, 'learning_rate': 0.035537394023171624, 'epoch': 1.82}\n",
            "{'loss': 1.3421, 'grad_norm': 0.017754163593053818, 'learning_rate': 0.03512484730723986, 'epoch': 1.83}\n",
            "{'loss': 1.9329, 'grad_norm': 0.045663267374038696, 'learning_rate': 0.03471340863201237, 'epoch': 1.84}\n",
            "{'loss': 1.8098, 'grad_norm': 0.023192496970295906, 'learning_rate': 0.0343031086452955, 'epoch': 1.85}\n",
            "{'loss': 1.4262, 'grad_norm': 0.011588403023779392, 'learning_rate': 0.03389397791007548, 'epoch': 1.86}\n",
            "{'loss': 2.0605, 'grad_norm': 0.046171557158231735, 'learning_rate': 0.03348604690224166, 'epoch': 1.86}\n",
            "{'loss': 1.9552, 'grad_norm': 0.03713107109069824, 'learning_rate': 0.03307934600831648, 'epoch': 1.87}\n",
            "{'loss': 1.795, 'grad_norm': 0.023409541696310043, 'learning_rate': 0.032673905523192, 'epoch': 1.88}\n",
            "{'loss': 2.1981, 'grad_norm': 0.044156964868307114, 'learning_rate': 0.03226975564787322, 'epoch': 1.89}\n",
            "{'loss': 1.6285, 'grad_norm': 4.094969272613525, 'learning_rate': 0.0318669264872284, 'epoch': 1.9}\n",
            "{'loss': 1.6658, 'grad_norm': 0.08041489869356155, 'learning_rate': 0.031465448047746626, 'epoch': 1.9}\n",
            "{'loss': 1.6245, 'grad_norm': 0.06175902113318443, 'learning_rate': 0.03106535023530262, 'epoch': 1.91}\n",
            "{'loss': 1.5361, 'grad_norm': 0.07329872995615005, 'learning_rate': 0.03066666285292906, 'epoch': 1.92}\n",
            "{'loss': 1.3924, 'grad_norm': 0.046892598271369934, 'learning_rate': 0.0302694155985966, 'epoch': 1.93}\n",
            "{'loss': 1.5376, 'grad_norm': 0.05122711881995201, 'learning_rate': 0.02987363806300163, 'epoch': 1.94}\n",
            "{'loss': 1.6218, 'grad_norm': 0.028157051652669907, 'learning_rate': 0.02947935972736217, 'epoch': 1.94}\n",
            "{'loss': 1.65, 'grad_norm': 0.03264305368065834, 'learning_rate': 0.029086609961221754, 'epoch': 1.95}\n",
            "{'loss': 1.3418, 'grad_norm': 0.02473900467157364, 'learning_rate': 0.028695418020261754, 'epoch': 1.96}\n",
            "{'loss': 1.8677, 'grad_norm': 0.04562465101480484, 'learning_rate': 0.028305813044122097, 'epoch': 1.97}\n",
            "{'loss': 1.7225, 'grad_norm': 0.03475731611251831, 'learning_rate': 0.027917824054230784, 'epoch': 1.98}\n",
            "{'loss': 1.5476, 'grad_norm': 0.027998363599181175, 'learning_rate': 0.027531479951641926, 'epoch': 1.98}\n",
            "{'loss': 1.4793, 'grad_norm': 0.030004575848579407, 'learning_rate': 0.02714680951488312, 'epoch': 1.99}\n",
            "{'loss': 1.4614, 'grad_norm': 0.0228355061262846, 'learning_rate': 0.026763841397811572, 'epoch': 2.0}\n",
            "{'loss': 1.749, 'grad_norm': 0.03629405051469803, 'learning_rate': 0.026382604127479815, 'epoch': 2.01}\n",
            "{'loss': 1.9811, 'grad_norm': 0.053138166666030884, 'learning_rate': 0.026003126102010693, 'epoch': 2.02}\n",
            "{'loss': 1.274, 'grad_norm': 0.015164672397077084, 'learning_rate': 0.025625435588482015, 'epoch': 2.02}\n",
            "{'loss': 1.0903, 'grad_norm': 0.05607321858406067, 'learning_rate': 0.02524956072082093, 'epoch': 2.03}\n",
            "{'loss': 1.5882, 'grad_norm': 0.027420690283179283, 'learning_rate': 0.024875529497708354, 'epoch': 2.04}\n",
            "{'loss': 1.8146, 'grad_norm': 0.026680834591388702, 'learning_rate': 0.02450336978049322, 'epoch': 2.05}\n",
            "{'loss': 1.4176, 'grad_norm': 0.026877492666244507, 'learning_rate': 0.024133109291117158, 'epoch': 2.06}\n",
            "{'loss': 1.5526, 'grad_norm': 0.03236936032772064, 'learning_rate': 0.0237647756100496, 'epoch': 2.06}\n",
            "{'loss': 1.3453, 'grad_norm': 0.023758282884955406, 'learning_rate': 0.02339839617423318, 'epoch': 2.07}\n",
            "{'loss': 1.5565, 'grad_norm': 0.02468426153063774, 'learning_rate': 0.023033998275040046, 'epoch': 2.08}\n",
            "{'loss': 1.4313, 'grad_norm': 0.042276788502931595, 'learning_rate': 0.022671609056238953, 'epoch': 2.09}\n",
            "{'loss': 1.5879, 'grad_norm': 0.020409800112247467, 'learning_rate': 0.022311255511973344, 'epoch': 2.1}\n",
            "{'loss': 1.192, 'grad_norm': 0.01974959298968315, 'learning_rate': 0.021952964484750526, 'epoch': 2.1}\n",
            "{'loss': 1.425, 'grad_norm': 0.04123825579881668, 'learning_rate': 0.021596762663442216, 'epoch': 2.11}\n",
            "{'loss': 1.3633, 'grad_norm': 0.01598276197910309, 'learning_rate': 0.021242676581296527, 'epoch': 2.12}\n",
            "{'loss': 1.6113, 'grad_norm': 0.030426019802689552, 'learning_rate': 0.020890732613961478, 'epoch': 2.13}\n",
            "{'loss': 1.6527, 'grad_norm': 0.023207882419228554, 'learning_rate': 0.02054095697752032, 'epoch': 2.14}\n",
            "{'loss': 1.1953, 'grad_norm': 0.021865498274564743, 'learning_rate': 0.02019337572653874, 'epoch': 2.14}\n",
            "{'loss': 1.2513, 'grad_norm': 0.014629049226641655, 'learning_rate': 0.01984801475212398, 'epoch': 2.15}\n",
            "{'loss': 1.4254, 'grad_norm': 0.03407499939203262, 'learning_rate': 0.019504899779996355, 'epoch': 2.16}\n",
            "{'loss': 1.1972, 'grad_norm': 0.02082895301282406, 'learning_rate': 0.019164056368572848, 'epoch': 2.17}\n",
            "{'loss': 1.2231, 'grad_norm': 0.015772154554724693, 'learning_rate': 0.018825509907063328, 'epoch': 2.18}\n",
            "{'loss': 1.1512, 'grad_norm': 0.013096729293465614, 'learning_rate': 0.018489285613579327, 'epoch': 2.18}\n",
            "{'loss': 1.2084, 'grad_norm': 0.017416175454854965, 'learning_rate': 0.018155408533255552, 'epoch': 2.19}\n",
            "{'loss': 1.4381, 'grad_norm': 0.05525516718626022, 'learning_rate': 0.017823903536384262, 'epoch': 2.2}\n",
            "{'loss': 1.1499, 'grad_norm': 0.014278148300945759, 'learning_rate': 0.01749479531656279, 'epoch': 2.21}\n",
            "{'loss': 1.3262, 'grad_norm': 0.020318007096648216, 'learning_rate': 0.017168108388854, 'epoch': 2.22}\n",
            "{'loss': 1.405, 'grad_norm': 0.02324838750064373, 'learning_rate': 0.016843867087960252, 'epoch': 2.22}\n",
            "{'loss': 1.7908, 'grad_norm': 0.03276682645082474, 'learning_rate': 0.016522095566410728, 'epoch': 2.23}\n",
            "{'loss': 1.5454, 'grad_norm': 0.02259575016796589, 'learning_rate': 0.01620281779276228, 'epoch': 2.24}\n",
            "{'loss': 1.2753, 'grad_norm': 0.010581654496490955, 'learning_rate': 0.01588605754981413, 'epoch': 2.25}\n",
            "{'loss': 1.3665, 'grad_norm': 0.015719518065452576, 'learning_rate': 0.01557183843283614, 'epoch': 2.26}\n",
            "{'loss': 1.0156, 'grad_norm': 0.015055635944008827, 'learning_rate': 0.015260183847811382, 'epoch': 2.26}\n",
            "{'loss': 1.3439, 'grad_norm': 0.014589019119739532, 'learning_rate': 0.014951117009692528, 'epoch': 2.27}\n",
            "{'loss': 1.2489, 'grad_norm': 0.01673363894224167, 'learning_rate': 0.014644660940672627, 'epoch': 2.28}\n",
            "{'loss': 1.0629, 'grad_norm': 0.02187114767730236, 'learning_rate': 0.014340838468470197, 'epoch': 2.29}\n",
            "{'loss': 1.793, 'grad_norm': 0.06678074598312378, 'learning_rate': 0.014039672224628786, 'epoch': 2.3}\n",
            "{'loss': 1.2219, 'grad_norm': 0.018715444952249527, 'learning_rate': 0.01374118464283119, 'epoch': 2.3}\n",
            "{'loss': 1.2858, 'grad_norm': 0.05040258541703224, 'learning_rate': 0.01344539795722834, 'epoch': 2.31}\n",
            "{'loss': 1.0915, 'grad_norm': 0.017107367515563965, 'learning_rate': 0.013152334200783168, 'epoch': 2.32}\n",
            "{'loss': 1.0291, 'grad_norm': 0.022631505504250526, 'learning_rate': 0.012862015203629274, 'epoch': 2.33}\n",
            "{'loss': 1.2913, 'grad_norm': 0.01635710336267948, 'learning_rate': 0.012574462591444941, 'epoch': 2.34}\n",
            "{'loss': 1.0849, 'grad_norm': 0.00999990664422512, 'learning_rate': 0.012289697783842141, 'epoch': 2.34}\n",
            "{'loss': 1.4966, 'grad_norm': 0.025364099070429802, 'learning_rate': 0.012007741992771066, 'epoch': 2.35}\n",
            "{'loss': 1.0754, 'grad_norm': 0.009927265346050262, 'learning_rate': 0.011728616220940031, 'epoch': 2.36}\n",
            "{'loss': 1.257, 'grad_norm': 0.020529767498373985, 'learning_rate': 0.01145234126025102, 'epoch': 2.37}\n",
            "{'loss': 1.1515, 'grad_norm': 0.01573334075510502, 'learning_rate': 0.011178937690250919, 'epoch': 2.38}\n",
            "{'loss': 1.0745, 'grad_norm': 0.01296545471996069, 'learning_rate': 0.01090842587659851, 'epoch': 2.38}\n",
            "{'loss': 1.2927, 'grad_norm': 0.012735449708998203, 'learning_rate': 0.010640825969547497, 'epoch': 2.39}\n",
            "{'loss': 1.0944, 'grad_norm': 0.013720491901040077, 'learning_rate': 0.010376157902445489, 'epoch': 2.4}\n",
            "{'loss': 1.1595, 'grad_norm': 0.01600733771920204, 'learning_rate': 0.010114441390249203, 'epoch': 2.41}\n",
            "{'loss': 1.3573, 'grad_norm': 0.014017731882631779, 'learning_rate': 0.00985569592805588, 'epoch': 2.42}\n",
            "{'loss': 1.2857, 'grad_norm': 0.012485756538808346, 'learning_rate': 0.009599940789651179, 'epoch': 2.42}\n",
            "{'loss': 1.2771, 'grad_norm': 0.02329060435295105, 'learning_rate': 0.009347195026073368, 'epoch': 2.43}\n",
            "{'loss': 0.9478, 'grad_norm': 0.012545883655548096, 'learning_rate': 0.00909747746419436, 'epoch': 2.44}\n",
            "{'loss': 1.5148, 'grad_norm': 0.018012601882219315, 'learning_rate': 0.008850806705317182, 'epoch': 2.45}\n",
            "{'loss': 1.5325, 'grad_norm': 0.02693089097738266, 'learning_rate': 0.008607201123790459, 'epoch': 2.46}\n",
            "{'loss': 1.3664, 'grad_norm': 0.027625273913145065, 'learning_rate': 0.008366678865639687, 'epoch': 2.46}\n",
            "{'loss': 1.2128, 'grad_norm': 0.017545705661177635, 'learning_rate': 0.008129257847215571, 'epoch': 2.47}\n",
            "{'loss': 1.2375, 'grad_norm': 0.012485179118812084, 'learning_rate': 0.007894955753859413, 'epoch': 2.48}\n",
            "{'loss': 1.0006, 'grad_norm': 0.02016078680753708, 'learning_rate': 0.0076637900385857945, 'epoch': 2.49}\n",
            "{'loss': 1.4809, 'grad_norm': 0.031000323593616486, 'learning_rate': 0.007435777920782444, 'epoch': 2.5}\n",
            "{'loss': 1.2312, 'grad_norm': 0.03481345996260643, 'learning_rate': 0.00721093638492763, 'epoch': 2.5}\n",
            "{'loss': 1.2755, 'grad_norm': 0.014288466423749924, 'learning_rate': 0.006989282179324963, 'epoch': 2.51}\n",
            "{'loss': 1.0832, 'grad_norm': 0.01291587483137846, 'learning_rate': 0.006770831814855882, 'epoch': 2.52}\n",
            "{'loss': 1.6474, 'grad_norm': 0.051654234528541565, 'learning_rate': 0.006555601563749675, 'epoch': 2.53}\n",
            "{'loss': 1.5983, 'grad_norm': 0.03173329681158066, 'learning_rate': 0.006343607458371459, 'epoch': 2.54}\n",
            "{'loss': 1.3467, 'grad_norm': 0.013936628587543964, 'learning_rate': 0.0061348652900279025, 'epoch': 2.54}\n",
            "{'loss': 0.9987, 'grad_norm': 0.008127906359732151, 'learning_rate': 0.00592939060779093, 'epoch': 2.55}\n",
            "{'loss': 1.3463, 'grad_norm': 0.045413948595523834, 'learning_rate': 0.00572719871733951, 'epoch': 2.56}\n",
            "{'loss': 1.3005, 'grad_norm': 0.01433384045958519, 'learning_rate': 0.005528304679819513, 'epoch': 2.57}\n",
            "{'loss': 1.4164, 'grad_norm': 0.02443194016814232, 'learning_rate': 0.005332723310721855, 'epoch': 2.58}\n",
            "{'loss': 1.0971, 'grad_norm': 0.012100564315915108, 'learning_rate': 0.005140469178778845, 'epoch': 2.58}\n",
            "{'loss': 1.4169, 'grad_norm': 0.015625014901161194, 'learning_rate': 0.004951556604879049, 'epoch': 2.59}\n",
            "{'loss': 1.6723, 'grad_norm': 0.0237045306712389, 'learning_rate': 0.004765999661000442, 'epoch': 2.6}\n",
            "{'loss': 1.5813, 'grad_norm': 0.020696453750133514, 'learning_rate': 0.004583812169162299, 'epoch': 2.61}\n",
            "{'loss': 1.2759, 'grad_norm': 0.015502418391406536, 'learning_rate': 0.004405007700395497, 'epoch': 2.62}\n",
            "{'loss': 1.1498, 'grad_norm': 0.014471780508756638, 'learning_rate': 0.004229599573731685, 'epoch': 2.62}\n",
            "{'loss': 1.4776, 'grad_norm': 0.017629623413085938, 'learning_rate': 0.004057600855211141, 'epoch': 2.63}\n",
            "{'loss': 1.3507, 'grad_norm': 0.04772209748625755, 'learning_rate': 0.0038890243569094877, 'epoch': 2.64}\n",
            "{'loss': 1.0173, 'grad_norm': 0.010682967491447926, 'learning_rate': 0.003723882635983328, 'epoch': 2.65}\n",
            "{'loss': 1.2802, 'grad_norm': 0.031100744381546974, 'learning_rate': 0.0035621879937348835, 'epoch': 2.66}\n",
            "{'loss': 1.3145, 'grad_norm': 0.016547594219446182, 'learning_rate': 0.0034039524746956595, 'epoch': 2.66}\n",
            "{'loss': 1.0589, 'grad_norm': 0.01499991025775671, 'learning_rate': 0.003249187865729264, 'epoch': 2.67}\n",
            "{'loss': 1.2135, 'grad_norm': 0.013688619248569012, 'learning_rate': 0.003097905695153408, 'epoch': 2.68}\n",
            "{'loss': 1.2782, 'grad_norm': 0.014743341132998466, 'learning_rate': 0.002950117231881183, 'epoch': 2.69}\n",
            "{'loss': 1.0744, 'grad_norm': 0.010238038375973701, 'learning_rate': 0.0028058334845816216, 'epoch': 2.7}\n",
            "{'loss': 1.2497, 'grad_norm': 0.017913689836859703, 'learning_rate': 0.002665065200859707, 'epoch': 2.7}\n",
            "{'loss': 1.2749, 'grad_norm': 0.015731776133179665, 'learning_rate': 0.0025278228664557313, 'epoch': 2.71}\n",
            "{'loss': 1.2676, 'grad_norm': 0.011455440893769264, 'learning_rate': 0.002394116704464294, 'epoch': 2.72}\n",
            "{'loss': 1.5544, 'grad_norm': 0.019443679600954056, 'learning_rate': 0.0022639566745727203, 'epoch': 2.73}\n",
            "{'loss': 1.2037, 'grad_norm': 0.009767605923116207, 'learning_rate': 0.002137352472319215, 'epoch': 2.74}\n",
            "{'loss': 1.1643, 'grad_norm': 0.016220390796661377, 'learning_rate': 0.002014313528370626, 'epoch': 2.74}\n",
            "{'loss': 1.1047, 'grad_norm': 0.010962733998894691, 'learning_rate': 0.0018948490078199765, 'epoch': 2.75}\n",
            "{'loss': 1.0643, 'grad_norm': 0.022770393639802933, 'learning_rate': 0.0017789678095037455, 'epoch': 2.76}\n",
            "{'loss': 1.265, 'grad_norm': 0.011363491415977478, 'learning_rate': 0.001666678565339025, 'epoch': 2.77}\n",
            "{'loss': 1.4253, 'grad_norm': 0.01483161374926567, 'learning_rate': 0.0015579896396804961, 'epoch': 2.78}\n",
            "{'loss': 1.1628, 'grad_norm': 0.009855907410383224, 'learning_rate': 0.0014529091286973996, 'epoch': 2.78}\n",
            "{'loss': 1.0903, 'grad_norm': 6.814610958099365, 'learning_rate': 0.0013514448597704621, 'epoch': 2.79}\n",
            "{'loss': 1.1857, 'grad_norm': 0.019093189388513565, 'learning_rate': 0.0012536043909088192, 'epoch': 2.8}\n",
            "{'loss': 1.1514, 'grad_norm': 0.008197423070669174, 'learning_rate': 0.001159395010187042, 'epoch': 2.81}\n",
            "{'loss': 1.5757, 'grad_norm': 0.021639754995703697, 'learning_rate': 0.0010688237352022346, 'epoch': 2.82}\n",
            "{'loss': 1.1248, 'grad_norm': 0.014286641962826252, 'learning_rate': 0.0009818973125513275, 'epoch': 2.82}\n",
            "{'loss': 1.4334, 'grad_norm': 0.017347993329167366, 'learning_rate': 0.0008986222173284875, 'epoch': 2.83}\n",
            "{'loss': 1.2424, 'grad_norm': 0.02126779593527317, 'learning_rate': 0.0008190046526428241, 'epoch': 2.84}\n",
            "{'loss': 1.6986, 'grad_norm': 0.023666538298130035, 'learning_rate': 0.00074305054915631, 'epoch': 2.85}\n",
            "{'loss': 1.5397, 'grad_norm': 0.01921229064464569, 'learning_rate': 0.0006707655646420231, 'epoch': 2.86}\n",
            "{'loss': 1.3844, 'grad_norm': 0.017575468868017197, 'learning_rate': 0.0006021550835626777, 'epoch': 2.86}\n",
            "{'loss': 1.1422, 'grad_norm': 0.009238097816705704, 'learning_rate': 0.0005372242166695685, 'epoch': 2.87}\n",
            "{'loss': 1.3522, 'grad_norm': 0.011366235092282295, 'learning_rate': 0.00047597780062184073, 'epoch': 2.88}\n",
            "{'loss': 1.2172, 'grad_norm': 0.014327533543109894, 'learning_rate': 0.0004184203976262513, 'epoch': 2.89}\n",
            "{'loss': 1.2311, 'grad_norm': 0.012483477592468262, 'learning_rate': 0.0003645562950973014, 'epoch': 2.9}\n",
            "{'loss': 1.2503, 'grad_norm': 0.014773097820580006, 'learning_rate': 0.00031438950533786984, 'epoch': 2.9}\n",
            "{'loss': 1.1984, 'grad_norm': 0.0070965769700706005, 'learning_rate': 0.0002679237652403688, 'epoch': 2.91}\n",
            "{'loss': 1.2445, 'grad_norm': 0.023013288155198097, 'learning_rate': 0.0002251625360083387, 'epoch': 2.92}\n",
            "{'loss': 0.9698, 'grad_norm': 0.012677508406341076, 'learning_rate': 0.00018610900289867672, 'epoch': 2.93}\n",
            "{'loss': 1.233, 'grad_norm': 0.01254852395504713, 'learning_rate': 0.00015076607498433204, 'epoch': 2.94}\n",
            "{'loss': 1.5011, 'grad_norm': 0.019038818776607513, 'learning_rate': 0.00011913638493762369, 'epoch': 2.94}\n",
            "{'loss': 1.0747, 'grad_norm': 0.009585436433553696, 'learning_rate': 9.12222888341252e-05, 'epoch': 2.95}\n",
            "{'loss': 1.0748, 'grad_norm': 0.007987774908542633, 'learning_rate': 6.702586597719385e-05, 'epoch': 2.96}\n",
            "{'loss': 1.0648, 'grad_norm': 0.010348564013838768, 'learning_rate': 4.654891874303346e-05, 'epoch': 2.97}\n",
            "{'loss': 1.2592, 'grad_norm': 0.034953244030475616, 'learning_rate': 2.9792972446479606e-05, 'epoch': 2.98}\n",
            "{'loss': 1.1703, 'grad_norm': 0.022398749366402626, 'learning_rate': 1.6759275227357096e-05, 'epoch': 2.98}\n",
            "{'loss': 1.4346, 'grad_norm': 0.02078314498066902, 'learning_rate': 7.4487979575266206e-06, 'epoch': 2.99}\n",
            "{'loss': 1.616, 'grad_norm': 0.021786583587527275, 'learning_rate': 1.862234168542587e-06, 'epoch': 3.0}\n",
            "{'train_runtime': 48.7814, 'train_samples_per_second': 15.375, 'train_steps_per_second': 7.687, 'train_loss': 2.448689432621002, 'epoch': 3.0}\n",
            "100% 375/375 [00:48<00:00,  7.69it/s]\n",
            "Training complete.\n",
            "Model saved to loras/self-edit/training_set_iteration_1/8be77c9e/8\n",
            "Training on 250 examples for 3 epochs, lr: 0.1\n",
            "No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n",
            "Starting training...\n",
            "{'loss': 6.9193, 'grad_norm': 8.76836109161377, 'learning_rate': 0.0, 'epoch': 0.01}\n",
            "{'loss': 6.5188, 'grad_norm': 8.714265823364258, 'learning_rate': 0.009090909090909092, 'epoch': 0.02}\n",
            "{'loss': 4.1123, 'grad_norm': 19.360837936401367, 'learning_rate': 0.018181818181818184, 'epoch': 0.02}\n",
            "{'loss': 5.5646, 'grad_norm': 12.27811336517334, 'learning_rate': 0.02727272727272727, 'epoch': 0.03}\n",
            "{'loss': 30.4933, 'grad_norm': 72.93162536621094, 'learning_rate': 0.03636363636363637, 'epoch': 0.04}\n",
            "{'loss': 16.4456, 'grad_norm': 6.194705486297607, 'learning_rate': 0.045454545454545456, 'epoch': 0.05}\n",
            "{'loss': 18.8148, 'grad_norm': 33.04230880737305, 'learning_rate': 0.05454545454545454, 'epoch': 0.06}\n",
            "{'loss': 12.659, 'grad_norm': 1.9988185167312622, 'learning_rate': 0.06363636363636364, 'epoch': 0.06}\n",
            "{'loss': 13.7059, 'grad_norm': 1.5856577157974243, 'learning_rate': 0.07272727272727274, 'epoch': 0.07}\n",
            "{'loss': 4.0385, 'grad_norm': 0.7728901505470276, 'learning_rate': 0.08181818181818183, 'epoch': 0.08}\n",
            "{'loss': 13.0507, 'grad_norm': 0.7721354961395264, 'learning_rate': 0.09090909090909091, 'epoch': 0.09}\n",
            "{'loss': 5.9226, 'grad_norm': 0.28875941038131714, 'learning_rate': 0.1, 'epoch': 0.1}\n",
            "{'loss': 4.5926, 'grad_norm': 0.20168039202690125, 'learning_rate': 0.09999813776583147, 'epoch': 0.1}\n",
            "{'loss': 7.7227, 'grad_norm': 0.3266504108905792, 'learning_rate': 0.09999255120204248, 'epoch': 0.11}\n",
            "{'loss': 3.9397, 'grad_norm': 0.2357664555311203, 'learning_rate': 0.09998324072477266, 'epoch': 0.12}\n",
            "{'loss': 4.8532, 'grad_norm': 0.15781643986701965, 'learning_rate': 0.09997020702755353, 'epoch': 0.13}\n",
            "{'loss': 2.6948, 'grad_norm': 0.10262776166200638, 'learning_rate': 0.09995345108125697, 'epoch': 0.14}\n",
            "{'loss': 4.3145, 'grad_norm': 0.1710919886827469, 'learning_rate': 0.0999329741340228, 'epoch': 0.14}\n",
            "{'loss': 3.7551, 'grad_norm': 0.17566096782684326, 'learning_rate': 0.09990877771116588, 'epoch': 0.15}\n",
            "{'loss': 2.5483, 'grad_norm': 0.19943688809871674, 'learning_rate': 0.09988086361506239, 'epoch': 0.16}\n",
            "{'loss': 3.7635, 'grad_norm': 0.10656639188528061, 'learning_rate': 0.09984923392501567, 'epoch': 0.17}\n",
            "{'loss': 3.2578, 'grad_norm': 0.09018446505069733, 'learning_rate': 0.09981389099710132, 'epoch': 0.18}\n",
            "{'loss': 3.5105, 'grad_norm': 0.12769825756549835, 'learning_rate': 0.09977483746399167, 'epoch': 0.18}\n",
            "{'loss': 3.0109, 'grad_norm': 0.07790517807006836, 'learning_rate': 0.09973207623475965, 'epoch': 0.19}\n",
            "{'loss': 2.0152, 'grad_norm': 0.08378465473651886, 'learning_rate': 0.09968561049466214, 'epoch': 0.2}\n",
            "{'loss': 3.2674, 'grad_norm': 0.16915558278560638, 'learning_rate': 0.0996354437049027, 'epoch': 0.21}\n",
            "{'loss': 3.0609, 'grad_norm': 0.5813865661621094, 'learning_rate': 0.09958157960237375, 'epoch': 0.22}\n",
            "{'loss': 2.2511, 'grad_norm': 0.053845107555389404, 'learning_rate': 0.09952402219937817, 'epoch': 0.22}\n",
            "{'loss': 1.8667, 'grad_norm': 0.033294033259153366, 'learning_rate': 0.09946277578333045, 'epoch': 0.23}\n",
            "{'loss': 1.8808, 'grad_norm': 0.04551197588443756, 'learning_rate': 0.09939784491643733, 'epoch': 0.24}\n",
            "{'loss': 1.7619, 'grad_norm': 0.039315115660429, 'learning_rate': 0.09932923443535797, 'epoch': 0.25}\n",
            "{'loss': 2.1694, 'grad_norm': 0.06297063082456589, 'learning_rate': 0.09925694945084369, 'epoch': 0.26}\n",
            "{'loss': 1.9441, 'grad_norm': 0.029165571555495262, 'learning_rate': 0.09918099534735719, 'epoch': 0.26}\n",
            "{'loss': 2.0836, 'grad_norm': 0.02183123119175434, 'learning_rate': 0.09910137778267153, 'epoch': 0.27}\n",
            "{'loss': 2.4919, 'grad_norm': 0.037999965250492096, 'learning_rate': 0.09901810268744868, 'epoch': 0.28}\n",
            "{'loss': 1.9191, 'grad_norm': 0.06516275554895401, 'learning_rate': 0.09893117626479776, 'epoch': 0.29}\n",
            "{'loss': 1.945, 'grad_norm': 0.02834370918571949, 'learning_rate': 0.09884060498981295, 'epoch': 0.3}\n",
            "{'loss': 1.9835, 'grad_norm': 0.09367651492357254, 'learning_rate': 0.09874639560909118, 'epoch': 0.3}\n",
            "{'loss': 2.3021, 'grad_norm': 0.04204992949962616, 'learning_rate': 0.09864855514022955, 'epoch': 0.31}\n",
            "{'loss': 1.6559, 'grad_norm': 0.01790282316505909, 'learning_rate': 0.0985470908713026, 'epoch': 0.32}\n",
            "{'loss': 1.7893, 'grad_norm': 0.023234928026795387, 'learning_rate': 0.09844201036031952, 'epoch': 0.33}\n",
            "{'loss': 2.2009, 'grad_norm': 0.030927760526537895, 'learning_rate': 0.09833332143466099, 'epoch': 0.34}\n",
            "{'loss': 1.8364, 'grad_norm': 0.07112576812505722, 'learning_rate': 0.09822103219049626, 'epoch': 0.34}\n",
            "{'loss': 2.2532, 'grad_norm': 0.09845925867557526, 'learning_rate': 0.09810515099218003, 'epoch': 0.35}\n",
            "{'loss': 2.1182, 'grad_norm': 0.033712197095155716, 'learning_rate': 0.09798568647162938, 'epoch': 0.36}\n",
            "{'loss': 2.0764, 'grad_norm': 0.05115703493356705, 'learning_rate': 0.0978626475276808, 'epoch': 0.37}\n",
            "{'loss': 1.531, 'grad_norm': 0.054661691188812256, 'learning_rate': 0.09773604332542729, 'epoch': 0.38}\n",
            "{'loss': 1.6519, 'grad_norm': 0.031067734584212303, 'learning_rate': 0.09760588329553571, 'epoch': 0.38}\n",
            "{'loss': 1.6598, 'grad_norm': 0.048148013651371, 'learning_rate': 0.09747217713354428, 'epoch': 0.39}\n",
            "{'loss': 2.5266, 'grad_norm': 0.06893599033355713, 'learning_rate': 0.09733493479914031, 'epoch': 0.4}\n",
            "{'loss': 1.5339, 'grad_norm': 0.023773759603500366, 'learning_rate': 0.09719416651541839, 'epoch': 0.41}\n",
            "{'loss': 1.5731, 'grad_norm': 0.02676127664744854, 'learning_rate': 0.09704988276811882, 'epoch': 0.42}\n",
            "{'loss': 2.3613, 'grad_norm': 0.03879203274846077, 'learning_rate': 0.0969020943048466, 'epoch': 0.42}\n",
            "{'loss': 1.9617, 'grad_norm': 0.026290684938430786, 'learning_rate': 0.09675081213427075, 'epoch': 0.43}\n",
            "{'loss': 2.4109, 'grad_norm': 0.023462241515517235, 'learning_rate': 0.09659604752530435, 'epoch': 0.44}\n",
            "{'loss': 1.6406, 'grad_norm': 0.03799809142947197, 'learning_rate': 0.09643781200626511, 'epoch': 0.45}\n",
            "{'loss': 2.2304, 'grad_norm': 0.04259827360510826, 'learning_rate': 0.09627611736401667, 'epoch': 0.46}\n",
            "{'loss': 2.6768, 'grad_norm': 0.04777506738901138, 'learning_rate': 0.09611097564309053, 'epoch': 0.46}\n",
            "{'loss': 1.7192, 'grad_norm': 0.023420369252562523, 'learning_rate': 0.09594239914478886, 'epoch': 0.47}\n",
            "{'loss': 1.3874, 'grad_norm': 0.02121998369693756, 'learning_rate': 0.09577040042626833, 'epoch': 0.48}\n",
            "{'loss': 1.5147, 'grad_norm': 0.03282472863793373, 'learning_rate': 0.09559499229960451, 'epoch': 0.49}\n",
            "{'loss': 1.7212, 'grad_norm': 0.028701964765787125, 'learning_rate': 0.0954161878308377, 'epoch': 0.5}\n",
            "{'loss': 1.8081, 'grad_norm': 0.014384838752448559, 'learning_rate': 0.09523400033899956, 'epoch': 0.5}\n",
            "{'loss': 1.4402, 'grad_norm': 0.014176919125020504, 'learning_rate': 0.09504844339512096, 'epoch': 0.51}\n",
            "{'loss': 1.5062, 'grad_norm': 0.07008389383554459, 'learning_rate': 0.09485953082122117, 'epoch': 0.52}\n",
            "{'loss': 2.5022, 'grad_norm': 0.060255154967308044, 'learning_rate': 0.09466727668927816, 'epoch': 0.53}\n",
            "{'loss': 1.8156, 'grad_norm': 13.30473518371582, 'learning_rate': 0.0944716953201805, 'epoch': 0.54}\n",
            "{'loss': 1.9557, 'grad_norm': 0.020860305055975914, 'learning_rate': 0.0942728012826605, 'epoch': 0.54}\n",
            "{'loss': 2.3798, 'grad_norm': 0.05703430622816086, 'learning_rate': 0.09407060939220907, 'epoch': 0.55}\n",
            "{'loss': 2.2345, 'grad_norm': 0.03350868821144104, 'learning_rate': 0.0938651347099721, 'epoch': 0.56}\n",
            "{'loss': 1.5552, 'grad_norm': 0.06380811333656311, 'learning_rate': 0.09365639254162855, 'epoch': 0.57}\n",
            "{'loss': 2.2836, 'grad_norm': 0.05141270533204079, 'learning_rate': 0.09344439843625034, 'epoch': 0.58}\n",
            "{'loss': 1.8605, 'grad_norm': 0.02960953302681446, 'learning_rate': 0.09322916818514414, 'epoch': 0.58}\n",
            "{'loss': 1.8226, 'grad_norm': 0.03311699256300926, 'learning_rate': 0.09301071782067505, 'epoch': 0.59}\n",
            "{'loss': 2.3993, 'grad_norm': 0.042324576526880264, 'learning_rate': 0.09278906361507239, 'epoch': 0.6}\n",
            "{'loss': 1.7587, 'grad_norm': 0.02728249318897724, 'learning_rate': 0.09256422207921756, 'epoch': 0.61}\n",
            "{'loss': 1.3489, 'grad_norm': 0.008202746510505676, 'learning_rate': 0.09233620996141421, 'epoch': 0.62}\n",
            "{'loss': 1.6652, 'grad_norm': 0.02956819348037243, 'learning_rate': 0.09210504424614059, 'epoch': 0.62}\n",
            "{'loss': 1.6968, 'grad_norm': 0.11344660818576813, 'learning_rate': 0.09187074215278444, 'epoch': 0.63}\n",
            "{'loss': 2.0203, 'grad_norm': 0.026662111282348633, 'learning_rate': 0.09163332113436032, 'epoch': 0.64}\n",
            "{'loss': 2.8393, 'grad_norm': 0.04719075188040733, 'learning_rate': 0.09139279887620955, 'epoch': 0.65}\n",
            "{'loss': 1.6546, 'grad_norm': 0.019163092598319054, 'learning_rate': 0.09114919329468282, 'epoch': 0.66}\n",
            "{'loss': 1.7154, 'grad_norm': 0.023840460926294327, 'learning_rate': 0.09090252253580565, 'epoch': 0.66}\n",
            "{'loss': 1.9011, 'grad_norm': 0.03624353185296059, 'learning_rate': 0.09065280497392664, 'epoch': 0.67}\n",
            "{'loss': 2.0344, 'grad_norm': 0.03750906139612198, 'learning_rate': 0.09040005921034883, 'epoch': 0.68}\n",
            "{'loss': 1.3822, 'grad_norm': 0.019752174615859985, 'learning_rate': 0.09014430407194413, 'epoch': 0.69}\n",
            "{'loss': 1.2471, 'grad_norm': 0.013147593475878239, 'learning_rate': 0.08988555860975082, 'epoch': 0.7}\n",
            "{'loss': 1.4379, 'grad_norm': 0.022224467247724533, 'learning_rate': 0.08962384209755453, 'epoch': 0.7}\n",
            "{'loss': 1.8561, 'grad_norm': 0.026439953595399857, 'learning_rate': 0.08935917403045252, 'epoch': 0.71}\n",
            "{'loss': 1.6562, 'grad_norm': 0.023061204701662064, 'learning_rate': 0.0890915741234015, 'epoch': 0.72}\n",
            "{'loss': 1.6416, 'grad_norm': 0.021449662744998932, 'learning_rate': 0.0888210623097491, 'epoch': 0.73}\n",
            "{'loss': 1.2853, 'grad_norm': 0.007659868337213993, 'learning_rate': 0.08854765873974899, 'epoch': 0.74}\n",
            "{'loss': 1.6157, 'grad_norm': 0.015997739508748055, 'learning_rate': 0.08827138377905999, 'epoch': 0.74}\n",
            "{'loss': 1.2974, 'grad_norm': 0.011234027333557606, 'learning_rate': 0.08799225800722894, 'epoch': 0.75}\n",
            "{'loss': 1.6867, 'grad_norm': 0.04195982217788696, 'learning_rate': 0.08771030221615786, 'epoch': 0.76}\n",
            "{'loss': 1.3199, 'grad_norm': 0.014010610058903694, 'learning_rate': 0.08742553740855506, 'epoch': 0.77}\n",
            "{'loss': 1.4414, 'grad_norm': 0.009796569123864174, 'learning_rate': 0.08713798479637072, 'epoch': 0.78}\n",
            "{'loss': 1.9169, 'grad_norm': 0.013604100793600082, 'learning_rate': 0.08684766579921684, 'epoch': 0.78}\n",
            "{'loss': 1.8571, 'grad_norm': 0.01181063149124384, 'learning_rate': 0.08655460204277166, 'epoch': 0.79}\n",
            "{'loss': 1.7077, 'grad_norm': 0.01689895987510681, 'learning_rate': 0.08625881535716884, 'epoch': 0.8}\n",
            "{'loss': 1.6658, 'grad_norm': 0.014195707626640797, 'learning_rate': 0.08596032777537123, 'epoch': 0.81}\n",
            "{'loss': 1.6986, 'grad_norm': 0.0061063989996910095, 'learning_rate': 0.08565916153152982, 'epoch': 0.82}\n",
            "{'loss': 1.6317, 'grad_norm': 0.009835065342485905, 'learning_rate': 0.08535533905932738, 'epoch': 0.82}\n",
            "{'loss': 1.2768, 'grad_norm': 0.007230198476463556, 'learning_rate': 0.08504888299030748, 'epoch': 0.83}\n",
            "{'loss': 2.6072, 'grad_norm': 0.042430803179740906, 'learning_rate': 0.08473981615218862, 'epoch': 0.84}\n",
            "{'loss': 1.3472, 'grad_norm': 0.03478985279798508, 'learning_rate': 0.08442816156716386, 'epoch': 0.85}\n",
            "{'loss': 1.4921, 'grad_norm': 0.012054444290697575, 'learning_rate': 0.08411394245018589, 'epoch': 0.86}\n",
            "{'loss': 1.7074, 'grad_norm': 0.015845252200961113, 'learning_rate': 0.08379718220723772, 'epoch': 0.86}\n",
            "{'loss': 2.1139, 'grad_norm': 0.024153532460331917, 'learning_rate': 0.0834779044335893, 'epoch': 0.87}\n",
            "{'loss': 1.2352, 'grad_norm': 0.01543830893933773, 'learning_rate': 0.08315613291203977, 'epoch': 0.88}\n",
            "{'loss': 1.6124, 'grad_norm': 0.01525814924389124, 'learning_rate': 0.08283189161114601, 'epoch': 0.89}\n",
            "{'loss': 1.6071, 'grad_norm': 0.02080816589295864, 'learning_rate': 0.08250520468343721, 'epoch': 0.9}\n",
            "{'loss': 1.6076, 'grad_norm': 0.016148224472999573, 'learning_rate': 0.08217609646361573, 'epoch': 0.9}\n",
            "{'loss': 2.0346, 'grad_norm': 0.01911812275648117, 'learning_rate': 0.08184459146674447, 'epoch': 0.91}\n",
            "{'loss': 1.2104, 'grad_norm': 0.0362158939242363, 'learning_rate': 0.08151071438642069, 'epoch': 0.92}\n",
            "{'loss': 1.363, 'grad_norm': 0.01270341407507658, 'learning_rate': 0.08117449009293669, 'epoch': 0.93}\n",
            "{'loss': 2.2774, 'grad_norm': 0.027423202991485596, 'learning_rate': 0.08083594363142717, 'epoch': 0.94}\n",
            "{'loss': 1.7267, 'grad_norm': 0.021131975576281548, 'learning_rate': 0.08049510022000364, 'epoch': 0.94}\n",
            "{'loss': 1.7545, 'grad_norm': 0.012757053598761559, 'learning_rate': 0.08015198524787602, 'epoch': 0.95}\n",
            "{'loss': 1.5071, 'grad_norm': 0.010059183463454247, 'learning_rate': 0.07980662427346127, 'epoch': 0.96}\n",
            "{'loss': 1.5553, 'grad_norm': 0.007709539961069822, 'learning_rate': 0.07945904302247969, 'epoch': 0.97}\n",
            "{'loss': 1.6816, 'grad_norm': 0.013123994693160057, 'learning_rate': 0.07910926738603855, 'epoch': 0.98}\n",
            "{'loss': 1.8255, 'grad_norm': 0.016182832419872284, 'learning_rate': 0.07875732341870349, 'epoch': 0.98}\n",
            "{'loss': 1.4601, 'grad_norm': 0.010336329229176044, 'learning_rate': 0.0784032373365578, 'epoch': 0.99}\n",
            "{'loss': 1.6951, 'grad_norm': 0.015402345918118954, 'learning_rate': 0.07804703551524948, 'epoch': 1.0}\n",
            "{'loss': 1.2242, 'grad_norm': 0.009727299213409424, 'learning_rate': 0.07768874448802665, 'epoch': 1.01}\n",
            "{'loss': 1.2119, 'grad_norm': 0.011003515683114529, 'learning_rate': 0.07732839094376105, 'epoch': 1.02}\n",
            "{'loss': 1.6056, 'grad_norm': 0.024960873648524284, 'learning_rate': 0.07696600172495997, 'epoch': 1.02}\n",
            "{'loss': 1.5979, 'grad_norm': 0.01921463944017887, 'learning_rate': 0.07660160382576683, 'epoch': 1.03}\n",
            "{'loss': 1.2553, 'grad_norm': 0.010093612596392632, 'learning_rate': 0.0762352243899504, 'epoch': 1.04}\n",
            "{'loss': 1.6847, 'grad_norm': 0.018227070569992065, 'learning_rate': 0.07586689070888285, 'epoch': 1.05}\n",
            "{'loss': 1.5186, 'grad_norm': 0.011618644930422306, 'learning_rate': 0.07549663021950681, 'epoch': 1.06}\n",
            "{'loss': 1.6057, 'grad_norm': 0.012266036123037338, 'learning_rate': 0.07512447050229165, 'epoch': 1.06}\n",
            "{'loss': 1.3, 'grad_norm': 0.018394602462649345, 'learning_rate': 0.07475043927917907, 'epoch': 1.07}\n",
            "{'loss': 1.2043, 'grad_norm': 0.01644931361079216, 'learning_rate': 0.074374564411518, 'epoch': 1.08}\n",
            "{'loss': 1.3729, 'grad_norm': 0.027221988886594772, 'learning_rate': 0.07399687389798933, 'epoch': 1.09}\n",
            "{'loss': 1.2288, 'grad_norm': 0.012942780740559101, 'learning_rate': 0.07361739587252018, 'epoch': 1.1}\n",
            "{'loss': 1.5785, 'grad_norm': 0.016338132321834564, 'learning_rate': 0.07323615860218843, 'epoch': 1.1}\n",
            "{'loss': 2.2991, 'grad_norm': 0.03667188435792923, 'learning_rate': 0.07285319048511689, 'epoch': 1.11}\n",
            "{'loss': 1.8132, 'grad_norm': 0.02217242307960987, 'learning_rate': 0.07246852004835806, 'epoch': 1.12}\n",
            "{'loss': 1.5777, 'grad_norm': 0.021846072748303413, 'learning_rate': 0.07208217594576923, 'epoch': 1.13}\n",
            "{'loss': 1.4757, 'grad_norm': 0.017608648166060448, 'learning_rate': 0.07169418695587791, 'epoch': 1.14}\n",
            "{'loss': 1.7596, 'grad_norm': 0.030600253492593765, 'learning_rate': 0.07130458197973828, 'epoch': 1.14}\n",
            "{'loss': 1.3823, 'grad_norm': 0.021137723699212074, 'learning_rate': 0.07091339003877827, 'epoch': 1.15}\n",
            "{'loss': 1.7254, 'grad_norm': 0.02985459379851818, 'learning_rate': 0.07052064027263785, 'epoch': 1.16}\n",
            "{'loss': 1.6589, 'grad_norm': 0.03346236050128937, 'learning_rate': 0.07012636193699838, 'epoch': 1.17}\n",
            "{'loss': 1.3886, 'grad_norm': 0.026880431920289993, 'learning_rate': 0.06973058440140341, 'epoch': 1.18}\n",
            "{'loss': 1.3145, 'grad_norm': 0.03617458418011665, 'learning_rate': 0.06933333714707095, 'epoch': 1.18}\n",
            "{'loss': 1.6638, 'grad_norm': 0.02512640878558159, 'learning_rate': 0.06893464976469739, 'epoch': 1.19}\n",
            "{'loss': 1.0687, 'grad_norm': 0.018242573365569115, 'learning_rate': 0.06853455195225339, 'epoch': 1.2}\n",
            "{'loss': 1.2955, 'grad_norm': 0.02402079477906227, 'learning_rate': 0.0681330735127716, 'epoch': 1.21}\n",
            "{'loss': 1.484, 'grad_norm': 0.021983327344059944, 'learning_rate': 0.06773024435212678, 'epoch': 1.22}\n",
            "{'loss': 1.3374, 'grad_norm': 0.023641442880034447, 'learning_rate': 0.067326094476808, 'epoch': 1.22}\n",
            "{'loss': 1.1498, 'grad_norm': 0.03295329958200455, 'learning_rate': 0.06692065399168352, 'epoch': 1.23}\n",
            "{'loss': 1.3883, 'grad_norm': 0.0463937409222126, 'learning_rate': 0.06651395309775836, 'epoch': 1.24}\n",
            "{'loss': 1.2465, 'grad_norm': 0.695949137210846, 'learning_rate': 0.06610602208992454, 'epoch': 1.25}\n",
            "{'loss': 1.7195, 'grad_norm': 0.034757066518068314, 'learning_rate': 0.06569689135470451, 'epoch': 1.26}\n",
            "{'loss': 1.7223, 'grad_norm': 0.03426305949687958, 'learning_rate': 0.06528659136798765, 'epoch': 1.26}\n",
            "{'loss': 1.5199, 'grad_norm': 0.018609097227454185, 'learning_rate': 0.06487515269276016, 'epoch': 1.27}\n",
            "{'loss': 1.0638, 'grad_norm': 0.05400504544377327, 'learning_rate': 0.06446260597682839, 'epoch': 1.28}\n",
            "{'loss': 1.2728, 'grad_norm': 0.03978995978832245, 'learning_rate': 0.06404898195053597, 'epoch': 1.29}\n",
            "{'loss': 1.2727, 'grad_norm': 0.028079282492399216, 'learning_rate': 0.06363431142447469, 'epoch': 1.3}\n",
            "{'loss': 1.5787, 'grad_norm': 0.06099069118499756, 'learning_rate': 0.06321862528718945, 'epoch': 1.3}\n",
            "{'loss': 1.4551, 'grad_norm': 0.05757618322968483, 'learning_rate': 0.06280195450287736, 'epoch': 1.31}\n",
            "{'loss': 1.0431, 'grad_norm': 0.026592908427119255, 'learning_rate': 0.0623843301090813, 'epoch': 1.32}\n",
            "{'loss': 1.1245, 'grad_norm': 0.021831298246979713, 'learning_rate': 0.061965783214377894, 'epoch': 1.33}\n",
            "{'loss': 1.2775, 'grad_norm': 0.01646161638200283, 'learning_rate': 0.06154634499606029, 'epoch': 1.34}\n",
            "{'loss': 1.0143, 'grad_norm': 0.016629565507173538, 'learning_rate': 0.06112604669781572, 'epoch': 1.34}\n",
            "{'loss': 1.3278, 'grad_norm': 0.021641623228788376, 'learning_rate': 0.0607049196273983, 'epoch': 1.35}\n",
            "{'loss': 1.3501, 'grad_norm': 0.05133473873138428, 'learning_rate': 0.06028299515429683, 'epoch': 1.36}\n",
            "{'loss': 1.2306, 'grad_norm': 0.02631060965359211, 'learning_rate': 0.05986030470739811, 'epoch': 1.37}\n",
            "{'loss': 1.8935, 'grad_norm': 0.04029350355267525, 'learning_rate': 0.059436879772645834, 'epoch': 1.38}\n",
            "{'loss': 1.7207, 'grad_norm': 0.017998449504375458, 'learning_rate': 0.0590127518906953, 'epoch': 1.38}\n",
            "{'loss': 1.2402, 'grad_norm': 0.020740704610943794, 'learning_rate': 0.05858795265456382, 'epoch': 1.39}\n",
            "{'loss': 1.3184, 'grad_norm': 0.05414852872490883, 'learning_rate': 0.05816251370727748, 'epoch': 1.4}\n",
            "{'loss': 1.2481, 'grad_norm': 0.02047410048544407, 'learning_rate': 0.05773646673951406, 'epoch': 1.41}\n",
            "{'loss': 1.0633, 'grad_norm': 0.03132324293255806, 'learning_rate': 0.05730984348724242, 'epoch': 1.42}\n",
            "{'loss': 1.0795, 'grad_norm': 0.0301379282027483, 'learning_rate': 0.05688267572935843, 'epoch': 1.42}\n",
            "{'loss': 1.2844, 'grad_norm': 0.022541804239153862, 'learning_rate': 0.05645499528531785, 'epoch': 1.43}\n",
            "{'loss': 1.2007, 'grad_norm': 0.019395040348172188, 'learning_rate': 0.05602683401276615, 'epoch': 1.44}\n",
            "{'loss': 1.1102, 'grad_norm': 0.018825283274054527, 'learning_rate': 0.055598223805165395, 'epoch': 1.45}\n",
            "{'loss': 1.3461, 'grad_norm': 0.06978636234998703, 'learning_rate': 0.055169196589418504, 'epoch': 1.46}\n",
            "{'loss': 1.5532, 'grad_norm': 0.026065442711114883, 'learning_rate': 0.054739784323491116, 'epoch': 1.46}\n",
            "{'loss': 1.1889, 'grad_norm': 0.04130169376730919, 'learning_rate': 0.05431001899403098, 'epoch': 1.47}\n",
            "{'loss': 1.1973, 'grad_norm': 0.019448885694146156, 'learning_rate': 0.05387993261398532, 'epoch': 1.48}\n",
            "{'loss': 1.0394, 'grad_norm': 0.02960607223212719, 'learning_rate': 0.05344955722021624, 'epoch': 1.49}\n",
            "{'loss': 1.3825, 'grad_norm': 0.03183398023247719, 'learning_rate': 0.05301892487111431, 'epoch': 1.5}\n",
            "{'loss': 1.0417, 'grad_norm': 0.024050075560808182, 'learning_rate': 0.05258806764421048, 'epoch': 1.5}\n",
            "{'loss': 0.9713, 'grad_norm': 0.10517590492963791, 'learning_rate': 0.05215701763378673, 'epoch': 1.51}\n",
            "{'loss': 0.8479, 'grad_norm': 0.03243682533502579, 'learning_rate': 0.051725806948485414, 'epoch': 1.52}\n",
            "{'loss': 0.9316, 'grad_norm': 0.049540258944034576, 'learning_rate': 0.05129446770891738, 'epoch': 1.53}\n",
            "{'loss': 1.1392, 'grad_norm': 0.023438729345798492, 'learning_rate': 0.05086303204526943, 'epoch': 1.54}\n",
            "{'loss': 1.0349, 'grad_norm': 0.02056933380663395, 'learning_rate': 0.05043153209491095, 'epoch': 1.54}\n",
            "{'loss': 0.9277, 'grad_norm': 0.037388093769550323, 'learning_rate': 0.05, 'epoch': 1.55}\n",
            "{'loss': 1.1947, 'grad_norm': 0.027250157669186592, 'learning_rate': 0.049568467905089064, 'epoch': 1.56}\n",
            "{'loss': 1.268, 'grad_norm': 0.03537280857563019, 'learning_rate': 0.049136967954730576, 'epoch': 1.57}\n",
            "{'loss': 1.1197, 'grad_norm': 0.08302843570709229, 'learning_rate': 0.04870553229108264, 'epoch': 1.58}\n",
            "{'loss': 1.1731, 'grad_norm': 0.04157011955976486, 'learning_rate': 0.04827419305151461, 'epoch': 1.58}\n",
            "{'loss': 0.9812, 'grad_norm': 0.0173630490899086, 'learning_rate': 0.047842982366213274, 'epoch': 1.59}\n",
            "{'loss': 1.1799, 'grad_norm': 0.017056426033377647, 'learning_rate': 0.04741193235578953, 'epoch': 1.6}\n",
            "{'loss': 0.8651, 'grad_norm': 0.13139255344867706, 'learning_rate': 0.04698107512888569, 'epoch': 1.61}\n",
            "{'loss': 0.8548, 'grad_norm': 0.02208271250128746, 'learning_rate': 0.046550442779783756, 'epoch': 1.62}\n",
            "{'loss': 1.1228, 'grad_norm': 0.02344897948205471, 'learning_rate': 0.04612006738601469, 'epoch': 1.62}\n",
            "{'loss': 1.4295, 'grad_norm': 0.025648120790719986, 'learning_rate': 0.04568998100596903, 'epoch': 1.63}\n",
            "{'loss': 1.0454, 'grad_norm': 0.026355255395174026, 'learning_rate': 0.0452602156765089, 'epoch': 1.64}\n",
            "{'loss': 1.219, 'grad_norm': 0.0677279680967331, 'learning_rate': 0.0448308034105815, 'epoch': 1.65}\n",
            "{'loss': 1.1753, 'grad_norm': 0.05015427991747856, 'learning_rate': 0.04440177619483461, 'epoch': 1.66}\n",
            "{'loss': 0.9041, 'grad_norm': 0.023219825699925423, 'learning_rate': 0.04397316598723386, 'epoch': 1.66}\n",
            "{'loss': 0.9715, 'grad_norm': 0.029089778661727905, 'learning_rate': 0.04354500471468217, 'epoch': 1.67}\n",
            "{'loss': 0.8503, 'grad_norm': 0.03972075879573822, 'learning_rate': 0.043117324270641605, 'epoch': 1.68}\n",
            "{'loss': 1.1729, 'grad_norm': 0.11246290802955627, 'learning_rate': 0.04269015651275761, 'epoch': 1.69}\n",
            "{'loss': 1.0358, 'grad_norm': 0.023876624181866646, 'learning_rate': 0.04226353326048593, 'epoch': 1.7}\n",
            "{'loss': 0.9629, 'grad_norm': 0.015069977380335331, 'learning_rate': 0.041837486292722534, 'epoch': 1.7}\n",
            "{'loss': 0.9456, 'grad_norm': 0.023588737472891808, 'learning_rate': 0.041412047345436194, 'epoch': 1.71}\n",
            "{'loss': 1.3714, 'grad_norm': 0.12871210277080536, 'learning_rate': 0.040987248109304715, 'epoch': 1.72}\n",
            "{'loss': 0.9797, 'grad_norm': 0.01807626336812973, 'learning_rate': 0.04056312022735417, 'epoch': 1.73}\n",
            "{'loss': 1.2651, 'grad_norm': 0.04054355248808861, 'learning_rate': 0.040139695292601904, 'epoch': 1.74}\n",
            "{'loss': 0.816, 'grad_norm': 12.649809837341309, 'learning_rate': 0.039717004845703174, 'epoch': 1.74}\n",
            "{'loss': 1.0974, 'grad_norm': 0.019690757617354393, 'learning_rate': 0.0392950803726017, 'epoch': 1.75}\n",
            "{'loss': 0.7894, 'grad_norm': 0.03394269198179245, 'learning_rate': 0.03887395330218429, 'epoch': 1.76}\n",
            "{'loss': 1.136, 'grad_norm': 0.08648771047592163, 'learning_rate': 0.03845365500393974, 'epoch': 1.77}\n",
            "{'loss': 0.9755, 'grad_norm': 0.04000420495867729, 'learning_rate': 0.03803421678562213, 'epoch': 1.78}\n",
            "{'loss': 1.3241, 'grad_norm': 0.05475643277168274, 'learning_rate': 0.037615669890918704, 'epoch': 1.78}\n",
            "{'loss': 1.1714, 'grad_norm': 0.06697418540716171, 'learning_rate': 0.03719804549712265, 'epoch': 1.79}\n",
            "{'loss': 1.6777, 'grad_norm': 0.07749633491039276, 'learning_rate': 0.03678137471281056, 'epoch': 1.8}\n",
            "{'loss': 1.3949, 'grad_norm': 0.0788067951798439, 'learning_rate': 0.036365688575525315, 'epoch': 1.81}\n",
            "{'loss': 1.275, 'grad_norm': 0.04063330218195915, 'learning_rate': 0.03595101804946404, 'epoch': 1.82}\n",
            "{'loss': 1.4835, 'grad_norm': 0.06530304998159409, 'learning_rate': 0.035537394023171624, 'epoch': 1.82}\n",
            "{'loss': 1.4487, 'grad_norm': 0.06175242364406586, 'learning_rate': 0.03512484730723986, 'epoch': 1.83}\n",
            "{'loss': 1.5095, 'grad_norm': 0.03185657039284706, 'learning_rate': 0.03471340863201237, 'epoch': 1.84}\n",
            "{'loss': 1.3356, 'grad_norm': 0.07564093917608261, 'learning_rate': 0.0343031086452955, 'epoch': 1.85}\n",
            "{'loss': 1.3441, 'grad_norm': 0.023376034572720528, 'learning_rate': 0.03389397791007548, 'epoch': 1.86}\n",
            "{'loss': 1.2754, 'grad_norm': 0.0407370962202549, 'learning_rate': 0.03348604690224166, 'epoch': 1.86}\n",
            "{'loss': 0.9258, 'grad_norm': 0.07477212697267532, 'learning_rate': 0.03307934600831648, 'epoch': 1.87}\n",
            "{'loss': 1.0334, 'grad_norm': 0.018108153715729713, 'learning_rate': 0.032673905523192, 'epoch': 1.88}\n",
            "{'loss': 0.9201, 'grad_norm': 0.028590211644768715, 'learning_rate': 0.03226975564787322, 'epoch': 1.89}\n",
            "{'loss': 1.3031, 'grad_norm': 0.02478797920048237, 'learning_rate': 0.0318669264872284, 'epoch': 1.9}\n",
            "{'loss': 0.9945, 'grad_norm': 0.0386749729514122, 'learning_rate': 0.031465448047746626, 'epoch': 1.9}\n",
            "{'loss': 1.0414, 'grad_norm': 0.027414780110120773, 'learning_rate': 0.03106535023530262, 'epoch': 1.91}\n",
            "{'loss': 1.0777, 'grad_norm': 0.017262326553463936, 'learning_rate': 0.03066666285292906, 'epoch': 1.92}\n",
            "{'loss': 0.8944, 'grad_norm': 0.03091985173523426, 'learning_rate': 0.0302694155985966, 'epoch': 1.93}\n",
            "{'loss': 0.7852, 'grad_norm': 0.01312349271029234, 'learning_rate': 0.02987363806300163, 'epoch': 1.94}\n",
            "{'loss': 1.0019, 'grad_norm': 0.017411084845662117, 'learning_rate': 0.02947935972736217, 'epoch': 1.94}\n",
            "{'loss': 1.2845, 'grad_norm': 0.17135120928287506, 'learning_rate': 0.029086609961221754, 'epoch': 1.95}\n",
            "{'loss': 1.058, 'grad_norm': 0.016931407153606415, 'learning_rate': 0.028695418020261754, 'epoch': 1.96}\n",
            "{'loss': 0.8028, 'grad_norm': 0.01845587231218815, 'learning_rate': 0.028305813044122097, 'epoch': 1.97}\n",
            "{'loss': 0.8609, 'grad_norm': 0.015962544828653336, 'learning_rate': 0.027917824054230784, 'epoch': 1.98}\n",
            "{'loss': 1.3265, 'grad_norm': 0.022645823657512665, 'learning_rate': 0.027531479951641926, 'epoch': 1.98}\n",
            "{'loss': 0.9241, 'grad_norm': 0.022478409111499786, 'learning_rate': 0.02714680951488312, 'epoch': 1.99}\n",
            "{'loss': 0.9637, 'grad_norm': 0.015021098777651787, 'learning_rate': 0.026763841397811572, 'epoch': 2.0}\n",
            "{'loss': 0.7512, 'grad_norm': 0.006659870035946369, 'learning_rate': 0.026382604127479815, 'epoch': 2.01}\n",
            "{'loss': 0.8426, 'grad_norm': 0.005926945712417364, 'learning_rate': 0.026003126102010693, 'epoch': 2.02}\n",
            "{'loss': 0.7722, 'grad_norm': 0.015507199801504612, 'learning_rate': 0.025625435588482015, 'epoch': 2.02}\n",
            "{'loss': 0.9761, 'grad_norm': 0.008565239608287811, 'learning_rate': 0.02524956072082093, 'epoch': 2.03}\n",
            "{'loss': 1.2277, 'grad_norm': 0.024483786895871162, 'learning_rate': 0.024875529497708354, 'epoch': 2.04}\n",
            "{'loss': 0.8323, 'grad_norm': 0.014197601936757565, 'learning_rate': 0.02450336978049322, 'epoch': 2.05}\n",
            "{'loss': 0.7521, 'grad_norm': 0.006829838268458843, 'learning_rate': 0.024133109291117158, 'epoch': 2.06}\n",
            "{'loss': 0.8126, 'grad_norm': 0.02213950827717781, 'learning_rate': 0.0237647756100496, 'epoch': 2.06}\n",
            "{'loss': 1.0276, 'grad_norm': 0.013191442005336285, 'learning_rate': 0.02339839617423318, 'epoch': 2.07}\n",
            "{'loss': 1.1294, 'grad_norm': 0.01537422277033329, 'learning_rate': 0.023033998275040046, 'epoch': 2.08}\n",
            "{'loss': 1.0124, 'grad_norm': 0.017870541661977768, 'learning_rate': 0.022671609056238953, 'epoch': 2.09}\n",
            "{'loss': 0.8383, 'grad_norm': 0.014349301345646381, 'learning_rate': 0.022311255511973344, 'epoch': 2.1}\n",
            "{'loss': 0.8805, 'grad_norm': 0.0077394964173436165, 'learning_rate': 0.021952964484750526, 'epoch': 2.1}\n",
            "{'loss': 0.8292, 'grad_norm': 0.013373760506510735, 'learning_rate': 0.021596762663442216, 'epoch': 2.11}\n",
            "{'loss': 1.1051, 'grad_norm': 0.011700538918375969, 'learning_rate': 0.021242676581296527, 'epoch': 2.12}\n",
            "{'loss': 0.9497, 'grad_norm': 0.009891964495182037, 'learning_rate': 0.020890732613961478, 'epoch': 2.13}\n",
            "{'loss': 1.0351, 'grad_norm': 0.015609788708388805, 'learning_rate': 0.02054095697752032, 'epoch': 2.14}\n",
            "{'loss': 1.3784, 'grad_norm': 0.018084418028593063, 'learning_rate': 0.02019337572653874, 'epoch': 2.14}\n",
            "{'loss': 1.2987, 'grad_norm': 0.018316833302378654, 'learning_rate': 0.01984801475212398, 'epoch': 2.15}\n",
            "{'loss': 0.7163, 'grad_norm': 0.007148056291043758, 'learning_rate': 0.019504899779996355, 'epoch': 2.16}\n",
            "{'loss': 0.8358, 'grad_norm': 0.005554706323891878, 'learning_rate': 0.019164056368572848, 'epoch': 2.17}\n",
            "{'loss': 1.0679, 'grad_norm': 0.05478699132800102, 'learning_rate': 0.018825509907063328, 'epoch': 2.18}\n",
            "{'loss': 1.033, 'grad_norm': 0.012925645336508751, 'learning_rate': 0.018489285613579327, 'epoch': 2.18}\n",
            "{'loss': 0.7694, 'grad_norm': 0.006077868863940239, 'learning_rate': 0.018155408533255552, 'epoch': 2.19}\n",
            "{'loss': 1.0735, 'grad_norm': 0.01081504113972187, 'learning_rate': 0.017823903536384262, 'epoch': 2.2}\n",
            "{'loss': 0.6947, 'grad_norm': 0.01048267725855112, 'learning_rate': 0.01749479531656279, 'epoch': 2.21}\n",
            "{'loss': 1.4304, 'grad_norm': 0.02653977833688259, 'learning_rate': 0.017168108388854, 'epoch': 2.22}\n",
            "{'loss': 1.1242, 'grad_norm': 0.15982100367546082, 'learning_rate': 0.016843867087960252, 'epoch': 2.22}\n",
            "{'loss': 1.2491, 'grad_norm': 0.04103647917509079, 'learning_rate': 0.016522095566410728, 'epoch': 2.23}\n",
            "{'loss': 1.0237, 'grad_norm': 0.02529997192323208, 'learning_rate': 0.01620281779276228, 'epoch': 2.24}\n",
            "{'loss': 1.4954, 'grad_norm': 0.035462453961372375, 'learning_rate': 0.01588605754981413, 'epoch': 2.25}\n",
            "{'loss': 1.3359, 'grad_norm': 0.02115675061941147, 'learning_rate': 0.01557183843283614, 'epoch': 2.26}\n",
            "{'loss': 1.2137, 'grad_norm': 0.0584731362760067, 'learning_rate': 0.015260183847811382, 'epoch': 2.26}\n",
            "{'loss': 1.3887, 'grad_norm': 0.024374568834900856, 'learning_rate': 0.014951117009692528, 'epoch': 2.27}\n",
            "{'loss': 0.9559, 'grad_norm': 0.025265924632549286, 'learning_rate': 0.014644660940672627, 'epoch': 2.28}\n",
            "{'loss': 1.6337, 'grad_norm': 0.05210425704717636, 'learning_rate': 0.014340838468470197, 'epoch': 2.29}\n",
            "{'loss': 1.7705, 'grad_norm': 0.029831578955054283, 'learning_rate': 0.014039672224628786, 'epoch': 2.3}\n",
            "{'loss': 1.2123, 'grad_norm': 0.02072644792497158, 'learning_rate': 0.01374118464283119, 'epoch': 2.3}\n",
            "{'loss': 0.9497, 'grad_norm': 1.1721572875976562, 'learning_rate': 0.01344539795722834, 'epoch': 2.31}\n",
            "{'loss': 1.0283, 'grad_norm': 0.04440896958112717, 'learning_rate': 0.013152334200783168, 'epoch': 2.32}\n",
            "{'loss': 1.1393, 'grad_norm': 0.02632668986916542, 'learning_rate': 0.012862015203629274, 'epoch': 2.33}\n",
            "{'loss': 1.3264, 'grad_norm': 0.01638656295835972, 'learning_rate': 0.012574462591444941, 'epoch': 2.34}\n",
            "{'loss': 0.8853, 'grad_norm': 0.014419825747609138, 'learning_rate': 0.012289697783842141, 'epoch': 2.34}\n",
            "{'loss': 1.2666, 'grad_norm': 0.027779677882790565, 'learning_rate': 0.012007741992771066, 'epoch': 2.35}\n",
            "{'loss': 1.687, 'grad_norm': 0.028672706335783005, 'learning_rate': 0.011728616220940031, 'epoch': 2.36}\n",
            "{'loss': 0.8392, 'grad_norm': 0.011878108605742455, 'learning_rate': 0.01145234126025102, 'epoch': 2.37}\n",
            "{'loss': 0.8507, 'grad_norm': 0.015876874327659607, 'learning_rate': 0.011178937690250919, 'epoch': 2.38}\n",
            "{'loss': 0.7894, 'grad_norm': 0.039341073483228683, 'learning_rate': 0.01090842587659851, 'epoch': 2.38}\n",
            "{'loss': 0.9835, 'grad_norm': 0.045930322259664536, 'learning_rate': 0.010640825969547497, 'epoch': 2.39}\n",
            "{'loss': 0.9648, 'grad_norm': 0.012064310722053051, 'learning_rate': 0.010376157902445489, 'epoch': 2.4}\n",
            "{'loss': 0.891, 'grad_norm': 0.022152064368128777, 'learning_rate': 0.010114441390249203, 'epoch': 2.41}\n",
            "{'loss': 0.8456, 'grad_norm': 0.021129991859197617, 'learning_rate': 0.00985569592805588, 'epoch': 2.42}\n",
            "{'loss': 0.9326, 'grad_norm': 0.011830213479697704, 'learning_rate': 0.009599940789651179, 'epoch': 2.42}\n",
            "{'loss': 0.9616, 'grad_norm': 0.04276655986905098, 'learning_rate': 0.009347195026073368, 'epoch': 2.43}\n",
            "{'loss': 1.016, 'grad_norm': 0.022592643275856972, 'learning_rate': 0.00909747746419436, 'epoch': 2.44}\n",
            "{'loss': 1.1359, 'grad_norm': 0.02418631874024868, 'learning_rate': 0.008850806705317182, 'epoch': 2.45}\n",
            "{'loss': 0.9054, 'grad_norm': 0.04871581867337227, 'learning_rate': 0.008607201123790459, 'epoch': 2.46}\n",
            "{'loss': 1.0189, 'grad_norm': 0.013512537814676762, 'learning_rate': 0.008366678865639687, 'epoch': 2.46}\n",
            "{'loss': 1.0452, 'grad_norm': 0.01139672938734293, 'learning_rate': 0.008129257847215571, 'epoch': 2.47}\n",
            "{'loss': 0.7792, 'grad_norm': 0.02671641670167446, 'learning_rate': 0.007894955753859413, 'epoch': 2.48}\n",
            "{'loss': 1.28, 'grad_norm': 0.016662146896123886, 'learning_rate': 0.0076637900385857945, 'epoch': 2.49}\n",
            "{'loss': 0.7992, 'grad_norm': 0.008369622752070427, 'learning_rate': 0.007435777920782444, 'epoch': 2.5}\n",
            "{'loss': 0.7428, 'grad_norm': 0.0057144020684063435, 'learning_rate': 0.00721093638492763, 'epoch': 2.5}\n",
            "{'loss': 1.0258, 'grad_norm': 0.011415801011025906, 'learning_rate': 0.006989282179324963, 'epoch': 2.51}\n",
            "{'loss': 0.7706, 'grad_norm': 0.00872188713401556, 'learning_rate': 0.006770831814855882, 'epoch': 2.52}\n",
            "{'loss': 0.799, 'grad_norm': 0.008643880486488342, 'learning_rate': 0.006555601563749675, 'epoch': 2.53}\n",
            "{'loss': 1.1668, 'grad_norm': 0.012747879140079021, 'learning_rate': 0.006343607458371459, 'epoch': 2.54}\n",
            "{'loss': 1.0391, 'grad_norm': 0.011771219782531261, 'learning_rate': 0.0061348652900279025, 'epoch': 2.54}\n",
            "{'loss': 0.9346, 'grad_norm': 0.010272923856973648, 'learning_rate': 0.00592939060779093, 'epoch': 2.55}\n",
            "{'loss': 0.9918, 'grad_norm': 0.0192069411277771, 'learning_rate': 0.00572719871733951, 'epoch': 2.56}\n",
            "{'loss': 0.884, 'grad_norm': 0.008949337527155876, 'learning_rate': 0.005528304679819513, 'epoch': 2.57}\n",
            "{'loss': 1.3219, 'grad_norm': 0.018837522715330124, 'learning_rate': 0.005332723310721855, 'epoch': 2.58}\n",
            "{'loss': 0.8353, 'grad_norm': 0.010643430054187775, 'learning_rate': 0.005140469178778845, 'epoch': 2.58}\n",
            "{'loss': 0.7854, 'grad_norm': 0.0065812012180686, 'learning_rate': 0.004951556604879049, 'epoch': 2.59}\n",
            "{'loss': 1.0239, 'grad_norm': 0.012318267486989498, 'learning_rate': 0.004765999661000442, 'epoch': 2.6}\n",
            "{'loss': 0.8074, 'grad_norm': 0.011855975724756718, 'learning_rate': 0.004583812169162299, 'epoch': 2.61}\n",
            "{'loss': 0.921, 'grad_norm': 0.015038558281958103, 'learning_rate': 0.004405007700395497, 'epoch': 2.62}\n",
            "{'loss': 1.1462, 'grad_norm': 0.020162463188171387, 'learning_rate': 0.004229599573731685, 'epoch': 2.62}\n",
            "{'loss': 1.1054, 'grad_norm': 0.012130475603044033, 'learning_rate': 0.004057600855211141, 'epoch': 2.63}\n",
            "{'loss': 0.9617, 'grad_norm': 0.013491062447428703, 'learning_rate': 0.0038890243569094877, 'epoch': 2.64}\n",
            "{'loss': 0.8424, 'grad_norm': 0.008959902450442314, 'learning_rate': 0.003723882635983328, 'epoch': 2.65}\n",
            "{'loss': 0.9896, 'grad_norm': 0.00697528850287199, 'learning_rate': 0.0035621879937348835, 'epoch': 2.66}\n",
            "{'loss': 0.7639, 'grad_norm': 0.032534241676330566, 'learning_rate': 0.0034039524746956595, 'epoch': 2.66}\n",
            "{'loss': 0.9521, 'grad_norm': 0.016468554735183716, 'learning_rate': 0.003249187865729264, 'epoch': 2.67}\n",
            "{'loss': 0.9758, 'grad_norm': 0.007355387322604656, 'learning_rate': 0.003097905695153408, 'epoch': 2.68}\n",
            "{'loss': 1.0161, 'grad_norm': 0.015293601900339127, 'learning_rate': 0.002950117231881183, 'epoch': 2.69}\n",
            "{'loss': 1.0273, 'grad_norm': 0.012861894443631172, 'learning_rate': 0.0028058334845816216, 'epoch': 2.7}\n",
            "{'loss': 0.9381, 'grad_norm': 0.010151776485145092, 'learning_rate': 0.002665065200859707, 'epoch': 2.7}\n",
            "{'loss': 0.9918, 'grad_norm': 0.0074357339181005955, 'learning_rate': 0.0025278228664557313, 'epoch': 2.71}\n",
            "{'loss': 1.2216, 'grad_norm': 0.013020209036767483, 'learning_rate': 0.002394116704464294, 'epoch': 2.72}\n",
            "{'loss': 0.8377, 'grad_norm': 0.008732522837817669, 'learning_rate': 0.0022639566745727203, 'epoch': 2.73}\n",
            "{'loss': 0.6816, 'grad_norm': 0.006102023180574179, 'learning_rate': 0.002137352472319215, 'epoch': 2.74}\n",
            "{'loss': 1.1688, 'grad_norm': 0.014321942813694477, 'learning_rate': 0.002014313528370626, 'epoch': 2.74}\n",
            "{'loss': 0.8512, 'grad_norm': 0.009739118628203869, 'learning_rate': 0.0018948490078199765, 'epoch': 2.75}\n",
            "{'loss': 0.7801, 'grad_norm': 0.008664276450872421, 'learning_rate': 0.0017789678095037455, 'epoch': 2.76}\n",
            "{'loss': 0.6873, 'grad_norm': 0.005844494793564081, 'learning_rate': 0.001666678565339025, 'epoch': 2.77}\n",
            "{'loss': 0.9371, 'grad_norm': 0.010706481523811817, 'learning_rate': 0.0015579896396804961, 'epoch': 2.78}\n",
            "{'loss': 0.9346, 'grad_norm': 0.00961294211447239, 'learning_rate': 0.0014529091286973996, 'epoch': 2.78}\n",
            "{'loss': 0.8408, 'grad_norm': 0.006215974688529968, 'learning_rate': 0.0013514448597704621, 'epoch': 2.79}\n",
            "{'loss': 0.7722, 'grad_norm': 0.0069704605266451836, 'learning_rate': 0.0012536043909088192, 'epoch': 2.8}\n",
            "{'loss': 0.8776, 'grad_norm': 0.00890445802360773, 'learning_rate': 0.001159395010187042, 'epoch': 2.81}\n",
            "{'loss': 1.0906, 'grad_norm': 0.014287896454334259, 'learning_rate': 0.0010688237352022346, 'epoch': 2.82}\n",
            "{'loss': 0.7378, 'grad_norm': 0.007747422903776169, 'learning_rate': 0.0009818973125513275, 'epoch': 2.82}\n",
            "{'loss': 0.9743, 'grad_norm': 0.015073342248797417, 'learning_rate': 0.0008986222173284875, 'epoch': 2.83}\n",
            "{'loss': 0.8764, 'grad_norm': 0.009869036264717579, 'learning_rate': 0.0008190046526428241, 'epoch': 2.84}\n",
            "{'loss': 0.9452, 'grad_norm': 0.006292304024100304, 'learning_rate': 0.00074305054915631, 'epoch': 2.85}\n",
            "{'loss': 0.7511, 'grad_norm': 0.005630156025290489, 'learning_rate': 0.0006707655646420231, 'epoch': 2.86}\n",
            "{'loss': 0.8642, 'grad_norm': 0.008889720775187016, 'learning_rate': 0.0006021550835626777, 'epoch': 2.86}\n",
            "{'loss': 0.8413, 'grad_norm': 0.009919332340359688, 'learning_rate': 0.0005372242166695685, 'epoch': 2.87}\n",
            "{'loss': 0.713, 'grad_norm': 0.005634166765958071, 'learning_rate': 0.00047597780062184073, 'epoch': 2.88}\n",
            "{'loss': 1.1292, 'grad_norm': 0.01293505635112524, 'learning_rate': 0.0004184203976262513, 'epoch': 2.89}\n",
            "{'loss': 1.2944, 'grad_norm': 0.01360154990106821, 'learning_rate': 0.0003645562950973014, 'epoch': 2.9}\n",
            "{'loss': 1.0393, 'grad_norm': 0.010945341549813747, 'learning_rate': 0.00031438950533786984, 'epoch': 2.9}\n",
            "{'loss': 0.8295, 'grad_norm': 0.008448527194559574, 'learning_rate': 0.0002679237652403688, 'epoch': 2.91}\n",
            "{'loss': 0.9114, 'grad_norm': 0.006237807683646679, 'learning_rate': 0.0002251625360083387, 'epoch': 2.92}\n",
            "{'loss': 1.0813, 'grad_norm': 0.014595968648791313, 'learning_rate': 0.00018610900289867672, 'epoch': 2.93}\n",
            "{'loss': 0.7072, 'grad_norm': 0.0065144686959683895, 'learning_rate': 0.00015076607498433204, 'epoch': 2.94}\n",
            "{'loss': 0.7516, 'grad_norm': 0.0053408388048410416, 'learning_rate': 0.00011913638493762369, 'epoch': 2.94}\n",
            "{'loss': 0.8392, 'grad_norm': 0.007057920563966036, 'learning_rate': 9.12222888341252e-05, 'epoch': 2.95}\n",
            "{'loss': 0.857, 'grad_norm': 0.0071794032119214535, 'learning_rate': 6.702586597719385e-05, 'epoch': 2.96}\n",
            "{'loss': 0.9651, 'grad_norm': 0.016178106889128685, 'learning_rate': 4.654891874303346e-05, 'epoch': 2.97}\n",
            "{'loss': 0.8206, 'grad_norm': 0.006746974773705006, 'learning_rate': 2.9792972446479606e-05, 'epoch': 2.98}\n",
            "{'loss': 0.8262, 'grad_norm': 0.007769013289362192, 'learning_rate': 1.6759275227357096e-05, 'epoch': 2.98}\n",
            "{'loss': 0.8163, 'grad_norm': 0.004865015856921673, 'learning_rate': 7.4487979575266206e-06, 'epoch': 2.99}\n",
            "{'loss': 1.1784, 'grad_norm': 0.016854990273714066, 'learning_rate': 1.862234168542587e-06, 'epoch': 3.0}\n",
            "{'train_runtime': 49.0591, 'train_samples_per_second': 15.288, 'train_steps_per_second': 7.644, 'train_loss': 1.7357400511105856, 'epoch': 3.0}\n",
            "100% 375/375 [00:49<00:00,  7.64it/s]\n",
            "Training complete.\n",
            "Model saved to loras/self-edit/training_set_iteration_1/8be77c9e/9\n",
            "Training on 10 examples for 3 epochs, lr: 0.001\n",
            "No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n",
            "Starting training...\n",
            "{'loss': 4.6972, 'grad_norm': 6.128959655761719, 'learning_rate': 0.0, 'epoch': 0.2}\n",
            "{'loss': 4.8718, 'grad_norm': 5.768027305603027, 'learning_rate': 9.090909090909092e-05, 'epoch': 0.4}\n",
            "{'loss': 5.7381, 'grad_norm': 9.854024887084961, 'learning_rate': 0.00018181818181818183, 'epoch': 0.6}\n",
            "{'loss': 1.1727, 'grad_norm': 5.880247116088867, 'learning_rate': 0.00027272727272727274, 'epoch': 0.8}\n",
            "{'loss': 0.6237, 'grad_norm': 5.0073323249816895, 'learning_rate': 0.00036363636363636367, 'epoch': 1.0}\n",
            "{'loss': 0.3875, 'grad_norm': 0.8534306287765503, 'learning_rate': 0.00045454545454545455, 'epoch': 1.2}\n",
            "{'loss': 0.2683, 'grad_norm': 0.6017436981201172, 'learning_rate': 0.0005454545454545455, 'epoch': 1.4}\n",
            "{'loss': 0.0863, 'grad_norm': 0.2506377398967743, 'learning_rate': 0.0006363636363636364, 'epoch': 1.6}\n",
            "{'loss': 0.0651, 'grad_norm': 0.507348358631134, 'learning_rate': 0.0007272727272727273, 'epoch': 1.8}\n",
            "{'loss': 0.1249, 'grad_norm': 0.4928025007247925, 'learning_rate': 0.0008181818181818183, 'epoch': 2.0}\n",
            "{'loss': 0.0196, 'grad_norm': 0.16490967571735382, 'learning_rate': 0.0009090909090909091, 'epoch': 2.2}\n",
            "{'loss': 0.0164, 'grad_norm': 0.2602466642856598, 'learning_rate': 0.001, 'epoch': 2.4}\n",
            "{'loss': 0.0016, 'grad_norm': 0.025066375732421875, 'learning_rate': 0.0008535533905932737, 'epoch': 2.6}\n",
            "{'loss': 0.0123, 'grad_norm': 0.5804195404052734, 'learning_rate': 0.0005, 'epoch': 2.8}\n",
            "{'loss': 0.0073, 'grad_norm': 0.3529105484485626, 'learning_rate': 0.00014644660940672628, 'epoch': 3.0}\n",
            "{'train_runtime': 1.938, 'train_samples_per_second': 15.48, 'train_steps_per_second': 7.74, 'train_loss': 1.2061884401055674, 'epoch': 3.0}\n",
            "100% 15/15 [00:01<00:00,  7.75it/s]\n",
            "Training complete.\n",
            "Model saved to loras/self-edit/training_set_iteration_1/8be77c9e/10\n",
            "Training on 10 examples for 5 epochs, lr: 0.001\n",
            "No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n",
            "Starting training...\n",
            "{'loss': 4.6972, 'grad_norm': 6.128959655761719, 'learning_rate': 0.0, 'epoch': 0.2}\n",
            "{'loss': 4.8718, 'grad_norm': 5.768027305603027, 'learning_rate': 9.090909090909092e-05, 'epoch': 0.4}\n",
            "{'loss': 5.7381, 'grad_norm': 9.854024887084961, 'learning_rate': 0.00018181818181818183, 'epoch': 0.6}\n",
            "{'loss': 1.1727, 'grad_norm': 5.880247116088867, 'learning_rate': 0.00027272727272727274, 'epoch': 0.8}\n",
            "{'loss': 0.6237, 'grad_norm': 5.0073323249816895, 'learning_rate': 0.00036363636363636367, 'epoch': 1.0}\n",
            "{'loss': 0.3875, 'grad_norm': 0.8534306287765503, 'learning_rate': 0.00045454545454545455, 'epoch': 1.2}\n",
            "{'loss': 0.2683, 'grad_norm': 0.6017436981201172, 'learning_rate': 0.0005454545454545455, 'epoch': 1.4}\n",
            "{'loss': 0.0863, 'grad_norm': 0.2506377398967743, 'learning_rate': 0.0006363636363636364, 'epoch': 1.6}\n",
            "{'loss': 0.0651, 'grad_norm': 0.507348358631134, 'learning_rate': 0.0007272727272727273, 'epoch': 1.8}\n",
            "{'loss': 0.1249, 'grad_norm': 0.4927365481853485, 'learning_rate': 0.0008181818181818183, 'epoch': 2.0}\n",
            "{'loss': 0.0191, 'grad_norm': 0.16104353964328766, 'learning_rate': 0.0009090909090909091, 'epoch': 2.2}\n",
            "{'loss': 0.0165, 'grad_norm': 0.2621174156665802, 'learning_rate': 0.001, 'epoch': 2.4}\n",
            "{'loss': 0.0016, 'grad_norm': 0.024265548214316368, 'learning_rate': 0.0009874639560909118, 'epoch': 2.6}\n",
            "{'loss': 0.0137, 'grad_norm': 0.653573215007782, 'learning_rate': 0.0009504844339512095, 'epoch': 2.8}\n",
            "{'loss': 0.1762, 'grad_norm': 1.8903642892837524, 'learning_rate': 0.000890915741234015, 'epoch': 3.0}\n",
            "{'loss': 0.0757, 'grad_norm': 0.39262285828590393, 'learning_rate': 0.0008117449009293668, 'epoch': 3.2}\n",
            "{'loss': 0.0431, 'grad_norm': 0.20485363900661469, 'learning_rate': 0.0007169418695587791, 'epoch': 3.4}\n",
            "{'loss': 0.0162, 'grad_norm': 0.4094812870025635, 'learning_rate': 0.0006112604669781572, 'epoch': 3.6}\n",
            "{'loss': 0.026, 'grad_norm': 0.14489975571632385, 'learning_rate': 0.0005, 'epoch': 3.8}\n",
            "{'loss': 0.0274, 'grad_norm': 0.22571586072444916, 'learning_rate': 0.00038873953302184284, 'epoch': 4.0}\n",
            "{'loss': 0.0214, 'grad_norm': 0.08484219014644623, 'learning_rate': 0.00028305813044122096, 'epoch': 4.2}\n",
            "{'loss': 0.0077, 'grad_norm': 0.032934267073869705, 'learning_rate': 0.00018825509907063325, 'epoch': 4.4}\n",
            "{'loss': 0.0035, 'grad_norm': 0.021422039717435837, 'learning_rate': 0.0001090842587659851, 'epoch': 4.6}\n",
            "{'loss': 0.0061, 'grad_norm': 0.03876129910349846, 'learning_rate': 4.9515566048790485e-05, 'epoch': 4.8}\n",
            "{'loss': 0.0057, 'grad_norm': 0.03741675615310669, 'learning_rate': 1.2536043909088191e-05, 'epoch': 5.0}\n",
            "{'train_runtime': 3.1716, 'train_samples_per_second': 15.765, 'train_steps_per_second': 7.883, 'train_loss': 0.7398270401312038, 'epoch': 5.0}\n",
            "100% 25/25 [00:03<00:00,  7.89it/s]\n",
            "Training complete.\n",
            "Model saved to loras/self-edit/training_set_iteration_1/8be77c9e/11\n",
            "Skipping training for task 8be77c9e because the number of steps is greater than 375\n",
            "Training on 250 examples for 0 epochs, lr: 0.01\n",
            "No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n",
            "Starting training...\n",
            "{'train_runtime': 0.0021, 'train_samples_per_second': 0.0, 'train_steps_per_second': 0.0, 'train_loss': 0.0, 'epoch': 0}\n",
            "0it [00:00, ?it/s]\n",
            "Training complete.\n",
            "Model saved to loras/self-edit/training_set_iteration_1/8be77c9e/12\n",
            "Training on 10 examples for 4 epochs, lr: 0.0\n",
            "No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n",
            "Starting training...\n",
            "{'loss': 3.1411, 'grad_norm': 1.8904353380203247, 'learning_rate': 0.0, 'epoch': 0.2}\n",
            "{'loss': 3.1856, 'grad_norm': 1.792729139328003, 'learning_rate': 0.0, 'epoch': 0.4}\n",
            "{'loss': 4.3432, 'grad_norm': 3.559659242630005, 'learning_rate': 0.0, 'epoch': 0.6}\n",
            "{'loss': 3.1593, 'grad_norm': 1.8272141218185425, 'learning_rate': 0.0, 'epoch': 0.8}\n",
            "{'loss': 3.1594, 'grad_norm': 1.8337490558624268, 'learning_rate': 0.0, 'epoch': 1.0}\n",
            "{'loss': 4.408, 'grad_norm': 3.442500352859497, 'learning_rate': 0.0, 'epoch': 1.2}\n",
            "{'loss': 3.1593, 'grad_norm': 1.8272138833999634, 'learning_rate': 0.0, 'epoch': 1.4}\n",
            "{'loss': 3.1209, 'grad_norm': 1.8925079107284546, 'learning_rate': 0.0, 'epoch': 1.6}\n",
            "{'loss': 4.3786, 'grad_norm': 3.543750047683716, 'learning_rate': 0.0, 'epoch': 1.8}\n",
            "{'loss': 1.9197, 'grad_norm': 0.6338075399398804, 'learning_rate': 0.0, 'epoch': 2.0}\n",
            "{'loss': 3.1411, 'grad_norm': 1.8904353380203247, 'learning_rate': 0.0, 'epoch': 2.2}\n",
            "{'loss': 3.197, 'grad_norm': 1.7936806678771973, 'learning_rate': 0.0, 'epoch': 2.4}\n",
            "{'loss': 4.3913, 'grad_norm': 3.4766530990600586, 'learning_rate': 0.0, 'epoch': 2.6}\n",
            "{'loss': 3.1337, 'grad_norm': 1.840197205543518, 'learning_rate': 0.0, 'epoch': 2.8}\n",
            "{'loss': 3.1254, 'grad_norm': 1.8925002813339233, 'learning_rate': 0.0, 'epoch': 3.0}\n",
            "{'loss': 4.3786, 'grad_norm': 3.543750047683716, 'learning_rate': 0.0, 'epoch': 3.2}\n",
            "{'loss': 3.1323, 'grad_norm': 1.8927710056304932, 'learning_rate': 0.0, 'epoch': 3.4}\n",
            "{'loss': 4.3771, 'grad_norm': 3.478585720062256, 'learning_rate': 0.0, 'epoch': 3.6}\n",
            "{'loss': 3.1902, 'grad_norm': 1.7927318811416626, 'learning_rate': 0.0, 'epoch': 3.8}\n",
            "{'loss': 1.9091, 'grad_norm': 0.6317539811134338, 'learning_rate': 0.0, 'epoch': 4.0}\n",
            "{'train_runtime': 2.5553, 'train_samples_per_second': 15.654, 'train_steps_per_second': 7.827, 'train_loss': 3.397531282901764, 'epoch': 4.0}\n",
            "100% 20/20 [00:02<00:00,  7.83it/s]\n",
            "Training complete.\n",
            "Model saved to loras/self-edit/training_set_iteration_1/8be77c9e/13\n",
            "Training on 10 examples for 3 epochs, lr: 0.1\n",
            "No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n",
            "Starting training...\n",
            "{'loss': 3.1411, 'grad_norm': 1.8904353380203247, 'learning_rate': 0.0, 'epoch': 0.2}\n",
            "{'loss': 3.1856, 'grad_norm': 1.792729139328003, 'learning_rate': 0.009090909090909092, 'epoch': 0.4}\n",
            "{'loss': 2.7696, 'grad_norm': 7.3576860427856445, 'learning_rate': 0.018181818181818184, 'epoch': 0.6}\n",
            "{'loss': 14.6716, 'grad_norm': 63.942630767822266, 'learning_rate': 0.02727272727272727, 'epoch': 0.8}\n",
            "{'loss': 16.865, 'grad_norm': 11.682975769042969, 'learning_rate': 0.03636363636363637, 'epoch': 1.0}\n",
            "{'loss': 26.17, 'grad_norm': 149.75143432617188, 'learning_rate': 0.045454545454545456, 'epoch': 1.2}\n",
            "{'loss': 14.5565, 'grad_norm': 2.537130355834961, 'learning_rate': 0.05454545454545454, 'epoch': 1.4}\n",
            "{'loss': 17.8192, 'grad_norm': 10.351460456848145, 'learning_rate': 0.06363636363636364, 'epoch': 1.6}\n",
            "{'loss': 43.2163, 'grad_norm': 2.4630019664764404, 'learning_rate': 0.07272727272727274, 'epoch': 1.8}\n",
            "{'loss': 18.2382, 'grad_norm': 1.1299034357070923, 'learning_rate': 0.08181818181818183, 'epoch': 2.0}\n",
            "{'loss': 12.2053, 'grad_norm': 0.9991644024848938, 'learning_rate': 0.09090909090909091, 'epoch': 2.2}\n",
            "{'loss': 11.3223, 'grad_norm': 0.713196337223053, 'learning_rate': 0.1, 'epoch': 2.4}\n",
            "{'loss': 14.0168, 'grad_norm': 0.8886701464653015, 'learning_rate': 0.08535533905932738, 'epoch': 2.6}\n",
            "{'loss': 10.6815, 'grad_norm': 0.37227025628089905, 'learning_rate': 0.05, 'epoch': 2.8}\n",
            "{'loss': 10.9526, 'grad_norm': 0.4368029534816742, 'learning_rate': 0.014644660940672627, 'epoch': 3.0}\n",
            "{'train_runtime': 1.8959, 'train_samples_per_second': 15.823, 'train_steps_per_second': 7.912, 'train_loss': 14.654107332229614, 'epoch': 3.0}\n",
            "100% 15/15 [00:01<00:00,  7.92it/s]\n",
            "Training complete.\n",
            "Model saved to loras/self-edit/training_set_iteration_1/8be77c9e/14\n",
            "Training on 250 examples for 3 epochs, lr: 0.01\n",
            "No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n",
            "Starting training...\n",
            "{'loss': 4.5655, 'grad_norm': 5.244909286499023, 'learning_rate': 0.0, 'epoch': 0.01}\n",
            "{'loss': 5.9031, 'grad_norm': 7.481143474578857, 'learning_rate': 0.0009090909090909091, 'epoch': 0.02}\n",
            "{'loss': 0.6359, 'grad_norm': 0.6235630512237549, 'learning_rate': 0.0018181818181818182, 'epoch': 0.02}\n",
            "{'loss': 0.4637, 'grad_norm': 1.8826669454574585, 'learning_rate': 0.002727272727272727, 'epoch': 0.03}\n",
            "{'loss': 0.6459, 'grad_norm': 0.462176650762558, 'learning_rate': 0.0036363636363636364, 'epoch': 0.04}\n",
            "{'loss': 2.1227, 'grad_norm': 9.060483932495117, 'learning_rate': 0.004545454545454545, 'epoch': 0.05}\n",
            "{'loss': 0.7415, 'grad_norm': 2.3861608505249023, 'learning_rate': 0.005454545454545454, 'epoch': 0.06}\n",
            "{'loss': 0.7621, 'grad_norm': 1.4219396114349365, 'learning_rate': 0.006363636363636364, 'epoch': 0.06}\n",
            "{'loss': 1.0477, 'grad_norm': 4.274951457977295, 'learning_rate': 0.007272727272727273, 'epoch': 0.07}\n",
            "{'loss': 1.8171, 'grad_norm': 16.443096160888672, 'learning_rate': 0.008181818181818182, 'epoch': 0.08}\n",
            "{'loss': 1.9973, 'grad_norm': 9.596484184265137, 'learning_rate': 0.00909090909090909, 'epoch': 0.09}\n",
            "{'loss': 6.0942, 'grad_norm': 48.0977897644043, 'learning_rate': 0.01, 'epoch': 0.1}\n",
            "{'loss': 11.6454, 'grad_norm': 35.01673126220703, 'learning_rate': 0.009999813776583147, 'epoch': 0.1}\n",
            "{'loss': 12.9904, 'grad_norm': 22.980680465698242, 'learning_rate': 0.009999255120204246, 'epoch': 0.11}\n",
            "{'loss': 6.1327, 'grad_norm': 8.246633529663086, 'learning_rate': 0.009998324072477265, 'epoch': 0.12}\n",
            "{'loss': 15.5117, 'grad_norm': 6.878859519958496, 'learning_rate': 0.009997020702755353, 'epoch': 0.13}\n",
            "{'loss': 8.9289, 'grad_norm': 4.314034938812256, 'learning_rate': 0.009995345108125697, 'epoch': 0.14}\n",
            "{'loss': 13.3092, 'grad_norm': 20.40738296508789, 'learning_rate': 0.009993297413402281, 'epoch': 0.14}\n",
            "{'loss': 12.2415, 'grad_norm': 4.752323627471924, 'learning_rate': 0.009990877771116588, 'epoch': 0.15}\n",
            "{'loss': 8.9941, 'grad_norm': 4.08892297744751, 'learning_rate': 0.009988086361506238, 'epoch': 0.16}\n",
            "{'loss': 6.4634, 'grad_norm': 2.528502941131592, 'learning_rate': 0.009984923392501567, 'epoch': 0.17}\n",
            "{'loss': 2.6862, 'grad_norm': 0.9425624012947083, 'learning_rate': 0.009981389099710133, 'epoch': 0.18}\n",
            "{'loss': 4.1851, 'grad_norm': 1.1704223155975342, 'learning_rate': 0.009977483746399167, 'epoch': 0.18}\n",
            "{'loss': 3.3094, 'grad_norm': 3.5228002071380615, 'learning_rate': 0.009973207623475963, 'epoch': 0.19}\n",
            "{'loss': 2.5111, 'grad_norm': 2.9418962001800537, 'learning_rate': 0.009968561049466213, 'epoch': 0.2}\n",
            "{'loss': 3.7959, 'grad_norm': 2.242039680480957, 'learning_rate': 0.00996354437049027, 'epoch': 0.21}\n",
            "{'loss': 4.3115, 'grad_norm': 2.0756890773773193, 'learning_rate': 0.009958157960237374, 'epoch': 0.22}\n",
            "{'loss': 2.5466, 'grad_norm': 0.8815900683403015, 'learning_rate': 0.009952402219937815, 'epoch': 0.22}\n",
            "{'loss': 4.6873, 'grad_norm': 2.784856081008911, 'learning_rate': 0.009946277578333045, 'epoch': 0.23}\n",
            "{'loss': 2.4917, 'grad_norm': 0.7741329669952393, 'learning_rate': 0.009939784491643733, 'epoch': 0.24}\n",
            "{'loss': 3.0738, 'grad_norm': 1.5565115213394165, 'learning_rate': 0.009932923443535798, 'epoch': 0.25}\n",
            "{'loss': 2.4415, 'grad_norm': 0.697239339351654, 'learning_rate': 0.009925694945084369, 'epoch': 0.26}\n",
            "{'loss': 2.9194, 'grad_norm': 0.6742638945579529, 'learning_rate': 0.009918099534735719, 'epoch': 0.26}\n",
            "{'loss': 2.455, 'grad_norm': 0.852360725402832, 'learning_rate': 0.009910137778267152, 'epoch': 0.27}\n",
            "{'loss': 2.5278, 'grad_norm': 0.658845841884613, 'learning_rate': 0.009901810268744867, 'epoch': 0.28}\n",
            "{'loss': 2.3575, 'grad_norm': 0.5118542313575745, 'learning_rate': 0.009893117626479776, 'epoch': 0.29}\n",
            "{'loss': 2.3072, 'grad_norm': 0.5257301926612854, 'learning_rate': 0.009884060498981296, 'epoch': 0.3}\n",
            "{'loss': 1.9507, 'grad_norm': 0.4013283848762512, 'learning_rate': 0.009874639560909117, 'epoch': 0.3}\n",
            "{'loss': 2.0699, 'grad_norm': 0.5712435841560364, 'learning_rate': 0.009864855514022955, 'epoch': 0.31}\n",
            "{'loss': 1.5533, 'grad_norm': 0.31254079937934875, 'learning_rate': 0.009854709087130261, 'epoch': 0.32}\n",
            "{'loss': 1.7656, 'grad_norm': 0.3558737337589264, 'learning_rate': 0.00984420103603195, 'epoch': 0.33}\n",
            "{'loss': 1.1959, 'grad_norm': 0.35759443044662476, 'learning_rate': 0.009833332143466099, 'epoch': 0.34}\n",
            "{'loss': 1.8446, 'grad_norm': 0.4659200608730316, 'learning_rate': 0.009822103219049624, 'epoch': 0.34}\n",
            "{'loss': 1.4391, 'grad_norm': 0.8687809705734253, 'learning_rate': 0.009810515099218002, 'epoch': 0.35}\n",
            "{'loss': 1.2565, 'grad_norm': 0.6507587432861328, 'learning_rate': 0.009798568647162938, 'epoch': 0.36}\n",
            "{'loss': 1.3055, 'grad_norm': 0.6208480000495911, 'learning_rate': 0.00978626475276808, 'epoch': 0.37}\n",
            "{'loss': 1.7068, 'grad_norm': 1.2637968063354492, 'learning_rate': 0.009773604332542728, 'epoch': 0.38}\n",
            "{'loss': 1.2533, 'grad_norm': 0.20040924847126007, 'learning_rate': 0.00976058832955357, 'epoch': 0.38}\n",
            "{'loss': 1.9682, 'grad_norm': 0.6594369411468506, 'learning_rate': 0.009747217713354427, 'epoch': 0.39}\n",
            "{'loss': 1.2016, 'grad_norm': 0.24783271551132202, 'learning_rate': 0.009733493479914031, 'epoch': 0.4}\n",
            "{'loss': 1.8671, 'grad_norm': 0.4083903431892395, 'learning_rate': 0.009719416651541838, 'epoch': 0.41}\n",
            "{'loss': 1.9783, 'grad_norm': 0.342747300863266, 'learning_rate': 0.009704988276811882, 'epoch': 0.42}\n",
            "{'loss': 0.9047, 'grad_norm': 0.12399867922067642, 'learning_rate': 0.00969020943048466, 'epoch': 0.42}\n",
            "{'loss': 1.1943, 'grad_norm': 0.2453927844762802, 'learning_rate': 0.009675081213427075, 'epoch': 0.43}\n",
            "{'loss': 1.2124, 'grad_norm': 0.18529805541038513, 'learning_rate': 0.009659604752530434, 'epoch': 0.44}\n",
            "{'loss': 1.4913, 'grad_norm': 0.2134077250957489, 'learning_rate': 0.00964378120062651, 'epoch': 0.45}\n",
            "{'loss': 1.0152, 'grad_norm': 0.1360868364572525, 'learning_rate': 0.009627611736401667, 'epoch': 0.46}\n",
            "{'loss': 1.2025, 'grad_norm': 0.17477089166641235, 'learning_rate': 0.009611097564309053, 'epoch': 0.46}\n",
            "{'loss': 1.7826, 'grad_norm': 0.46976977586746216, 'learning_rate': 0.009594239914478886, 'epoch': 0.47}\n",
            "{'loss': 1.0717, 'grad_norm': 0.10387920588254929, 'learning_rate': 0.009577040042626833, 'epoch': 0.48}\n",
            "{'loss': 1.266, 'grad_norm': 0.1576230227947235, 'learning_rate': 0.00955949922996045, 'epoch': 0.49}\n",
            "{'loss': 1.3116, 'grad_norm': 0.5253888368606567, 'learning_rate': 0.00954161878308377, 'epoch': 0.5}\n",
            "{'loss': 0.9905, 'grad_norm': 0.07006882131099701, 'learning_rate': 0.009523400033899955, 'epoch': 0.5}\n",
            "{'loss': 1.2227, 'grad_norm': 0.17004501819610596, 'learning_rate': 0.009504844339512096, 'epoch': 0.51}\n",
            "{'loss': 1.4865, 'grad_norm': 0.1274002492427826, 'learning_rate': 0.009485953082122116, 'epoch': 0.52}\n",
            "{'loss': 0.7712, 'grad_norm': 0.05231666564941406, 'learning_rate': 0.009466727668927815, 'epoch': 0.53}\n",
            "{'loss': 1.6551, 'grad_norm': 0.23508431017398834, 'learning_rate': 0.00944716953201805, 'epoch': 0.54}\n",
            "{'loss': 0.8162, 'grad_norm': 0.059947725385427475, 'learning_rate': 0.009427280128266049, 'epoch': 0.54}\n",
            "{'loss': 1.0492, 'grad_norm': 0.10676023364067078, 'learning_rate': 0.009407060939220908, 'epoch': 0.55}\n",
            "{'loss': 1.044, 'grad_norm': 0.08573633432388306, 'learning_rate': 0.00938651347099721, 'epoch': 0.56}\n",
            "{'loss': 0.7589, 'grad_norm': 0.06351034343242645, 'learning_rate': 0.009365639254162854, 'epoch': 0.57}\n",
            "{'loss': 1.1079, 'grad_norm': 0.06806081533432007, 'learning_rate': 0.009344439843625034, 'epoch': 0.58}\n",
            "{'loss': 0.8788, 'grad_norm': 0.057235389947891235, 'learning_rate': 0.009322916818514413, 'epoch': 0.58}\n",
            "{'loss': 1.3702, 'grad_norm': 0.2017260044813156, 'learning_rate': 0.009301071782067504, 'epoch': 0.59}\n",
            "{'loss': 1.4006, 'grad_norm': 0.5016472935676575, 'learning_rate': 0.009278906361507237, 'epoch': 0.6}\n",
            "{'loss': 0.8802, 'grad_norm': 0.08316349983215332, 'learning_rate': 0.009256422207921756, 'epoch': 0.61}\n",
            "{'loss': 1.1467, 'grad_norm': 0.15811675786972046, 'learning_rate': 0.00923362099614142, 'epoch': 0.62}\n",
            "{'loss': 1.1571, 'grad_norm': 0.15402375161647797, 'learning_rate': 0.009210504424614059, 'epoch': 0.62}\n",
            "{'loss': 1.0829, 'grad_norm': 0.11848655343055725, 'learning_rate': 0.009187074215278444, 'epoch': 0.63}\n",
            "{'loss': 1.022, 'grad_norm': 0.06574918329715729, 'learning_rate': 0.009163332113436031, 'epoch': 0.64}\n",
            "{'loss': 0.8615, 'grad_norm': 0.0575018934905529, 'learning_rate': 0.009139279887620954, 'epoch': 0.65}\n",
            "{'loss': 1.0709, 'grad_norm': 0.16878767311573029, 'learning_rate': 0.009114919329468282, 'epoch': 0.66}\n",
            "{'loss': 1.3204, 'grad_norm': 0.13727551698684692, 'learning_rate': 0.009090252253580565, 'epoch': 0.66}\n",
            "{'loss': 0.8431, 'grad_norm': 0.04635259881615639, 'learning_rate': 0.009065280497392662, 'epoch': 0.67}\n",
            "{'loss': 0.959, 'grad_norm': 0.17111614346504211, 'learning_rate': 0.009040005921034882, 'epoch': 0.68}\n",
            "{'loss': 1.2127, 'grad_norm': 0.16732081770896912, 'learning_rate': 0.009014430407194412, 'epoch': 0.69}\n",
            "{'loss': 0.8406, 'grad_norm': 2.610232353210449, 'learning_rate': 0.008988555860975082, 'epoch': 0.7}\n",
            "{'loss': 1.0121, 'grad_norm': 0.46094179153442383, 'learning_rate': 0.008962384209755451, 'epoch': 0.7}\n",
            "{'loss': 0.9461, 'grad_norm': 0.11070148646831512, 'learning_rate': 0.00893591740304525, 'epoch': 0.71}\n",
            "{'loss': 1.1006, 'grad_norm': 0.11076976358890533, 'learning_rate': 0.008909157412340149, 'epoch': 0.72}\n",
            "{'loss': 1.2446, 'grad_norm': 0.1210821121931076, 'learning_rate': 0.008882106230974908, 'epoch': 0.73}\n",
            "{'loss': 1.2232, 'grad_norm': 0.17038476467132568, 'learning_rate': 0.008854765873974898, 'epoch': 0.74}\n",
            "{'loss': 0.8181, 'grad_norm': 0.07378800958395004, 'learning_rate': 0.008827138377905998, 'epoch': 0.74}\n",
            "{'loss': 0.9214, 'grad_norm': 0.29357218742370605, 'learning_rate': 0.008799225800722895, 'epoch': 0.75}\n",
            "{'loss': 1.1678, 'grad_norm': 0.11989116668701172, 'learning_rate': 0.008771030221615786, 'epoch': 0.76}\n",
            "{'loss': 0.6631, 'grad_norm': 0.04882950335741043, 'learning_rate': 0.008742553740855506, 'epoch': 0.77}\n",
            "{'loss': 0.8621, 'grad_norm': 0.07647755742073059, 'learning_rate': 0.008713798479637071, 'epoch': 0.78}\n",
            "{'loss': 1.1402, 'grad_norm': 0.12223022431135178, 'learning_rate': 0.008684766579921684, 'epoch': 0.78}\n",
            "{'loss': 1.1255, 'grad_norm': 0.11721216887235641, 'learning_rate': 0.008655460204277167, 'epoch': 0.79}\n",
            "{'loss': 1.1016, 'grad_norm': 0.18333008885383606, 'learning_rate': 0.008625881535716882, 'epoch': 0.8}\n",
            "{'loss': 1.0612, 'grad_norm': 0.0814572125673294, 'learning_rate': 0.008596032777537123, 'epoch': 0.81}\n",
            "{'loss': 0.9598, 'grad_norm': 0.07621357589960098, 'learning_rate': 0.008565916153152981, 'epoch': 0.82}\n",
            "{'loss': 0.97, 'grad_norm': 0.0822998583316803, 'learning_rate': 0.008535533905932738, 'epoch': 0.82}\n",
            "{'loss': 0.8847, 'grad_norm': 0.11472123116254807, 'learning_rate': 0.008504888299030747, 'epoch': 0.83}\n",
            "{'loss': 0.7554, 'grad_norm': 0.10058077424764633, 'learning_rate': 0.008473981615218862, 'epoch': 0.84}\n",
            "{'loss': 0.8621, 'grad_norm': 0.05493820086121559, 'learning_rate': 0.008442816156716385, 'epoch': 0.85}\n",
            "{'loss': 1.1152, 'grad_norm': 0.12210230529308319, 'learning_rate': 0.008411394245018588, 'epoch': 0.86}\n",
            "{'loss': 0.7719, 'grad_norm': 0.2220204770565033, 'learning_rate': 0.008379718220723772, 'epoch': 0.86}\n",
            "{'loss': 0.8537, 'grad_norm': 0.08580467849969864, 'learning_rate': 0.008347790443358928, 'epoch': 0.87}\n",
            "{'loss': 0.9945, 'grad_norm': 0.10732174664735794, 'learning_rate': 0.008315613291203975, 'epoch': 0.88}\n",
            "{'loss': 1.01, 'grad_norm': 0.09024951606988907, 'learning_rate': 0.0082831891611146, 'epoch': 0.89}\n",
            "{'loss': 0.6312, 'grad_norm': 0.045868776738643646, 'learning_rate': 0.00825052046834372, 'epoch': 0.9}\n",
            "{'loss': 0.911, 'grad_norm': 0.14213134348392487, 'learning_rate': 0.008217609646361573, 'epoch': 0.9}\n",
            "{'loss': 0.8681, 'grad_norm': 0.06434012204408646, 'learning_rate': 0.008184459146674447, 'epoch': 0.91}\n",
            "{'loss': 0.7468, 'grad_norm': 0.0530850812792778, 'learning_rate': 0.008151071438642068, 'epoch': 0.92}\n",
            "{'loss': 1.4131, 'grad_norm': 0.18711227178573608, 'learning_rate': 0.008117449009293669, 'epoch': 0.93}\n",
            "{'loss': 1.1121, 'grad_norm': 0.1428617686033249, 'learning_rate': 0.008083594363142717, 'epoch': 0.94}\n",
            "{'loss': 0.6553, 'grad_norm': 2.389239549636841, 'learning_rate': 0.008049510022000364, 'epoch': 0.94}\n",
            "{'loss': 0.6713, 'grad_norm': 0.10236380249261856, 'learning_rate': 0.008015198524787602, 'epoch': 0.95}\n",
            "{'loss': 0.6828, 'grad_norm': 0.10479537397623062, 'learning_rate': 0.007980662427346127, 'epoch': 0.96}\n",
            "{'loss': 0.8877, 'grad_norm': 0.18206220865249634, 'learning_rate': 0.007945904302247968, 'epoch': 0.97}\n",
            "{'loss': 0.8954, 'grad_norm': 0.11877681314945221, 'learning_rate': 0.007910926738603854, 'epoch': 0.98}\n",
            "{'loss': 0.9222, 'grad_norm': 0.14932020008563995, 'learning_rate': 0.007875732341870348, 'epoch': 0.98}\n",
            "{'loss': 0.9999, 'grad_norm': 0.19091100990772247, 'learning_rate': 0.007840323733655778, 'epoch': 0.99}\n",
            "{'loss': 0.8538, 'grad_norm': 0.06972408294677734, 'learning_rate': 0.007804703551524948, 'epoch': 1.0}\n",
            "{'loss': 1.0557, 'grad_norm': 0.27598512172698975, 'learning_rate': 0.0077688744488026654, 'epoch': 1.01}\n",
            "{'loss': 0.8023, 'grad_norm': 0.0805322602391243, 'learning_rate': 0.007732839094376105, 'epoch': 1.02}\n",
            "{'loss': 1.0444, 'grad_norm': 0.10900586098432541, 'learning_rate': 0.007696600172495996, 'epoch': 1.02}\n",
            "{'loss': 0.7289, 'grad_norm': 0.12366750836372375, 'learning_rate': 0.007660160382576683, 'epoch': 1.03}\n",
            "{'loss': 0.9429, 'grad_norm': 0.2608392834663391, 'learning_rate': 0.00762352243899504, 'epoch': 1.04}\n",
            "{'loss': 1.0781, 'grad_norm': 0.09757160395383835, 'learning_rate': 0.007586689070888284, 'epoch': 1.05}\n",
            "{'loss': 1.074, 'grad_norm': 0.10317100584506989, 'learning_rate': 0.00754966302195068, 'epoch': 1.06}\n",
            "{'loss': 0.8682, 'grad_norm': 0.10376229882240295, 'learning_rate': 0.007512447050229166, 'epoch': 1.06}\n",
            "{'loss': 1.0351, 'grad_norm': 0.24485301971435547, 'learning_rate': 0.007475043927917907, 'epoch': 1.07}\n",
            "{'loss': 0.9244, 'grad_norm': 0.10151180624961853, 'learning_rate': 0.007437456441151799, 'epoch': 1.08}\n",
            "{'loss': 0.9474, 'grad_norm': 0.09056437760591507, 'learning_rate': 0.007399687389798932, 'epoch': 1.09}\n",
            "{'loss': 0.5971, 'grad_norm': 0.0695687010884285, 'learning_rate': 0.007361739587252019, 'epoch': 1.1}\n",
            "{'loss': 0.9344, 'grad_norm': 0.12153428047895432, 'learning_rate': 0.007323615860218843, 'epoch': 1.1}\n",
            "{'loss': 0.899, 'grad_norm': 0.08706735074520111, 'learning_rate': 0.00728531904851169, 'epoch': 1.11}\n",
            "{'loss': 1.0994, 'grad_norm': 0.13976329565048218, 'learning_rate': 0.007246852004835807, 'epoch': 1.12}\n",
            "{'loss': 1.0962, 'grad_norm': 0.13205747306346893, 'learning_rate': 0.007208217594576923, 'epoch': 1.13}\n",
            "{'loss': 0.8504, 'grad_norm': 0.1549188643693924, 'learning_rate': 0.007169418695587791, 'epoch': 1.14}\n",
            "{'loss': 0.5817, 'grad_norm': 0.06497932225465775, 'learning_rate': 0.007130458197973828, 'epoch': 1.14}\n",
            "{'loss': 0.6471, 'grad_norm': 0.0646403506398201, 'learning_rate': 0.0070913390038778255, 'epoch': 1.15}\n",
            "{'loss': 0.8125, 'grad_norm': 0.13668082654476166, 'learning_rate': 0.007052064027263785, 'epoch': 1.16}\n",
            "{'loss': 0.9041, 'grad_norm': 0.11805674433708191, 'learning_rate': 0.0070126361936998375, 'epoch': 1.17}\n",
            "{'loss': 1.1749, 'grad_norm': 0.20388475060462952, 'learning_rate': 0.006973058440140341, 'epoch': 1.18}\n",
            "{'loss': 1.5344, 'grad_norm': 0.24541133642196655, 'learning_rate': 0.006933333714707094, 'epoch': 1.18}\n",
            "{'loss': 0.7592, 'grad_norm': 0.0941336378455162, 'learning_rate': 0.006893464976469739, 'epoch': 1.19}\n",
            "{'loss': 0.804, 'grad_norm': 0.10812597721815109, 'learning_rate': 0.006853455195225339, 'epoch': 1.2}\n",
            "{'loss': 1.0791, 'grad_norm': 0.20451179146766663, 'learning_rate': 0.00681330735127716, 'epoch': 1.21}\n",
            "{'loss': 0.9206, 'grad_norm': 0.11422067880630493, 'learning_rate': 0.006773024435212678, 'epoch': 1.22}\n",
            "{'loss': 1.1393, 'grad_norm': 0.19427822530269623, 'learning_rate': 0.0067326094476808, 'epoch': 1.22}\n",
            "{'loss': 1.3263, 'grad_norm': 0.2891645133495331, 'learning_rate': 0.0066920653991683525, 'epoch': 1.23}\n",
            "{'loss': 0.8152, 'grad_norm': 0.11344049870967865, 'learning_rate': 0.006651395309775836, 'epoch': 1.24}\n",
            "{'loss': 0.9396, 'grad_norm': 0.12350242584943771, 'learning_rate': 0.006610602208992454, 'epoch': 1.25}\n",
            "{'loss': 0.6296, 'grad_norm': 0.0847158432006836, 'learning_rate': 0.00656968913547045, 'epoch': 1.26}\n",
            "{'loss': 0.5675, 'grad_norm': 0.08175498992204666, 'learning_rate': 0.006528659136798765, 'epoch': 1.26}\n",
            "{'loss': 1.0261, 'grad_norm': 0.2226743996143341, 'learning_rate': 0.006487515269276016, 'epoch': 1.27}\n",
            "{'loss': 0.8421, 'grad_norm': 0.07835966348648071, 'learning_rate': 0.0064462605976828395, 'epoch': 1.28}\n",
            "{'loss': 0.8303, 'grad_norm': 0.0842791199684143, 'learning_rate': 0.0064048981950535966, 'epoch': 1.29}\n",
            "{'loss': 0.6356, 'grad_norm': 0.06192167103290558, 'learning_rate': 0.006363431142447469, 'epoch': 1.3}\n",
            "{'loss': 1.226, 'grad_norm': 0.1760963350534439, 'learning_rate': 0.006321862528718945, 'epoch': 1.3}\n",
            "{'loss': 0.8148, 'grad_norm': 0.1018008440732956, 'learning_rate': 0.006280195450287736, 'epoch': 1.31}\n",
            "{'loss': 0.9449, 'grad_norm': 0.06711854785680771, 'learning_rate': 0.00623843301090813, 'epoch': 1.32}\n",
            "{'loss': 0.7138, 'grad_norm': 0.05902521684765816, 'learning_rate': 0.006196578321437789, 'epoch': 1.33}\n",
            "{'loss': 0.5163, 'grad_norm': 0.04877990856766701, 'learning_rate': 0.006154634499606029, 'epoch': 1.34}\n",
            "{'loss': 0.8198, 'grad_norm': 0.09157656133174896, 'learning_rate': 0.006112604669781572, 'epoch': 1.34}\n",
            "{'loss': 0.7616, 'grad_norm': 0.08102747052907944, 'learning_rate': 0.0060704919627398305, 'epoch': 1.35}\n",
            "{'loss': 0.6995, 'grad_norm': 0.08201447874307632, 'learning_rate': 0.006028299515429682, 'epoch': 1.36}\n",
            "{'loss': 0.7818, 'grad_norm': 0.10473905503749847, 'learning_rate': 0.005986030470739811, 'epoch': 1.37}\n",
            "{'loss': 0.9537, 'grad_norm': 0.12205028533935547, 'learning_rate': 0.005943687977264584, 'epoch': 1.38}\n",
            "{'loss': 0.6305, 'grad_norm': 0.07205091416835785, 'learning_rate': 0.005901275189069529, 'epoch': 1.38}\n",
            "{'loss': 1.0739, 'grad_norm': 0.26855412125587463, 'learning_rate': 0.005858795265456382, 'epoch': 1.39}\n",
            "{'loss': 0.7769, 'grad_norm': 0.05555976182222366, 'learning_rate': 0.005816251370727748, 'epoch': 1.4}\n",
            "{'loss': 0.6753, 'grad_norm': 0.07506293803453445, 'learning_rate': 0.005773646673951406, 'epoch': 1.41}\n",
            "{'loss': 0.8116, 'grad_norm': 0.09779217839241028, 'learning_rate': 0.005730984348724242, 'epoch': 1.42}\n",
            "{'loss': 0.8259, 'grad_norm': 0.11892601102590561, 'learning_rate': 0.005688267572935842, 'epoch': 1.42}\n",
            "{'loss': 0.9739, 'grad_norm': 0.10970408469438553, 'learning_rate': 0.005645499528531784, 'epoch': 1.43}\n",
            "{'loss': 0.6164, 'grad_norm': 0.07045941054821014, 'learning_rate': 0.005602683401276615, 'epoch': 1.44}\n",
            "{'loss': 0.78, 'grad_norm': 0.08129164576530457, 'learning_rate': 0.005559822380516539, 'epoch': 1.45}\n",
            "{'loss': 0.5826, 'grad_norm': 0.04585223272442818, 'learning_rate': 0.00551691965894185, 'epoch': 1.46}\n",
            "{'loss': 0.7137, 'grad_norm': 0.05720951408147812, 'learning_rate': 0.005473978432349111, 'epoch': 1.46}\n",
            "{'loss': 1.0047, 'grad_norm': 0.19495448470115662, 'learning_rate': 0.0054310018994030975, 'epoch': 1.47}\n",
            "{'loss': 0.6838, 'grad_norm': 0.05064854025840759, 'learning_rate': 0.005387993261398532, 'epoch': 1.48}\n",
            "{'loss': 1.0695, 'grad_norm': 0.13803960382938385, 'learning_rate': 0.005344955722021624, 'epoch': 1.49}\n",
            "{'loss': 0.5054, 'grad_norm': 0.0370267853140831, 'learning_rate': 0.00530189248711143, 'epoch': 1.5}\n",
            "{'loss': 1.1317, 'grad_norm': 0.11268320679664612, 'learning_rate': 0.005258806764421048, 'epoch': 1.5}\n",
            "{'loss': 0.7312, 'grad_norm': 0.09430290758609772, 'learning_rate': 0.005215701763378673, 'epoch': 1.51}\n",
            "{'loss': 0.8787, 'grad_norm': 0.10793398320674896, 'learning_rate': 0.005172580694848541, 'epoch': 1.52}\n",
            "{'loss': 0.8367, 'grad_norm': 0.10226130485534668, 'learning_rate': 0.005129446770891738, 'epoch': 1.53}\n",
            "{'loss': 0.735, 'grad_norm': 0.07915312051773071, 'learning_rate': 0.0050863032045269435, 'epoch': 1.54}\n",
            "{'loss': 0.9947, 'grad_norm': 0.11266650259494781, 'learning_rate': 0.0050431532094910945, 'epoch': 1.54}\n",
            "{'loss': 0.829, 'grad_norm': 0.08091016113758087, 'learning_rate': 0.005, 'epoch': 1.55}\n",
            "{'loss': 1.2347, 'grad_norm': 0.15918004512786865, 'learning_rate': 0.004956846790508906, 'epoch': 1.56}\n",
            "{'loss': 0.6389, 'grad_norm': 0.05580276995897293, 'learning_rate': 0.004913696795473058, 'epoch': 1.57}\n",
            "{'loss': 0.9308, 'grad_norm': 0.18010708689689636, 'learning_rate': 0.004870553229108264, 'epoch': 1.58}\n",
            "{'loss': 0.525, 'grad_norm': 0.051398273557424545, 'learning_rate': 0.004827419305151461, 'epoch': 1.58}\n",
            "{'loss': 0.7545, 'grad_norm': 0.08011730760335922, 'learning_rate': 0.004784298236621327, 'epoch': 1.59}\n",
            "{'loss': 0.8257, 'grad_norm': 0.06116746366024017, 'learning_rate': 0.0047411932355789525, 'epoch': 1.6}\n",
            "{'loss': 0.8605, 'grad_norm': 0.09522988647222519, 'learning_rate': 0.004698107512888569, 'epoch': 1.61}\n",
            "{'loss': 0.5894, 'grad_norm': 0.06947411596775055, 'learning_rate': 0.004655044277978375, 'epoch': 1.62}\n",
            "{'loss': 0.8043, 'grad_norm': 0.0668419599533081, 'learning_rate': 0.004612006738601469, 'epoch': 1.62}\n",
            "{'loss': 0.6392, 'grad_norm': 0.0704270601272583, 'learning_rate': 0.004568998100596903, 'epoch': 1.63}\n",
            "{'loss': 0.9268, 'grad_norm': 0.09109706431627274, 'learning_rate': 0.004526021567650889, 'epoch': 1.64}\n",
            "{'loss': 0.7217, 'grad_norm': 0.07708512991666794, 'learning_rate': 0.00448308034105815, 'epoch': 1.65}\n",
            "{'loss': 1.0277, 'grad_norm': 0.1356024146080017, 'learning_rate': 0.004440177619483461, 'epoch': 1.66}\n",
            "{'loss': 0.5403, 'grad_norm': 0.04928038641810417, 'learning_rate': 0.004397316598723385, 'epoch': 1.66}\n",
            "{'loss': 0.7339, 'grad_norm': 0.08320572972297668, 'learning_rate': 0.004354500471468217, 'epoch': 1.67}\n",
            "{'loss': 0.6103, 'grad_norm': 0.07438863068819046, 'learning_rate': 0.00431173242706416, 'epoch': 1.68}\n",
            "{'loss': 0.6875, 'grad_norm': 0.06578102707862854, 'learning_rate': 0.004269015651275761, 'epoch': 1.69}\n",
            "{'loss': 0.6282, 'grad_norm': 0.05488157644867897, 'learning_rate': 0.004226353326048593, 'epoch': 1.7}\n",
            "{'loss': 0.4448, 'grad_norm': 0.036704402416944504, 'learning_rate': 0.004183748629272253, 'epoch': 1.7}\n",
            "{'loss': 0.7176, 'grad_norm': 0.06431492418050766, 'learning_rate': 0.004141204734543619, 'epoch': 1.71}\n",
            "{'loss': 0.6146, 'grad_norm': 0.06771325320005417, 'learning_rate': 0.004098724810930472, 'epoch': 1.72}\n",
            "{'loss': 0.476, 'grad_norm': 0.03753695636987686, 'learning_rate': 0.004056312022735417, 'epoch': 1.73}\n",
            "{'loss': 0.6748, 'grad_norm': 0.06190671771764755, 'learning_rate': 0.00401396952926019, 'epoch': 1.74}\n",
            "{'loss': 0.6213, 'grad_norm': 0.06148390471935272, 'learning_rate': 0.003971700484570318, 'epoch': 1.74}\n",
            "{'loss': 0.7653, 'grad_norm': 0.09314478188753128, 'learning_rate': 0.00392950803726017, 'epoch': 1.75}\n",
            "{'loss': 0.641, 'grad_norm': 0.08691948652267456, 'learning_rate': 0.003887395330218428, 'epoch': 1.76}\n",
            "{'loss': 0.7244, 'grad_norm': 0.13248923420906067, 'learning_rate': 0.0038453655003939735, 'epoch': 1.77}\n",
            "{'loss': 1.3836, 'grad_norm': 0.17767533659934998, 'learning_rate': 0.003803421678562213, 'epoch': 1.78}\n",
            "{'loss': 0.9018, 'grad_norm': 0.0874471589922905, 'learning_rate': 0.00376156698909187, 'epoch': 1.78}\n",
            "{'loss': 0.5592, 'grad_norm': 0.06711278110742569, 'learning_rate': 0.0037198045497122646, 'epoch': 1.79}\n",
            "{'loss': 1.1958, 'grad_norm': 0.18282535672187805, 'learning_rate': 0.0036781374712810556, 'epoch': 1.8}\n",
            "{'loss': 0.8616, 'grad_norm': 0.0964638888835907, 'learning_rate': 0.0036365688575525313, 'epoch': 1.81}\n",
            "{'loss': 0.6024, 'grad_norm': 0.05654570832848549, 'learning_rate': 0.003595101804946404, 'epoch': 1.82}\n",
            "{'loss': 0.6152, 'grad_norm': 0.10132615268230438, 'learning_rate': 0.003553739402317162, 'epoch': 1.82}\n",
            "{'loss': 0.5318, 'grad_norm': 0.08091920614242554, 'learning_rate': 0.003512484730723986, 'epoch': 1.83}\n",
            "{'loss': 0.6213, 'grad_norm': 0.06365980207920074, 'learning_rate': 0.0034713408632012365, 'epoch': 1.84}\n",
            "{'loss': 0.8374, 'grad_norm': 0.13179291784763336, 'learning_rate': 0.00343031086452955, 'epoch': 1.85}\n",
            "{'loss': 0.8167, 'grad_norm': 0.12207825481891632, 'learning_rate': 0.003389397791007548, 'epoch': 1.86}\n",
            "{'loss': 1.0297, 'grad_norm': 0.1225503459572792, 'learning_rate': 0.0033486046902241663, 'epoch': 1.86}\n",
            "{'loss': 1.0537, 'grad_norm': 0.1305576115846634, 'learning_rate': 0.003307934600831648, 'epoch': 1.87}\n",
            "{'loss': 0.7113, 'grad_norm': 0.0874437466263771, 'learning_rate': 0.0032673905523191997, 'epoch': 1.88}\n",
            "{'loss': 0.7218, 'grad_norm': 0.10265184193849564, 'learning_rate': 0.0032269755647873215, 'epoch': 1.89}\n",
            "{'loss': 0.7293, 'grad_norm': 0.06088748946785927, 'learning_rate': 0.00318669264872284, 'epoch': 1.9}\n",
            "{'loss': 0.5271, 'grad_norm': 0.05780515447258949, 'learning_rate': 0.0031465448047746625, 'epoch': 1.9}\n",
            "{'loss': 0.8272, 'grad_norm': 0.08691465854644775, 'learning_rate': 0.003106535023530262, 'epoch': 1.91}\n",
            "{'loss': 0.4925, 'grad_norm': 0.07332848012447357, 'learning_rate': 0.003066666285292906, 'epoch': 1.92}\n",
            "{'loss': 0.6066, 'grad_norm': 0.09279269725084305, 'learning_rate': 0.00302694155985966, 'epoch': 1.93}\n",
            "{'loss': 0.544, 'grad_norm': 0.06848099082708359, 'learning_rate': 0.0029873638063001627, 'epoch': 1.94}\n",
            "{'loss': 0.6036, 'grad_norm': 0.06900867074728012, 'learning_rate': 0.002947935972736217, 'epoch': 1.94}\n",
            "{'loss': 0.5471, 'grad_norm': 0.05586675927042961, 'learning_rate': 0.0029086609961221756, 'epoch': 1.95}\n",
            "{'loss': 0.7789, 'grad_norm': 0.08471587300300598, 'learning_rate': 0.0028695418020261753, 'epoch': 1.96}\n",
            "{'loss': 0.4476, 'grad_norm': 0.03397984057664871, 'learning_rate': 0.00283058130441221, 'epoch': 1.97}\n",
            "{'loss': 0.657, 'grad_norm': 0.07335337996482849, 'learning_rate': 0.0027917824054230784, 'epoch': 1.98}\n",
            "{'loss': 0.8163, 'grad_norm': 0.10537733137607574, 'learning_rate': 0.0027531479951641924, 'epoch': 1.98}\n",
            "{'loss': 0.6319, 'grad_norm': 0.16648714244365692, 'learning_rate': 0.002714680951488312, 'epoch': 1.99}\n",
            "{'loss': 0.9518, 'grad_norm': 0.13076098263263702, 'learning_rate': 0.002676384139781157, 'epoch': 2.0}\n",
            "{'loss': 0.6955, 'grad_norm': 0.09814606606960297, 'learning_rate': 0.0026382604127479815, 'epoch': 2.01}\n",
            "{'loss': 0.7432, 'grad_norm': 0.09608912467956543, 'learning_rate': 0.0026003126102010694, 'epoch': 2.02}\n",
            "{'loss': 0.7065, 'grad_norm': 0.0659918412566185, 'learning_rate': 0.0025625435588482017, 'epoch': 2.02}\n",
            "{'loss': 0.5346, 'grad_norm': 0.05443469434976578, 'learning_rate': 0.002524956072082093, 'epoch': 2.03}\n",
            "{'loss': 0.7844, 'grad_norm': 0.07452299445867538, 'learning_rate': 0.0024875529497708354, 'epoch': 2.04}\n",
            "{'loss': 1.0242, 'grad_norm': 0.09955967217683792, 'learning_rate': 0.0024503369780493217, 'epoch': 2.05}\n",
            "{'loss': 1.0252, 'grad_norm': 0.10950685292482376, 'learning_rate': 0.0024133109291117156, 'epoch': 2.06}\n",
            "{'loss': 0.6373, 'grad_norm': 0.06109117716550827, 'learning_rate': 0.00237647756100496, 'epoch': 2.06}\n",
            "{'loss': 0.6617, 'grad_norm': 0.06337283551692963, 'learning_rate': 0.0023398396174233176, 'epoch': 2.07}\n",
            "{'loss': 0.7637, 'grad_norm': 0.08042600750923157, 'learning_rate': 0.002303399827504005, 'epoch': 2.08}\n",
            "{'loss': 0.5176, 'grad_norm': 0.04892062023282051, 'learning_rate': 0.002267160905623895, 'epoch': 2.09}\n",
            "{'loss': 0.6268, 'grad_norm': 0.07712976634502411, 'learning_rate': 0.0022311255511973343, 'epoch': 2.1}\n",
            "{'loss': 0.5215, 'grad_norm': 0.04232753813266754, 'learning_rate': 0.0021952964484750525, 'epoch': 2.1}\n",
            "{'loss': 0.8568, 'grad_norm': 0.07816394418478012, 'learning_rate': 0.0021596762663442215, 'epoch': 2.11}\n",
            "{'loss': 0.9363, 'grad_norm': 0.09688913822174072, 'learning_rate': 0.0021242676581296528, 'epoch': 2.12}\n",
            "{'loss': 0.7173, 'grad_norm': 0.08724556863307953, 'learning_rate': 0.0020890732613961477, 'epoch': 2.13}\n",
            "{'loss': 0.8141, 'grad_norm': 0.06676916778087616, 'learning_rate': 0.002054095697752032, 'epoch': 2.14}\n",
            "{'loss': 0.7672, 'grad_norm': 0.09380265325307846, 'learning_rate': 0.002019337572653874, 'epoch': 2.14}\n",
            "{'loss': 0.7625, 'grad_norm': 0.10435088723897934, 'learning_rate': 0.0019848014752123977, 'epoch': 2.15}\n",
            "{'loss': 1.0059, 'grad_norm': 0.11356691271066666, 'learning_rate': 0.0019504899779996354, 'epoch': 2.16}\n",
            "{'loss': 0.6874, 'grad_norm': 0.07599510252475739, 'learning_rate': 0.0019164056368572847, 'epoch': 2.17}\n",
            "{'loss': 0.6538, 'grad_norm': 0.08059504628181458, 'learning_rate': 0.0018825509907063327, 'epoch': 2.18}\n",
            "{'loss': 0.8632, 'grad_norm': 0.17253853380680084, 'learning_rate': 0.0018489285613579327, 'epoch': 2.18}\n",
            "{'loss': 0.6108, 'grad_norm': 0.047212760895490646, 'learning_rate': 0.0018155408533255552, 'epoch': 2.19}\n",
            "{'loss': 0.7199, 'grad_norm': 0.09666639566421509, 'learning_rate': 0.001782390353638426, 'epoch': 2.2}\n",
            "{'loss': 0.6408, 'grad_norm': 0.057451121509075165, 'learning_rate': 0.0017494795316562789, 'epoch': 2.21}\n",
            "{'loss': 0.8444, 'grad_norm': 0.08928608149290085, 'learning_rate': 0.0017168108388853998, 'epoch': 2.22}\n",
            "{'loss': 0.5181, 'grad_norm': 0.035294223576784134, 'learning_rate': 0.001684386708796025, 'epoch': 2.22}\n",
            "{'loss': 0.631, 'grad_norm': 0.060556188225746155, 'learning_rate': 0.0016522095566410728, 'epoch': 2.23}\n",
            "{'loss': 0.8574, 'grad_norm': 0.16120518743991852, 'learning_rate': 0.001620281779276228, 'epoch': 2.24}\n",
            "{'loss': 0.5324, 'grad_norm': 0.043363168835639954, 'learning_rate': 0.0015886057549814132, 'epoch': 2.25}\n",
            "{'loss': 0.5211, 'grad_norm': 0.057904377579689026, 'learning_rate': 0.001557183843283614, 'epoch': 2.26}\n",
            "{'loss': 1.0056, 'grad_norm': 0.12047314643859863, 'learning_rate': 0.0015260183847811382, 'epoch': 2.26}\n",
            "{'loss': 0.5783, 'grad_norm': 0.05241019278764725, 'learning_rate': 0.0014951117009692528, 'epoch': 2.27}\n",
            "{'loss': 0.6084, 'grad_norm': 0.05620162561535835, 'learning_rate': 0.0014644660940672626, 'epoch': 2.28}\n",
            "{'loss': 0.6769, 'grad_norm': 0.08633313328027725, 'learning_rate': 0.0014340838468470197, 'epoch': 2.29}\n",
            "{'loss': 0.8498, 'grad_norm': 0.10483001917600632, 'learning_rate': 0.0014039672224628785, 'epoch': 2.3}\n",
            "{'loss': 0.4839, 'grad_norm': 0.03349129483103752, 'learning_rate': 0.001374118464283119, 'epoch': 2.3}\n",
            "{'loss': 0.5319, 'grad_norm': 0.03808964416384697, 'learning_rate': 0.0013445397957228338, 'epoch': 2.31}\n",
            "{'loss': 0.6161, 'grad_norm': 0.04934651777148247, 'learning_rate': 0.0013152334200783166, 'epoch': 2.32}\n",
            "{'loss': 0.7888, 'grad_norm': 0.07278920710086823, 'learning_rate': 0.0012862015203629273, 'epoch': 2.33}\n",
            "{'loss': 0.4824, 'grad_norm': 0.04878506064414978, 'learning_rate': 0.001257446259144494, 'epoch': 2.34}\n",
            "{'loss': 0.7042, 'grad_norm': 0.0641350969672203, 'learning_rate': 0.0012289697783842142, 'epoch': 2.34}\n",
            "{'loss': 0.5927, 'grad_norm': 0.07874120771884918, 'learning_rate': 0.0012007741992771065, 'epoch': 2.35}\n",
            "{'loss': 0.4878, 'grad_norm': 0.06032104417681694, 'learning_rate': 0.0011728616220940031, 'epoch': 2.36}\n",
            "{'loss': 0.7847, 'grad_norm': 0.06453721225261688, 'learning_rate': 0.001145234126025102, 'epoch': 2.37}\n",
            "{'loss': 0.6922, 'grad_norm': 0.08203306794166565, 'learning_rate': 0.0011178937690250917, 'epoch': 2.38}\n",
            "{'loss': 1.0587, 'grad_norm': 0.10308270156383514, 'learning_rate': 0.001090842587659851, 'epoch': 2.38}\n",
            "{'loss': 0.5603, 'grad_norm': 0.06485792994499207, 'learning_rate': 0.0010640825969547496, 'epoch': 2.39}\n",
            "{'loss': 0.8636, 'grad_norm': 0.08946379274129868, 'learning_rate': 0.0010376157902445488, 'epoch': 2.4}\n",
            "{'loss': 1.0138, 'grad_norm': 0.0848919004201889, 'learning_rate': 0.00101144413902492, 'epoch': 2.41}\n",
            "{'loss': 1.0583, 'grad_norm': 0.09681010991334915, 'learning_rate': 0.000985569592805588, 'epoch': 2.42}\n",
            "{'loss': 0.7363, 'grad_norm': 0.09202174842357635, 'learning_rate': 0.0009599940789651179, 'epoch': 2.42}\n",
            "{'loss': 0.683, 'grad_norm': 0.09781937301158905, 'learning_rate': 0.0009347195026073368, 'epoch': 2.43}\n",
            "{'loss': 0.5677, 'grad_norm': 0.04456937313079834, 'learning_rate': 0.000909747746419436, 'epoch': 2.44}\n",
            "{'loss': 0.4437, 'grad_norm': 0.029865670949220657, 'learning_rate': 0.0008850806705317183, 'epoch': 2.45}\n",
            "{'loss': 0.8106, 'grad_norm': 0.14068622887134552, 'learning_rate': 0.0008607201123790459, 'epoch': 2.46}\n",
            "{'loss': 0.4519, 'grad_norm': 0.03918393701314926, 'learning_rate': 0.0008366678865639688, 'epoch': 2.46}\n",
            "{'loss': 0.5024, 'grad_norm': 0.03369933366775513, 'learning_rate': 0.0008129257847215571, 'epoch': 2.47}\n",
            "{'loss': 0.5121, 'grad_norm': 0.04496437683701515, 'learning_rate': 0.0007894955753859412, 'epoch': 2.48}\n",
            "{'loss': 0.4886, 'grad_norm': 0.0509323850274086, 'learning_rate': 0.0007663790038585794, 'epoch': 2.49}\n",
            "{'loss': 0.7341, 'grad_norm': 0.0697750598192215, 'learning_rate': 0.0007435777920782444, 'epoch': 2.5}\n",
            "{'loss': 0.5339, 'grad_norm': 0.05507485195994377, 'learning_rate': 0.000721093638492763, 'epoch': 2.5}\n",
            "{'loss': 0.4931, 'grad_norm': 0.04901605844497681, 'learning_rate': 0.0006989282179324963, 'epoch': 2.51}\n",
            "{'loss': 0.888, 'grad_norm': 0.1207587942481041, 'learning_rate': 0.0006770831814855883, 'epoch': 2.52}\n",
            "{'loss': 0.6803, 'grad_norm': 0.08487999439239502, 'learning_rate': 0.0006555601563749675, 'epoch': 2.53}\n",
            "{'loss': 0.5544, 'grad_norm': 0.0399707667529583, 'learning_rate': 0.0006343607458371459, 'epoch': 2.54}\n",
            "{'loss': 0.6258, 'grad_norm': 0.03307250887155533, 'learning_rate': 0.0006134865290027902, 'epoch': 2.54}\n",
            "{'loss': 0.6842, 'grad_norm': 0.1031404659152031, 'learning_rate': 0.000592939060779093, 'epoch': 2.55}\n",
            "{'loss': 0.4762, 'grad_norm': 0.03837660327553749, 'learning_rate': 0.000572719871733951, 'epoch': 2.56}\n",
            "{'loss': 0.4245, 'grad_norm': 0.04219139367341995, 'learning_rate': 0.0005528304679819513, 'epoch': 2.57}\n",
            "{'loss': 0.7436, 'grad_norm': 0.08898425847291946, 'learning_rate': 0.0005332723310721854, 'epoch': 2.58}\n",
            "{'loss': 0.8392, 'grad_norm': 0.07646558433771133, 'learning_rate': 0.0005140469178778845, 'epoch': 2.58}\n",
            "{'loss': 0.7323, 'grad_norm': 0.07408452779054642, 'learning_rate': 0.0004951556604879049, 'epoch': 2.59}\n",
            "{'loss': 0.6833, 'grad_norm': 0.07459881901741028, 'learning_rate': 0.00047659996610004417, 'epoch': 2.6}\n",
            "{'loss': 0.8262, 'grad_norm': 0.07670855522155762, 'learning_rate': 0.00045838121691622993, 'epoch': 2.61}\n",
            "{'loss': 0.932, 'grad_norm': 0.0976768434047699, 'learning_rate': 0.0004405007700395497, 'epoch': 2.62}\n",
            "{'loss': 0.762, 'grad_norm': 0.3241598308086395, 'learning_rate': 0.0004229599573731685, 'epoch': 2.62}\n",
            "{'loss': 0.942, 'grad_norm': 0.13138729333877563, 'learning_rate': 0.0004057600855211141, 'epoch': 2.63}\n",
            "{'loss': 0.548, 'grad_norm': 0.04270884767174721, 'learning_rate': 0.00038890243569094876, 'epoch': 2.64}\n",
            "{'loss': 0.5989, 'grad_norm': 0.045391179621219635, 'learning_rate': 0.0003723882635983328, 'epoch': 2.65}\n",
            "{'loss': 0.6496, 'grad_norm': 0.05311073735356331, 'learning_rate': 0.00035621879937348835, 'epoch': 2.66}\n",
            "{'loss': 0.5332, 'grad_norm': 0.05629304423928261, 'learning_rate': 0.00034039524746956595, 'epoch': 2.66}\n",
            "{'loss': 0.8501, 'grad_norm': 0.08408201485872269, 'learning_rate': 0.0003249187865729264, 'epoch': 2.67}\n",
            "{'loss': 0.9223, 'grad_norm': 0.11375871300697327, 'learning_rate': 0.0003097905695153408, 'epoch': 2.68}\n",
            "{'loss': 0.7733, 'grad_norm': 0.11311718076467514, 'learning_rate': 0.0002950117231881183, 'epoch': 2.69}\n",
            "{'loss': 0.7073, 'grad_norm': 0.07721296697854996, 'learning_rate': 0.0002805833484581621, 'epoch': 2.7}\n",
            "{'loss': 0.5594, 'grad_norm': 0.037891972810029984, 'learning_rate': 0.00026650652008597067, 'epoch': 2.7}\n",
            "{'loss': 0.6101, 'grad_norm': 0.07568885385990143, 'learning_rate': 0.0002527822866455731, 'epoch': 2.71}\n",
            "{'loss': 0.6293, 'grad_norm': 0.05323534458875656, 'learning_rate': 0.00023941167044642941, 'epoch': 2.72}\n",
            "{'loss': 1.0478, 'grad_norm': 0.12239950150251389, 'learning_rate': 0.00022639566745727202, 'epoch': 2.73}\n",
            "{'loss': 0.8964, 'grad_norm': 0.10949083417654037, 'learning_rate': 0.0002137352472319215, 'epoch': 2.74}\n",
            "{'loss': 0.5019, 'grad_norm': 0.0741608589887619, 'learning_rate': 0.0002014313528370626, 'epoch': 2.74}\n",
            "{'loss': 0.7357, 'grad_norm': 0.07010354101657867, 'learning_rate': 0.00018948490078199765, 'epoch': 2.75}\n",
            "{'loss': 0.4816, 'grad_norm': 0.0379803329706192, 'learning_rate': 0.00017789678095037452, 'epoch': 2.76}\n",
            "{'loss': 0.7626, 'grad_norm': 0.09001804888248444, 'learning_rate': 0.0001666678565339025, 'epoch': 2.77}\n",
            "{'loss': 0.8216, 'grad_norm': 0.09297855943441391, 'learning_rate': 0.0001557989639680496, 'epoch': 2.78}\n",
            "{'loss': 0.5783, 'grad_norm': 0.06365068256855011, 'learning_rate': 0.00014529091286973994, 'epoch': 2.78}\n",
            "{'loss': 0.7214, 'grad_norm': 0.06931481510400772, 'learning_rate': 0.0001351444859770462, 'epoch': 2.79}\n",
            "{'loss': 0.8481, 'grad_norm': 0.08329317718744278, 'learning_rate': 0.0001253604390908819, 'epoch': 2.8}\n",
            "{'loss': 0.6218, 'grad_norm': 0.08670023083686829, 'learning_rate': 0.0001159395010187042, 'epoch': 2.81}\n",
            "{'loss': 0.7488, 'grad_norm': 0.07550110667943954, 'learning_rate': 0.00010688237352022346, 'epoch': 2.82}\n",
            "{'loss': 0.9764, 'grad_norm': 0.1014704555273056, 'learning_rate': 9.818973125513276e-05, 'epoch': 2.82}\n",
            "{'loss': 0.8925, 'grad_norm': 0.12245263904333115, 'learning_rate': 8.986222173284874e-05, 'epoch': 2.83}\n",
            "{'loss': 0.722, 'grad_norm': 0.04563257098197937, 'learning_rate': 8.190046526428241e-05, 'epoch': 2.84}\n",
            "{'loss': 0.9931, 'grad_norm': 0.10806917399168015, 'learning_rate': 7.4305054915631e-05, 'epoch': 2.85}\n",
            "{'loss': 0.6641, 'grad_norm': 0.05557522922754288, 'learning_rate': 6.707655646420229e-05, 'epoch': 2.86}\n",
            "{'loss': 0.8541, 'grad_norm': 0.10516610741615295, 'learning_rate': 6.0215508356267765e-05, 'epoch': 2.86}\n",
            "{'loss': 0.4004, 'grad_norm': 0.04534047469496727, 'learning_rate': 5.372242166695684e-05, 'epoch': 2.87}\n",
            "{'loss': 0.5215, 'grad_norm': 0.04665646702051163, 'learning_rate': 4.759778006218407e-05, 'epoch': 2.88}\n",
            "{'loss': 0.8765, 'grad_norm': 0.09728419780731201, 'learning_rate': 4.184203976262513e-05, 'epoch': 2.89}\n",
            "{'loss': 0.4172, 'grad_norm': 0.03206245228648186, 'learning_rate': 3.645562950973014e-05, 'epoch': 2.9}\n",
            "{'loss': 0.7092, 'grad_norm': 0.11335211247205734, 'learning_rate': 3.143895053378698e-05, 'epoch': 2.9}\n",
            "{'loss': 0.411, 'grad_norm': 0.04976535215973854, 'learning_rate': 2.6792376524036878e-05, 'epoch': 2.91}\n",
            "{'loss': 0.7849, 'grad_norm': 0.08502490818500519, 'learning_rate': 2.2516253600833868e-05, 'epoch': 2.92}\n",
            "{'loss': 0.7707, 'grad_norm': 0.050955988466739655, 'learning_rate': 1.8610900289867673e-05, 'epoch': 2.93}\n",
            "{'loss': 0.5737, 'grad_norm': 0.07290708273649216, 'learning_rate': 1.5076607498433204e-05, 'epoch': 2.94}\n",
            "{'loss': 0.5993, 'grad_norm': 0.056554365903139114, 'learning_rate': 1.1913638493762369e-05, 'epoch': 2.94}\n",
            "{'loss': 0.4184, 'grad_norm': 0.03287893533706665, 'learning_rate': 9.12222888341252e-06, 'epoch': 2.95}\n",
            "{'loss': 0.626, 'grad_norm': 0.07526498287916183, 'learning_rate': 6.702586597719385e-06, 'epoch': 2.96}\n",
            "{'loss': 0.6816, 'grad_norm': 0.08612503111362457, 'learning_rate': 4.654891874303346e-06, 'epoch': 2.97}\n",
            "{'loss': 0.8286, 'grad_norm': 0.08862461149692535, 'learning_rate': 2.9792972446479605e-06, 'epoch': 2.98}\n",
            "{'loss': 0.6984, 'grad_norm': 0.10181286931037903, 'learning_rate': 1.6759275227357095e-06, 'epoch': 2.98}\n",
            "{'loss': 0.5874, 'grad_norm': 0.041840385645627975, 'learning_rate': 7.448797957526621e-07, 'epoch': 2.99}\n",
            "{'loss': 0.8431, 'grad_norm': 0.07105281949043274, 'learning_rate': 1.862234168542587e-07, 'epoch': 3.0}\n",
            "{'train_runtime': 67.9512, 'train_samples_per_second': 11.037, 'train_steps_per_second': 5.519, 'train_loss': 1.2255134104887644, 'epoch': 3.0}\n",
            "100% 375/375 [01:07<00:00,  5.52it/s]\n",
            "Training complete.\n",
            "Model saved to loras/self-edit/training_set_iteration_1/8d5021e8/0\n",
            "Training on 250 examples for 3 epochs, lr: 0.01\n",
            "No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n",
            "Starting training...\n",
            "{'loss': 7.8795, 'grad_norm': 10.620111465454102, 'learning_rate': 0.0, 'epoch': 0.01}\n",
            "{'loss': 5.1219, 'grad_norm': 6.385308265686035, 'learning_rate': 0.0009090909090909091, 'epoch': 0.02}\n",
            "{'loss': 2.351, 'grad_norm': 9.388493537902832, 'learning_rate': 0.0018181818181818182, 'epoch': 0.02}\n",
            "{'loss': 1.5672, 'grad_norm': 7.8383636474609375, 'learning_rate': 0.002727272727272727, 'epoch': 0.03}\n",
            "{'loss': 0.9336, 'grad_norm': 1.2426090240478516, 'learning_rate': 0.0036363636363636364, 'epoch': 0.04}\n",
            "{'loss': 1.0618, 'grad_norm': 3.7937605381011963, 'learning_rate': 0.004545454545454545, 'epoch': 0.05}\n",
            "{'loss': 0.7308, 'grad_norm': 1.2000898122787476, 'learning_rate': 0.005454545454545454, 'epoch': 0.06}\n",
            "{'loss': 0.6709, 'grad_norm': 0.808712363243103, 'learning_rate': 0.006363636363636364, 'epoch': 0.06}\n",
            "{'loss': 2.2384, 'grad_norm': 5.722192764282227, 'learning_rate': 0.007272727272727273, 'epoch': 0.07}\n",
            "{'loss': 0.9023, 'grad_norm': 1.429145336151123, 'learning_rate': 0.008181818181818182, 'epoch': 0.08}\n",
            "{'loss': 1.1176, 'grad_norm': 4.452910423278809, 'learning_rate': 0.00909090909090909, 'epoch': 0.09}\n",
            "{'loss': 3.971, 'grad_norm': 18.572166442871094, 'learning_rate': 0.01, 'epoch': 0.1}\n",
            "{'loss': 10.3586, 'grad_norm': 16.500017166137695, 'learning_rate': 0.009999813776583147, 'epoch': 0.1}\n",
            "{'loss': 12.6559, 'grad_norm': 14.787131309509277, 'learning_rate': 0.009999255120204246, 'epoch': 0.11}\n",
            "{'loss': 7.8421, 'grad_norm': 5.690793514251709, 'learning_rate': 0.009998324072477265, 'epoch': 0.12}\n",
            "{'loss': 17.8403, 'grad_norm': 77.89269256591797, 'learning_rate': 0.009997020702755353, 'epoch': 0.13}\n",
            "{'loss': 11.0771, 'grad_norm': 4.655092239379883, 'learning_rate': 0.009995345108125697, 'epoch': 0.14}\n",
            "{'loss': 9.8211, 'grad_norm': 7.13299560546875, 'learning_rate': 0.009993297413402281, 'epoch': 0.14}\n",
            "{'loss': 3.2578, 'grad_norm': 1.4378492832183838, 'learning_rate': 0.009990877771116588, 'epoch': 0.15}\n",
            "{'loss': 5.5554, 'grad_norm': 3.8434555530548096, 'learning_rate': 0.009988086361506238, 'epoch': 0.16}\n",
            "{'loss': 3.3275, 'grad_norm': 4.410001277923584, 'learning_rate': 0.009984923392501567, 'epoch': 0.17}\n",
            "{'loss': 3.031, 'grad_norm': 3.043487310409546, 'learning_rate': 0.009981389099710133, 'epoch': 0.18}\n",
            "{'loss': 3.2149, 'grad_norm': 2.0851001739501953, 'learning_rate': 0.009977483746399167, 'epoch': 0.18}\n",
            "{'loss': 2.6528, 'grad_norm': 2.615750789642334, 'learning_rate': 0.009973207623475963, 'epoch': 0.19}\n",
            "{'loss': 1.8041, 'grad_norm': 0.42868033051490784, 'learning_rate': 0.009968561049466213, 'epoch': 0.2}\n",
            "{'loss': 3.4688, 'grad_norm': 1.629291296005249, 'learning_rate': 0.00996354437049027, 'epoch': 0.21}\n",
            "{'loss': 2.5189, 'grad_norm': 1.0493959188461304, 'learning_rate': 0.009958157960237374, 'epoch': 0.22}\n",
            "{'loss': 3.6154, 'grad_norm': 2.108283758163452, 'learning_rate': 0.009952402219937815, 'epoch': 0.22}\n",
            "{'loss': 3.8088, 'grad_norm': 3.7084457874298096, 'learning_rate': 0.009946277578333045, 'epoch': 0.23}\n",
            "{'loss': 2.1569, 'grad_norm': 1.2327754497528076, 'learning_rate': 0.009939784491643733, 'epoch': 0.24}\n",
            "{'loss': 3.5835, 'grad_norm': 2.026815414428711, 'learning_rate': 0.009932923443535798, 'epoch': 0.25}\n",
            "{'loss': 3.1539, 'grad_norm': 1.4343819618225098, 'learning_rate': 0.009925694945084369, 'epoch': 0.26}\n",
            "{'loss': 4.0074, 'grad_norm': 2.856217861175537, 'learning_rate': 0.009918099534735719, 'epoch': 0.26}\n",
            "{'loss': 3.8006, 'grad_norm': 1.8909931182861328, 'learning_rate': 0.009910137778267152, 'epoch': 0.27}\n",
            "{'loss': 3.2809, 'grad_norm': 2.002262830734253, 'learning_rate': 0.009901810268744867, 'epoch': 0.28}\n",
            "{'loss': 4.3865, 'grad_norm': 3.2440309524536133, 'learning_rate': 0.009893117626479776, 'epoch': 0.29}\n",
            "{'loss': 3.8182, 'grad_norm': 3.0061588287353516, 'learning_rate': 0.009884060498981296, 'epoch': 0.3}\n",
            "{'loss': 2.5557, 'grad_norm': 0.9579041004180908, 'learning_rate': 0.009874639560909117, 'epoch': 0.3}\n",
            "{'loss': 1.1477, 'grad_norm': 0.29742640256881714, 'learning_rate': 0.009864855514022955, 'epoch': 0.31}\n",
            "{'loss': 3.3829, 'grad_norm': 1.9776684045791626, 'learning_rate': 0.009854709087130261, 'epoch': 0.32}\n",
            "{'loss': 1.7397, 'grad_norm': 0.7701912522315979, 'learning_rate': 0.00984420103603195, 'epoch': 0.33}\n",
            "{'loss': 1.9223, 'grad_norm': 0.810917854309082, 'learning_rate': 0.009833332143466099, 'epoch': 0.34}\n",
            "{'loss': 2.4469, 'grad_norm': 1.1993613243103027, 'learning_rate': 0.009822103219049624, 'epoch': 0.34}\n",
            "{'loss': 2.3419, 'grad_norm': 0.9751800298690796, 'learning_rate': 0.009810515099218002, 'epoch': 0.35}\n",
            "{'loss': 1.6875, 'grad_norm': 0.31377410888671875, 'learning_rate': 0.009798568647162938, 'epoch': 0.36}\n",
            "{'loss': 1.6402, 'grad_norm': 0.8549407720565796, 'learning_rate': 0.00978626475276808, 'epoch': 0.37}\n",
            "{'loss': 1.3038, 'grad_norm': 0.18299944698810577, 'learning_rate': 0.009773604332542728, 'epoch': 0.38}\n",
            "{'loss': 2.7416, 'grad_norm': 0.7635589838027954, 'learning_rate': 0.00976058832955357, 'epoch': 0.38}\n",
            "{'loss': 1.4921, 'grad_norm': 0.1993076205253601, 'learning_rate': 0.009747217713354427, 'epoch': 0.39}\n",
            "{'loss': 2.0437, 'grad_norm': 0.2731001675128937, 'learning_rate': 0.009733493479914031, 'epoch': 0.4}\n",
            "{'loss': 1.8631, 'grad_norm': 0.20652154088020325, 'learning_rate': 0.009719416651541838, 'epoch': 0.41}\n",
            "{'loss': 1.4007, 'grad_norm': 0.16864773631095886, 'learning_rate': 0.009704988276811882, 'epoch': 0.42}\n",
            "{'loss': 1.7349, 'grad_norm': 0.20715545117855072, 'learning_rate': 0.00969020943048466, 'epoch': 0.42}\n",
            "{'loss': 1.323, 'grad_norm': 0.13873441517353058, 'learning_rate': 0.009675081213427075, 'epoch': 0.43}\n",
            "{'loss': 2.0417, 'grad_norm': 0.28851521015167236, 'learning_rate': 0.009659604752530434, 'epoch': 0.44}\n",
            "{'loss': 1.601, 'grad_norm': 0.13800576329231262, 'learning_rate': 0.00964378120062651, 'epoch': 0.45}\n",
            "{'loss': 1.2843, 'grad_norm': 0.11323874443769455, 'learning_rate': 0.009627611736401667, 'epoch': 0.46}\n",
            "{'loss': 1.4407, 'grad_norm': 0.23581890761852264, 'learning_rate': 0.009611097564309053, 'epoch': 0.46}\n",
            "{'loss': 1.7834, 'grad_norm': 0.29178372025489807, 'learning_rate': 0.009594239914478886, 'epoch': 0.47}\n",
            "{'loss': 1.6309, 'grad_norm': 0.15749427676200867, 'learning_rate': 0.009577040042626833, 'epoch': 0.48}\n",
            "{'loss': 1.5474, 'grad_norm': 0.2379162609577179, 'learning_rate': 0.00955949922996045, 'epoch': 0.49}\n",
            "{'loss': 1.1596, 'grad_norm': 0.13857832551002502, 'learning_rate': 0.00954161878308377, 'epoch': 0.5}\n",
            "{'loss': 1.4987, 'grad_norm': 0.2293819934129715, 'learning_rate': 0.009523400033899955, 'epoch': 0.5}\n",
            "{'loss': 1.6377, 'grad_norm': 0.1962425261735916, 'learning_rate': 0.009504844339512096, 'epoch': 0.51}\n",
            "{'loss': 1.7245, 'grad_norm': 0.20064511895179749, 'learning_rate': 0.009485953082122116, 'epoch': 0.52}\n",
            "{'loss': 1.7814, 'grad_norm': 0.3677406907081604, 'learning_rate': 0.009466727668927815, 'epoch': 0.53}\n",
            "{'loss': 1.8043, 'grad_norm': 0.22812864184379578, 'learning_rate': 0.00944716953201805, 'epoch': 0.54}\n",
            "{'loss': 1.326, 'grad_norm': 0.09456007182598114, 'learning_rate': 0.009427280128266049, 'epoch': 0.54}\n",
            "{'loss': 1.3414, 'grad_norm': 0.15805716812610626, 'learning_rate': 0.009407060939220908, 'epoch': 0.55}\n",
            "{'loss': 1.4735, 'grad_norm': 0.16595661640167236, 'learning_rate': 0.00938651347099721, 'epoch': 0.56}\n",
            "{'loss': 1.3502, 'grad_norm': 0.17653855681419373, 'learning_rate': 0.009365639254162854, 'epoch': 0.57}\n",
            "{'loss': 1.7788, 'grad_norm': 0.13682852685451508, 'learning_rate': 0.009344439843625034, 'epoch': 0.58}\n",
            "{'loss': 1.8155, 'grad_norm': 0.17548559606075287, 'learning_rate': 0.009322916818514413, 'epoch': 0.58}\n",
            "{'loss': 1.2537, 'grad_norm': 0.09846457839012146, 'learning_rate': 0.009301071782067504, 'epoch': 0.59}\n",
            "{'loss': 1.0085, 'grad_norm': 0.08467083424329758, 'learning_rate': 0.009278906361507237, 'epoch': 0.6}\n",
            "{'loss': 1.0953, 'grad_norm': 0.052771005779504776, 'learning_rate': 0.009256422207921756, 'epoch': 0.61}\n",
            "{'loss': 1.053, 'grad_norm': 0.04927068203687668, 'learning_rate': 0.00923362099614142, 'epoch': 0.62}\n",
            "{'loss': 0.8349, 'grad_norm': 0.04433506727218628, 'learning_rate': 0.009210504424614059, 'epoch': 0.62}\n",
            "{'loss': 1.435, 'grad_norm': 0.22463096678256989, 'learning_rate': 0.009187074215278444, 'epoch': 0.63}\n",
            "{'loss': 1.4454, 'grad_norm': 0.1528596132993698, 'learning_rate': 0.009163332113436031, 'epoch': 0.64}\n",
            "{'loss': 0.9736, 'grad_norm': 0.09791674464941025, 'learning_rate': 0.009139279887620954, 'epoch': 0.65}\n",
            "{'loss': 1.5585, 'grad_norm': 0.14917805790901184, 'learning_rate': 0.009114919329468282, 'epoch': 0.66}\n",
            "{'loss': 1.1169, 'grad_norm': 0.33983689546585083, 'learning_rate': 0.009090252253580565, 'epoch': 0.66}\n",
            "{'loss': 1.2357, 'grad_norm': 0.06589280068874359, 'learning_rate': 0.009065280497392662, 'epoch': 0.67}\n",
            "{'loss': 0.9549, 'grad_norm': 0.0823209285736084, 'learning_rate': 0.009040005921034882, 'epoch': 0.68}\n",
            "{'loss': 0.925, 'grad_norm': 0.051820408552885056, 'learning_rate': 0.009014430407194412, 'epoch': 0.69}\n",
            "{'loss': 1.7366, 'grad_norm': 0.20006409287452698, 'learning_rate': 0.008988555860975082, 'epoch': 0.7}\n",
            "{'loss': 1.3075, 'grad_norm': 0.1279556006193161, 'learning_rate': 0.008962384209755451, 'epoch': 0.7}\n",
            "{'loss': 1.4203, 'grad_norm': 0.1875603348016739, 'learning_rate': 0.00893591740304525, 'epoch': 0.71}\n",
            "{'loss': 1.3251, 'grad_norm': 0.14945153892040253, 'learning_rate': 0.008909157412340149, 'epoch': 0.72}\n",
            "{'loss': 2.0304, 'grad_norm': 0.11195087432861328, 'learning_rate': 0.008882106230974908, 'epoch': 0.73}\n",
            "{'loss': 1.9666, 'grad_norm': 0.17269453406333923, 'learning_rate': 0.008854765873974898, 'epoch': 0.74}\n",
            "{'loss': 1.2265, 'grad_norm': 0.09004649519920349, 'learning_rate': 0.008827138377905998, 'epoch': 0.74}\n",
            "{'loss': 1.8894, 'grad_norm': 0.13771681487560272, 'learning_rate': 0.008799225800722895, 'epoch': 0.75}\n",
            "{'loss': 1.0976, 'grad_norm': 0.06956357508897781, 'learning_rate': 0.008771030221615786, 'epoch': 0.76}\n",
            "{'loss': 1.3132, 'grad_norm': 0.06771702319383621, 'learning_rate': 0.008742553740855506, 'epoch': 0.77}\n",
            "{'loss': 1.2476, 'grad_norm': 0.093589648604393, 'learning_rate': 0.008713798479637071, 'epoch': 0.78}\n",
            "{'loss': 1.4052, 'grad_norm': 0.16156414151191711, 'learning_rate': 0.008684766579921684, 'epoch': 0.78}\n",
            "{'loss': 1.7235, 'grad_norm': 0.12943223118782043, 'learning_rate': 0.008655460204277167, 'epoch': 0.79}\n",
            "{'loss': 1.4401, 'grad_norm': 0.14453952014446259, 'learning_rate': 0.008625881535716882, 'epoch': 0.8}\n",
            "{'loss': 1.407, 'grad_norm': 0.06645305454730988, 'learning_rate': 0.008596032777537123, 'epoch': 0.81}\n",
            "{'loss': 1.6091, 'grad_norm': 0.1719134896993637, 'learning_rate': 0.008565916153152981, 'epoch': 0.82}\n",
            "{'loss': 1.0836, 'grad_norm': 0.11250260472297668, 'learning_rate': 0.008535533905932738, 'epoch': 0.82}\n",
            "{'loss': 0.9056, 'grad_norm': 0.0765381008386612, 'learning_rate': 0.008504888299030747, 'epoch': 0.83}\n",
            "{'loss': 1.8775, 'grad_norm': 0.1304234266281128, 'learning_rate': 0.008473981615218862, 'epoch': 0.84}\n",
            "{'loss': 1.0586, 'grad_norm': 0.06215300038456917, 'learning_rate': 0.008442816156716385, 'epoch': 0.85}\n",
            "{'loss': 1.2595, 'grad_norm': 39.70316696166992, 'learning_rate': 0.008411394245018588, 'epoch': 0.86}\n",
            "{'loss': 1.3094, 'grad_norm': 0.11947723478078842, 'learning_rate': 0.008379718220723772, 'epoch': 0.86}\n",
            "{'loss': 1.1866, 'grad_norm': 0.09733554720878601, 'learning_rate': 0.008347790443358928, 'epoch': 0.87}\n",
            "{'loss': 1.2556, 'grad_norm': 0.07140187174081802, 'learning_rate': 0.008315613291203975, 'epoch': 0.88}\n",
            "{'loss': 2.2529, 'grad_norm': 0.19773849844932556, 'learning_rate': 0.0082831891611146, 'epoch': 0.89}\n",
            "{'loss': 1.692, 'grad_norm': 0.14160096645355225, 'learning_rate': 0.00825052046834372, 'epoch': 0.9}\n",
            "{'loss': 1.3535, 'grad_norm': 0.14726927876472473, 'learning_rate': 0.008217609646361573, 'epoch': 0.9}\n",
            "{'loss': 1.5149, 'grad_norm': 0.19787834584712982, 'learning_rate': 0.008184459146674447, 'epoch': 0.91}\n",
            "{'loss': 1.4752, 'grad_norm': 0.19270510971546173, 'learning_rate': 0.008151071438642068, 'epoch': 0.92}\n",
            "{'loss': 1.3214, 'grad_norm': 0.10602748394012451, 'learning_rate': 0.008117449009293669, 'epoch': 0.93}\n",
            "{'loss': 1.1958, 'grad_norm': 0.13600987195968628, 'learning_rate': 0.008083594363142717, 'epoch': 0.94}\n",
            "{'loss': 1.1501, 'grad_norm': 0.1456836760044098, 'learning_rate': 0.008049510022000364, 'epoch': 0.94}\n",
            "{'loss': 1.0317, 'grad_norm': 0.07030129432678223, 'learning_rate': 0.008015198524787602, 'epoch': 0.95}\n",
            "{'loss': 0.7615, 'grad_norm': 0.05843396112322807, 'learning_rate': 0.007980662427346127, 'epoch': 0.96}\n",
            "{'loss': 1.1557, 'grad_norm': 0.07851924002170563, 'learning_rate': 0.007945904302247968, 'epoch': 0.97}\n",
            "{'loss': 0.742, 'grad_norm': 0.06829395145177841, 'learning_rate': 0.007910926738603854, 'epoch': 0.98}\n",
            "{'loss': 1.963, 'grad_norm': 0.30984705686569214, 'learning_rate': 0.007875732341870348, 'epoch': 0.98}\n",
            "{'loss': 1.6069, 'grad_norm': 0.18811170756816864, 'learning_rate': 0.007840323733655778, 'epoch': 0.99}\n",
            "{'loss': 1.3488, 'grad_norm': 0.2939508259296417, 'learning_rate': 0.007804703551524948, 'epoch': 1.0}\n",
            "{'loss': 1.6538, 'grad_norm': 0.21553254127502441, 'learning_rate': 0.0077688744488026654, 'epoch': 1.01}\n",
            "{'loss': 1.3383, 'grad_norm': 0.2366226464509964, 'learning_rate': 0.007732839094376105, 'epoch': 1.02}\n",
            "{'loss': 0.7816, 'grad_norm': 0.0836116373538971, 'learning_rate': 0.007696600172495996, 'epoch': 1.02}\n",
            "{'loss': 1.3288, 'grad_norm': 0.13521385192871094, 'learning_rate': 0.007660160382576683, 'epoch': 1.03}\n",
            "{'loss': 1.0906, 'grad_norm': 0.1200791746377945, 'learning_rate': 0.00762352243899504, 'epoch': 1.04}\n",
            "{'loss': 1.418, 'grad_norm': 0.20785565674304962, 'learning_rate': 0.007586689070888284, 'epoch': 1.05}\n",
            "{'loss': 1.9798, 'grad_norm': 0.2940562963485718, 'learning_rate': 0.00754966302195068, 'epoch': 1.06}\n",
            "{'loss': 1.3573, 'grad_norm': 0.2225916087627411, 'learning_rate': 0.007512447050229166, 'epoch': 1.06}\n",
            "{'loss': 1.0933, 'grad_norm': 0.14975476264953613, 'learning_rate': 0.007475043927917907, 'epoch': 1.07}\n",
            "{'loss': 0.9537, 'grad_norm': 0.18238465487957, 'learning_rate': 0.007437456441151799, 'epoch': 1.08}\n",
            "{'loss': 1.4519, 'grad_norm': 0.28208693861961365, 'learning_rate': 0.007399687389798932, 'epoch': 1.09}\n",
            "{'loss': 1.6386, 'grad_norm': 0.18917231261730194, 'learning_rate': 0.007361739587252019, 'epoch': 1.1}\n",
            "{'loss': 1.1091, 'grad_norm': 0.21610331535339355, 'learning_rate': 0.007323615860218843, 'epoch': 1.1}\n",
            "{'loss': 0.933, 'grad_norm': 0.11470789462327957, 'learning_rate': 0.00728531904851169, 'epoch': 1.11}\n",
            "{'loss': 1.3075, 'grad_norm': 0.21689918637275696, 'learning_rate': 0.007246852004835807, 'epoch': 1.12}\n",
            "{'loss': 1.2483, 'grad_norm': 0.2506682276725769, 'learning_rate': 0.007208217594576923, 'epoch': 1.13}\n",
            "{'loss': 0.8491, 'grad_norm': 0.1104980856180191, 'learning_rate': 0.007169418695587791, 'epoch': 1.14}\n",
            "{'loss': 1.774, 'grad_norm': 0.22434473037719727, 'learning_rate': 0.007130458197973828, 'epoch': 1.14}\n",
            "{'loss': 1.1572, 'grad_norm': 0.14401070773601532, 'learning_rate': 0.0070913390038778255, 'epoch': 1.15}\n",
            "{'loss': 0.859, 'grad_norm': 0.21161490678787231, 'learning_rate': 0.007052064027263785, 'epoch': 1.16}\n",
            "{'loss': 1.374, 'grad_norm': 0.14286918938159943, 'learning_rate': 0.0070126361936998375, 'epoch': 1.17}\n",
            "{'loss': 1.3787, 'grad_norm': 0.14025326073169708, 'learning_rate': 0.006973058440140341, 'epoch': 1.18}\n",
            "{'loss': 1.8269, 'grad_norm': 0.19003267586231232, 'learning_rate': 0.006933333714707094, 'epoch': 1.18}\n",
            "{'loss': 1.1511, 'grad_norm': 0.07996556907892227, 'learning_rate': 0.006893464976469739, 'epoch': 1.19}\n",
            "{'loss': 0.6947, 'grad_norm': 0.048474233597517014, 'learning_rate': 0.006853455195225339, 'epoch': 1.2}\n",
            "{'loss': 0.9789, 'grad_norm': 0.06523282825946808, 'learning_rate': 0.00681330735127716, 'epoch': 1.21}\n",
            "{'loss': 1.4713, 'grad_norm': 0.25648602843284607, 'learning_rate': 0.006773024435212678, 'epoch': 1.22}\n",
            "{'loss': 1.3356, 'grad_norm': 0.14970183372497559, 'learning_rate': 0.0067326094476808, 'epoch': 1.22}\n",
            "{'loss': 1.3202, 'grad_norm': 0.11795289069414139, 'learning_rate': 0.0066920653991683525, 'epoch': 1.23}\n",
            "{'loss': 0.8776, 'grad_norm': 0.10603103786706924, 'learning_rate': 0.006651395309775836, 'epoch': 1.24}\n",
            "{'loss': 1.1353, 'grad_norm': 0.08813275396823883, 'learning_rate': 0.006610602208992454, 'epoch': 1.25}\n",
            "{'loss': 1.0072, 'grad_norm': 0.1206098198890686, 'learning_rate': 0.00656968913547045, 'epoch': 1.26}\n",
            "{'loss': 1.1494, 'grad_norm': 0.1738118678331375, 'learning_rate': 0.006528659136798765, 'epoch': 1.26}\n",
            "{'loss': 1.2906, 'grad_norm': 0.08092503249645233, 'learning_rate': 0.006487515269276016, 'epoch': 1.27}\n",
            "{'loss': 1.6053, 'grad_norm': 0.23109133541584015, 'learning_rate': 0.0064462605976828395, 'epoch': 1.28}\n",
            "{'loss': 1.4369, 'grad_norm': 0.09784240275621414, 'learning_rate': 0.0064048981950535966, 'epoch': 1.29}\n",
            "{'loss': 1.3576, 'grad_norm': 0.18511508405208588, 'learning_rate': 0.006363431142447469, 'epoch': 1.3}\n",
            "{'loss': 0.7784, 'grad_norm': 0.05411655455827713, 'learning_rate': 0.006321862528718945, 'epoch': 1.3}\n",
            "{'loss': 1.033, 'grad_norm': 0.06565108895301819, 'learning_rate': 0.006280195450287736, 'epoch': 1.31}\n",
            "{'loss': 0.7359, 'grad_norm': 0.0790945291519165, 'learning_rate': 0.00623843301090813, 'epoch': 1.32}\n",
            "{'loss': 1.1162, 'grad_norm': 0.1235610619187355, 'learning_rate': 0.006196578321437789, 'epoch': 1.33}\n",
            "{'loss': 1.1294, 'grad_norm': 0.11697815358638763, 'learning_rate': 0.006154634499606029, 'epoch': 1.34}\n",
            "{'loss': 1.0768, 'grad_norm': 0.08809687942266464, 'learning_rate': 0.006112604669781572, 'epoch': 1.34}\n",
            "{'loss': 0.8607, 'grad_norm': 0.061536066234111786, 'learning_rate': 0.0060704919627398305, 'epoch': 1.35}\n",
            "{'loss': 1.5769, 'grad_norm': 0.1549707055091858, 'learning_rate': 0.006028299515429682, 'epoch': 1.36}\n",
            "{'loss': 1.555, 'grad_norm': 0.10882501304149628, 'learning_rate': 0.005986030470739811, 'epoch': 1.37}\n",
            "{'loss': 0.9544, 'grad_norm': 0.09319377690553665, 'learning_rate': 0.005943687977264584, 'epoch': 1.38}\n",
            "{'loss': 0.9951, 'grad_norm': 0.0962105393409729, 'learning_rate': 0.005901275189069529, 'epoch': 1.38}\n",
            "{'loss': 1.8409, 'grad_norm': 0.3450789153575897, 'learning_rate': 0.005858795265456382, 'epoch': 1.39}\n",
            "{'loss': 1.1895, 'grad_norm': 0.20617057383060455, 'learning_rate': 0.005816251370727748, 'epoch': 1.4}\n",
            "{'loss': 1.2241, 'grad_norm': 0.20612753927707672, 'learning_rate': 0.005773646673951406, 'epoch': 1.41}\n",
            "{'loss': 0.7355, 'grad_norm': 0.43791961669921875, 'learning_rate': 0.005730984348724242, 'epoch': 1.42}\n",
            "{'loss': 0.8319, 'grad_norm': 0.13998393714427948, 'learning_rate': 0.005688267572935842, 'epoch': 1.42}\n",
            "{'loss': 0.7878, 'grad_norm': 0.09630464017391205, 'learning_rate': 0.005645499528531784, 'epoch': 1.43}\n",
            "{'loss': 1.2023, 'grad_norm': 0.17566727101802826, 'learning_rate': 0.005602683401276615, 'epoch': 1.44}\n",
            "{'loss': 1.3497, 'grad_norm': 0.1819871962070465, 'learning_rate': 0.005559822380516539, 'epoch': 1.45}\n",
            "{'loss': 0.8984, 'grad_norm': 0.18658071756362915, 'learning_rate': 0.00551691965894185, 'epoch': 1.46}\n",
            "{'loss': 0.9754, 'grad_norm': 0.27406373620033264, 'learning_rate': 0.005473978432349111, 'epoch': 1.46}\n",
            "{'loss': 0.8265, 'grad_norm': 0.08472580462694168, 'learning_rate': 0.0054310018994030975, 'epoch': 1.47}\n",
            "{'loss': 1.4181, 'grad_norm': 0.32408496737480164, 'learning_rate': 0.005387993261398532, 'epoch': 1.48}\n",
            "{'loss': 1.4443, 'grad_norm': 0.2899182140827179, 'learning_rate': 0.005344955722021624, 'epoch': 1.49}\n",
            "{'loss': 1.6613, 'grad_norm': 0.40941688418388367, 'learning_rate': 0.00530189248711143, 'epoch': 1.5}\n",
            "{'loss': 1.1886, 'grad_norm': 0.19313572347164154, 'learning_rate': 0.005258806764421048, 'epoch': 1.5}\n",
            "{'loss': 1.4152, 'grad_norm': 0.2640238106250763, 'learning_rate': 0.005215701763378673, 'epoch': 1.51}\n",
            "{'loss': 1.0106, 'grad_norm': 0.1600465029478073, 'learning_rate': 0.005172580694848541, 'epoch': 1.52}\n",
            "{'loss': 1.003, 'grad_norm': 0.3086461126804352, 'learning_rate': 0.005129446770891738, 'epoch': 1.53}\n",
            "{'loss': 0.7452, 'grad_norm': 0.13665378093719482, 'learning_rate': 0.0050863032045269435, 'epoch': 1.54}\n",
            "{'loss': 0.7495, 'grad_norm': 0.18148061633110046, 'learning_rate': 0.0050431532094910945, 'epoch': 1.54}\n",
            "{'loss': 0.7943, 'grad_norm': 0.16603630781173706, 'learning_rate': 0.005, 'epoch': 1.55}\n",
            "{'loss': 1.1477, 'grad_norm': 0.24163886904716492, 'learning_rate': 0.004956846790508906, 'epoch': 1.56}\n",
            "{'loss': 0.6033, 'grad_norm': 0.0775512233376503, 'learning_rate': 0.004913696795473058, 'epoch': 1.57}\n",
            "{'loss': 0.9655, 'grad_norm': 0.1611924022436142, 'learning_rate': 0.004870553229108264, 'epoch': 1.58}\n",
            "{'loss': 0.8347, 'grad_norm': 0.11389341950416565, 'learning_rate': 0.004827419305151461, 'epoch': 1.58}\n",
            "{'loss': 0.9477, 'grad_norm': 0.09441205859184265, 'learning_rate': 0.004784298236621327, 'epoch': 1.59}\n",
            "{'loss': 0.8411, 'grad_norm': 0.11721836030483246, 'learning_rate': 0.0047411932355789525, 'epoch': 1.6}\n",
            "{'loss': 0.6689, 'grad_norm': 0.04652570188045502, 'learning_rate': 0.004698107512888569, 'epoch': 1.61}\n",
            "{'loss': 1.1528, 'grad_norm': 0.5500931143760681, 'learning_rate': 0.004655044277978375, 'epoch': 1.62}\n",
            "{'loss': 1.05, 'grad_norm': 0.1650368720293045, 'learning_rate': 0.004612006738601469, 'epoch': 1.62}\n",
            "{'loss': 0.6637, 'grad_norm': 0.1017608791589737, 'learning_rate': 0.004568998100596903, 'epoch': 1.63}\n",
            "{'loss': 0.8991, 'grad_norm': 0.16054631769657135, 'learning_rate': 0.004526021567650889, 'epoch': 1.64}\n",
            "{'loss': 1.3779, 'grad_norm': 0.34544405341148376, 'learning_rate': 0.00448308034105815, 'epoch': 1.65}\n",
            "{'loss': 0.7154, 'grad_norm': 0.12718269228935242, 'learning_rate': 0.004440177619483461, 'epoch': 1.66}\n",
            "{'loss': 0.856, 'grad_norm': 0.2385793775320053, 'learning_rate': 0.004397316598723385, 'epoch': 1.66}\n",
            "{'loss': 1.0649, 'grad_norm': 0.1715903878211975, 'learning_rate': 0.004354500471468217, 'epoch': 1.67}\n",
            "{'loss': 0.6221, 'grad_norm': 0.1057969331741333, 'learning_rate': 0.00431173242706416, 'epoch': 1.68}\n",
            "{'loss': 1.1631, 'grad_norm': 0.45202764868736267, 'learning_rate': 0.004269015651275761, 'epoch': 1.69}\n",
            "{'loss': 0.6519, 'grad_norm': 0.1107078418135643, 'learning_rate': 0.004226353326048593, 'epoch': 1.7}\n",
            "{'loss': 0.9534, 'grad_norm': 0.6129950284957886, 'learning_rate': 0.004183748629272253, 'epoch': 1.7}\n",
            "{'loss': 0.593, 'grad_norm': 0.07254689931869507, 'learning_rate': 0.004141204734543619, 'epoch': 1.71}\n",
            "{'loss': 0.8113, 'grad_norm': 0.12339036911725998, 'learning_rate': 0.004098724810930472, 'epoch': 1.72}\n",
            "{'loss': 0.7978, 'grad_norm': 0.15564796328544617, 'learning_rate': 0.004056312022735417, 'epoch': 1.73}\n",
            "{'loss': 0.5287, 'grad_norm': 0.059787776321172714, 'learning_rate': 0.00401396952926019, 'epoch': 1.74}\n",
            "{'loss': 0.7157, 'grad_norm': 0.0623834952712059, 'learning_rate': 0.003971700484570318, 'epoch': 1.74}\n",
            "{'loss': 0.6037, 'grad_norm': 0.055201929062604904, 'learning_rate': 0.00392950803726017, 'epoch': 1.75}\n",
            "{'loss': 0.7792, 'grad_norm': 0.14713039994239807, 'learning_rate': 0.003887395330218428, 'epoch': 1.76}\n",
            "{'loss': 0.6123, 'grad_norm': 0.08288710564374924, 'learning_rate': 0.0038453655003939735, 'epoch': 1.77}\n",
            "{'loss': 1.2364, 'grad_norm': 0.18812024593353271, 'learning_rate': 0.003803421678562213, 'epoch': 1.78}\n",
            "{'loss': 0.8824, 'grad_norm': 0.09651151299476624, 'learning_rate': 0.00376156698909187, 'epoch': 1.78}\n",
            "{'loss': 0.8708, 'grad_norm': 0.057506926357746124, 'learning_rate': 0.0037198045497122646, 'epoch': 1.79}\n",
            "{'loss': 0.6695, 'grad_norm': 0.08937930315732956, 'learning_rate': 0.0036781374712810556, 'epoch': 1.8}\n",
            "{'loss': 0.6011, 'grad_norm': 0.05988548696041107, 'learning_rate': 0.0036365688575525313, 'epoch': 1.81}\n",
            "{'loss': 1.0027, 'grad_norm': 0.1048608049750328, 'learning_rate': 0.003595101804946404, 'epoch': 1.82}\n",
            "{'loss': 0.5826, 'grad_norm': 0.05580473318696022, 'learning_rate': 0.003553739402317162, 'epoch': 1.82}\n",
            "{'loss': 0.723, 'grad_norm': 0.14767774939537048, 'learning_rate': 0.003512484730723986, 'epoch': 1.83}\n",
            "{'loss': 0.8293, 'grad_norm': 0.06646299362182617, 'learning_rate': 0.0034713408632012365, 'epoch': 1.84}\n",
            "{'loss': 0.9715, 'grad_norm': 0.11272862553596497, 'learning_rate': 0.00343031086452955, 'epoch': 1.85}\n",
            "{'loss': 0.7957, 'grad_norm': 0.1217881441116333, 'learning_rate': 0.003389397791007548, 'epoch': 1.86}\n",
            "{'loss': 0.6036, 'grad_norm': 0.05820537358522415, 'learning_rate': 0.0033486046902241663, 'epoch': 1.86}\n",
            "{'loss': 0.5284, 'grad_norm': 0.058564193546772, 'learning_rate': 0.003307934600831648, 'epoch': 1.87}\n",
            "{'loss': 0.7324, 'grad_norm': 0.08634400367736816, 'learning_rate': 0.0032673905523191997, 'epoch': 1.88}\n",
            "{'loss': 0.6002, 'grad_norm': 0.038257673382759094, 'learning_rate': 0.0032269755647873215, 'epoch': 1.89}\n",
            "{'loss': 0.7525, 'grad_norm': 0.15244808793067932, 'learning_rate': 0.00318669264872284, 'epoch': 1.9}\n",
            "{'loss': 0.6097, 'grad_norm': 0.03342146426439285, 'learning_rate': 0.0031465448047746625, 'epoch': 1.9}\n",
            "{'loss': 0.7717, 'grad_norm': 0.09108959883451462, 'learning_rate': 0.003106535023530262, 'epoch': 1.91}\n",
            "{'loss': 0.7793, 'grad_norm': 0.1006702110171318, 'learning_rate': 0.003066666285292906, 'epoch': 1.92}\n",
            "{'loss': 0.7073, 'grad_norm': 0.07141561061143875, 'learning_rate': 0.00302694155985966, 'epoch': 1.93}\n",
            "{'loss': 0.8629, 'grad_norm': 0.07714030891656876, 'learning_rate': 0.0029873638063001627, 'epoch': 1.94}\n",
            "{'loss': 0.573, 'grad_norm': 0.07378686964511871, 'learning_rate': 0.002947935972736217, 'epoch': 1.94}\n",
            "{'loss': 0.8498, 'grad_norm': 0.18475684523582458, 'learning_rate': 0.0029086609961221756, 'epoch': 1.95}\n",
            "{'loss': 0.6998, 'grad_norm': 0.0735279843211174, 'learning_rate': 0.0028695418020261753, 'epoch': 1.96}\n",
            "{'loss': 0.5686, 'grad_norm': 0.07203846424818039, 'learning_rate': 0.00283058130441221, 'epoch': 1.97}\n",
            "{'loss': 0.7391, 'grad_norm': 0.058397579938173294, 'learning_rate': 0.0027917824054230784, 'epoch': 1.98}\n",
            "{'loss': 0.4404, 'grad_norm': 0.040002938359975815, 'learning_rate': 0.0027531479951641924, 'epoch': 1.98}\n",
            "{'loss': 0.9622, 'grad_norm': 0.10720276087522507, 'learning_rate': 0.002714680951488312, 'epoch': 1.99}\n",
            "{'loss': 0.5651, 'grad_norm': 0.05383455753326416, 'learning_rate': 0.002676384139781157, 'epoch': 2.0}\n",
            "{'loss': 0.8003, 'grad_norm': 0.1049250066280365, 'learning_rate': 0.0026382604127479815, 'epoch': 2.01}\n",
            "{'loss': 0.6185, 'grad_norm': 0.06761086732149124, 'learning_rate': 0.0026003126102010694, 'epoch': 2.02}\n",
            "{'loss': 0.9398, 'grad_norm': 0.18664203584194183, 'learning_rate': 0.0025625435588482017, 'epoch': 2.02}\n",
            "{'loss': 0.4279, 'grad_norm': 0.03805263340473175, 'learning_rate': 0.002524956072082093, 'epoch': 2.03}\n",
            "{'loss': 0.9299, 'grad_norm': 0.10255852341651917, 'learning_rate': 0.0024875529497708354, 'epoch': 2.04}\n",
            "{'loss': 0.6691, 'grad_norm': 0.09648095816373825, 'learning_rate': 0.0024503369780493217, 'epoch': 2.05}\n",
            "{'loss': 1.0834, 'grad_norm': 0.12726721167564392, 'learning_rate': 0.0024133109291117156, 'epoch': 2.06}\n",
            "{'loss': 0.7845, 'grad_norm': 0.07571318745613098, 'learning_rate': 0.00237647756100496, 'epoch': 2.06}\n",
            "{'loss': 0.6213, 'grad_norm': 0.06441570818424225, 'learning_rate': 0.0023398396174233176, 'epoch': 2.07}\n",
            "{'loss': 0.9089, 'grad_norm': 0.10673772543668747, 'learning_rate': 0.002303399827504005, 'epoch': 2.08}\n",
            "{'loss': 0.7499, 'grad_norm': 0.11365970224142075, 'learning_rate': 0.002267160905623895, 'epoch': 2.09}\n",
            "{'loss': 0.7378, 'grad_norm': 0.13624612987041473, 'learning_rate': 0.0022311255511973343, 'epoch': 2.1}\n",
            "{'loss': 0.677, 'grad_norm': 0.0888909325003624, 'learning_rate': 0.0021952964484750525, 'epoch': 2.1}\n",
            "{'loss': 0.4373, 'grad_norm': 0.05096329003572464, 'learning_rate': 0.0021596762663442215, 'epoch': 2.11}\n",
            "{'loss': 0.7894, 'grad_norm': 0.13731466233730316, 'learning_rate': 0.0021242676581296528, 'epoch': 2.12}\n",
            "{'loss': 0.6703, 'grad_norm': 0.2592329680919647, 'learning_rate': 0.0020890732613961477, 'epoch': 2.13}\n",
            "{'loss': 1.0302, 'grad_norm': 0.16503098607063293, 'learning_rate': 0.002054095697752032, 'epoch': 2.14}\n",
            "{'loss': 0.4885, 'grad_norm': 0.05722576379776001, 'learning_rate': 0.002019337572653874, 'epoch': 2.14}\n",
            "{'loss': 0.4876, 'grad_norm': 0.056300871074199677, 'learning_rate': 0.0019848014752123977, 'epoch': 2.15}\n",
            "{'loss': 1.2515, 'grad_norm': 0.21347451210021973, 'learning_rate': 0.0019504899779996354, 'epoch': 2.16}\n",
            "{'loss': 0.5939, 'grad_norm': 0.06879807263612747, 'learning_rate': 0.0019164056368572847, 'epoch': 2.17}\n",
            "{'loss': 0.6527, 'grad_norm': 0.07859103381633759, 'learning_rate': 0.0018825509907063327, 'epoch': 2.18}\n",
            "{'loss': 0.4801, 'grad_norm': 0.06792346388101578, 'learning_rate': 0.0018489285613579327, 'epoch': 2.18}\n",
            "{'loss': 0.7817, 'grad_norm': 0.08721397072076797, 'learning_rate': 0.0018155408533255552, 'epoch': 2.19}\n",
            "{'loss': 0.6184, 'grad_norm': 0.054651763290166855, 'learning_rate': 0.001782390353638426, 'epoch': 2.2}\n",
            "{'loss': 0.801, 'grad_norm': 0.08007413148880005, 'learning_rate': 0.0017494795316562789, 'epoch': 2.21}\n",
            "{'loss': 0.5307, 'grad_norm': 0.06780719012022018, 'learning_rate': 0.0017168108388853998, 'epoch': 2.22}\n",
            "{'loss': 0.5007, 'grad_norm': 0.04856451600790024, 'learning_rate': 0.001684386708796025, 'epoch': 2.22}\n",
            "{'loss': 0.6441, 'grad_norm': 0.07137641310691833, 'learning_rate': 0.0016522095566410728, 'epoch': 2.23}\n",
            "{'loss': 0.6546, 'grad_norm': 0.08925890922546387, 'learning_rate': 0.001620281779276228, 'epoch': 2.24}\n",
            "{'loss': 0.6965, 'grad_norm': 0.07154451310634613, 'learning_rate': 0.0015886057549814132, 'epoch': 2.25}\n",
            "{'loss': 0.8942, 'grad_norm': 0.1281164586544037, 'learning_rate': 0.001557183843283614, 'epoch': 2.26}\n",
            "{'loss': 0.8037, 'grad_norm': 0.09635214507579803, 'learning_rate': 0.0015260183847811382, 'epoch': 2.26}\n",
            "{'loss': 0.6919, 'grad_norm': 0.10999970883131027, 'learning_rate': 0.0014951117009692528, 'epoch': 2.27}\n",
            "{'loss': 0.5884, 'grad_norm': 0.12479378283023834, 'learning_rate': 0.0014644660940672626, 'epoch': 2.28}\n",
            "{'loss': 0.7028, 'grad_norm': 0.10374130308628082, 'learning_rate': 0.0014340838468470197, 'epoch': 2.29}\n",
            "{'loss': 0.8835, 'grad_norm': 0.17196258902549744, 'learning_rate': 0.0014039672224628785, 'epoch': 2.3}\n",
            "{'loss': 0.513, 'grad_norm': 0.05154597386717796, 'learning_rate': 0.001374118464283119, 'epoch': 2.3}\n",
            "{'loss': 0.9026, 'grad_norm': 0.17932440340518951, 'learning_rate': 0.0013445397957228338, 'epoch': 2.31}\n",
            "{'loss': 0.995, 'grad_norm': 0.10741937905550003, 'learning_rate': 0.0013152334200783166, 'epoch': 2.32}\n",
            "{'loss': 0.5549, 'grad_norm': 0.06929189711809158, 'learning_rate': 0.0012862015203629273, 'epoch': 2.33}\n",
            "{'loss': 0.7784, 'grad_norm': 0.06728717684745789, 'learning_rate': 0.001257446259144494, 'epoch': 2.34}\n",
            "{'loss': 0.6235, 'grad_norm': 0.05516957864165306, 'learning_rate': 0.0012289697783842142, 'epoch': 2.34}\n",
            "{'loss': 0.736, 'grad_norm': 0.05922890454530716, 'learning_rate': 0.0012007741992771065, 'epoch': 2.35}\n",
            "{'loss': 0.7931, 'grad_norm': 0.07219688594341278, 'learning_rate': 0.0011728616220940031, 'epoch': 2.36}\n",
            "{'loss': 0.4598, 'grad_norm': 0.02951384149491787, 'learning_rate': 0.001145234126025102, 'epoch': 2.37}\n",
            "{'loss': 0.7537, 'grad_norm': 0.10817241668701172, 'learning_rate': 0.0011178937690250917, 'epoch': 2.38}\n",
            "{'loss': 0.5307, 'grad_norm': 0.06882032752037048, 'learning_rate': 0.001090842587659851, 'epoch': 2.38}\n",
            "{'loss': 0.7886, 'grad_norm': 3.9445345401763916, 'learning_rate': 0.0010640825969547496, 'epoch': 2.39}\n",
            "{'loss': 0.7826, 'grad_norm': 1.023622989654541, 'learning_rate': 0.0010376157902445488, 'epoch': 2.4}\n",
            "{'loss': 2.7004, 'grad_norm': 105.54307556152344, 'learning_rate': 0.00101144413902492, 'epoch': 2.41}\n",
            "{'loss': 1.5719, 'grad_norm': 6.241580486297607, 'learning_rate': 0.000985569592805588, 'epoch': 2.42}\n",
            "{'loss': 1.2514, 'grad_norm': 2.6310882568359375, 'learning_rate': 0.0009599940789651179, 'epoch': 2.42}\n",
            "{'loss': 0.482, 'grad_norm': 0.5935360789299011, 'learning_rate': 0.0009347195026073368, 'epoch': 2.43}\n",
            "{'loss': 0.7036, 'grad_norm': 91.0683364868164, 'learning_rate': 0.000909747746419436, 'epoch': 2.44}\n",
            "{'loss': 1.3903, 'grad_norm': 0.5255951881408691, 'learning_rate': 0.0008850806705317183, 'epoch': 2.45}\n",
            "{'loss': 1.0499, 'grad_norm': 0.2069018930196762, 'learning_rate': 0.0008607201123790459, 'epoch': 2.46}\n",
            "{'loss': 0.6071, 'grad_norm': 0.06473823636770248, 'learning_rate': 0.0008366678865639688, 'epoch': 2.46}\n",
            "{'loss': 0.5024, 'grad_norm': 0.05160832405090332, 'learning_rate': 0.0008129257847215571, 'epoch': 2.47}\n",
            "{'loss': 0.8579, 'grad_norm': 0.1529153287410736, 'learning_rate': 0.0007894955753859412, 'epoch': 2.48}\n",
            "{'loss': 0.735, 'grad_norm': 0.10365266352891922, 'learning_rate': 0.0007663790038585794, 'epoch': 2.49}\n",
            "{'loss': 0.6869, 'grad_norm': 0.12976984679698944, 'learning_rate': 0.0007435777920782444, 'epoch': 2.5}\n",
            "{'loss': 0.6524, 'grad_norm': 0.09676839411258698, 'learning_rate': 0.000721093638492763, 'epoch': 2.5}\n",
            "{'loss': 0.6123, 'grad_norm': 0.08478875458240509, 'learning_rate': 0.0006989282179324963, 'epoch': 2.51}\n",
            "{'loss': 0.5856, 'grad_norm': 0.09571249783039093, 'learning_rate': 0.0006770831814855883, 'epoch': 2.52}\n",
            "{'loss': 0.8602, 'grad_norm': 0.10698202252388, 'learning_rate': 0.0006555601563749675, 'epoch': 2.53}\n",
            "{'loss': 0.4352, 'grad_norm': 0.06615152209997177, 'learning_rate': 0.0006343607458371459, 'epoch': 2.54}\n",
            "{'loss': 0.7765, 'grad_norm': 0.07300804555416107, 'learning_rate': 0.0006134865290027902, 'epoch': 2.54}\n",
            "{'loss': 0.5611, 'grad_norm': 0.045296017080545425, 'learning_rate': 0.000592939060779093, 'epoch': 2.55}\n",
            "{'loss': 0.8534, 'grad_norm': 0.10391007363796234, 'learning_rate': 0.000572719871733951, 'epoch': 2.56}\n",
            "{'loss': 0.6617, 'grad_norm': 0.12072136253118515, 'learning_rate': 0.0005528304679819513, 'epoch': 2.57}\n",
            "{'loss': 0.5287, 'grad_norm': 0.0441741906106472, 'learning_rate': 0.0005332723310721854, 'epoch': 2.58}\n",
            "{'loss': 1.022, 'grad_norm': 0.14954155683517456, 'learning_rate': 0.0005140469178778845, 'epoch': 2.58}\n",
            "{'loss': 0.6974, 'grad_norm': 0.12595559656620026, 'learning_rate': 0.0004951556604879049, 'epoch': 2.59}\n",
            "{'loss': 0.7413, 'grad_norm': 0.08476581424474716, 'learning_rate': 0.00047659996610004417, 'epoch': 2.6}\n",
            "{'loss': 0.4836, 'grad_norm': 0.043001096695661545, 'learning_rate': 0.00045838121691622993, 'epoch': 2.61}\n",
            "{'loss': 0.4219, 'grad_norm': 0.04471369832754135, 'learning_rate': 0.0004405007700395497, 'epoch': 2.62}\n",
            "{'loss': 0.6488, 'grad_norm': 0.09448711574077606, 'learning_rate': 0.0004229599573731685, 'epoch': 2.62}\n",
            "{'loss': 0.4937, 'grad_norm': 0.05834076926112175, 'learning_rate': 0.0004057600855211141, 'epoch': 2.63}\n",
            "{'loss': 0.6305, 'grad_norm': 0.0948362872004509, 'learning_rate': 0.00038890243569094876, 'epoch': 2.64}\n",
            "{'loss': 0.5175, 'grad_norm': 0.0683869794011116, 'learning_rate': 0.0003723882635983328, 'epoch': 2.65}\n",
            "{'loss': 0.8406, 'grad_norm': 0.12073964625597, 'learning_rate': 0.00035621879937348835, 'epoch': 2.66}\n",
            "{'loss': 0.464, 'grad_norm': 0.03293376415967941, 'learning_rate': 0.00034039524746956595, 'epoch': 2.66}\n",
            "{'loss': 0.5021, 'grad_norm': 0.03900524601340294, 'learning_rate': 0.0003249187865729264, 'epoch': 2.67}\n",
            "{'loss': 0.7946, 'grad_norm': 0.0771687850356102, 'learning_rate': 0.0003097905695153408, 'epoch': 2.68}\n",
            "{'loss': 0.934, 'grad_norm': 0.2458101511001587, 'learning_rate': 0.0002950117231881183, 'epoch': 2.69}\n",
            "{'loss': 0.5968, 'grad_norm': 0.056947045028209686, 'learning_rate': 0.0002805833484581621, 'epoch': 2.7}\n",
            "{'loss': 0.4087, 'grad_norm': 0.031186018139123917, 'learning_rate': 0.00026650652008597067, 'epoch': 2.7}\n",
            "{'loss': 0.4897, 'grad_norm': 0.03967098519206047, 'learning_rate': 0.0002527822866455731, 'epoch': 2.71}\n",
            "{'loss': 0.5468, 'grad_norm': 0.0665535032749176, 'learning_rate': 0.00023941167044642941, 'epoch': 2.72}\n",
            "{'loss': 0.6462, 'grad_norm': 0.04805939272046089, 'learning_rate': 0.00022639566745727202, 'epoch': 2.73}\n",
            "{'loss': 0.6113, 'grad_norm': 0.07976275682449341, 'learning_rate': 0.0002137352472319215, 'epoch': 2.74}\n",
            "{'loss': 0.5892, 'grad_norm': 0.0488065704703331, 'learning_rate': 0.0002014313528370626, 'epoch': 2.74}\n",
            "{'loss': 0.5379, 'grad_norm': 0.0638684406876564, 'learning_rate': 0.00018948490078199765, 'epoch': 2.75}\n",
            "{'loss': 0.7277, 'grad_norm': 0.10123800486326218, 'learning_rate': 0.00017789678095037452, 'epoch': 2.76}\n",
            "{'loss': 0.7731, 'grad_norm': 0.11431321501731873, 'learning_rate': 0.0001666678565339025, 'epoch': 2.77}\n",
            "{'loss': 0.6156, 'grad_norm': 0.030801493674516678, 'learning_rate': 0.0001557989639680496, 'epoch': 2.78}\n",
            "{'loss': 0.7572, 'grad_norm': 0.062103271484375, 'learning_rate': 0.00014529091286973994, 'epoch': 2.78}\n",
            "{'loss': 0.6563, 'grad_norm': 0.07060069590806961, 'learning_rate': 0.0001351444859770462, 'epoch': 2.79}\n",
            "{'loss': 0.6587, 'grad_norm': 0.11498510837554932, 'learning_rate': 0.0001253604390908819, 'epoch': 2.8}\n",
            "{'loss': 0.6332, 'grad_norm': 0.09352225065231323, 'learning_rate': 0.0001159395010187042, 'epoch': 2.81}\n",
            "{'loss': 0.7732, 'grad_norm': 0.11165916174650192, 'learning_rate': 0.00010688237352022346, 'epoch': 2.82}\n",
            "{'loss': 0.5693, 'grad_norm': 0.06388048827648163, 'learning_rate': 9.818973125513276e-05, 'epoch': 2.82}\n",
            "{'loss': 0.5188, 'grad_norm': 0.044294681400060654, 'learning_rate': 8.986222173284874e-05, 'epoch': 2.83}\n",
            "{'loss': 0.5524, 'grad_norm': 0.05702120438218117, 'learning_rate': 8.190046526428241e-05, 'epoch': 2.84}\n",
            "{'loss': 0.402, 'grad_norm': 0.024331845343112946, 'learning_rate': 7.4305054915631e-05, 'epoch': 2.85}\n",
            "{'loss': 0.5328, 'grad_norm': 0.050305917859077454, 'learning_rate': 6.707655646420229e-05, 'epoch': 2.86}\n",
            "{'loss': 0.7344, 'grad_norm': 0.08997093141078949, 'learning_rate': 6.0215508356267765e-05, 'epoch': 2.86}\n",
            "{'loss': 0.7491, 'grad_norm': 0.10516425967216492, 'learning_rate': 5.372242166695684e-05, 'epoch': 2.87}\n",
            "{'loss': 0.671, 'grad_norm': 0.09334728866815567, 'learning_rate': 4.759778006218407e-05, 'epoch': 2.88}\n",
            "{'loss': 0.4807, 'grad_norm': 0.04296207055449486, 'learning_rate': 4.184203976262513e-05, 'epoch': 2.89}\n",
            "{'loss': 0.6212, 'grad_norm': 0.07204475998878479, 'learning_rate': 3.645562950973014e-05, 'epoch': 2.9}\n",
            "{'loss': 0.4752, 'grad_norm': 0.04564519226551056, 'learning_rate': 3.143895053378698e-05, 'epoch': 2.9}\n",
            "{'loss': 0.613, 'grad_norm': 0.058373115956783295, 'learning_rate': 2.6792376524036878e-05, 'epoch': 2.91}\n",
            "{'loss': 0.7774, 'grad_norm': 0.06654953211545944, 'learning_rate': 2.2516253600833868e-05, 'epoch': 2.92}\n",
            "{'loss': 0.5106, 'grad_norm': 0.057644639164209366, 'learning_rate': 1.8610900289867673e-05, 'epoch': 2.93}\n",
            "{'loss': 0.7192, 'grad_norm': 0.09967372566461563, 'learning_rate': 1.5076607498433204e-05, 'epoch': 2.94}\n",
            "{'loss': 0.7883, 'grad_norm': 0.08420154452323914, 'learning_rate': 1.1913638493762369e-05, 'epoch': 2.94}\n",
            "{'loss': 0.7675, 'grad_norm': 0.08381970971822739, 'learning_rate': 9.12222888341252e-06, 'epoch': 2.95}\n",
            "{'loss': 0.9229, 'grad_norm': 0.10960283130407333, 'learning_rate': 6.702586597719385e-06, 'epoch': 2.96}\n",
            "{'loss': 0.5072, 'grad_norm': 0.03874215856194496, 'learning_rate': 4.654891874303346e-06, 'epoch': 2.97}\n",
            "{'loss': 0.5164, 'grad_norm': 0.04660634323954582, 'learning_rate': 2.9792972446479605e-06, 'epoch': 2.98}\n",
            "{'loss': 0.7842, 'grad_norm': 0.1484236866235733, 'learning_rate': 1.6759275227357095e-06, 'epoch': 2.98}\n",
            "{'loss': 0.5699, 'grad_norm': 0.055154964327812195, 'learning_rate': 7.448797957526621e-07, 'epoch': 2.99}\n",
            "{'loss': 0.6559, 'grad_norm': 0.09959112852811813, 'learning_rate': 1.862234168542587e-07, 'epoch': 3.0}\n",
            "{'train_runtime': 67.9983, 'train_samples_per_second': 11.03, 'train_steps_per_second': 5.515, 'train_loss': 1.358439245700836, 'epoch': 3.0}\n",
            "100% 375/375 [01:07<00:00,  5.51it/s]\n",
            "Training complete.\n",
            "Model saved to loras/self-edit/training_set_iteration_1/8d5021e8/1\n",
            "Skipping training for task 8d5021e8 because the number of steps is greater than 375\n",
            "Training on 250 examples for 0 epochs, lr: 0.01\n",
            "No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n",
            "Starting training...\n",
            "{'train_runtime': 0.0021, 'train_samples_per_second': 0.0, 'train_steps_per_second': 0.0, 'train_loss': 0.0, 'epoch': 0}\n",
            "0it [00:00, ?it/s]\n",
            "Training complete.\n",
            "Model saved to loras/self-edit/training_set_iteration_1/8d5021e8/2\n",
            "Training on 250 examples for 3 epochs, lr: 0.001\n",
            "No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n",
            "Starting training...\n",
            "{'loss': 7.387, 'grad_norm': 10.39533805847168, 'learning_rate': 0.0, 'epoch': 0.01}\n",
            "{'loss': 6.5478, 'grad_norm': 7.915547847747803, 'learning_rate': 9.090909090909092e-05, 'epoch': 0.02}\n",
            "{'loss': 5.6338, 'grad_norm': 9.076550483703613, 'learning_rate': 0.00018181818181818183, 'epoch': 0.02}\n",
            "{'loss': 1.4429, 'grad_norm': 7.379814624786377, 'learning_rate': 0.00027272727272727274, 'epoch': 0.03}\n",
            "{'loss': 2.627, 'grad_norm': 18.29509925842285, 'learning_rate': 0.00036363636363636367, 'epoch': 0.04}\n",
            "{'loss': 0.5581, 'grad_norm': 2.617154598236084, 'learning_rate': 0.00045454545454545455, 'epoch': 0.05}\n",
            "{'loss': 0.5214, 'grad_norm': 0.2370593100786209, 'learning_rate': 0.0005454545454545455, 'epoch': 0.06}\n",
            "{'loss': 0.4708, 'grad_norm': 0.21711154282093048, 'learning_rate': 0.0006363636363636364, 'epoch': 0.06}\n",
            "{'loss': 0.4493, 'grad_norm': 0.23090915381908417, 'learning_rate': 0.0007272727272727273, 'epoch': 0.07}\n",
            "{'loss': 0.4054, 'grad_norm': 0.14145374298095703, 'learning_rate': 0.0008181818181818183, 'epoch': 0.08}\n",
            "{'loss': 0.3486, 'grad_norm': 0.11364201456308365, 'learning_rate': 0.0009090909090909091, 'epoch': 0.09}\n",
            "{'loss': 0.2972, 'grad_norm': 0.11391042917966843, 'learning_rate': 0.001, 'epoch': 0.1}\n",
            "{'loss': 0.256, 'grad_norm': 0.09068788588047028, 'learning_rate': 0.0009999813776583146, 'epoch': 0.1}\n",
            "{'loss': 0.2108, 'grad_norm': 0.10612380504608154, 'learning_rate': 0.0009999255120204248, 'epoch': 0.11}\n",
            "{'loss': 0.1897, 'grad_norm': 0.10135775804519653, 'learning_rate': 0.0009998324072477264, 'epoch': 0.12}\n",
            "{'loss': 0.1429, 'grad_norm': 0.07253861427307129, 'learning_rate': 0.0009997020702755353, 'epoch': 0.13}\n",
            "{'loss': 0.1196, 'grad_norm': 0.07339674234390259, 'learning_rate': 0.0009995345108125698, 'epoch': 0.14}\n",
            "{'loss': 0.086, 'grad_norm': 0.06706761568784714, 'learning_rate': 0.0009993297413402281, 'epoch': 0.14}\n",
            "{'loss': 0.0794, 'grad_norm': 0.07485035061836243, 'learning_rate': 0.0009990877771116587, 'epoch': 0.15}\n",
            "{'loss': 0.0693, 'grad_norm': 0.06982623785734177, 'learning_rate': 0.0009988086361506238, 'epoch': 0.16}\n",
            "{'loss': 0.0608, 'grad_norm': 0.06634104251861572, 'learning_rate': 0.0009984923392501567, 'epoch': 0.17}\n",
            "{'loss': 0.087, 'grad_norm': 0.1637413054704666, 'learning_rate': 0.0009981389099710132, 'epoch': 0.18}\n",
            "{'loss': 0.0628, 'grad_norm': 0.09898971766233444, 'learning_rate': 0.0009977483746399167, 'epoch': 0.18}\n",
            "{'loss': 0.0634, 'grad_norm': 0.10178656876087189, 'learning_rate': 0.0009973207623475964, 'epoch': 0.19}\n",
            "{'loss': 0.1022, 'grad_norm': 0.18509237468242645, 'learning_rate': 0.0009968561049466214, 'epoch': 0.2}\n",
            "{'loss': 0.0562, 'grad_norm': 0.05988512560725212, 'learning_rate': 0.000996354437049027, 'epoch': 0.21}\n",
            "{'loss': 0.0588, 'grad_norm': 0.06742025911808014, 'learning_rate': 0.0009958157960237375, 'epoch': 0.22}\n",
            "{'loss': 0.0864, 'grad_norm': 0.08313672989606857, 'learning_rate': 0.0009952402219937815, 'epoch': 0.22}\n",
            "{'loss': 0.0656, 'grad_norm': 0.05902095511555672, 'learning_rate': 0.0009946277578333045, 'epoch': 0.23}\n",
            "{'loss': 0.0487, 'grad_norm': 0.054048940539360046, 'learning_rate': 0.0009939784491643732, 'epoch': 0.24}\n",
            "{'loss': 0.0606, 'grad_norm': 0.04598763585090637, 'learning_rate': 0.0009932923443535797, 'epoch': 0.25}\n",
            "{'loss': 0.0534, 'grad_norm': 0.051832713186740875, 'learning_rate': 0.000992569494508437, 'epoch': 0.26}\n",
            "{'loss': 0.0484, 'grad_norm': 0.04924307018518448, 'learning_rate': 0.0009918099534735718, 'epoch': 0.26}\n",
            "{'loss': 0.0516, 'grad_norm': 0.04374033212661743, 'learning_rate': 0.0009910137778267152, 'epoch': 0.27}\n",
            "{'loss': 0.0513, 'grad_norm': 0.05758887156844139, 'learning_rate': 0.0009901810268744867, 'epoch': 0.28}\n",
            "{'loss': 0.045, 'grad_norm': 0.04761281609535217, 'learning_rate': 0.0009893117626479776, 'epoch': 0.29}\n",
            "{'loss': 0.0353, 'grad_norm': 0.036251433193683624, 'learning_rate': 0.0009884060498981295, 'epoch': 0.3}\n",
            "{'loss': 0.0467, 'grad_norm': 0.0745445117354393, 'learning_rate': 0.0009874639560909118, 'epoch': 0.3}\n",
            "{'loss': 0.0413, 'grad_norm': 0.08419369906187057, 'learning_rate': 0.0009864855514022954, 'epoch': 0.31}\n",
            "{'loss': 0.0497, 'grad_norm': 0.11887383460998535, 'learning_rate': 0.000985470908713026, 'epoch': 0.32}\n",
            "{'loss': 0.0281, 'grad_norm': 0.03212813287973404, 'learning_rate': 0.0009844201036031952, 'epoch': 0.33}\n",
            "{'loss': 0.0393, 'grad_norm': 0.0628424882888794, 'learning_rate': 0.0009833332143466098, 'epoch': 0.34}\n",
            "{'loss': 0.03, 'grad_norm': 0.04405825212597847, 'learning_rate': 0.0009822103219049626, 'epoch': 0.34}\n",
            "{'loss': 0.0337, 'grad_norm': 0.05911277234554291, 'learning_rate': 0.0009810515099218002, 'epoch': 0.35}\n",
            "{'loss': 0.024, 'grad_norm': 0.058618512004613876, 'learning_rate': 0.0009798568647162937, 'epoch': 0.36}\n",
            "{'loss': 0.0332, 'grad_norm': 0.0557674877345562, 'learning_rate': 0.000978626475276808, 'epoch': 0.37}\n",
            "{'loss': 0.0269, 'grad_norm': 0.04114918038249016, 'learning_rate': 0.0009773604332542728, 'epoch': 0.38}\n",
            "{'loss': 0.0266, 'grad_norm': 0.06005590036511421, 'learning_rate': 0.0009760588329553571, 'epoch': 0.38}\n",
            "{'loss': 0.0255, 'grad_norm': 0.05396036058664322, 'learning_rate': 0.0009747217713354427, 'epoch': 0.39}\n",
            "{'loss': 0.0286, 'grad_norm': 0.08065929263830185, 'learning_rate': 0.000973349347991403, 'epoch': 0.4}\n",
            "{'loss': 0.0181, 'grad_norm': 0.03888924792408943, 'learning_rate': 0.0009719416651541838, 'epoch': 0.41}\n",
            "{'loss': 0.0281, 'grad_norm': 0.08423873037099838, 'learning_rate': 0.0009704988276811882, 'epoch': 0.42}\n",
            "{'loss': 0.0256, 'grad_norm': 0.04925880208611488, 'learning_rate': 0.000969020943048466, 'epoch': 0.42}\n",
            "{'loss': 0.0157, 'grad_norm': 0.02576407417654991, 'learning_rate': 0.0009675081213427075, 'epoch': 0.43}\n",
            "{'loss': 0.0183, 'grad_norm': 0.028348460793495178, 'learning_rate': 0.0009659604752530434, 'epoch': 0.44}\n",
            "{'loss': 0.0179, 'grad_norm': 0.03625985607504845, 'learning_rate': 0.0009643781200626511, 'epoch': 0.45}\n",
            "{'loss': 0.0278, 'grad_norm': 0.07025431096553802, 'learning_rate': 0.0009627611736401667, 'epoch': 0.46}\n",
            "{'loss': 0.0179, 'grad_norm': 0.03066915273666382, 'learning_rate': 0.0009611097564309052, 'epoch': 0.46}\n",
            "{'loss': 0.0274, 'grad_norm': 0.06228969618678093, 'learning_rate': 0.0009594239914478886, 'epoch': 0.47}\n",
            "{'loss': 0.0157, 'grad_norm': 0.03001980669796467, 'learning_rate': 0.0009577040042626832, 'epoch': 0.48}\n",
            "{'loss': 0.0281, 'grad_norm': 0.05548115819692612, 'learning_rate': 0.0009559499229960451, 'epoch': 0.49}\n",
            "{'loss': 0.0219, 'grad_norm': 0.05134885758161545, 'learning_rate': 0.000954161878308377, 'epoch': 0.5}\n",
            "{'loss': 0.0232, 'grad_norm': 0.050313130021095276, 'learning_rate': 0.0009523400033899956, 'epoch': 0.5}\n",
            "{'loss': 0.0215, 'grad_norm': 0.02699100226163864, 'learning_rate': 0.0009504844339512095, 'epoch': 0.51}\n",
            "{'loss': 0.0239, 'grad_norm': 0.04530801251530647, 'learning_rate': 0.0009485953082122116, 'epoch': 0.52}\n",
            "{'loss': 0.036, 'grad_norm': 0.11406765133142471, 'learning_rate': 0.0009466727668927816, 'epoch': 0.53}\n",
            "{'loss': 0.0219, 'grad_norm': 0.04560094326734543, 'learning_rate': 0.000944716953201805, 'epoch': 0.54}\n",
            "{'loss': 0.0245, 'grad_norm': 0.037861015647649765, 'learning_rate': 0.0009427280128266049, 'epoch': 0.54}\n",
            "{'loss': 0.0258, 'grad_norm': 0.050974324345588684, 'learning_rate': 0.0009407060939220907, 'epoch': 0.55}\n",
            "{'loss': 0.0236, 'grad_norm': 0.06850288808345795, 'learning_rate': 0.000938651347099721, 'epoch': 0.56}\n",
            "{'loss': 0.0187, 'grad_norm': 0.033955950289964676, 'learning_rate': 0.0009365639254162854, 'epoch': 0.57}\n",
            "{'loss': 0.0262, 'grad_norm': 0.035629019141197205, 'learning_rate': 0.0009344439843625034, 'epoch': 0.58}\n",
            "{'loss': 0.0123, 'grad_norm': 0.018977714702486992, 'learning_rate': 0.0009322916818514413, 'epoch': 0.58}\n",
            "{'loss': 0.0298, 'grad_norm': 0.040103454142808914, 'learning_rate': 0.0009301071782067504, 'epoch': 0.59}\n",
            "{'loss': 0.025, 'grad_norm': 0.1213579997420311, 'learning_rate': 0.0009278906361507238, 'epoch': 0.6}\n",
            "{'loss': 0.0306, 'grad_norm': 0.04701785743236542, 'learning_rate': 0.0009256422207921756, 'epoch': 0.61}\n",
            "{'loss': 0.0164, 'grad_norm': 0.019654113799333572, 'learning_rate': 0.0009233620996141421, 'epoch': 0.62}\n",
            "{'loss': 0.0217, 'grad_norm': 0.037649791687726974, 'learning_rate': 0.0009210504424614059, 'epoch': 0.62}\n",
            "{'loss': 0.015, 'grad_norm': 0.023695243522524834, 'learning_rate': 0.0009187074215278444, 'epoch': 0.63}\n",
            "{'loss': 0.0149, 'grad_norm': 0.019014282152056694, 'learning_rate': 0.0009163332113436032, 'epoch': 0.64}\n",
            "{'loss': 0.0169, 'grad_norm': 0.023264167830348015, 'learning_rate': 0.0009139279887620955, 'epoch': 0.65}\n",
            "{'loss': 0.0157, 'grad_norm': 0.026809517294168472, 'learning_rate': 0.0009114919329468282, 'epoch': 0.66}\n",
            "{'loss': 0.0176, 'grad_norm': 0.026535436511039734, 'learning_rate': 0.0009090252253580565, 'epoch': 0.66}\n",
            "{'loss': 0.0194, 'grad_norm': 0.028128530830144882, 'learning_rate': 0.0009065280497392663, 'epoch': 0.67}\n",
            "{'loss': 0.0176, 'grad_norm': 0.022632166743278503, 'learning_rate': 0.0009040005921034883, 'epoch': 0.68}\n",
            "{'loss': 0.0277, 'grad_norm': 0.05723502114415169, 'learning_rate': 0.0009014430407194413, 'epoch': 0.69}\n",
            "{'loss': 0.0154, 'grad_norm': 0.02398974634706974, 'learning_rate': 0.0008988555860975081, 'epoch': 0.7}\n",
            "{'loss': 0.0139, 'grad_norm': 0.03328057378530502, 'learning_rate': 0.0008962384209755452, 'epoch': 0.7}\n",
            "{'loss': 0.0197, 'grad_norm': 0.0723533108830452, 'learning_rate': 0.000893591740304525, 'epoch': 0.71}\n",
            "{'loss': 0.0162, 'grad_norm': 0.028397122398018837, 'learning_rate': 0.000890915741234015, 'epoch': 0.72}\n",
            "{'loss': 0.0125, 'grad_norm': 0.028699584305286407, 'learning_rate': 0.0008882106230974909, 'epoch': 0.73}\n",
            "{'loss': 0.0148, 'grad_norm': 0.03456741198897362, 'learning_rate': 0.0008854765873974899, 'epoch': 0.74}\n",
            "{'loss': 0.0198, 'grad_norm': 0.07023998349905014, 'learning_rate': 0.0008827138377905998, 'epoch': 0.74}\n",
            "{'loss': 0.014, 'grad_norm': 0.03994039446115494, 'learning_rate': 0.0008799225800722895, 'epoch': 0.75}\n",
            "{'loss': 0.0185, 'grad_norm': 0.055050645023584366, 'learning_rate': 0.0008771030221615785, 'epoch': 0.76}\n",
            "{'loss': 0.0203, 'grad_norm': 0.054299820214509964, 'learning_rate': 0.0008742553740855505, 'epoch': 0.77}\n",
            "{'loss': 0.0171, 'grad_norm': 0.04923553392291069, 'learning_rate': 0.0008713798479637072, 'epoch': 0.78}\n",
            "{'loss': 0.0182, 'grad_norm': 0.0753573626279831, 'learning_rate': 0.0008684766579921683, 'epoch': 0.78}\n",
            "{'loss': 0.0206, 'grad_norm': 0.03593084216117859, 'learning_rate': 0.0008655460204277166, 'epoch': 0.79}\n",
            "{'loss': 0.0104, 'grad_norm': 0.0211779922246933, 'learning_rate': 0.0008625881535716883, 'epoch': 0.8}\n",
            "{'loss': 0.0124, 'grad_norm': 0.014396924525499344, 'learning_rate': 0.0008596032777537123, 'epoch': 0.81}\n",
            "{'loss': 0.0135, 'grad_norm': 0.031000889837741852, 'learning_rate': 0.0008565916153152981, 'epoch': 0.82}\n",
            "{'loss': 0.0224, 'grad_norm': 0.08916160464286804, 'learning_rate': 0.0008535533905932737, 'epoch': 0.82}\n",
            "{'loss': 0.0136, 'grad_norm': 0.03438689187169075, 'learning_rate': 0.0008504888299030747, 'epoch': 0.83}\n",
            "{'loss': 0.0246, 'grad_norm': 0.05593755096197128, 'learning_rate': 0.0008473981615218862, 'epoch': 0.84}\n",
            "{'loss': 0.0174, 'grad_norm': 0.024269219487905502, 'learning_rate': 0.0008442816156716386, 'epoch': 0.85}\n",
            "{'loss': 0.0187, 'grad_norm': 0.03087543696165085, 'learning_rate': 0.0008411394245018588, 'epoch': 0.86}\n",
            "{'loss': 0.0221, 'grad_norm': 0.056909870356321335, 'learning_rate': 0.0008379718220723773, 'epoch': 0.86}\n",
            "{'loss': 0.0159, 'grad_norm': 0.03823781758546829, 'learning_rate': 0.0008347790443358929, 'epoch': 0.87}\n",
            "{'loss': 0.0113, 'grad_norm': 0.03500152379274368, 'learning_rate': 0.0008315613291203976, 'epoch': 0.88}\n",
            "{'loss': 0.0129, 'grad_norm': 0.02359757572412491, 'learning_rate': 0.0008283189161114601, 'epoch': 0.89}\n",
            "{'loss': 0.0211, 'grad_norm': 0.04580382630228996, 'learning_rate': 0.000825052046834372, 'epoch': 0.9}\n",
            "{'loss': 0.022, 'grad_norm': 0.05439632758498192, 'learning_rate': 0.0008217609646361573, 'epoch': 0.9}\n",
            "{'loss': 0.0116, 'grad_norm': 0.015469255857169628, 'learning_rate': 0.0008184459146674447, 'epoch': 0.91}\n",
            "{'loss': 0.0148, 'grad_norm': 0.03714827820658684, 'learning_rate': 0.0008151071438642068, 'epoch': 0.92}\n",
            "{'loss': 0.016, 'grad_norm': 0.015522565692663193, 'learning_rate': 0.0008117449009293668, 'epoch': 0.93}\n",
            "{'loss': 0.0133, 'grad_norm': 0.0447002537548542, 'learning_rate': 0.0008083594363142716, 'epoch': 0.94}\n",
            "{'loss': 0.0159, 'grad_norm': 0.03567984700202942, 'learning_rate': 0.0008049510022000364, 'epoch': 0.94}\n",
            "{'loss': 0.0139, 'grad_norm': 0.019195308908820152, 'learning_rate': 0.0008015198524787601, 'epoch': 0.95}\n",
            "{'loss': 0.0141, 'grad_norm': 0.030609238892793655, 'learning_rate': 0.0007980662427346127, 'epoch': 0.96}\n",
            "{'loss': 0.0144, 'grad_norm': 0.01464232336729765, 'learning_rate': 0.0007945904302247968, 'epoch': 0.97}\n",
            "{'loss': 0.0137, 'grad_norm': 0.01661810092628002, 'learning_rate': 0.0007910926738603854, 'epoch': 0.98}\n",
            "{'loss': 0.0114, 'grad_norm': 0.009907662868499756, 'learning_rate': 0.0007875732341870349, 'epoch': 0.98}\n",
            "{'loss': 0.0149, 'grad_norm': 0.022917989641427994, 'learning_rate': 0.0007840323733655779, 'epoch': 0.99}\n",
            "{'loss': 0.0124, 'grad_norm': 0.021485090255737305, 'learning_rate': 0.0007804703551524948, 'epoch': 1.0}\n",
            "{'loss': 0.0146, 'grad_norm': 0.03792644664645195, 'learning_rate': 0.0007768874448802665, 'epoch': 1.01}\n",
            "{'loss': 0.0165, 'grad_norm': 0.03689463809132576, 'learning_rate': 0.0007732839094376105, 'epoch': 1.02}\n",
            "{'loss': 0.0121, 'grad_norm': 0.03467888385057449, 'learning_rate': 0.0007696600172495997, 'epoch': 1.02}\n",
            "{'loss': 0.0163, 'grad_norm': 0.03128335624933243, 'learning_rate': 0.0007660160382576683, 'epoch': 1.03}\n",
            "{'loss': 0.0172, 'grad_norm': 0.050671301782131195, 'learning_rate': 0.000762352243899504, 'epoch': 1.04}\n",
            "{'loss': 0.011, 'grad_norm': 0.02204018272459507, 'learning_rate': 0.0007586689070888284, 'epoch': 1.05}\n",
            "{'loss': 0.0098, 'grad_norm': 0.07954981923103333, 'learning_rate': 0.000754966302195068, 'epoch': 1.06}\n",
            "{'loss': 0.009, 'grad_norm': 0.01839725859463215, 'learning_rate': 0.0007512447050229165, 'epoch': 1.06}\n",
            "{'loss': 0.013, 'grad_norm': 0.032849084585905075, 'learning_rate': 0.0007475043927917907, 'epoch': 1.07}\n",
            "{'loss': 0.0127, 'grad_norm': 0.04307921975851059, 'learning_rate': 0.00074374564411518, 'epoch': 1.08}\n",
            "{'loss': 0.0115, 'grad_norm': 0.014732934534549713, 'learning_rate': 0.0007399687389798933, 'epoch': 1.09}\n",
            "{'loss': 0.0169, 'grad_norm': 0.07522599399089813, 'learning_rate': 0.0007361739587252019, 'epoch': 1.1}\n",
            "{'loss': 0.0115, 'grad_norm': 0.055412501096725464, 'learning_rate': 0.0007323615860218843, 'epoch': 1.1}\n",
            "{'loss': 0.0148, 'grad_norm': 0.02551860176026821, 'learning_rate': 0.000728531904851169, 'epoch': 1.11}\n",
            "{'loss': 0.0103, 'grad_norm': 0.01651778072118759, 'learning_rate': 0.0007246852004835807, 'epoch': 1.12}\n",
            "{'loss': 0.0081, 'grad_norm': 0.019384505227208138, 'learning_rate': 0.0007208217594576922, 'epoch': 1.13}\n",
            "{'loss': 0.0187, 'grad_norm': 0.044289082288742065, 'learning_rate': 0.0007169418695587791, 'epoch': 1.14}\n",
            "{'loss': 0.014, 'grad_norm': 0.02897968515753746, 'learning_rate': 0.0007130458197973828, 'epoch': 1.14}\n",
            "{'loss': 0.016, 'grad_norm': 0.04910096153616905, 'learning_rate': 0.0007091339003877826, 'epoch': 1.15}\n",
            "{'loss': 0.0152, 'grad_norm': 0.029619714245200157, 'learning_rate': 0.0007052064027263785, 'epoch': 1.16}\n",
            "{'loss': 0.0167, 'grad_norm': 0.0782882496714592, 'learning_rate': 0.0007012636193699837, 'epoch': 1.17}\n",
            "{'loss': 0.0156, 'grad_norm': 0.0407523438334465, 'learning_rate': 0.0006973058440140341, 'epoch': 1.18}\n",
            "{'loss': 0.0099, 'grad_norm': 0.011966499499976635, 'learning_rate': 0.0006933333714707094, 'epoch': 1.18}\n",
            "{'loss': 0.0094, 'grad_norm': 0.012108394876122475, 'learning_rate': 0.0006893464976469738, 'epoch': 1.19}\n",
            "{'loss': 0.0166, 'grad_norm': 0.03309682384133339, 'learning_rate': 0.0006853455195225339, 'epoch': 1.2}\n",
            "{'loss': 0.0113, 'grad_norm': 0.01719343103468418, 'learning_rate': 0.000681330735127716, 'epoch': 1.21}\n",
            "{'loss': 0.0177, 'grad_norm': 0.03526630997657776, 'learning_rate': 0.0006773024435212678, 'epoch': 1.22}\n",
            "{'loss': 0.0205, 'grad_norm': 0.057506218552589417, 'learning_rate': 0.00067326094476808, 'epoch': 1.22}\n",
            "{'loss': 0.0141, 'grad_norm': 0.022691937163472176, 'learning_rate': 0.0006692065399168352, 'epoch': 1.23}\n",
            "{'loss': 0.0133, 'grad_norm': 0.017102288082242012, 'learning_rate': 0.0006651395309775837, 'epoch': 1.24}\n",
            "{'loss': 0.0152, 'grad_norm': 0.04148780554533005, 'learning_rate': 0.0006610602208992453, 'epoch': 1.25}\n",
            "{'loss': 0.0119, 'grad_norm': 0.019464993849396706, 'learning_rate': 0.000656968913547045, 'epoch': 1.26}\n",
            "{'loss': 0.0135, 'grad_norm': 0.051149096339941025, 'learning_rate': 0.0006528659136798764, 'epoch': 1.26}\n",
            "{'loss': 0.008, 'grad_norm': 0.00908732134848833, 'learning_rate': 0.0006487515269276015, 'epoch': 1.27}\n",
            "{'loss': 0.0165, 'grad_norm': 0.03267256170511246, 'learning_rate': 0.0006446260597682839, 'epoch': 1.28}\n",
            "{'loss': 0.0094, 'grad_norm': 0.013052084483206272, 'learning_rate': 0.0006404898195053597, 'epoch': 1.29}\n",
            "{'loss': 0.0102, 'grad_norm': 0.015608134679496288, 'learning_rate': 0.0006363431142447468, 'epoch': 1.3}\n",
            "{'loss': 0.0109, 'grad_norm': 0.03178655356168747, 'learning_rate': 0.0006321862528718945, 'epoch': 1.3}\n",
            "{'loss': 0.0175, 'grad_norm': 0.03932661563158035, 'learning_rate': 0.0006280195450287736, 'epoch': 1.31}\n",
            "{'loss': 0.0131, 'grad_norm': 0.013623747043311596, 'learning_rate': 0.000623843301090813, 'epoch': 1.32}\n",
            "{'loss': 0.0091, 'grad_norm': 0.014384203590452671, 'learning_rate': 0.0006196578321437789, 'epoch': 1.33}\n",
            "{'loss': 0.0143, 'grad_norm': 0.027206098660826683, 'learning_rate': 0.0006154634499606029, 'epoch': 1.34}\n",
            "{'loss': 0.0093, 'grad_norm': 0.011910717934370041, 'learning_rate': 0.0006112604669781572, 'epoch': 1.34}\n",
            "{'loss': 0.0179, 'grad_norm': 0.03616945445537567, 'learning_rate': 0.000607049196273983, 'epoch': 1.35}\n",
            "{'loss': 0.0119, 'grad_norm': 0.013508234173059464, 'learning_rate': 0.0006028299515429683, 'epoch': 1.36}\n",
            "{'loss': 0.014, 'grad_norm': 0.023634690791368484, 'learning_rate': 0.0005986030470739811, 'epoch': 1.37}\n",
            "{'loss': 0.0145, 'grad_norm': 0.013429820537567139, 'learning_rate': 0.0005943687977264583, 'epoch': 1.38}\n",
            "{'loss': 0.0131, 'grad_norm': 0.014089771546423435, 'learning_rate': 0.000590127518906953, 'epoch': 1.38}\n",
            "{'loss': 0.0161, 'grad_norm': 0.017755471169948578, 'learning_rate': 0.0005858795265456381, 'epoch': 1.39}\n",
            "{'loss': 0.0103, 'grad_norm': 0.024089129641652107, 'learning_rate': 0.0005816251370727748, 'epoch': 1.4}\n",
            "{'loss': 0.0122, 'grad_norm': 0.01890135183930397, 'learning_rate': 0.0005773646673951406, 'epoch': 1.41}\n",
            "{'loss': 0.0115, 'grad_norm': 0.015664584934711456, 'learning_rate': 0.0005730984348724242, 'epoch': 1.42}\n",
            "{'loss': 0.0164, 'grad_norm': 0.014619440771639347, 'learning_rate': 0.0005688267572935842, 'epoch': 1.42}\n",
            "{'loss': 0.0143, 'grad_norm': 0.012476296164095402, 'learning_rate': 0.0005645499528531784, 'epoch': 1.43}\n",
            "{'loss': 0.0119, 'grad_norm': 0.01068723201751709, 'learning_rate': 0.0005602683401276614, 'epoch': 1.44}\n",
            "{'loss': 0.0108, 'grad_norm': 0.011480978690087795, 'learning_rate': 0.0005559822380516539, 'epoch': 1.45}\n",
            "{'loss': 0.0127, 'grad_norm': 0.010685811750590801, 'learning_rate': 0.000551691965894185, 'epoch': 1.46}\n",
            "{'loss': 0.012, 'grad_norm': 0.01137862354516983, 'learning_rate': 0.0005473978432349112, 'epoch': 1.46}\n",
            "{'loss': 0.0143, 'grad_norm': 0.012062162160873413, 'learning_rate': 0.0005431001899403097, 'epoch': 1.47}\n",
            "{'loss': 0.0108, 'grad_norm': 0.011534936726093292, 'learning_rate': 0.0005387993261398532, 'epoch': 1.48}\n",
            "{'loss': 0.0142, 'grad_norm': 0.01894747093319893, 'learning_rate': 0.0005344955722021623, 'epoch': 1.49}\n",
            "{'loss': 0.0138, 'grad_norm': 0.022980807349085808, 'learning_rate': 0.0005301892487111431, 'epoch': 1.5}\n",
            "{'loss': 0.0108, 'grad_norm': 0.012907637283205986, 'learning_rate': 0.0005258806764421047, 'epoch': 1.5}\n",
            "{'loss': 0.0117, 'grad_norm': 0.04018515720963478, 'learning_rate': 0.0005215701763378673, 'epoch': 1.51}\n",
            "{'loss': 0.0115, 'grad_norm': 0.03226698189973831, 'learning_rate': 0.0005172580694848541, 'epoch': 1.52}\n",
            "{'loss': 0.0139, 'grad_norm': 0.01520086545497179, 'learning_rate': 0.0005129446770891738, 'epoch': 1.53}\n",
            "{'loss': 0.0112, 'grad_norm': 0.011873316019773483, 'learning_rate': 0.0005086303204526943, 'epoch': 1.54}\n",
            "{'loss': 0.0101, 'grad_norm': 0.010602686554193497, 'learning_rate': 0.0005043153209491095, 'epoch': 1.54}\n",
            "{'loss': 0.0102, 'grad_norm': 0.011365261860191822, 'learning_rate': 0.0005, 'epoch': 1.55}\n",
            "{'loss': 0.012, 'grad_norm': 0.013865967281162739, 'learning_rate': 0.0004956846790508906, 'epoch': 1.56}\n",
            "{'loss': 0.0086, 'grad_norm': 0.012932364828884602, 'learning_rate': 0.0004913696795473058, 'epoch': 1.57}\n",
            "{'loss': 0.0136, 'grad_norm': 0.014560949057340622, 'learning_rate': 0.0004870553229108264, 'epoch': 1.58}\n",
            "{'loss': 0.0129, 'grad_norm': 0.018347611650824547, 'learning_rate': 0.0004827419305151461, 'epoch': 1.58}\n",
            "{'loss': 0.0092, 'grad_norm': 0.022049907594919205, 'learning_rate': 0.00047842982366213274, 'epoch': 1.59}\n",
            "{'loss': 0.0112, 'grad_norm': 0.01522993016988039, 'learning_rate': 0.0004741193235578952, 'epoch': 1.6}\n",
            "{'loss': 0.0127, 'grad_norm': 0.01470254547894001, 'learning_rate': 0.0004698107512888569, 'epoch': 1.61}\n",
            "{'loss': 0.0132, 'grad_norm': 0.011893099173903465, 'learning_rate': 0.0004655044277978375, 'epoch': 1.62}\n",
            "{'loss': 0.0087, 'grad_norm': 0.012085292488336563, 'learning_rate': 0.0004612006738601469, 'epoch': 1.62}\n",
            "{'loss': 0.0108, 'grad_norm': 0.029374154284596443, 'learning_rate': 0.00045689981005969026, 'epoch': 1.63}\n",
            "{'loss': 0.0118, 'grad_norm': 0.019859014078974724, 'learning_rate': 0.00045260215676508895, 'epoch': 1.64}\n",
            "{'loss': 0.0107, 'grad_norm': 0.01507850643247366, 'learning_rate': 0.000448308034105815, 'epoch': 1.65}\n",
            "{'loss': 0.0098, 'grad_norm': 0.012140030972659588, 'learning_rate': 0.0004440177619483461, 'epoch': 1.66}\n",
            "{'loss': 0.0078, 'grad_norm': 0.011207640171051025, 'learning_rate': 0.00043973165987233853, 'epoch': 1.66}\n",
            "{'loss': 0.0147, 'grad_norm': 0.0207273717969656, 'learning_rate': 0.0004354500471468217, 'epoch': 1.67}\n",
            "{'loss': 0.013, 'grad_norm': 0.01969391293823719, 'learning_rate': 0.00043117324270641603, 'epoch': 1.68}\n",
            "{'loss': 0.0131, 'grad_norm': 0.01316528208553791, 'learning_rate': 0.00042690156512757607, 'epoch': 1.69}\n",
            "{'loss': 0.0119, 'grad_norm': 0.01513092964887619, 'learning_rate': 0.0004226353326048593, 'epoch': 1.7}\n",
            "{'loss': 0.0156, 'grad_norm': 0.017340978607535362, 'learning_rate': 0.00041837486292722534, 'epoch': 1.7}\n",
            "{'loss': 0.0097, 'grad_norm': 0.007719944231212139, 'learning_rate': 0.00041412047345436195, 'epoch': 1.71}\n",
            "{'loss': 0.012, 'grad_norm': 0.013245697133243084, 'learning_rate': 0.00040987248109304716, 'epoch': 1.72}\n",
            "{'loss': 0.011, 'grad_norm': 0.01330483052879572, 'learning_rate': 0.0004056312022735417, 'epoch': 1.73}\n",
            "{'loss': 0.0097, 'grad_norm': 0.009633572772145271, 'learning_rate': 0.000401396952926019, 'epoch': 1.74}\n",
            "{'loss': 0.0142, 'grad_norm': 0.016445737332105637, 'learning_rate': 0.00039717004845703176, 'epoch': 1.74}\n",
            "{'loss': 0.0117, 'grad_norm': 0.01036906335502863, 'learning_rate': 0.000392950803726017, 'epoch': 1.75}\n",
            "{'loss': 0.0117, 'grad_norm': 0.010842684656381607, 'learning_rate': 0.00038873953302184284, 'epoch': 1.76}\n",
            "{'loss': 0.0103, 'grad_norm': 0.0098766153678298, 'learning_rate': 0.0003845365500393974, 'epoch': 1.77}\n",
            "{'loss': 0.0144, 'grad_norm': 0.012150737456977367, 'learning_rate': 0.00038034216785622126, 'epoch': 1.78}\n",
            "{'loss': 0.0083, 'grad_norm': 0.010824503377079964, 'learning_rate': 0.00037615669890918703, 'epoch': 1.78}\n",
            "{'loss': 0.0088, 'grad_norm': 0.00791722722351551, 'learning_rate': 0.00037198045497122644, 'epoch': 1.79}\n",
            "{'loss': 0.0125, 'grad_norm': 0.016139419749379158, 'learning_rate': 0.00036781374712810557, 'epoch': 1.8}\n",
            "{'loss': 0.0109, 'grad_norm': 0.009806118905544281, 'learning_rate': 0.0003636568857552531, 'epoch': 1.81}\n",
            "{'loss': 0.0117, 'grad_norm': 0.008589234203100204, 'learning_rate': 0.0003595101804946404, 'epoch': 1.82}\n",
            "{'loss': 0.0096, 'grad_norm': 0.011056412011384964, 'learning_rate': 0.0003553739402317162, 'epoch': 1.82}\n",
            "{'loss': 0.0127, 'grad_norm': 0.010911748744547367, 'learning_rate': 0.0003512484730723986, 'epoch': 1.83}\n",
            "{'loss': 0.0109, 'grad_norm': 0.016745537519454956, 'learning_rate': 0.00034713408632012366, 'epoch': 1.84}\n",
            "{'loss': 0.0098, 'grad_norm': 0.008527836762368679, 'learning_rate': 0.00034303108645295497, 'epoch': 1.85}\n",
            "{'loss': 0.0114, 'grad_norm': 0.007684612181037664, 'learning_rate': 0.0003389397791007548, 'epoch': 1.86}\n",
            "{'loss': 0.0116, 'grad_norm': 0.010469106025993824, 'learning_rate': 0.00033486046902241664, 'epoch': 1.86}\n",
            "{'loss': 0.0101, 'grad_norm': 0.013023046776652336, 'learning_rate': 0.0003307934600831648, 'epoch': 1.87}\n",
            "{'loss': 0.0097, 'grad_norm': 0.007639162242412567, 'learning_rate': 0.00032673905523192, 'epoch': 1.88}\n",
            "{'loss': 0.0119, 'grad_norm': 0.014438525773584843, 'learning_rate': 0.00032269755647873217, 'epoch': 1.89}\n",
            "{'loss': 0.008, 'grad_norm': 0.00787378754466772, 'learning_rate': 0.000318669264872284, 'epoch': 1.9}\n",
            "{'loss': 0.0085, 'grad_norm': 0.013741936534643173, 'learning_rate': 0.00031465448047746623, 'epoch': 1.9}\n",
            "{'loss': 0.0161, 'grad_norm': 0.01725217141211033, 'learning_rate': 0.0003106535023530262, 'epoch': 1.91}\n",
            "{'loss': 0.0105, 'grad_norm': 0.009583871811628342, 'learning_rate': 0.0003066666285292906, 'epoch': 1.92}\n",
            "{'loss': 0.0109, 'grad_norm': 0.011323106475174427, 'learning_rate': 0.000302694155985966, 'epoch': 1.93}\n",
            "{'loss': 0.009, 'grad_norm': 0.008949266746640205, 'learning_rate': 0.0002987363806300163, 'epoch': 1.94}\n",
            "{'loss': 0.0089, 'grad_norm': 0.012236031703650951, 'learning_rate': 0.0002947935972736217, 'epoch': 1.94}\n",
            "{'loss': 0.0084, 'grad_norm': 0.010186822153627872, 'learning_rate': 0.00029086609961221754, 'epoch': 1.95}\n",
            "{'loss': 0.0138, 'grad_norm': 0.015217011794447899, 'learning_rate': 0.00028695418020261755, 'epoch': 1.96}\n",
            "{'loss': 0.0085, 'grad_norm': 0.01132962666451931, 'learning_rate': 0.00028305813044122096, 'epoch': 1.97}\n",
            "{'loss': 0.0107, 'grad_norm': 0.012540102005004883, 'learning_rate': 0.00027917824054230785, 'epoch': 1.98}\n",
            "{'loss': 0.0066, 'grad_norm': 0.007831020280718803, 'learning_rate': 0.00027531479951641924, 'epoch': 1.98}\n",
            "{'loss': 0.0139, 'grad_norm': 0.017180509865283966, 'learning_rate': 0.0002714680951488312, 'epoch': 1.99}\n",
            "{'loss': 0.0118, 'grad_norm': 0.013230234384536743, 'learning_rate': 0.00026763841397811573, 'epoch': 2.0}\n",
            "{'loss': 0.0102, 'grad_norm': 0.01082710362970829, 'learning_rate': 0.00026382604127479813, 'epoch': 2.01}\n",
            "{'loss': 0.0093, 'grad_norm': 0.010493297129869461, 'learning_rate': 0.00026003126102010693, 'epoch': 2.02}\n",
            "{'loss': 0.01, 'grad_norm': 0.009152105078101158, 'learning_rate': 0.0002562543558848202, 'epoch': 2.02}\n",
            "{'loss': 0.0123, 'grad_norm': 0.015084727667272091, 'learning_rate': 0.0002524956072082093, 'epoch': 2.03}\n",
            "{'loss': 0.0124, 'grad_norm': 0.012490514665842056, 'learning_rate': 0.00024875529497708353, 'epoch': 2.04}\n",
            "{'loss': 0.0103, 'grad_norm': 0.01385331992059946, 'learning_rate': 0.0002450336978049322, 'epoch': 2.05}\n",
            "{'loss': 0.0107, 'grad_norm': 0.016799908131361008, 'learning_rate': 0.00024133109291117155, 'epoch': 2.06}\n",
            "{'loss': 0.0114, 'grad_norm': 0.012506106868386269, 'learning_rate': 0.000237647756100496, 'epoch': 2.06}\n",
            "{'loss': 0.0093, 'grad_norm': 0.010141629725694656, 'learning_rate': 0.00023398396174233177, 'epoch': 2.07}\n",
            "{'loss': 0.0082, 'grad_norm': 0.008484195917844772, 'learning_rate': 0.00023033998275040046, 'epoch': 2.08}\n",
            "{'loss': 0.0095, 'grad_norm': 0.01056758500635624, 'learning_rate': 0.0002267160905623895, 'epoch': 2.09}\n",
            "{'loss': 0.0085, 'grad_norm': 0.00902846734970808, 'learning_rate': 0.00022311255511973344, 'epoch': 2.1}\n",
            "{'loss': 0.0098, 'grad_norm': 0.012360557913780212, 'learning_rate': 0.00021952964484750527, 'epoch': 2.1}\n",
            "{'loss': 0.0074, 'grad_norm': 0.008235083892941475, 'learning_rate': 0.00021596762663442215, 'epoch': 2.11}\n",
            "{'loss': 0.0141, 'grad_norm': 0.0545743964612484, 'learning_rate': 0.00021242676581296528, 'epoch': 2.12}\n",
            "{'loss': 0.0119, 'grad_norm': 0.014041741378605366, 'learning_rate': 0.00020890732613961478, 'epoch': 2.13}\n",
            "{'loss': 0.0074, 'grad_norm': 0.007484931964427233, 'learning_rate': 0.00020540956977520319, 'epoch': 2.14}\n",
            "{'loss': 0.0095, 'grad_norm': 0.01260009128600359, 'learning_rate': 0.00020193375726538737, 'epoch': 2.14}\n",
            "{'loss': 0.0079, 'grad_norm': 0.010385832749307156, 'learning_rate': 0.00019848014752123978, 'epoch': 2.15}\n",
            "{'loss': 0.0079, 'grad_norm': 0.008803357370197773, 'learning_rate': 0.00019504899779996355, 'epoch': 2.16}\n",
            "{'loss': 0.009, 'grad_norm': 0.009183736518025398, 'learning_rate': 0.00019164056368572847, 'epoch': 2.17}\n",
            "{'loss': 0.0074, 'grad_norm': 0.007276434917002916, 'learning_rate': 0.00018825509907063325, 'epoch': 2.18}\n",
            "{'loss': 0.0121, 'grad_norm': 0.013514379039406776, 'learning_rate': 0.00018489285613579326, 'epoch': 2.18}\n",
            "{'loss': 0.0095, 'grad_norm': 0.01554864551872015, 'learning_rate': 0.0001815540853325555, 'epoch': 2.19}\n",
            "{'loss': 0.0104, 'grad_norm': 0.014682936482131481, 'learning_rate': 0.00017823903536384262, 'epoch': 2.2}\n",
            "{'loss': 0.009, 'grad_norm': 0.008547846227884293, 'learning_rate': 0.0001749479531656279, 'epoch': 2.21}\n",
            "{'loss': 0.0089, 'grad_norm': 0.012435095384716988, 'learning_rate': 0.00017168108388853997, 'epoch': 2.22}\n",
            "{'loss': 0.0089, 'grad_norm': 0.009411850944161415, 'learning_rate': 0.00016843867087960252, 'epoch': 2.22}\n",
            "{'loss': 0.0076, 'grad_norm': 0.009152903221547604, 'learning_rate': 0.00016522095566410728, 'epoch': 2.23}\n",
            "{'loss': 0.0092, 'grad_norm': 0.013501310721039772, 'learning_rate': 0.00016202817792762282, 'epoch': 2.24}\n",
            "{'loss': 0.0117, 'grad_norm': 0.01154536847025156, 'learning_rate': 0.0001588605754981413, 'epoch': 2.25}\n",
            "{'loss': 0.0075, 'grad_norm': 0.010552243329584599, 'learning_rate': 0.00015571838432836137, 'epoch': 2.26}\n",
            "{'loss': 0.0091, 'grad_norm': 0.025007067248225212, 'learning_rate': 0.00015260183847811383, 'epoch': 2.26}\n",
            "{'loss': 0.0106, 'grad_norm': 0.0145094720646739, 'learning_rate': 0.00014951117009692527, 'epoch': 2.27}\n",
            "{'loss': 0.0086, 'grad_norm': 0.013829533942043781, 'learning_rate': 0.00014644660940672628, 'epoch': 2.28}\n",
            "{'loss': 0.0137, 'grad_norm': 0.02142864465713501, 'learning_rate': 0.00014340838468470196, 'epoch': 2.29}\n",
            "{'loss': 0.0079, 'grad_norm': 0.014178234152495861, 'learning_rate': 0.00014039672224628786, 'epoch': 2.3}\n",
            "{'loss': 0.0107, 'grad_norm': 0.01515472587198019, 'learning_rate': 0.0001374118464283119, 'epoch': 2.3}\n",
            "{'loss': 0.0076, 'grad_norm': 0.009043112397193909, 'learning_rate': 0.0001344539795722834, 'epoch': 2.31}\n",
            "{'loss': 0.0106, 'grad_norm': 0.012356569059193134, 'learning_rate': 0.00013152334200783168, 'epoch': 2.32}\n",
            "{'loss': 0.0129, 'grad_norm': 0.020832404494285583, 'learning_rate': 0.00012862015203629273, 'epoch': 2.33}\n",
            "{'loss': 0.0108, 'grad_norm': 0.013534492813050747, 'learning_rate': 0.0001257446259144494, 'epoch': 2.34}\n",
            "{'loss': 0.0117, 'grad_norm': 0.01788148283958435, 'learning_rate': 0.0001228969778384214, 'epoch': 2.34}\n",
            "{'loss': 0.0104, 'grad_norm': 0.013515124097466469, 'learning_rate': 0.00012007741992771066, 'epoch': 2.35}\n",
            "{'loss': 0.013, 'grad_norm': 0.014293551445007324, 'learning_rate': 0.0001172861622094003, 'epoch': 2.36}\n",
            "{'loss': 0.0075, 'grad_norm': 0.008024413138628006, 'learning_rate': 0.0001145234126025102, 'epoch': 2.37}\n",
            "{'loss': 0.0112, 'grad_norm': 0.01254114881157875, 'learning_rate': 0.00011178937690250917, 'epoch': 2.38}\n",
            "{'loss': 0.0096, 'grad_norm': 0.011141538619995117, 'learning_rate': 0.0001090842587659851, 'epoch': 2.38}\n",
            "{'loss': 0.0093, 'grad_norm': 0.008996696211397648, 'learning_rate': 0.00010640825969547497, 'epoch': 2.39}\n",
            "{'loss': 0.0101, 'grad_norm': 0.009918567724525928, 'learning_rate': 0.00010376157902445487, 'epoch': 2.4}\n",
            "{'loss': 0.0089, 'grad_norm': 0.009868239983916283, 'learning_rate': 0.00010114441390249201, 'epoch': 2.41}\n",
            "{'loss': 0.0104, 'grad_norm': 0.01236904226243496, 'learning_rate': 9.85569592805588e-05, 'epoch': 2.42}\n",
            "{'loss': 0.0127, 'grad_norm': 0.013751651160418987, 'learning_rate': 9.599940789651179e-05, 'epoch': 2.42}\n",
            "{'loss': 0.0074, 'grad_norm': 0.011166069656610489, 'learning_rate': 9.347195026073368e-05, 'epoch': 2.43}\n",
            "{'loss': 0.0103, 'grad_norm': 0.011781320907175541, 'learning_rate': 9.09747746419436e-05, 'epoch': 2.44}\n",
            "{'loss': 0.0097, 'grad_norm': 0.013478335924446583, 'learning_rate': 8.850806705317183e-05, 'epoch': 2.45}\n",
            "{'loss': 0.0093, 'grad_norm': 0.009204564616084099, 'learning_rate': 8.60720112379046e-05, 'epoch': 2.46}\n",
            "{'loss': 0.0115, 'grad_norm': 0.012939156033098698, 'learning_rate': 8.366678865639687e-05, 'epoch': 2.46}\n",
            "{'loss': 0.0083, 'grad_norm': 0.009808773174881935, 'learning_rate': 8.129257847215571e-05, 'epoch': 2.47}\n",
            "{'loss': 0.0098, 'grad_norm': 0.011274430900812149, 'learning_rate': 7.894955753859412e-05, 'epoch': 2.48}\n",
            "{'loss': 0.0082, 'grad_norm': 0.011190631426870823, 'learning_rate': 7.663790038585794e-05, 'epoch': 2.49}\n",
            "{'loss': 0.0095, 'grad_norm': 0.013396278023719788, 'learning_rate': 7.435777920782444e-05, 'epoch': 2.5}\n",
            "{'loss': 0.0114, 'grad_norm': 0.03857959806919098, 'learning_rate': 7.21093638492763e-05, 'epoch': 2.5}\n",
            "{'loss': 0.0103, 'grad_norm': 0.013882748782634735, 'learning_rate': 6.989282179324962e-05, 'epoch': 2.51}\n",
            "{'loss': 0.0093, 'grad_norm': 0.010016524232923985, 'learning_rate': 6.770831814855882e-05, 'epoch': 2.52}\n",
            "{'loss': 0.0101, 'grad_norm': 0.011056074872612953, 'learning_rate': 6.555601563749674e-05, 'epoch': 2.53}\n",
            "{'loss': 0.0105, 'grad_norm': 0.01238744705915451, 'learning_rate': 6.343607458371459e-05, 'epoch': 2.54}\n",
            "{'loss': 0.0125, 'grad_norm': 0.013816622085869312, 'learning_rate': 6.134865290027902e-05, 'epoch': 2.54}\n",
            "{'loss': 0.0102, 'grad_norm': 0.01029503345489502, 'learning_rate': 5.92939060779093e-05, 'epoch': 2.55}\n",
            "{'loss': 0.0087, 'grad_norm': 0.013803721405565739, 'learning_rate': 5.72719871733951e-05, 'epoch': 2.56}\n",
            "{'loss': 0.0095, 'grad_norm': 0.009218833409249783, 'learning_rate': 5.5283046798195126e-05, 'epoch': 2.57}\n",
            "{'loss': 0.0096, 'grad_norm': 0.012236044742166996, 'learning_rate': 5.3327233107218545e-05, 'epoch': 2.58}\n",
            "{'loss': 0.0113, 'grad_norm': 0.015915347263216972, 'learning_rate': 5.140469178778845e-05, 'epoch': 2.58}\n",
            "{'loss': 0.0091, 'grad_norm': 0.009892423637211323, 'learning_rate': 4.9515566048790485e-05, 'epoch': 2.59}\n",
            "{'loss': 0.0122, 'grad_norm': 0.01808064989745617, 'learning_rate': 4.765999661000442e-05, 'epoch': 2.6}\n",
            "{'loss': 0.0086, 'grad_norm': 0.009771723300218582, 'learning_rate': 4.583812169162299e-05, 'epoch': 2.61}\n",
            "{'loss': 0.01, 'grad_norm': 0.011783968657255173, 'learning_rate': 4.405007700395497e-05, 'epoch': 2.62}\n",
            "{'loss': 0.0079, 'grad_norm': 0.011260823346674442, 'learning_rate': 4.2295995737316854e-05, 'epoch': 2.62}\n",
            "{'loss': 0.0088, 'grad_norm': 0.011176679283380508, 'learning_rate': 4.057600855211141e-05, 'epoch': 2.63}\n",
            "{'loss': 0.0084, 'grad_norm': 0.011842180974781513, 'learning_rate': 3.8890243569094874e-05, 'epoch': 2.64}\n",
            "{'loss': 0.0085, 'grad_norm': 0.01376926340162754, 'learning_rate': 3.7238826359833275e-05, 'epoch': 2.65}\n",
            "{'loss': 0.0072, 'grad_norm': 0.009811736643314362, 'learning_rate': 3.562187993734883e-05, 'epoch': 2.66}\n",
            "{'loss': 0.0085, 'grad_norm': 0.010088931769132614, 'learning_rate': 3.40395247469566e-05, 'epoch': 2.66}\n",
            "{'loss': 0.0084, 'grad_norm': 0.01036896463483572, 'learning_rate': 3.249187865729264e-05, 'epoch': 2.67}\n",
            "{'loss': 0.0103, 'grad_norm': 0.01306021399796009, 'learning_rate': 3.097905695153408e-05, 'epoch': 2.68}\n",
            "{'loss': 0.0077, 'grad_norm': 0.011454255320131779, 'learning_rate': 2.9501172318811832e-05, 'epoch': 2.69}\n",
            "{'loss': 0.0116, 'grad_norm': 0.012966266833245754, 'learning_rate': 2.8058334845816213e-05, 'epoch': 2.7}\n",
            "{'loss': 0.0068, 'grad_norm': 0.008191855624318123, 'learning_rate': 2.6650652008597063e-05, 'epoch': 2.7}\n",
            "{'loss': 0.008, 'grad_norm': 0.008665075525641441, 'learning_rate': 2.527822866455731e-05, 'epoch': 2.71}\n",
            "{'loss': 0.0101, 'grad_norm': 0.010646614246070385, 'learning_rate': 2.3941167044642943e-05, 'epoch': 2.72}\n",
            "{'loss': 0.0089, 'grad_norm': 0.008927341550588608, 'learning_rate': 2.2639566745727203e-05, 'epoch': 2.73}\n",
            "{'loss': 0.009, 'grad_norm': 0.010015270672738552, 'learning_rate': 2.137352472319215e-05, 'epoch': 2.74}\n",
            "{'loss': 0.0094, 'grad_norm': 0.008906004950404167, 'learning_rate': 2.0143135283706258e-05, 'epoch': 2.74}\n",
            "{'loss': 0.0112, 'grad_norm': 0.014181743375957012, 'learning_rate': 1.8948490078199765e-05, 'epoch': 2.75}\n",
            "{'loss': 0.0097, 'grad_norm': 0.010791151784360409, 'learning_rate': 1.7789678095037452e-05, 'epoch': 2.76}\n",
            "{'loss': 0.0095, 'grad_norm': 0.008831379935145378, 'learning_rate': 1.6666785653390248e-05, 'epoch': 2.77}\n",
            "{'loss': 0.0097, 'grad_norm': 0.01055032666772604, 'learning_rate': 1.557989639680496e-05, 'epoch': 2.78}\n",
            "{'loss': 0.0103, 'grad_norm': 0.011708667501807213, 'learning_rate': 1.4529091286973995e-05, 'epoch': 2.78}\n",
            "{'loss': 0.0102, 'grad_norm': 0.01608484610915184, 'learning_rate': 1.351444859770462e-05, 'epoch': 2.79}\n",
            "{'loss': 0.009, 'grad_norm': 0.010492446832358837, 'learning_rate': 1.2536043909088191e-05, 'epoch': 2.8}\n",
            "{'loss': 0.009, 'grad_norm': 0.00966991763561964, 'learning_rate': 1.159395010187042e-05, 'epoch': 2.81}\n",
            "{'loss': 0.0072, 'grad_norm': 0.009630144573748112, 'learning_rate': 1.0688237352022346e-05, 'epoch': 2.82}\n",
            "{'loss': 0.0088, 'grad_norm': 0.011049605906009674, 'learning_rate': 9.818973125513276e-06, 'epoch': 2.82}\n",
            "{'loss': 0.0093, 'grad_norm': 0.009881281293928623, 'learning_rate': 8.986222173284874e-06, 'epoch': 2.83}\n",
            "{'loss': 0.0077, 'grad_norm': 0.012242704629898071, 'learning_rate': 8.190046526428241e-06, 'epoch': 2.84}\n",
            "{'loss': 0.011, 'grad_norm': 0.013819975778460503, 'learning_rate': 7.4305054915631e-06, 'epoch': 2.85}\n",
            "{'loss': 0.008, 'grad_norm': 0.008598856627941132, 'learning_rate': 6.7076556464202296e-06, 'epoch': 2.86}\n",
            "{'loss': 0.0083, 'grad_norm': 0.009445811621844769, 'learning_rate': 6.021550835626777e-06, 'epoch': 2.86}\n",
            "{'loss': 0.0101, 'grad_norm': 0.013926884159445763, 'learning_rate': 5.372242166695684e-06, 'epoch': 2.87}\n",
            "{'loss': 0.0073, 'grad_norm': 0.0076430486515164375, 'learning_rate': 4.759778006218407e-06, 'epoch': 2.88}\n",
            "{'loss': 0.0103, 'grad_norm': 0.013948303647339344, 'learning_rate': 4.184203976262513e-06, 'epoch': 2.89}\n",
            "{'loss': 0.007, 'grad_norm': 0.00920045468956232, 'learning_rate': 3.645562950973014e-06, 'epoch': 2.9}\n",
            "{'loss': 0.0077, 'grad_norm': 0.009386301971971989, 'learning_rate': 3.143895053378698e-06, 'epoch': 2.9}\n",
            "{'loss': 0.0096, 'grad_norm': 0.00977471936494112, 'learning_rate': 2.6792376524036878e-06, 'epoch': 2.91}\n",
            "{'loss': 0.0128, 'grad_norm': 0.01508726179599762, 'learning_rate': 2.251625360083387e-06, 'epoch': 2.92}\n",
            "{'loss': 0.0083, 'grad_norm': 0.009649976156651974, 'learning_rate': 1.8610900289867672e-06, 'epoch': 2.93}\n",
            "{'loss': 0.0086, 'grad_norm': 0.009437119588255882, 'learning_rate': 1.5076607498433204e-06, 'epoch': 2.94}\n",
            "{'loss': 0.0105, 'grad_norm': 0.013278740458190441, 'learning_rate': 1.1913638493762368e-06, 'epoch': 2.94}\n",
            "{'loss': 0.0081, 'grad_norm': 0.009278221055865288, 'learning_rate': 9.12222888341252e-07, 'epoch': 2.95}\n",
            "{'loss': 0.01, 'grad_norm': 0.011908997781574726, 'learning_rate': 6.702586597719384e-07, 'epoch': 2.96}\n",
            "{'loss': 0.0069, 'grad_norm': 0.00875764712691307, 'learning_rate': 4.6548918743033465e-07, 'epoch': 2.97}\n",
            "{'loss': 0.0095, 'grad_norm': 0.01159925851970911, 'learning_rate': 2.9792972446479607e-07, 'epoch': 2.98}\n",
            "{'loss': 0.0077, 'grad_norm': 0.008232842199504375, 'learning_rate': 1.6759275227357095e-07, 'epoch': 2.98}\n",
            "{'loss': 0.0068, 'grad_norm': 0.009662839584052563, 'learning_rate': 7.448797957526621e-08, 'epoch': 2.99}\n",
            "{'loss': 0.0072, 'grad_norm': 0.008619796484708786, 'learning_rate': 1.862234168542587e-08, 'epoch': 3.0}\n",
            "{'train_runtime': 68.0448, 'train_samples_per_second': 11.022, 'train_steps_per_second': 5.511, 'train_loss': 0.08919029743969441, 'epoch': 3.0}\n",
            "100% 375/375 [01:08<00:00,  5.51it/s]\n",
            "Training complete.\n",
            "Model saved to loras/self-edit/training_set_iteration_1/8d5021e8/3\n",
            "Training on 200 examples for 3 epochs, lr: 0.01\n",
            "No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n",
            "Starting training...\n",
            "{'loss': 6.3894, 'grad_norm': 6.897727966308594, 'learning_rate': 0.0, 'epoch': 0.01}\n",
            "{'loss': 7.3193, 'grad_norm': 8.249114990234375, 'learning_rate': 0.0009090909090909091, 'epoch': 0.02}\n",
            "{'loss': 1.9354, 'grad_norm': 7.193881034851074, 'learning_rate': 0.0018181818181818182, 'epoch': 0.03}\n",
            "{'loss': 4.307, 'grad_norm': 13.709684371948242, 'learning_rate': 0.002727272727272727, 'epoch': 0.04}\n",
            "{'loss': 1.6549, 'grad_norm': 1.9906024932861328, 'learning_rate': 0.0036363636363636364, 'epoch': 0.05}\n",
            "{'loss': 2.9835, 'grad_norm': 10.449861526489258, 'learning_rate': 0.004545454545454545, 'epoch': 0.06}\n",
            "{'loss': 1.1369, 'grad_norm': 1.1939876079559326, 'learning_rate': 0.005454545454545454, 'epoch': 0.07}\n",
            "{'loss': 0.9016, 'grad_norm': 0.8352376818656921, 'learning_rate': 0.006363636363636364, 'epoch': 0.08}\n",
            "{'loss': 1.4491, 'grad_norm': 2.7313995361328125, 'learning_rate': 0.007272727272727273, 'epoch': 0.09}\n",
            "{'loss': 1.9527, 'grad_norm': 2.75235652923584, 'learning_rate': 0.008181818181818182, 'epoch': 0.1}\n",
            "{'loss': 4.7397, 'grad_norm': 19.280715942382812, 'learning_rate': 0.00909090909090909, 'epoch': 0.11}\n",
            "{'loss': 7.1772, 'grad_norm': 157.40464782714844, 'learning_rate': 0.01, 'epoch': 0.12}\n",
            "{'loss': 8.9929, 'grad_norm': 25.279186248779297, 'learning_rate': 0.009999704580069347, 'epoch': 0.13}\n",
            "{'loss': 13.2716, 'grad_norm': 15.700900077819824, 'learning_rate': 0.009998818355186559, 'epoch': 0.14}\n",
            "{'loss': 9.5602, 'grad_norm': 7.228950500488281, 'learning_rate': 0.009997341430075036, 'epoch': 0.15}\n",
            "{'loss': 7.3973, 'grad_norm': 4.286048889160156, 'learning_rate': 0.009995273979260023, 'epoch': 0.16}\n",
            "{'loss': 4.9589, 'grad_norm': 2.8097116947174072, 'learning_rate': 0.009992616247047989, 'epoch': 0.17}\n",
            "{'loss': 6.6143, 'grad_norm': 1.9483989477157593, 'learning_rate': 0.009989368547497763, 'epoch': 0.18}\n",
            "{'loss': 5.8158, 'grad_norm': 17.681467056274414, 'learning_rate': 0.009985531264383412, 'epoch': 0.19}\n",
            "{'loss': 10.6256, 'grad_norm': 7.805730819702148, 'learning_rate': 0.009981104851148904, 'epoch': 0.2}\n",
            "{'loss': 5.7318, 'grad_norm': 21.243408203125, 'learning_rate': 0.009976089830854514, 'epoch': 0.21}\n",
            "{'loss': 10.337, 'grad_norm': 8.075250625610352, 'learning_rate': 0.00997048679611502, 'epoch': 0.22}\n",
            "{'loss': 5.6793, 'grad_norm': 1.7177845239639282, 'learning_rate': 0.009964296409029676, 'epoch': 0.23}\n",
            "{'loss': 5.2355, 'grad_norm': 1.5359164476394653, 'learning_rate': 0.009957519401103971, 'epoch': 0.24}\n",
            "{'loss': 7.3998, 'grad_norm': 3.778501510620117, 'learning_rate': 0.009950156573163192, 'epoch': 0.25}\n",
            "{'loss': 6.226, 'grad_norm': 94.33245086669922, 'learning_rate': 0.009942208795257786, 'epoch': 0.26}\n",
            "{'loss': 6.3048, 'grad_norm': 2.9497172832489014, 'learning_rate': 0.009933677006560549, 'epoch': 0.27}\n",
            "{'loss': 3.5186, 'grad_norm': 6.034068584442139, 'learning_rate': 0.009924562215255655, 'epoch': 0.28}\n",
            "{'loss': 3.5342, 'grad_norm': 0.9873142242431641, 'learning_rate': 0.009914865498419509, 'epoch': 0.29}\n",
            "{'loss': 4.8883, 'grad_norm': 3.2513372898101807, 'learning_rate': 0.009904588001893476, 'epoch': 0.3}\n",
            "{'loss': 3.4181, 'grad_norm': 1.8942664861679077, 'learning_rate': 0.009893730940148482, 'epoch': 0.31}\n",
            "{'loss': 4.955, 'grad_norm': 1.5658499002456665, 'learning_rate': 0.009882295596141497, 'epoch': 0.32}\n",
            "{'loss': 2.4055, 'grad_norm': 0.6362298727035522, 'learning_rate': 0.009870283321163933, 'epoch': 0.33}\n",
            "{'loss': 3.982, 'grad_norm': 1.911805510520935, 'learning_rate': 0.00985769553468197, 'epoch': 0.34}\n",
            "{'loss': 2.6127, 'grad_norm': 0.7016500234603882, 'learning_rate': 0.009844533724168809, 'epoch': 0.35}\n",
            "{'loss': 3.1138, 'grad_norm': 1.4148566722869873, 'learning_rate': 0.00983079944492891, 'epoch': 0.36}\n",
            "{'loss': 3.1965, 'grad_norm': 0.9632812142372131, 'learning_rate': 0.009816494319914203, 'epoch': 0.37}\n",
            "{'loss': 2.7888, 'grad_norm': 0.591769278049469, 'learning_rate': 0.009801620039532302, 'epoch': 0.38}\n",
            "{'loss': 2.7803, 'grad_norm': 0.4097205400466919, 'learning_rate': 0.00978617836144676, 'epoch': 0.39}\n",
            "{'loss': 2.6838, 'grad_norm': 1.6564687490463257, 'learning_rate': 0.009770171110369362, 'epoch': 0.4}\n",
            "{'loss': 2.3277, 'grad_norm': 9.526281356811523, 'learning_rate': 0.009753600177844513, 'epoch': 0.41}\n",
            "{'loss': 3.2596, 'grad_norm': 0.9489327073097229, 'learning_rate': 0.009736467522025704, 'epoch': 0.42}\n",
            "{'loss': 3.9045, 'grad_norm': 1.0725038051605225, 'learning_rate': 0.009718775167444139, 'epoch': 0.43}\n",
            "{'loss': 2.5939, 'grad_norm': 0.6985507607460022, 'learning_rate': 0.009700525204769475, 'epoch': 0.44}\n",
            "{'loss': 3.0761, 'grad_norm': 0.6607099771499634, 'learning_rate': 0.009681719790562801, 'epoch': 0.45}\n",
            "{'loss': 2.5366, 'grad_norm': 0.7325736284255981, 'learning_rate': 0.009662361147021778, 'epoch': 0.46}\n",
            "{'loss': 2.8272, 'grad_norm': 0.48159417510032654, 'learning_rate': 0.009642451561718062, 'epoch': 0.47}\n",
            "{'loss': 1.8706, 'grad_norm': 0.37825676798820496, 'learning_rate': 0.009621993387326977, 'epoch': 0.48}\n",
            "{'loss': 1.8064, 'grad_norm': 0.84010910987854, 'learning_rate': 0.009600989041349504, 'epoch': 0.49}\n",
            "{'loss': 2.5461, 'grad_norm': 0.45625627040863037, 'learning_rate': 0.009579441005826616, 'epoch': 0.5}\n",
            "{'loss': 2.8489, 'grad_norm': 0.8312674164772034, 'learning_rate': 0.00955735182704598, 'epoch': 0.51}\n",
            "{'loss': 1.8744, 'grad_norm': 0.2561495900154114, 'learning_rate': 0.00953472411524106, 'epoch': 0.52}\n",
            "{'loss': 1.6351, 'grad_norm': 0.23891083896160126, 'learning_rate': 0.009511560544282675, 'epoch': 0.53}\n",
            "{'loss': 1.8774, 'grad_norm': 0.30334773659706116, 'learning_rate': 0.009487863851363038, 'epoch': 0.54}\n",
            "{'loss': 2.5782, 'grad_norm': 0.2863510251045227, 'learning_rate': 0.009463636836672298, 'epoch': 0.55}\n",
            "{'loss': 2.0313, 'grad_norm': 0.4386358857154846, 'learning_rate': 0.00943888236306766, 'epoch': 0.56}\n",
            "{'loss': 1.7594, 'grad_norm': 6.3410210609436035, 'learning_rate': 0.00941360335573507, 'epoch': 0.57}\n",
            "{'loss': 1.8798, 'grad_norm': 0.3300406038761139, 'learning_rate': 0.009387802801843563, 'epoch': 0.58}\n",
            "{'loss': 1.4743, 'grad_norm': 0.20193281769752502, 'learning_rate': 0.009361483750192282, 'epoch': 0.59}\n",
            "{'loss': 1.6003, 'grad_norm': 0.2855215072631836, 'learning_rate': 0.009334649310850188, 'epoch': 0.6}\n",
            "{'loss': 1.5544, 'grad_norm': 0.2845306098461151, 'learning_rate': 0.009307302654788567, 'epoch': 0.61}\n",
            "{'loss': 1.9451, 'grad_norm': 0.6761665344238281, 'learning_rate': 0.009279447013506312, 'epoch': 0.62}\n",
            "{'loss': 1.479, 'grad_norm': 0.2191120684146881, 'learning_rate': 0.009251085678648071, 'epoch': 0.63}\n",
            "{'loss': 1.3597, 'grad_norm': 0.18141677975654602, 'learning_rate': 0.009222222001615274, 'epoch': 0.64}\n",
            "{'loss': 1.6488, 'grad_norm': 0.17231784760951996, 'learning_rate': 0.009192859393170107, 'epoch': 0.65}\n",
            "{'loss': 1.8109, 'grad_norm': 0.18903310596942902, 'learning_rate': 0.009163001323032475, 'epoch': 0.66}\n",
            "{'loss': 1.6348, 'grad_norm': 0.15788830816745758, 'learning_rate': 0.009132651319469975, 'epoch': 0.67}\n",
            "{'loss': 1.3998, 'grad_norm': 0.2892548739910126, 'learning_rate': 0.00910181296888099, 'epoch': 0.68}\n",
            "{'loss': 1.677, 'grad_norm': 0.1288394033908844, 'learning_rate': 0.009070489915370876, 'epoch': 0.69}\n",
            "{'loss': 1.7826, 'grad_norm': 0.16293567419052124, 'learning_rate': 0.009038685860321354, 'epoch': 0.7}\n",
            "{'loss': 1.3713, 'grad_norm': 0.1254333257675171, 'learning_rate': 0.009006404561953115, 'epoch': 0.71}\n",
            "{'loss': 1.5122, 'grad_norm': 0.10458951443433762, 'learning_rate': 0.00897364983488173, 'epoch': 0.72}\n",
            "{'loss': 1.253, 'grad_norm': 0.10807032883167267, 'learning_rate': 0.008940425549666882, 'epoch': 0.73}\n",
            "{'loss': 1.2655, 'grad_norm': 0.10081721842288971, 'learning_rate': 0.008906735632354978, 'epoch': 0.74}\n",
            "{'loss': 2.1448, 'grad_norm': 0.4663280248641968, 'learning_rate': 0.00887258406401524, 'epoch': 0.75}\n",
            "{'loss': 1.4669, 'grad_norm': 0.14132553339004517, 'learning_rate': 0.008837974880269247, 'epoch': 0.76}\n",
            "{'loss': 1.4351, 'grad_norm': 0.23658029735088348, 'learning_rate': 0.008802912170814059, 'epoch': 0.77}\n",
            "{'loss': 1.1679, 'grad_norm': 0.1838248372077942, 'learning_rate': 0.00876740007893896, 'epoch': 0.78}\n",
            "{'loss': 1.3917, 'grad_norm': 0.10927725583314896, 'learning_rate': 0.008731442801035832, 'epoch': 0.79}\n",
            "{'loss': 1.6658, 'grad_norm': 0.29798632860183716, 'learning_rate': 0.008695044586103295, 'epoch': 0.8}\n",
            "{'loss': 1.2322, 'grad_norm': 0.8460581302642822, 'learning_rate': 0.008658209735244605, 'epoch': 0.81}\n",
            "{'loss': 1.302, 'grad_norm': 0.12880411744117737, 'learning_rate': 0.008620942601159394, 'epoch': 0.82}\n",
            "{'loss': 1.2527, 'grad_norm': 0.1234525516629219, 'learning_rate': 0.008583247587629326, 'epoch': 0.83}\n",
            "{'loss': 1.3125, 'grad_norm': 0.1269562989473343, 'learning_rate': 0.008545129148997719, 'epoch': 0.84}\n",
            "{'loss': 1.6368, 'grad_norm': 0.15350307524204254, 'learning_rate': 0.00850659178964317, 'epoch': 0.85}\n",
            "{'loss': 1.0652, 'grad_norm': 0.11323898285627365, 'learning_rate': 0.008467640063447288, 'epoch': 0.86}\n",
            "{'loss': 1.2629, 'grad_norm': 0.18520300090312958, 'learning_rate': 0.008428278573256578, 'epoch': 0.87}\n",
            "{'loss': 1.1991, 'grad_norm': 0.09103719890117645, 'learning_rate': 0.008388511970338517, 'epoch': 0.88}\n",
            "{'loss': 1.1385, 'grad_norm': 9.452598571777344, 'learning_rate': 0.00834834495383194, 'epoch': 0.89}\n",
            "{'loss': 1.428, 'grad_norm': 0.20907777547836304, 'learning_rate': 0.008307782270191733, 'epoch': 0.9}\n",
            "{'loss': 1.327, 'grad_norm': 0.1467590034008026, 'learning_rate': 0.008266828712627976, 'epoch': 0.91}\n",
            "{'loss': 1.0825, 'grad_norm': 0.09886863827705383, 'learning_rate': 0.008225489120539522, 'epoch': 0.92}\n",
            "{'loss': 1.5515, 'grad_norm': 10.428705215454102, 'learning_rate': 0.008183768378942143, 'epoch': 0.93}\n",
            "{'loss': 1.3733, 'grad_norm': 0.2674986720085144, 'learning_rate': 0.008141671417891275, 'epoch': 0.94}\n",
            "{'loss': 1.9251, 'grad_norm': 0.4405261278152466, 'learning_rate': 0.00809920321189944, 'epoch': 0.95}\n",
            "{'loss': 2.0094, 'grad_norm': 0.3080374002456665, 'learning_rate': 0.00805636877934843, 'epoch': 0.96}\n",
            "{'loss': 1.3971, 'grad_norm': 0.22851800918579102, 'learning_rate': 0.008013173181896283, 'epoch': 0.97}\n",
            "{'loss': 1.6024, 'grad_norm': 0.2364828735589981, 'learning_rate': 0.007969621523879155, 'epoch': 0.98}\n",
            "{'loss': 1.7925, 'grad_norm': 0.25854697823524475, 'learning_rate': 0.007925718951708169, 'epoch': 0.99}\n",
            "{'loss': 1.5692, 'grad_norm': 3.905332326889038, 'learning_rate': 0.00788147065326125, 'epoch': 1.0}\n",
            "{'loss': 1.6278, 'grad_norm': 0.23878929018974304, 'learning_rate': 0.007836881857270106, 'epoch': 1.01}\n",
            "{'loss': 1.3167, 'grad_norm': 0.21122466027736664, 'learning_rate': 0.007791957832702343, 'epoch': 1.02}\n",
            "{'loss': 1.5387, 'grad_norm': 0.25456702709198, 'learning_rate': 0.007746703888138849, 'epoch': 1.03}\n",
            "{'loss': 1.6418, 'grad_norm': 0.22729597985744476, 'learning_rate': 0.007701125371146492, 'epoch': 1.04}\n",
            "{'loss': 1.2735, 'grad_norm': 0.13351313769817352, 'learning_rate': 0.007655227667646201, 'epoch': 1.05}\n",
            "{'loss': 1.4369, 'grad_norm': 0.14747564494609833, 'learning_rate': 0.007609016201276533, 'epoch': 1.06}\n",
            "{'loss': 1.3199, 'grad_norm': 0.15640763938426971, 'learning_rate': 0.007562496432752761, 'epoch': 1.07}\n",
            "{'loss': 1.2476, 'grad_norm': 0.1569264680147171, 'learning_rate': 0.007515673859221606, 'epoch': 1.08}\n",
            "{'loss': 1.3079, 'grad_norm': 7.658690452575684, 'learning_rate': 0.007468554013611632, 'epoch': 1.09}\n",
            "{'loss': 1.0521, 'grad_norm': 0.10038682818412781, 'learning_rate': 0.007421142463979453, 'epoch': 1.1}\n",
            "{'loss': 1.0577, 'grad_norm': 33.74722671508789, 'learning_rate': 0.007373444812851751, 'epoch': 1.11}\n",
            "{'loss': 1.3595, 'grad_norm': 0.2664811909198761, 'learning_rate': 0.007325466696563238, 'epoch': 1.12}\n",
            "{'loss': 0.9855, 'grad_norm': 0.07817899435758591, 'learning_rate': 0.00727721378459063, 'epoch': 1.13}\n",
            "{'loss': 1.054, 'grad_norm': 0.19143469631671906, 'learning_rate': 0.0072286917788826925, 'epoch': 1.14}\n",
            "{'loss': 1.1551, 'grad_norm': 0.2589007616043091, 'learning_rate': 0.007179906413186447, 'epoch': 1.15}\n",
            "{'loss': 1.0396, 'grad_norm': 0.12373417615890503, 'learning_rate': 0.007130863452369636, 'epoch': 1.16}\n",
            "{'loss': 1.1228, 'grad_norm': 0.2601383626461029, 'learning_rate': 0.007081568691739492, 'epoch': 1.17}\n",
            "{'loss': 1.021, 'grad_norm': 0.08816822618246078, 'learning_rate': 0.007032027956357922, 'epoch': 1.18}\n",
            "{'loss': 1.2938, 'grad_norm': 0.2221890240907669, 'learning_rate': 0.0069822471003531715, 'epoch': 1.19}\n",
            "{'loss': 1.1527, 'grad_norm': 0.42728954553604126, 'learning_rate': 0.006932232006228051, 'epoch': 1.2}\n",
            "{'loss': 1.3797, 'grad_norm': 0.2199316918849945, 'learning_rate': 0.006881988584164816, 'epoch': 1.21}\n",
            "{'loss': 0.9642, 'grad_norm': 0.10665077716112137, 'learning_rate': 0.006831522771326769, 'epoch': 1.22}\n",
            "{'loss': 1.1333, 'grad_norm': 0.13776785135269165, 'learning_rate': 0.006780840531156684, 'epoch': 1.23}\n",
            "{'loss': 1.2387, 'grad_norm': 0.16288647055625916, 'learning_rate': 0.0067299478526721135, 'epoch': 1.24}\n",
            "{'loss': 1.5022, 'grad_norm': 0.19151724874973297, 'learning_rate': 0.006678850749757673, 'epoch': 1.25}\n",
            "{'loss': 1.0657, 'grad_norm': 14.863166809082031, 'learning_rate': 0.006627555260454403, 'epoch': 1.26}\n",
            "{'loss': 0.9439, 'grad_norm': 0.2799872159957886, 'learning_rate': 0.006576067446246262, 'epoch': 1.27}\n",
            "{'loss': 1.3028, 'grad_norm': 0.14316047728061676, 'learning_rate': 0.006524393391343852, 'epoch': 1.28}\n",
            "{'loss': 1.2178, 'grad_norm': 0.1370125263929367, 'learning_rate': 0.006472539201965458, 'epoch': 1.29}\n",
            "{'loss': 1.4045, 'grad_norm': 0.1900361329317093, 'learning_rate': 0.00642051100561549, 'epoch': 1.3}\n",
            "{'loss': 1.1499, 'grad_norm': 0.07733050733804703, 'learning_rate': 0.006368314950360415, 'epoch': 1.31}\n",
            "{'loss': 1.046, 'grad_norm': 0.08510550111532211, 'learning_rate': 0.006315957204102241, 'epoch': 1.32}\n",
            "{'loss': 0.9058, 'grad_norm': 0.07636629045009613, 'learning_rate': 0.006263443953849674, 'epoch': 1.33}\n",
            "{'loss': 0.9532, 'grad_norm': 0.09421149641275406, 'learning_rate': 0.0062107814049870156, 'epoch': 1.34}\n",
            "{'loss': 1.3261, 'grad_norm': 0.261453777551651, 'learning_rate': 0.006157975780540876, 'epoch': 1.35}\n",
            "{'loss': 1.099, 'grad_norm': 0.08056113868951797, 'learning_rate': 0.006105033320444824, 'epoch': 1.36}\n",
            "{'loss': 1.1747, 'grad_norm': 0.1311858892440796, 'learning_rate': 0.006051960280802014, 'epoch': 1.37}\n",
            "{'loss': 1.005, 'grad_norm': 0.13272185623645782, 'learning_rate': 0.00599876293314592, 'epoch': 1.38}\n",
            "{'loss': 1.351, 'grad_norm': 0.21134968101978302, 'learning_rate': 0.005945447563699247, 'epoch': 1.39}\n",
            "{'loss': 1.0827, 'grad_norm': 0.10772795975208282, 'learning_rate': 0.005892020472631092, 'epoch': 1.4}\n",
            "{'loss': 1.2429, 'grad_norm': 0.1795605719089508, 'learning_rate': 0.005838487973312472, 'epoch': 1.41}\n",
            "{'loss': 1.0588, 'grad_norm': 0.18792995810508728, 'learning_rate': 0.005784856391570279, 'epoch': 1.42}\n",
            "{'loss': 1.1302, 'grad_norm': 0.1747765690088272, 'learning_rate': 0.0057311320649397765, 'epoch': 1.43}\n",
            "{'loss': 0.8925, 'grad_norm': 0.1259765625, 'learning_rate': 0.005677321341915707, 'epoch': 1.44}\n",
            "{'loss': 1.2423, 'grad_norm': 0.1852744221687317, 'learning_rate': 0.005623430581202091, 'epoch': 1.45}\n",
            "{'loss': 1.266, 'grad_norm': 0.17128992080688477, 'learning_rate': 0.005569466150960851, 'epoch': 1.46}\n",
            "{'loss': 1.1165, 'grad_norm': 0.12330900877714157, 'learning_rate': 0.0055154344280592795, 'epoch': 1.47}\n",
            "{'loss': 1.2892, 'grad_norm': 0.11707994341850281, 'learning_rate': 0.00546134179731651, 'epoch': 1.48}\n",
            "{'loss': 0.9424, 'grad_norm': 0.13291208446025848, 'learning_rate': 0.005407194650749033, 'epoch': 1.49}\n",
            "{'loss': 1.021, 'grad_norm': 0.12224071472883224, 'learning_rate': 0.005352999386815361, 'epoch': 1.5}\n",
            "{'loss': 0.9691, 'grad_norm': 0.09826409816741943, 'learning_rate': 0.00529876240965994, 'epoch': 1.51}\n",
            "{'loss': 1.0185, 'grad_norm': 0.11212631314992905, 'learning_rate': 0.00524449012835638, 'epoch': 1.52}\n",
            "{'loss': 0.9845, 'grad_norm': 0.12425516545772552, 'learning_rate': 0.005190188956150115, 'epoch': 1.53}\n",
            "{'loss': 1.1935, 'grad_norm': 0.07816995680332184, 'learning_rate': 0.005135865309700556, 'epoch': 1.54}\n",
            "{'loss': 0.8257, 'grad_norm': 0.0386597216129303, 'learning_rate': 0.005081525608322847, 'epoch': 1.55}\n",
            "{'loss': 1.2073, 'grad_norm': 0.07992309331893921, 'learning_rate': 0.005027176273229317, 'epoch': 1.56}\n",
            "{'loss': 1.2271, 'grad_norm': 0.09715446829795837, 'learning_rate': 0.004972823726770685, 'epoch': 1.57}\n",
            "{'loss': 1.0493, 'grad_norm': 0.10376717895269394, 'learning_rate': 0.004918474391677154, 'epoch': 1.58}\n",
            "{'loss': 1.3551, 'grad_norm': 0.11822694540023804, 'learning_rate': 0.004864134690299445, 'epoch': 1.59}\n",
            "{'loss': 1.2109, 'grad_norm': 0.1260610669851303, 'learning_rate': 0.004809811043849887, 'epoch': 1.6}\n",
            "{'loss': 0.9095, 'grad_norm': 0.0657036155462265, 'learning_rate': 0.004755509871643621, 'epoch': 1.61}\n",
            "{'loss': 1.0608, 'grad_norm': 0.29116490483283997, 'learning_rate': 0.004701237590340063, 'epoch': 1.62}\n",
            "{'loss': 0.9353, 'grad_norm': 0.07452772557735443, 'learning_rate': 0.00464700061318464, 'epoch': 1.63}\n",
            "{'loss': 1.0337, 'grad_norm': 0.07530437409877777, 'learning_rate': 0.004592805349250969, 'epoch': 1.64}\n",
            "{'loss': 1.0688, 'grad_norm': 0.07310722768306732, 'learning_rate': 0.004538658202683491, 'epoch': 1.65}\n",
            "{'loss': 1.0682, 'grad_norm': 0.12859228253364563, 'learning_rate': 0.004484565571940722, 'epoch': 1.66}\n",
            "{'loss': 0.9861, 'grad_norm': 0.08454214036464691, 'learning_rate': 0.00443053384903915, 'epoch': 1.67}\n",
            "{'loss': 1.0047, 'grad_norm': 0.06408929824829102, 'learning_rate': 0.004376569418797908, 'epoch': 1.68}\n",
            "{'loss': 0.8589, 'grad_norm': 0.057398825883865356, 'learning_rate': 0.0043226786580842945, 'epoch': 1.69}\n",
            "{'loss': 1.0158, 'grad_norm': 0.07872488349676132, 'learning_rate': 0.004268867935060223, 'epoch': 1.7}\n",
            "{'loss': 1.2901, 'grad_norm': 0.17863157391548157, 'learning_rate': 0.004215143608429722, 'epoch': 1.71}\n",
            "{'loss': 1.0471, 'grad_norm': 0.13743813335895538, 'learning_rate': 0.004161512026687528, 'epoch': 1.72}\n",
            "{'loss': 1.4976, 'grad_norm': 0.23391559720039368, 'learning_rate': 0.004107979527368908, 'epoch': 1.73}\n",
            "{'loss': 1.0895, 'grad_norm': 0.09130120277404785, 'learning_rate': 0.004054552436300752, 'epoch': 1.74}\n",
            "{'loss': 0.9563, 'grad_norm': 0.15599317848682404, 'learning_rate': 0.004001237066854081, 'epoch': 1.75}\n",
            "{'loss': 1.0978, 'grad_norm': 0.3237520456314087, 'learning_rate': 0.003948039719197987, 'epoch': 1.76}\n",
            "{'loss': 0.9961, 'grad_norm': 0.09184721112251282, 'learning_rate': 0.003894966679555177, 'epoch': 1.77}\n",
            "{'loss': 1.179, 'grad_norm': 0.16019640862941742, 'learning_rate': 0.003842024219459124, 'epoch': 1.78}\n",
            "{'loss': 0.8738, 'grad_norm': 0.10954497754573822, 'learning_rate': 0.003789218595012986, 'epoch': 1.79}\n",
            "{'loss': 1.2136, 'grad_norm': 0.14702600240707397, 'learning_rate': 0.003736556046150327, 'epoch': 1.8}\n",
            "{'loss': 0.8086, 'grad_norm': 0.09307091683149338, 'learning_rate': 0.0036840427958977607, 'epoch': 1.81}\n",
            "{'loss': 0.8944, 'grad_norm': 0.07133820652961731, 'learning_rate': 0.003631685049639586, 'epoch': 1.82}\n",
            "{'loss': 0.9439, 'grad_norm': 0.10853350162506104, 'learning_rate': 0.0035794889943845114, 'epoch': 1.83}\n",
            "{'loss': 0.9483, 'grad_norm': 0.09333247691392899, 'learning_rate': 0.003527460798034543, 'epoch': 1.84}\n",
            "{'loss': 1.1059, 'grad_norm': 0.14071817696094513, 'learning_rate': 0.00347560660865615, 'epoch': 1.85}\n",
            "{'loss': 0.9362, 'grad_norm': 0.06797351688146591, 'learning_rate': 0.0034239325537537384, 'epoch': 1.86}\n",
            "{'loss': 0.9637, 'grad_norm': 0.12331589311361313, 'learning_rate': 0.003372444739545598, 'epoch': 1.87}\n",
            "{'loss': 0.7933, 'grad_norm': 0.0745975449681282, 'learning_rate': 0.0033211492502423284, 'epoch': 1.88}\n",
            "{'loss': 0.8148, 'grad_norm': 0.06573597341775894, 'learning_rate': 0.003270052147327889, 'epoch': 1.89}\n",
            "{'loss': 1.0312, 'grad_norm': 0.06652531027793884, 'learning_rate': 0.003219159468843316, 'epoch': 1.9}\n",
            "{'loss': 0.8585, 'grad_norm': 0.05398453772068024, 'learning_rate': 0.0031684772286732312, 'epoch': 1.91}\n",
            "{'loss': 1.0312, 'grad_norm': 0.10613816976547241, 'learning_rate': 0.0031180114158351857, 'epoch': 1.92}\n",
            "{'loss': 0.9346, 'grad_norm': 0.09138397127389908, 'learning_rate': 0.003067767993771949, 'epoch': 1.93}\n",
            "{'loss': 0.8651, 'grad_norm': 0.06561680138111115, 'learning_rate': 0.0030177528996468282, 'epoch': 1.94}\n",
            "{'loss': 1.15, 'grad_norm': 0.1376708596944809, 'learning_rate': 0.002967972043642077, 'epoch': 1.95}\n",
            "{'loss': 0.8086, 'grad_norm': 0.05049335956573486, 'learning_rate': 0.002918431308260508, 'epoch': 1.96}\n",
            "{'loss': 0.9523, 'grad_norm': 0.06783708184957504, 'learning_rate': 0.002869136547630364, 'epoch': 1.97}\n",
            "{'loss': 0.7955, 'grad_norm': 0.08399708569049835, 'learning_rate': 0.002820093586813555, 'epoch': 1.98}\n",
            "{'loss': 0.7755, 'grad_norm': 0.11173756420612335, 'learning_rate': 0.002771308221117309, 'epoch': 1.99}\n",
            "{'loss': 1.0404, 'grad_norm': 0.0942869484424591, 'learning_rate': 0.002722786215409372, 'epoch': 2.0}\n",
            "{'loss': 0.8351, 'grad_norm': 0.04843432083725929, 'learning_rate': 0.0026745333034367625, 'epoch': 2.01}\n",
            "{'loss': 0.8614, 'grad_norm': 0.07887914031744003, 'learning_rate': 0.0026265551871482505, 'epoch': 2.02}\n",
            "{'loss': 1.182, 'grad_norm': 0.1550879031419754, 'learning_rate': 0.002578857536020547, 'epoch': 2.03}\n",
            "{'loss': 0.8954, 'grad_norm': 0.10017593204975128, 'learning_rate': 0.002531445986388369, 'epoch': 2.04}\n",
            "{'loss': 0.8012, 'grad_norm': 0.05937770754098892, 'learning_rate': 0.002484326140778397, 'epoch': 2.05}\n",
            "{'loss': 0.9561, 'grad_norm': 0.09336364269256592, 'learning_rate': 0.0024375035672472393, 'epoch': 2.06}\n",
            "{'loss': 1.2087, 'grad_norm': 0.16442051529884338, 'learning_rate': 0.0023909837987234677, 'epoch': 2.07}\n",
            "{'loss': 1.058, 'grad_norm': 0.08147144317626953, 'learning_rate': 0.0023447723323538, 'epoch': 2.08}\n",
            "{'loss': 0.8867, 'grad_norm': 0.12128003686666489, 'learning_rate': 0.0022988746288535094, 'epoch': 2.09}\n",
            "{'loss': 0.8521, 'grad_norm': 0.07909131795167923, 'learning_rate': 0.002253296111861153, 'epoch': 2.1}\n",
            "{'loss': 0.8436, 'grad_norm': 0.05327773839235306, 'learning_rate': 0.002208042167297657, 'epoch': 2.11}\n",
            "{'loss': 0.9568, 'grad_norm': 0.07580379396677017, 'learning_rate': 0.0021631181427298946, 'epoch': 2.12}\n",
            "{'loss': 0.7499, 'grad_norm': 0.10439877212047577, 'learning_rate': 0.0021185293467387493, 'epoch': 2.13}\n",
            "{'loss': 0.9408, 'grad_norm': 0.06593909114599228, 'learning_rate': 0.0020742810482918313, 'epoch': 2.14}\n",
            "{'loss': 0.9932, 'grad_norm': 0.04989362135529518, 'learning_rate': 0.0020303784761208457, 'epoch': 2.15}\n",
            "{'loss': 0.8501, 'grad_norm': 0.06614594906568527, 'learning_rate': 0.0019868268181037186, 'epoch': 2.16}\n",
            "{'loss': 0.811, 'grad_norm': 0.06901129335165024, 'learning_rate': 0.0019436312206515694, 'epoch': 2.17}\n",
            "{'loss': 1.0798, 'grad_norm': 0.11086488515138626, 'learning_rate': 0.001900796788100559, 'epoch': 2.18}\n",
            "{'loss': 0.8418, 'grad_norm': 0.0470397062599659, 'learning_rate': 0.001858328582108727, 'epoch': 2.19}\n",
            "{'loss': 0.9743, 'grad_norm': 0.07897813618183136, 'learning_rate': 0.0018162316210578572, 'epoch': 2.2}\n",
            "{'loss': 0.8717, 'grad_norm': 0.06000790372490883, 'learning_rate': 0.0017745108794604775, 'epoch': 2.21}\n",
            "{'loss': 0.8889, 'grad_norm': 0.09561100602149963, 'learning_rate': 0.0017331712873720235, 'epoch': 2.22}\n",
            "{'loss': 0.9141, 'grad_norm': 0.08802483975887299, 'learning_rate': 0.001692217729808268, 'epoch': 2.23}\n",
            "{'loss': 0.8679, 'grad_norm': 0.06081667169928551, 'learning_rate': 0.0016516550461680623, 'epoch': 2.24}\n",
            "{'loss': 0.8671, 'grad_norm': 0.17021256685256958, 'learning_rate': 0.0016114880296614843, 'epoch': 2.25}\n",
            "{'loss': 0.9697, 'grad_norm': 0.12852491438388824, 'learning_rate': 0.0015717214267434232, 'epoch': 2.26}\n",
            "{'loss': 0.8595, 'grad_norm': 0.09629558771848679, 'learning_rate': 0.001532359936552712, 'epoch': 2.27}\n",
            "{'loss': 1.1849, 'grad_norm': 0.244807168841362, 'learning_rate': 0.0014934082103568308, 'epoch': 2.28}\n",
            "{'loss': 0.8759, 'grad_norm': 0.1305960863828659, 'learning_rate': 0.0014548708510022823, 'epoch': 2.29}\n",
            "{'loss': 0.7841, 'grad_norm': 0.07311481237411499, 'learning_rate': 0.0014167524123706744, 'epoch': 2.3}\n",
            "{'loss': 0.893, 'grad_norm': 0.0845131054520607, 'learning_rate': 0.0013790573988406074, 'epoch': 2.31}\n",
            "{'loss': 0.9179, 'grad_norm': 0.12198445200920105, 'learning_rate': 0.0013417902647553947, 'epoch': 2.32}\n",
            "{'loss': 1.0813, 'grad_norm': 0.11212367564439774, 'learning_rate': 0.001304955413896705, 'epoch': 2.33}\n",
            "{'loss': 0.8772, 'grad_norm': 0.09500069171190262, 'learning_rate': 0.0012685571989641698, 'epoch': 2.34}\n",
            "{'loss': 1.0286, 'grad_norm': 0.09512768685817719, 'learning_rate': 0.0012325999210610423, 'epoch': 2.35}\n",
            "{'loss': 0.8991, 'grad_norm': 0.1002148762345314, 'learning_rate': 0.0011970878291859422, 'epoch': 2.36}\n",
            "{'loss': 0.872, 'grad_norm': 0.11388973891735077, 'learning_rate': 0.0011620251197307534, 'epoch': 2.37}\n",
            "{'loss': 0.8374, 'grad_norm': 0.11007460951805115, 'learning_rate': 0.0011274159359847592, 'epoch': 2.38}\n",
            "{'loss': 0.9745, 'grad_norm': 0.07878387719392776, 'learning_rate': 0.0010932643676450204, 'epoch': 2.39}\n",
            "{'loss': 0.9029, 'grad_norm': 0.12014215439558029, 'learning_rate': 0.0010595744503331206, 'epoch': 2.4}\n",
            "{'loss': 1.1052, 'grad_norm': 0.08303382247686386, 'learning_rate': 0.0010263501651182705, 'epoch': 2.41}\n",
            "{'loss': 0.8451, 'grad_norm': 0.09340906888246536, 'learning_rate': 0.000993595438046886, 'epoch': 2.42}\n",
            "{'loss': 0.7536, 'grad_norm': 0.09851708263158798, 'learning_rate': 0.0009613141396786463, 'epoch': 2.43}\n",
            "{'loss': 1.0765, 'grad_norm': 0.14927156269550323, 'learning_rate': 0.0009295100846291237, 'epoch': 2.44}\n",
            "{'loss': 0.9741, 'grad_norm': 0.10300790518522263, 'learning_rate': 0.0008981870311190099, 'epoch': 2.45}\n",
            "{'loss': 0.8686, 'grad_norm': 0.07537995278835297, 'learning_rate': 0.0008673486805300262, 'epoch': 2.46}\n",
            "{'loss': 0.8199, 'grad_norm': 0.06917697191238403, 'learning_rate': 0.000836998676967527, 'epoch': 2.47}\n",
            "{'loss': 0.9415, 'grad_norm': 0.0816984698176384, 'learning_rate': 0.0008071406068298926, 'epoch': 2.48}\n",
            "{'loss': 0.9198, 'grad_norm': 0.09057894349098206, 'learning_rate': 0.000777777998384726, 'epoch': 2.49}\n",
            "{'loss': 0.9064, 'grad_norm': 0.10797218233346939, 'learning_rate': 0.00074891432135193, 'epoch': 2.5}\n",
            "{'loss': 1.1471, 'grad_norm': 0.08926952630281448, 'learning_rate': 0.0007205529864936882, 'epoch': 2.51}\n",
            "{'loss': 1.0289, 'grad_norm': 0.07979282736778259, 'learning_rate': 0.0006926973452114338, 'epoch': 2.52}\n",
            "{'loss': 1.1836, 'grad_norm': 0.09987223148345947, 'learning_rate': 0.0006653506891498118, 'epoch': 2.53}\n",
            "{'loss': 1.0435, 'grad_norm': 0.09603255242109299, 'learning_rate': 0.0006385162498077191, 'epoch': 2.54}\n",
            "{'loss': 0.8507, 'grad_norm': 0.054125793278217316, 'learning_rate': 0.0006121971981564367, 'epoch': 2.55}\n",
            "{'loss': 0.8062, 'grad_norm': 0.08233580738306046, 'learning_rate': 0.0005863966442649326, 'epoch': 2.56}\n",
            "{'loss': 0.8478, 'grad_norm': 0.08256354928016663, 'learning_rate': 0.0005611176369323412, 'epoch': 2.57}\n",
            "{'loss': 0.6999, 'grad_norm': 0.07862880825996399, 'learning_rate': 0.0005363631633277005, 'epoch': 2.58}\n",
            "{'loss': 0.9296, 'grad_norm': 0.09420740604400635, 'learning_rate': 0.0005121361486369625, 'epoch': 2.59}\n",
            "{'loss': 0.9326, 'grad_norm': 0.17694634199142456, 'learning_rate': 0.000488439455717325, 'epoch': 2.6}\n",
            "{'loss': 0.7243, 'grad_norm': 0.06766850501298904, 'learning_rate': 0.0004652758847589417, 'epoch': 2.61}\n",
            "{'loss': 0.8277, 'grad_norm': 0.05982106178998947, 'learning_rate': 0.0004426481729540205, 'epoch': 2.62}\n",
            "{'loss': 1.16, 'grad_norm': 0.13001084327697754, 'learning_rate': 0.0004205589941733834, 'epoch': 2.63}\n",
            "{'loss': 0.7656, 'grad_norm': 0.05244317650794983, 'learning_rate': 0.00039901095865049643, 'epoch': 2.64}\n",
            "{'loss': 0.7481, 'grad_norm': 0.05700349062681198, 'learning_rate': 0.00037800661267302414, 'epoch': 2.65}\n",
            "{'loss': 1.1754, 'grad_norm': 0.16908428072929382, 'learning_rate': 0.0003575484382819372, 'epoch': 2.66}\n",
            "{'loss': 1.0918, 'grad_norm': 0.06856804341077805, 'learning_rate': 0.0003376388529782215, 'epoch': 2.67}\n",
            "{'loss': 1.2431, 'grad_norm': 0.15146072208881378, 'learning_rate': 0.0003182802094371989, 'epoch': 2.68}\n",
            "{'loss': 1.092, 'grad_norm': 0.23834222555160522, 'learning_rate': 0.00029947479523052546, 'epoch': 2.69}\n",
            "{'loss': 1.2087, 'grad_norm': 0.09866538643836975, 'learning_rate': 0.0002812248325558625, 'epoch': 2.7}\n",
            "{'loss': 0.9197, 'grad_norm': 0.08040295541286469, 'learning_rate': 0.00026353247797429537, 'epoch': 2.71}\n",
            "{'loss': 1.0732, 'grad_norm': 0.10708166658878326, 'learning_rate': 0.0002463998221554875, 'epoch': 2.72}\n",
            "{'loss': 1.0055, 'grad_norm': 0.08636549860239029, 'learning_rate': 0.00022982888963063775, 'epoch': 2.73}\n",
            "{'loss': 0.9198, 'grad_norm': 0.1319819837808609, 'learning_rate': 0.000213821638553241, 'epoch': 2.74}\n",
            "{'loss': 0.8784, 'grad_norm': 0.10276523232460022, 'learning_rate': 0.00019837996046769834, 'epoch': 2.75}\n",
            "{'loss': 0.8447, 'grad_norm': 0.09938179701566696, 'learning_rate': 0.00018350568008579704, 'epoch': 2.76}\n",
            "{'loss': 0.8878, 'grad_norm': 0.08652705699205399, 'learning_rate': 0.0001692005550710901, 'epoch': 2.77}\n",
            "{'loss': 0.7533, 'grad_norm': 0.0834285169839859, 'learning_rate': 0.0001554662758311909, 'epoch': 2.78}\n",
            "{'loss': 1.0417, 'grad_norm': 0.08219914883375168, 'learning_rate': 0.00014230446531802998, 'epoch': 2.79}\n",
            "{'loss': 0.805, 'grad_norm': 0.10075872391462326, 'learning_rate': 0.00012971667883606653, 'epoch': 2.8}\n",
            "{'loss': 0.8868, 'grad_norm': 0.07779855281114578, 'learning_rate': 0.00011770440385850401, 'epoch': 2.81}\n",
            "{'loss': 0.7476, 'grad_norm': 0.06641772389411926, 'learning_rate': 0.00010626905985151869, 'epoch': 2.82}\n",
            "{'loss': 0.9774, 'grad_norm': 0.11989941447973251, 'learning_rate': 9.54119981065238e-05, 'epoch': 2.83}\n",
            "{'loss': 0.9084, 'grad_norm': 0.126014843583107, 'learning_rate': 8.513450158049108e-05, 'epoch': 2.84}\n",
            "{'loss': 0.8632, 'grad_norm': 0.07037883996963501, 'learning_rate': 7.543778474434438e-05, 'epoch': 2.85}\n",
            "{'loss': 0.7754, 'grad_norm': 0.07934193313121796, 'learning_rate': 6.632299343945103e-05, 'epoch': 2.86}\n",
            "{'loss': 0.9682, 'grad_norm': 0.07657839357852936, 'learning_rate': 5.779120474221522e-05, 'epoch': 2.87}\n",
            "{'loss': 0.747, 'grad_norm': 0.06491274386644363, 'learning_rate': 4.984342683680809e-05, 'epoch': 2.88}\n",
            "{'loss': 1.1189, 'grad_norm': 0.08255255222320557, 'learning_rate': 4.248059889602862e-05, 'epoch': 2.89}\n",
            "{'loss': 0.7159, 'grad_norm': 0.05714718624949455, 'learning_rate': 3.570359097032516e-05, 'epoch': 2.9}\n",
            "{'loss': 0.8874, 'grad_norm': 0.07777907699346542, 'learning_rate': 2.9513203884981577e-05, 'epoch': 2.91}\n",
            "{'loss': 0.7131, 'grad_norm': 0.05418432876467705, 'learning_rate': 2.3910169145487936e-05, 'epoch': 2.92}\n",
            "{'loss': 0.8565, 'grad_norm': 0.0597667396068573, 'learning_rate': 1.889514885109689e-05, 'epoch': 2.93}\n",
            "{'loss': 0.9767, 'grad_norm': 0.09429644048213959, 'learning_rate': 1.4468735616587903e-05, 'epoch': 2.94}\n",
            "{'loss': 0.8168, 'grad_norm': 0.05453229323029518, 'learning_rate': 1.0631452502237737e-05, 'epoch': 2.95}\n",
            "{'loss': 0.9505, 'grad_norm': 0.12199185788631439, 'learning_rate': 7.383752952010991e-06, 'epoch': 2.96}\n",
            "{'loss': 0.8056, 'grad_norm': 0.08642485737800598, 'learning_rate': 4.72602073997741e-06, 'epoch': 2.97}\n",
            "{'loss': 0.7834, 'grad_norm': 0.088529072701931, 'learning_rate': 2.658569924964271e-06, 'epoch': 2.98}\n",
            "{'loss': 0.7291, 'grad_norm': 0.0692191869020462, 'learning_rate': 1.181644813441074e-06, 'epoch': 2.99}\n",
            "{'loss': 0.8073, 'grad_norm': 0.07920201867818832, 'learning_rate': 2.9541993065373976e-07, 'epoch': 3.0}\n",
            "{'train_runtime': 37.9051, 'train_samples_per_second': 15.829, 'train_steps_per_second': 7.914, 'train_loss': 1.692214756011963, 'epoch': 3.0}\n",
            "100% 300/300 [00:37<00:00,  7.91it/s]\n",
            "Training complete.\n",
            "Model saved to loras/self-edit/training_set_iteration_1/8d5021e8/4\n",
            "Training on 72 examples for 3 epochs, lr: 0.01\n",
            "No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n",
            "Starting training...\n",
            "{'loss': 2.8555, 'grad_norm': 2.991123676300049, 'learning_rate': 0.0, 'epoch': 0.03}\n",
            "{'loss': 7.3151, 'grad_norm': 10.516687393188477, 'learning_rate': 0.0009090909090909091, 'epoch': 0.06}\n",
            "{'loss': 2.7002, 'grad_norm': 16.908126831054688, 'learning_rate': 0.0018181818181818182, 'epoch': 0.08}\n",
            "{'loss': 3.979, 'grad_norm': 14.410773277282715, 'learning_rate': 0.002727272727272727, 'epoch': 0.11}\n",
            "{'loss': 0.8707, 'grad_norm': 0.9187971949577332, 'learning_rate': 0.0036363636363636364, 'epoch': 0.14}\n",
            "{'loss': 1.9233, 'grad_norm': 11.232937812805176, 'learning_rate': 0.004545454545454545, 'epoch': 0.17}\n",
            "{'loss': 0.6533, 'grad_norm': 0.6473528742790222, 'learning_rate': 0.005454545454545454, 'epoch': 0.19}\n",
            "{'loss': 0.6135, 'grad_norm': 1.1547633409500122, 'learning_rate': 0.006363636363636364, 'epoch': 0.22}\n",
            "{'loss': 0.8324, 'grad_norm': 3.824866771697998, 'learning_rate': 0.007272727272727273, 'epoch': 0.25}\n",
            "{'loss': 1.507, 'grad_norm': 10.273015022277832, 'learning_rate': 0.008181818181818182, 'epoch': 0.28}\n",
            "{'loss': 3.6068, 'grad_norm': 9.715307235717773, 'learning_rate': 0.00909090909090909, 'epoch': 0.31}\n",
            "{'loss': 8.7464, 'grad_norm': 14.786336898803711, 'learning_rate': 0.01, 'epoch': 0.33}\n",
            "{'loss': 12.683, 'grad_norm': 12.541963577270508, 'learning_rate': 0.009997377845227575, 'epoch': 0.36}\n",
            "{'loss': 11.7619, 'grad_norm': 24.405967712402344, 'learning_rate': 0.009989514131188558, 'epoch': 0.39}\n",
            "{'loss': 14.275, 'grad_norm': 6.215941429138184, 'learning_rate': 0.00997641710583307, 'epoch': 0.42}\n",
            "{'loss': 12.6932, 'grad_norm': 7.499688148498535, 'learning_rate': 0.009958100506132127, 'epoch': 0.44}\n",
            "{'loss': 6.1226, 'grad_norm': 5.689170837402344, 'learning_rate': 0.009934583543669454, 'epoch': 0.47}\n",
            "{'loss': 6.8442, 'grad_norm': 21.621559143066406, 'learning_rate': 0.009905890884491196, 'epoch': 0.5}\n",
            "{'loss': 5.7501, 'grad_norm': 3.6109776496887207, 'learning_rate': 0.009872052623234632, 'epoch': 0.53}\n",
            "{'loss': 8.4814, 'grad_norm': 4.100182056427002, 'learning_rate': 0.009833104251563056, 'epoch': 0.56}\n",
            "{'loss': 4.5985, 'grad_norm': 2.824054002761841, 'learning_rate': 0.009789086620939936, 'epoch': 0.58}\n",
            "{'loss': 5.8285, 'grad_norm': 2.268401622772217, 'learning_rate': 0.009740045899781353, 'epoch': 0.61}\n",
            "{'loss': 4.4801, 'grad_norm': 1.7427538633346558, 'learning_rate': 0.00968603352503172, 'epoch': 0.64}\n",
            "{'loss': 3.8653, 'grad_norm': 1.0865533351898193, 'learning_rate': 0.009627106148213521, 'epoch': 0.67}\n",
            "{'loss': 4.9513, 'grad_norm': 9.336969375610352, 'learning_rate': 0.0095633255760077, 'epoch': 0.69}\n",
            "{'loss': 7.1852, 'grad_norm': 3.2672295570373535, 'learning_rate': 0.009494758705426976, 'epoch': 0.72}\n",
            "{'loss': 6.5694, 'grad_norm': 2.6914188861846924, 'learning_rate': 0.009421477453650118, 'epoch': 0.75}\n",
            "{'loss': 4.5956, 'grad_norm': 2.543518543243408, 'learning_rate': 0.009343558682590757, 'epoch': 0.78}\n",
            "{'loss': 3.51, 'grad_norm': 1.583820104598999, 'learning_rate': 0.009261084118279847, 'epoch': 0.81}\n",
            "{'loss': 4.6016, 'grad_norm': 2.662209987640381, 'learning_rate': 0.009174140265146355, 'epoch': 0.83}\n",
            "{'loss': 3.7316, 'grad_norm': 1.4896817207336426, 'learning_rate': 0.009082818315286054, 'epoch': 0.86}\n",
            "{'loss': 3.3463, 'grad_norm': 3.66904878616333, 'learning_rate': 0.008987214052813604, 'epoch': 0.89}\n",
            "{'loss': 3.6038, 'grad_norm': 1.943809151649475, 'learning_rate': 0.008887427753398248, 'epoch': 0.92}\n",
            "{'loss': 3.8272, 'grad_norm': 1.368039846420288, 'learning_rate': 0.008783564079088476, 'epoch': 0.94}\n",
            "{'loss': 2.1434, 'grad_norm': 1.0588302612304688, 'learning_rate': 0.008675731968536002, 'epoch': 0.97}\n",
            "{'loss': 3.3801, 'grad_norm': 1.3366725444793701, 'learning_rate': 0.008564044522734147, 'epoch': 1.0}\n",
            "{'loss': 1.8913, 'grad_norm': 0.34461739659309387, 'learning_rate': 0.008448618886390521, 'epoch': 1.03}\n",
            "{'loss': 3.2066, 'grad_norm': 1.2253392934799194, 'learning_rate': 0.008329576125058406, 'epoch': 1.06}\n",
            "{'loss': 1.8379, 'grad_norm': 0.4317726492881775, 'learning_rate': 0.0082070410981557, 'epoch': 1.08}\n",
            "{'loss': 2.1067, 'grad_norm': 0.6648250222206116, 'learning_rate': 0.008081142328004637, 'epoch': 1.11}\n",
            "{'loss': 2.1659, 'grad_norm': 0.6635622382164001, 'learning_rate': 0.007952011865029614, 'epoch': 1.14}\n",
            "{'loss': 2.2303, 'grad_norm': 0.29915255308151245, 'learning_rate': 0.007819785149254532, 'epoch': 1.17}\n",
            "{'loss': 2.1346, 'grad_norm': 0.6146628260612488, 'learning_rate': 0.00768460086824492, 'epoch': 1.19}\n",
            "{'loss': 2.0178, 'grad_norm': 0.46265166997909546, 'learning_rate': 0.007546600811643816, 'epoch': 1.22}\n",
            "{'loss': 2.2231, 'grad_norm': 0.4266800284385681, 'learning_rate': 0.007405929722454026, 'epoch': 1.25}\n",
            "{'loss': 1.7503, 'grad_norm': 0.3333660960197449, 'learning_rate': 0.007262735145222695, 'epoch': 1.28}\n",
            "{'loss': 2.0113, 'grad_norm': 0.5052953958511353, 'learning_rate': 0.007117167271287452, 'epoch': 1.31}\n",
            "{'loss': 1.7293, 'grad_norm': 0.2439398467540741, 'learning_rate': 0.006969378781246436, 'epoch': 1.33}\n",
            "{'loss': 1.974, 'grad_norm': 0.20327694714069366, 'learning_rate': 0.006819524684817438, 'epoch': 1.36}\n",
            "{'loss': 1.9225, 'grad_norm': 0.33244431018829346, 'learning_rate': 0.006667762158254104, 'epoch': 1.39}\n",
            "{'loss': 2.0198, 'grad_norm': 0.4511777460575104, 'learning_rate': 0.006514250379489753, 'epoch': 1.42}\n",
            "{'loss': 1.8142, 'grad_norm': 0.24197492003440857, 'learning_rate': 0.006359150361181715, 'epoch': 1.44}\n",
            "{'loss': 1.7505, 'grad_norm': 0.1891191601753235, 'learning_rate': 0.0062026247818312685, 'epoch': 1.47}\n",
            "{'loss': 1.3654, 'grad_norm': 0.18472841382026672, 'learning_rate': 0.006044837815156376, 'epoch': 1.5}\n",
            "{'loss': 1.3918, 'grad_norm': 0.21441484987735748, 'learning_rate': 0.0058859549578961145, 'epoch': 1.53}\n",
            "{'loss': 1.9316, 'grad_norm': 0.44357830286026, 'learning_rate': 0.005726142856227452, 'epoch': 1.56}\n",
            "{'loss': 2.3558, 'grad_norm': 0.3491044044494629, 'learning_rate': 0.005565569130976423, 'epoch': 1.58}\n",
            "{'loss': 1.604, 'grad_norm': 0.1522926390171051, 'learning_rate': 0.005404402201807022, 'epoch': 1.61}\n",
            "{'loss': 1.474, 'grad_norm': 0.2406502068042755, 'learning_rate': 0.005242811110572242, 'epoch': 1.64}\n",
            "{'loss': 1.5266, 'grad_norm': 0.3109172582626343, 'learning_rate': 0.005080965344012508, 'epoch': 1.67}\n",
            "{'loss': 1.729, 'grad_norm': 0.24656184017658234, 'learning_rate': 0.004919034655987493, 'epoch': 1.69}\n",
            "{'loss': 1.6145, 'grad_norm': 0.20981824398040771, 'learning_rate': 0.0047571888894277605, 'epoch': 1.72}\n",
            "{'loss': 1.7345, 'grad_norm': 0.33985599875450134, 'learning_rate': 0.0045955977981929795, 'epoch': 1.75}\n",
            "{'loss': 1.3941, 'grad_norm': 0.17405647039413452, 'learning_rate': 0.004434430869023579, 'epoch': 1.78}\n",
            "{'loss': 1.8571, 'grad_norm': 0.19600141048431396, 'learning_rate': 0.00427385714377255, 'epoch': 1.81}\n",
            "{'loss': 1.5151, 'grad_norm': 0.16164222359657288, 'learning_rate': 0.0041140450421038866, 'epoch': 1.83}\n",
            "{'loss': 1.5968, 'grad_norm': 0.29379186034202576, 'learning_rate': 0.003955162184843625, 'epoch': 1.86}\n",
            "{'loss': 1.4105, 'grad_norm': 0.17956480383872986, 'learning_rate': 0.003797375218168733, 'epoch': 1.89}\n",
            "{'loss': 1.7085, 'grad_norm': 0.21800076961517334, 'learning_rate': 0.0036408496388182854, 'epoch': 1.92}\n",
            "{'loss': 1.4837, 'grad_norm': 0.1129821315407753, 'learning_rate': 0.003485749620510247, 'epoch': 1.94}\n",
            "{'loss': 1.5106, 'grad_norm': 0.13384871184825897, 'learning_rate': 0.0033322378417458983, 'epoch': 1.97}\n",
            "{'loss': 1.4159, 'grad_norm': 0.1454935371875763, 'learning_rate': 0.0031804753151825627, 'epoch': 2.0}\n",
            "{'loss': 1.341, 'grad_norm': 0.11603636294603348, 'learning_rate': 0.0030306212187535654, 'epoch': 2.03}\n",
            "{'loss': 1.5408, 'grad_norm': 0.25446754693984985, 'learning_rate': 0.002882832728712551, 'epoch': 2.06}\n",
            "{'loss': 1.5203, 'grad_norm': 0.19278134405612946, 'learning_rate': 0.002737264854777306, 'epoch': 2.08}\n",
            "{'loss': 1.1928, 'grad_norm': 0.07884330302476883, 'learning_rate': 0.0025940702775459745, 'epoch': 2.11}\n",
            "{'loss': 1.3586, 'grad_norm': 0.10802778601646423, 'learning_rate': 0.0024533991883561868, 'epoch': 2.14}\n",
            "{'loss': 1.5121, 'grad_norm': 0.16952992975711823, 'learning_rate': 0.002315399131755081, 'epoch': 2.17}\n",
            "{'loss': 1.5401, 'grad_norm': 0.18512624502182007, 'learning_rate': 0.0021802148507454673, 'epoch': 2.19}\n",
            "{'loss': 1.3818, 'grad_norm': 0.10882221162319183, 'learning_rate': 0.0020479881349703883, 'epoch': 2.22}\n",
            "{'loss': 1.2206, 'grad_norm': 0.10773769021034241, 'learning_rate': 0.0019188576719953632, 'epoch': 2.25}\n",
            "{'loss': 1.337, 'grad_norm': 0.11410132050514221, 'learning_rate': 0.0017929589018443016, 'epoch': 2.28}\n",
            "{'loss': 1.1845, 'grad_norm': 0.09640669822692871, 'learning_rate': 0.0016704238749415956, 'epoch': 2.31}\n",
            "{'loss': 1.5859, 'grad_norm': 0.1885981559753418, 'learning_rate': 0.0015513811136094785, 'epoch': 2.33}\n",
            "{'loss': 1.8639, 'grad_norm': 0.24626734852790833, 'learning_rate': 0.0014359554772658551, 'epoch': 2.36}\n",
            "{'loss': 1.3765, 'grad_norm': 0.11358286440372467, 'learning_rate': 0.0013242680314639993, 'epoch': 2.39}\n",
            "{'loss': 1.5356, 'grad_norm': 0.11800514161586761, 'learning_rate': 0.0012164359209115233, 'epoch': 2.42}\n",
            "{'loss': 1.7964, 'grad_norm': 0.12943695485591888, 'learning_rate': 0.0011125722466017547, 'epoch': 2.44}\n",
            "{'loss': 1.4841, 'grad_norm': 0.3032072186470032, 'learning_rate': 0.001012785947186397, 'epoch': 2.47}\n",
            "{'loss': 1.8656, 'grad_norm': 0.09668608754873276, 'learning_rate': 0.0009171816847139447, 'epoch': 2.5}\n",
            "{'loss': 1.6198, 'grad_norm': 0.13705793023109436, 'learning_rate': 0.000825859734853645, 'epoch': 2.53}\n",
            "{'loss': 1.8599, 'grad_norm': 0.1411387324333191, 'learning_rate': 0.0007389158817201541, 'epoch': 2.56}\n",
            "{'loss': 1.705, 'grad_norm': 0.12250053137540817, 'learning_rate': 0.0006564413174092443, 'epoch': 2.58}\n",
            "{'loss': 1.5991, 'grad_norm': 0.145987406373024, 'learning_rate': 0.0005785225463498828, 'epoch': 2.61}\n",
            "{'loss': 1.5968, 'grad_norm': 0.1078701913356781, 'learning_rate': 0.0005052412945730239, 'epoch': 2.64}\n",
            "{'loss': 1.4492, 'grad_norm': 0.08529451489448547, 'learning_rate': 0.00043667442399229983, 'epoch': 2.67}\n",
            "{'loss': 1.3155, 'grad_norm': 0.06312344968318939, 'learning_rate': 0.0003728938517864794, 'epoch': 2.69}\n",
            "{'loss': 1.2295, 'grad_norm': 0.05596475303173065, 'learning_rate': 0.0003139664749682825, 'epoch': 2.72}\n",
            "{'loss': 1.8465, 'grad_norm': 0.12470895051956177, 'learning_rate': 0.00025995410021864785, 'epoch': 2.75}\n",
            "{'loss': 2.2007, 'grad_norm': 0.17163893580436707, 'learning_rate': 0.0002109133790600648, 'epoch': 2.78}\n",
            "{'loss': 1.3953, 'grad_norm': 0.09462776780128479, 'learning_rate': 0.00016689574843694433, 'epoch': 2.81}\n",
            "{'loss': 1.615, 'grad_norm': 0.07224937528371811, 'learning_rate': 0.00012794737676536993, 'epoch': 2.83}\n",
            "{'loss': 1.5481, 'grad_norm': 0.11050914227962494, 'learning_rate': 9.410911550880474e-05, 'epoch': 2.86}\n",
            "{'loss': 1.3525, 'grad_norm': 0.07482820004224777, 'learning_rate': 6.54164563305465e-05, 'epoch': 2.89}\n",
            "{'loss': 1.2827, 'grad_norm': 0.06270372867584229, 'learning_rate': 4.1899493867874615e-05, 'epoch': 2.92}\n",
            "{'loss': 1.0457, 'grad_norm': 0.06639232486486435, 'learning_rate': 2.358289416693027e-05, 'epoch': 2.94}\n",
            "{'loss': 1.5679, 'grad_norm': 0.077408067882061, 'learning_rate': 1.0485868811441756e-05, 'epoch': 2.97}\n",
            "{'loss': 1.5259, 'grad_norm': 0.12507425248622894, 'learning_rate': 2.6221547724253337e-06, 'epoch': 3.0}\n",
            "{'train_runtime': 19.6242, 'train_samples_per_second': 11.007, 'train_steps_per_second': 5.503, 'train_loss': 2.816953423950407, 'epoch': 3.0}\n",
            "100% 108/108 [00:19<00:00,  5.50it/s]\n",
            "Training complete.\n",
            "Model saved to loras/self-edit/training_set_iteration_1/8d5021e8/5\n",
            "Training on 250 examples for 3 epochs, lr: 0.01\n",
            "No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n",
            "Starting training...\n",
            "{'loss': 7.8795, 'grad_norm': 10.619950294494629, 'learning_rate': 0.0, 'epoch': 0.01}\n",
            "{'loss': 5.1219, 'grad_norm': 6.385613441467285, 'learning_rate': 0.0009090909090909091, 'epoch': 0.02}\n",
            "{'loss': 2.3589, 'grad_norm': 9.418131828308105, 'learning_rate': 0.0018181818181818182, 'epoch': 0.02}\n",
            "{'loss': 1.5574, 'grad_norm': 7.8310089111328125, 'learning_rate': 0.002727272727272727, 'epoch': 0.03}\n",
            "{'loss': 0.9345, 'grad_norm': 1.2301315069198608, 'learning_rate': 0.0036363636363636364, 'epoch': 0.04}\n",
            "{'loss': 1.0537, 'grad_norm': 3.7526001930236816, 'learning_rate': 0.004545454545454545, 'epoch': 0.05}\n",
            "{'loss': 0.7297, 'grad_norm': 1.2002049684524536, 'learning_rate': 0.005454545454545454, 'epoch': 0.06}\n",
            "{'loss': 0.6721, 'grad_norm': 0.7622437477111816, 'learning_rate': 0.006363636363636364, 'epoch': 0.06}\n",
            "{'loss': 2.516, 'grad_norm': 7.17767333984375, 'learning_rate': 0.007272727272727273, 'epoch': 0.07}\n",
            "{'loss': 0.8793, 'grad_norm': 1.230568766593933, 'learning_rate': 0.008181818181818182, 'epoch': 0.08}\n",
            "{'loss': 1.2227, 'grad_norm': 3.696221351623535, 'learning_rate': 0.00909090909090909, 'epoch': 0.09}\n",
            "{'loss': 5.0332, 'grad_norm': 5.903087615966797, 'learning_rate': 0.01, 'epoch': 0.1}\n",
            "{'loss': 16.3547, 'grad_norm': 64.91173553466797, 'learning_rate': 0.009999813776583147, 'epoch': 0.1}\n",
            "{'loss': 25.5193, 'grad_norm': 18.5764102935791, 'learning_rate': 0.009999255120204246, 'epoch': 0.11}\n",
            "{'loss': 13.9425, 'grad_norm': 55.442970275878906, 'learning_rate': 0.009998324072477265, 'epoch': 0.12}\n",
            "{'loss': 18.4106, 'grad_norm': 6.261184215545654, 'learning_rate': 0.009997020702755353, 'epoch': 0.13}\n",
            "{'loss': 8.3013, 'grad_norm': 7.442843914031982, 'learning_rate': 0.009995345108125697, 'epoch': 0.14}\n",
            "{'loss': 5.0302, 'grad_norm': 4.0561842918396, 'learning_rate': 0.009993297413402281, 'epoch': 0.14}\n",
            "{'loss': 3.5127, 'grad_norm': 11.427550315856934, 'learning_rate': 0.009990877771116588, 'epoch': 0.15}\n",
            "{'loss': 6.4781, 'grad_norm': 8.561861991882324, 'learning_rate': 0.009988086361506238, 'epoch': 0.16}\n",
            "{'loss': 6.7565, 'grad_norm': 5.891345024108887, 'learning_rate': 0.009984923392501567, 'epoch': 0.17}\n",
            "{'loss': 5.0748, 'grad_norm': 1.984158992767334, 'learning_rate': 0.009981389099710133, 'epoch': 0.18}\n",
            "{'loss': 6.2072, 'grad_norm': 3.8942062854766846, 'learning_rate': 0.009977483746399167, 'epoch': 0.18}\n",
            "{'loss': 3.1446, 'grad_norm': 1.5997278690338135, 'learning_rate': 0.009973207623475963, 'epoch': 0.19}\n",
            "{'loss': 3.5658, 'grad_norm': 5.672101974487305, 'learning_rate': 0.009968561049466213, 'epoch': 0.2}\n",
            "{'loss': 4.7153, 'grad_norm': 1.0328384637832642, 'learning_rate': 0.00996354437049027, 'epoch': 0.21}\n",
            "{'loss': 3.4044, 'grad_norm': 0.7973971962928772, 'learning_rate': 0.009958157960237374, 'epoch': 0.22}\n",
            "{'loss': 3.7771, 'grad_norm': 1.5556929111480713, 'learning_rate': 0.009952402219937815, 'epoch': 0.22}\n",
            "{'loss': 3.2944, 'grad_norm': 2.820007562637329, 'learning_rate': 0.009946277578333045, 'epoch': 0.23}\n",
            "{'loss': 2.302, 'grad_norm': 1.1424225568771362, 'learning_rate': 0.009939784491643733, 'epoch': 0.24}\n",
            "{'loss': 2.0379, 'grad_norm': 0.7124279737472534, 'learning_rate': 0.009932923443535798, 'epoch': 0.25}\n",
            "{'loss': 2.209, 'grad_norm': 0.36537811160087585, 'learning_rate': 0.009925694945084369, 'epoch': 0.26}\n",
            "{'loss': 2.5769, 'grad_norm': 0.5017962455749512, 'learning_rate': 0.009918099534735719, 'epoch': 0.26}\n",
            "{'loss': 3.539, 'grad_norm': 0.6362864375114441, 'learning_rate': 0.009910137778267152, 'epoch': 0.27}\n",
            "{'loss': 2.0688, 'grad_norm': 0.3436262607574463, 'learning_rate': 0.009901810268744867, 'epoch': 0.28}\n",
            "{'loss': 1.983, 'grad_norm': 0.4208236634731293, 'learning_rate': 0.009893117626479776, 'epoch': 0.29}\n",
            "{'loss': 1.3131, 'grad_norm': 0.2154582440853119, 'learning_rate': 0.009884060498981296, 'epoch': 0.3}\n",
            "{'loss': 2.1078, 'grad_norm': 0.45679938793182373, 'learning_rate': 0.009874639560909117, 'epoch': 0.3}\n",
            "{'loss': 1.0481, 'grad_norm': 0.1843089759349823, 'learning_rate': 0.009864855514022955, 'epoch': 0.31}\n",
            "{'loss': 2.1772, 'grad_norm': 0.5350353717803955, 'learning_rate': 0.009854709087130261, 'epoch': 0.32}\n",
            "{'loss': 1.2744, 'grad_norm': 0.19584737718105316, 'learning_rate': 0.00984420103603195, 'epoch': 0.33}\n",
            "{'loss': 1.7528, 'grad_norm': 0.6021513342857361, 'learning_rate': 0.009833332143466099, 'epoch': 0.34}\n",
            "{'loss': 2.3807, 'grad_norm': 0.30459675192832947, 'learning_rate': 0.009822103219049624, 'epoch': 0.34}\n",
            "{'loss': 2.0458, 'grad_norm': 0.6237755417823792, 'learning_rate': 0.009810515099218002, 'epoch': 0.35}\n",
            "{'loss': 1.4162, 'grad_norm': 0.21039630472660065, 'learning_rate': 0.009798568647162938, 'epoch': 0.36}\n",
            "{'loss': 1.4772, 'grad_norm': 0.3473862409591675, 'learning_rate': 0.00978626475276808, 'epoch': 0.37}\n",
            "{'loss': 1.0958, 'grad_norm': 0.19858501851558685, 'learning_rate': 0.009773604332542728, 'epoch': 0.38}\n",
            "{'loss': 2.2052, 'grad_norm': 0.5977444648742676, 'learning_rate': 0.00976058832955357, 'epoch': 0.38}\n",
            "{'loss': 1.2053, 'grad_norm': 0.2118653655052185, 'learning_rate': 0.009747217713354427, 'epoch': 0.39}\n",
            "{'loss': 2.0296, 'grad_norm': 0.7043007016181946, 'learning_rate': 0.009733493479914031, 'epoch': 0.4}\n",
            "{'loss': 1.7932, 'grad_norm': 2.486522912979126, 'learning_rate': 0.009719416651541838, 'epoch': 0.41}\n",
            "{'loss': 1.286, 'grad_norm': 0.22297397255897522, 'learning_rate': 0.009704988276811882, 'epoch': 0.42}\n",
            "{'loss': 1.6601, 'grad_norm': 0.42884477972984314, 'learning_rate': 0.00969020943048466, 'epoch': 0.42}\n",
            "{'loss': 1.1308, 'grad_norm': 0.13279476761817932, 'learning_rate': 0.009675081213427075, 'epoch': 0.43}\n",
            "{'loss': 1.8216, 'grad_norm': 0.20771273970603943, 'learning_rate': 0.009659604752530434, 'epoch': 0.44}\n",
            "{'loss': 1.4136, 'grad_norm': 0.25831139087677, 'learning_rate': 0.00964378120062651, 'epoch': 0.45}\n",
            "{'loss': 1.1646, 'grad_norm': 0.20966553688049316, 'learning_rate': 0.009627611736401667, 'epoch': 0.46}\n",
            "{'loss': 1.3311, 'grad_norm': 0.13395798206329346, 'learning_rate': 0.009611097564309053, 'epoch': 0.46}\n",
            "{'loss': 1.6085, 'grad_norm': 0.3703150153160095, 'learning_rate': 0.009594239914478886, 'epoch': 0.47}\n",
            "{'loss': 1.5796, 'grad_norm': 0.1830647885799408, 'learning_rate': 0.009577040042626833, 'epoch': 0.48}\n",
            "{'loss': 1.4, 'grad_norm': 0.16410543024539948, 'learning_rate': 0.00955949922996045, 'epoch': 0.49}\n",
            "{'loss': 1.0041, 'grad_norm': 0.07964713126420975, 'learning_rate': 0.00954161878308377, 'epoch': 0.5}\n",
            "{'loss': 1.3301, 'grad_norm': 0.17907190322875977, 'learning_rate': 0.009523400033899955, 'epoch': 0.5}\n",
            "{'loss': 1.4146, 'grad_norm': 0.28270018100738525, 'learning_rate': 0.009504844339512096, 'epoch': 0.51}\n",
            "{'loss': 1.4669, 'grad_norm': 0.24431496858596802, 'learning_rate': 0.009485953082122116, 'epoch': 0.52}\n",
            "{'loss': 1.5335, 'grad_norm': 0.5591989755630493, 'learning_rate': 0.009466727668927815, 'epoch': 0.53}\n",
            "{'loss': 2.4145, 'grad_norm': 2.2672152519226074, 'learning_rate': 0.00944716953201805, 'epoch': 0.54}\n",
            "{'loss': 1.4153, 'grad_norm': 0.42263486981391907, 'learning_rate': 0.009427280128266049, 'epoch': 0.54}\n",
            "{'loss': 1.3786, 'grad_norm': 0.39863938093185425, 'learning_rate': 0.009407060939220908, 'epoch': 0.55}\n",
            "{'loss': 1.4235, 'grad_norm': 1.7336244583129883, 'learning_rate': 0.00938651347099721, 'epoch': 0.56}\n",
            "{'loss': 1.2934, 'grad_norm': 7.537093162536621, 'learning_rate': 0.009365639254162854, 'epoch': 0.57}\n",
            "{'loss': 1.9345, 'grad_norm': 0.7561440467834473, 'learning_rate': 0.009344439843625034, 'epoch': 0.58}\n",
            "{'loss': 1.7801, 'grad_norm': 0.4323343336582184, 'learning_rate': 0.009322916818514413, 'epoch': 0.58}\n",
            "{'loss': 1.1655, 'grad_norm': 1.3027820587158203, 'learning_rate': 0.009301071782067504, 'epoch': 0.59}\n",
            "{'loss': 1.0373, 'grad_norm': 0.21214446425437927, 'learning_rate': 0.009278906361507237, 'epoch': 0.6}\n",
            "{'loss': 1.1644, 'grad_norm': 0.25866276025772095, 'learning_rate': 0.009256422207921756, 'epoch': 0.61}\n",
            "{'loss': 1.1289, 'grad_norm': 0.23264089226722717, 'learning_rate': 0.00923362099614142, 'epoch': 0.62}\n",
            "{'loss': 0.834, 'grad_norm': 0.11550568789243698, 'learning_rate': 0.009210504424614059, 'epoch': 0.62}\n",
            "{'loss': 1.3229, 'grad_norm': 0.14361391961574554, 'learning_rate': 0.009187074215278444, 'epoch': 0.63}\n",
            "{'loss': 1.3934, 'grad_norm': 0.3229740560054779, 'learning_rate': 0.009163332113436031, 'epoch': 0.64}\n",
            "{'loss': 0.9446, 'grad_norm': 0.1763635128736496, 'learning_rate': 0.009139279887620954, 'epoch': 0.65}\n",
            "{'loss': 1.6499, 'grad_norm': 0.6290594339370728, 'learning_rate': 0.009114919329468282, 'epoch': 0.66}\n",
            "{'loss': 1.0595, 'grad_norm': 0.2962822914123535, 'learning_rate': 0.009090252253580565, 'epoch': 0.66}\n",
            "{'loss': 1.2165, 'grad_norm': 0.3034539222717285, 'learning_rate': 0.009065280497392662, 'epoch': 0.67}\n",
            "{'loss': 0.9095, 'grad_norm': 0.16215650737285614, 'learning_rate': 0.009040005921034882, 'epoch': 0.68}\n",
            "{'loss': 0.8962, 'grad_norm': 1.5456205606460571, 'learning_rate': 0.009014430407194412, 'epoch': 0.69}\n",
            "{'loss': 1.8321, 'grad_norm': 0.30445417761802673, 'learning_rate': 0.008988555860975082, 'epoch': 0.7}\n",
            "{'loss': 1.4024, 'grad_norm': 0.2431168407201767, 'learning_rate': 0.008962384209755451, 'epoch': 0.7}\n",
            "{'loss': 1.4598, 'grad_norm': 0.2844051420688629, 'learning_rate': 0.00893591740304525, 'epoch': 0.71}\n",
            "{'loss': 1.318, 'grad_norm': 0.2129184603691101, 'learning_rate': 0.008909157412340149, 'epoch': 0.72}\n",
            "{'loss': 1.9735, 'grad_norm': 0.26860442757606506, 'learning_rate': 0.008882106230974908, 'epoch': 0.73}\n",
            "{'loss': 1.8486, 'grad_norm': 0.25412803888320923, 'learning_rate': 0.008854765873974898, 'epoch': 0.74}\n",
            "{'loss': 1.2064, 'grad_norm': 0.2677755355834961, 'learning_rate': 0.008827138377905998, 'epoch': 0.74}\n",
            "{'loss': 1.7266, 'grad_norm': 0.19821776449680328, 'learning_rate': 0.008799225800722895, 'epoch': 0.75}\n",
            "{'loss': 1.1061, 'grad_norm': 0.4695376753807068, 'learning_rate': 0.008771030221615786, 'epoch': 0.76}\n",
            "{'loss': 1.2312, 'grad_norm': 0.11176259070634842, 'learning_rate': 0.008742553740855506, 'epoch': 0.77}\n",
            "{'loss': 1.1854, 'grad_norm': 0.15911366045475006, 'learning_rate': 0.008713798479637071, 'epoch': 0.78}\n",
            "{'loss': 1.2236, 'grad_norm': 0.10155640542507172, 'learning_rate': 0.008684766579921684, 'epoch': 0.78}\n",
            "{'loss': 1.5225, 'grad_norm': 0.15020066499710083, 'learning_rate': 0.008655460204277167, 'epoch': 0.79}\n",
            "{'loss': 1.2823, 'grad_norm': 0.1440967321395874, 'learning_rate': 0.008625881535716882, 'epoch': 0.8}\n",
            "{'loss': 1.2351, 'grad_norm': 0.12198406457901001, 'learning_rate': 0.008596032777537123, 'epoch': 0.81}\n",
            "{'loss': 1.41, 'grad_norm': 0.24158339202404022, 'learning_rate': 0.008565916153152981, 'epoch': 0.82}\n",
            "{'loss': 0.979, 'grad_norm': 0.17612788081169128, 'learning_rate': 0.008535533905932738, 'epoch': 0.82}\n",
            "{'loss': 0.7795, 'grad_norm': 0.08542359620332718, 'learning_rate': 0.008504888299030747, 'epoch': 0.83}\n",
            "{'loss': 1.4626, 'grad_norm': 0.4013746976852417, 'learning_rate': 0.008473981615218862, 'epoch': 0.84}\n",
            "{'loss': 0.9578, 'grad_norm': 0.3041120767593384, 'learning_rate': 0.008442816156716385, 'epoch': 0.85}\n",
            "{'loss': 1.0275, 'grad_norm': 0.3235781788825989, 'learning_rate': 0.008411394245018588, 'epoch': 0.86}\n",
            "{'loss': 1.6658, 'grad_norm': 1.79461669921875, 'learning_rate': 0.008379718220723772, 'epoch': 0.86}\n",
            "{'loss': 1.4398, 'grad_norm': 0.6497625708580017, 'learning_rate': 0.008347790443358928, 'epoch': 0.87}\n",
            "{'loss': 1.5578, 'grad_norm': 0.4767337739467621, 'learning_rate': 0.008315613291203975, 'epoch': 0.88}\n",
            "{'loss': 2.2359, 'grad_norm': 0.3583660423755646, 'learning_rate': 0.0082831891611146, 'epoch': 0.89}\n",
            "{'loss': 1.7596, 'grad_norm': 0.6367288827896118, 'learning_rate': 0.00825052046834372, 'epoch': 0.9}\n",
            "{'loss': 1.4316, 'grad_norm': 0.3412420153617859, 'learning_rate': 0.008217609646361573, 'epoch': 0.9}\n",
            "{'loss': 1.6024, 'grad_norm': 0.41829779744148254, 'learning_rate': 0.008184459146674447, 'epoch': 0.91}\n",
            "{'loss': 1.5213, 'grad_norm': 0.4482256770133972, 'learning_rate': 0.008151071438642068, 'epoch': 0.92}\n",
            "{'loss': 1.1985, 'grad_norm': 0.1390182375907898, 'learning_rate': 0.008117449009293669, 'epoch': 0.93}\n",
            "{'loss': 1.1048, 'grad_norm': 0.38210487365722656, 'learning_rate': 0.008083594363142717, 'epoch': 0.94}\n",
            "{'loss': 1.1263, 'grad_norm': 0.312387079000473, 'learning_rate': 0.008049510022000364, 'epoch': 0.94}\n",
            "{'loss': 0.8789, 'grad_norm': 0.08028291165828705, 'learning_rate': 0.008015198524787602, 'epoch': 0.95}\n",
            "{'loss': 0.6812, 'grad_norm': 0.09591278433799744, 'learning_rate': 0.007980662427346127, 'epoch': 0.96}\n",
            "{'loss': 1.051, 'grad_norm': 0.19063256680965424, 'learning_rate': 0.007945904302247968, 'epoch': 0.97}\n",
            "{'loss': 0.7138, 'grad_norm': 0.14198407530784607, 'learning_rate': 0.007910926738603854, 'epoch': 0.98}\n",
            "{'loss': 1.868, 'grad_norm': 0.590223491191864, 'learning_rate': 0.007875732341870348, 'epoch': 0.98}\n",
            "{'loss': 1.3436, 'grad_norm': 0.24761486053466797, 'learning_rate': 0.007840323733655778, 'epoch': 0.99}\n",
            "{'loss': 1.0276, 'grad_norm': 0.1737518459558487, 'learning_rate': 0.007804703551524948, 'epoch': 1.0}\n",
            "{'loss': 1.3857, 'grad_norm': 0.3127976357936859, 'learning_rate': 0.0077688744488026654, 'epoch': 1.01}\n",
            "{'loss': 1.1248, 'grad_norm': 0.24410885572433472, 'learning_rate': 0.007732839094376105, 'epoch': 1.02}\n",
            "{'loss': 0.729, 'grad_norm': 0.10597382485866547, 'learning_rate': 0.007696600172495996, 'epoch': 1.02}\n",
            "{'loss': 1.1399, 'grad_norm': 0.20945727825164795, 'learning_rate': 0.007660160382576683, 'epoch': 1.03}\n",
            "{'loss': 0.9377, 'grad_norm': 0.19121600687503815, 'learning_rate': 0.00762352243899504, 'epoch': 1.04}\n",
            "{'loss': 1.0894, 'grad_norm': 0.32026395201683044, 'learning_rate': 0.007586689070888284, 'epoch': 1.05}\n",
            "{'loss': 1.2877, 'grad_norm': 117.83091735839844, 'learning_rate': 0.00754966302195068, 'epoch': 1.06}\n",
            "{'loss': 0.9938, 'grad_norm': 0.09086660295724869, 'learning_rate': 0.007512447050229166, 'epoch': 1.06}\n",
            "{'loss': 0.8662, 'grad_norm': 0.1398526281118393, 'learning_rate': 0.007475043927917907, 'epoch': 1.07}\n",
            "{'loss': 0.8604, 'grad_norm': 0.48118162155151367, 'learning_rate': 0.007437456441151799, 'epoch': 1.08}\n",
            "{'loss': 1.1167, 'grad_norm': 0.15965868532657623, 'learning_rate': 0.007399687389798932, 'epoch': 1.09}\n",
            "{'loss': 1.2499, 'grad_norm': 0.23292027413845062, 'learning_rate': 0.007361739587252019, 'epoch': 1.1}\n",
            "{'loss': 0.9069, 'grad_norm': 0.20843233168125153, 'learning_rate': 0.007323615860218843, 'epoch': 1.1}\n",
            "{'loss': 0.7201, 'grad_norm': 0.10101588815450668, 'learning_rate': 0.00728531904851169, 'epoch': 1.11}\n",
            "{'loss': 0.9986, 'grad_norm': 0.1626858413219452, 'learning_rate': 0.007246852004835807, 'epoch': 1.12}\n",
            "{'loss': 0.9165, 'grad_norm': 0.14677287638187408, 'learning_rate': 0.007208217594576923, 'epoch': 1.13}\n",
            "{'loss': 0.6966, 'grad_norm': 0.10718656331300735, 'learning_rate': 0.007169418695587791, 'epoch': 1.14}\n",
            "{'loss': 1.3304, 'grad_norm': 0.2625109851360321, 'learning_rate': 0.007130458197973828, 'epoch': 1.14}\n",
            "{'loss': 0.9404, 'grad_norm': 0.1352148950099945, 'learning_rate': 0.0070913390038778255, 'epoch': 1.15}\n",
            "{'loss': 0.6804, 'grad_norm': 0.0910830944776535, 'learning_rate': 0.007052064027263785, 'epoch': 1.16}\n",
            "{'loss': 1.0333, 'grad_norm': 0.2865162491798401, 'learning_rate': 0.0070126361936998375, 'epoch': 1.17}\n",
            "{'loss': 0.9889, 'grad_norm': 0.09144368022680283, 'learning_rate': 0.006973058440140341, 'epoch': 1.18}\n",
            "{'loss': 1.2779, 'grad_norm': 0.12530122697353363, 'learning_rate': 0.006933333714707094, 'epoch': 1.18}\n",
            "{'loss': 0.8739, 'grad_norm': 0.27518337965011597, 'learning_rate': 0.006893464976469739, 'epoch': 1.19}\n",
            "{'loss': 0.5758, 'grad_norm': 0.05354594439268112, 'learning_rate': 0.006853455195225339, 'epoch': 1.2}\n",
            "{'loss': 0.7976, 'grad_norm': 0.07395101338624954, 'learning_rate': 0.00681330735127716, 'epoch': 1.21}\n",
            "{'loss': 1.0521, 'grad_norm': 0.1289139688014984, 'learning_rate': 0.006773024435212678, 'epoch': 1.22}\n",
            "{'loss': 1.0507, 'grad_norm': 0.1336035132408142, 'learning_rate': 0.0067326094476808, 'epoch': 1.22}\n",
            "{'loss': 1.0063, 'grad_norm': 0.09770264476537704, 'learning_rate': 0.0066920653991683525, 'epoch': 1.23}\n",
            "{'loss': 0.7039, 'grad_norm': 0.0658998042345047, 'learning_rate': 0.006651395309775836, 'epoch': 1.24}\n",
            "{'loss': 0.8561, 'grad_norm': 0.12663276493549347, 'learning_rate': 0.006610602208992454, 'epoch': 1.25}\n",
            "{'loss': 0.7719, 'grad_norm': 0.06577654927968979, 'learning_rate': 0.00656968913547045, 'epoch': 1.26}\n",
            "{'loss': 0.839, 'grad_norm': 0.09707622230052948, 'learning_rate': 0.006528659136798765, 'epoch': 1.26}\n",
            "{'loss': 0.9286, 'grad_norm': 0.09753554314374924, 'learning_rate': 0.006487515269276016, 'epoch': 1.27}\n",
            "{'loss': 1.1404, 'grad_norm': 0.0778612494468689, 'learning_rate': 0.0064462605976828395, 'epoch': 1.28}\n",
            "{'loss': 1.0062, 'grad_norm': 0.10563893616199493, 'learning_rate': 0.0064048981950535966, 'epoch': 1.29}\n",
            "{'loss': 0.9301, 'grad_norm': 0.11399459093809128, 'learning_rate': 0.006363431142447469, 'epoch': 1.3}\n",
            "{'loss': 0.6361, 'grad_norm': 0.06437822431325912, 'learning_rate': 0.006321862528718945, 'epoch': 1.3}\n",
            "{'loss': 0.8033, 'grad_norm': 0.09758730977773666, 'learning_rate': 0.006280195450287736, 'epoch': 1.31}\n",
            "{'loss': 0.6188, 'grad_norm': 0.06640984863042831, 'learning_rate': 0.00623843301090813, 'epoch': 1.32}\n",
            "{'loss': 0.8148, 'grad_norm': 0.07124686986207962, 'learning_rate': 0.006196578321437789, 'epoch': 1.33}\n",
            "{'loss': 0.8373, 'grad_norm': 0.07355747371912003, 'learning_rate': 0.006154634499606029, 'epoch': 1.34}\n",
            "{'loss': 0.8088, 'grad_norm': 0.07302217930555344, 'learning_rate': 0.006112604669781572, 'epoch': 1.34}\n",
            "{'loss': 0.6595, 'grad_norm': 0.06219503656029701, 'learning_rate': 0.0060704919627398305, 'epoch': 1.35}\n",
            "{'loss': 1.0904, 'grad_norm': 0.1609088033437729, 'learning_rate': 0.006028299515429682, 'epoch': 1.36}\n",
            "{'loss': 1.1158, 'grad_norm': 0.075952909886837, 'learning_rate': 0.005986030470739811, 'epoch': 1.37}\n",
            "{'loss': 0.7689, 'grad_norm': 0.07456240057945251, 'learning_rate': 0.005943687977264584, 'epoch': 1.38}\n",
            "{'loss': 0.8136, 'grad_norm': 0.1067030131816864, 'learning_rate': 0.005901275189069529, 'epoch': 1.38}\n",
            "{'loss': 1.2867, 'grad_norm': 0.14452314376831055, 'learning_rate': 0.005858795265456382, 'epoch': 1.39}\n",
            "{'loss': 0.9209, 'grad_norm': 0.11284194886684418, 'learning_rate': 0.005816251370727748, 'epoch': 1.4}\n",
            "{'loss': 0.9104, 'grad_norm': 0.10417915880680084, 'learning_rate': 0.005773646673951406, 'epoch': 1.41}\n",
            "{'loss': 0.6164, 'grad_norm': 0.042548611760139465, 'learning_rate': 0.005730984348724242, 'epoch': 1.42}\n",
            "{'loss': 0.63, 'grad_norm': 0.03926972299814224, 'learning_rate': 0.005688267572935842, 'epoch': 1.42}\n",
            "{'loss': 0.6019, 'grad_norm': 0.062083832919597626, 'learning_rate': 0.005645499528531784, 'epoch': 1.43}\n",
            "{'loss': 0.8997, 'grad_norm': 0.10441553592681885, 'learning_rate': 0.005602683401276615, 'epoch': 1.44}\n",
            "{'loss': 1.0207, 'grad_norm': 0.15584562718868256, 'learning_rate': 0.005559822380516539, 'epoch': 1.45}\n",
            "{'loss': 0.6411, 'grad_norm': 0.04447203502058983, 'learning_rate': 0.00551691965894185, 'epoch': 1.46}\n",
            "{'loss': 0.7186, 'grad_norm': 0.08274226635694504, 'learning_rate': 0.005473978432349111, 'epoch': 1.46}\n",
            "{'loss': 0.6783, 'grad_norm': 0.07861849665641785, 'learning_rate': 0.0054310018994030975, 'epoch': 1.47}\n",
            "{'loss': 1.0383, 'grad_norm': 0.10896464437246323, 'learning_rate': 0.005387993261398532, 'epoch': 1.48}\n",
            "{'loss': 1.0631, 'grad_norm': 0.13565245270729065, 'learning_rate': 0.005344955722021624, 'epoch': 1.49}\n",
            "{'loss': 1.1684, 'grad_norm': 0.15707165002822876, 'learning_rate': 0.00530189248711143, 'epoch': 1.5}\n",
            "{'loss': 0.9504, 'grad_norm': 0.09530904144048691, 'learning_rate': 0.005258806764421048, 'epoch': 1.5}\n",
            "{'loss': 1.0832, 'grad_norm': 0.09154053032398224, 'learning_rate': 0.005215701763378673, 'epoch': 1.51}\n",
            "{'loss': 0.8501, 'grad_norm': 0.06186690926551819, 'learning_rate': 0.005172580694848541, 'epoch': 1.52}\n",
            "{'loss': 0.8516, 'grad_norm': 0.08606589585542679, 'learning_rate': 0.005129446770891738, 'epoch': 1.53}\n",
            "{'loss': 0.6101, 'grad_norm': 0.04765792191028595, 'learning_rate': 0.0050863032045269435, 'epoch': 1.54}\n",
            "{'loss': 0.6153, 'grad_norm': 0.05183664709329605, 'learning_rate': 0.0050431532094910945, 'epoch': 1.54}\n",
            "{'loss': 0.6589, 'grad_norm': 0.04393531009554863, 'learning_rate': 0.005, 'epoch': 1.55}\n",
            "{'loss': 1.0034, 'grad_norm': 0.11800924688577652, 'learning_rate': 0.004956846790508906, 'epoch': 1.56}\n",
            "{'loss': 0.5261, 'grad_norm': 0.03386671841144562, 'learning_rate': 0.004913696795473058, 'epoch': 1.57}\n",
            "{'loss': 0.8381, 'grad_norm': 0.0783962830901146, 'learning_rate': 0.004870553229108264, 'epoch': 1.58}\n",
            "{'loss': 0.737, 'grad_norm': 0.07792351394891739, 'learning_rate': 0.004827419305151461, 'epoch': 1.58}\n",
            "{'loss': 0.8545, 'grad_norm': 0.07502605020999908, 'learning_rate': 0.004784298236621327, 'epoch': 1.59}\n",
            "{'loss': 0.7759, 'grad_norm': 0.0607694536447525, 'learning_rate': 0.0047411932355789525, 'epoch': 1.6}\n",
            "{'loss': 0.6541, 'grad_norm': 0.06943279504776001, 'learning_rate': 0.004698107512888569, 'epoch': 1.61}\n",
            "{'loss': 0.8691, 'grad_norm': 0.1038498729467392, 'learning_rate': 0.004655044277978375, 'epoch': 1.62}\n",
            "{'loss': 0.9672, 'grad_norm': 0.10608074069023132, 'learning_rate': 0.004612006738601469, 'epoch': 1.62}\n",
            "{'loss': 0.5703, 'grad_norm': 0.036281879991292953, 'learning_rate': 0.004568998100596903, 'epoch': 1.63}\n",
            "{'loss': 0.7464, 'grad_norm': 0.044448256492614746, 'learning_rate': 0.004526021567650889, 'epoch': 1.64}\n",
            "{'loss': 1.119, 'grad_norm': 0.10742385685443878, 'learning_rate': 0.00448308034105815, 'epoch': 1.65}\n",
            "{'loss': 0.6207, 'grad_norm': 0.03598083183169365, 'learning_rate': 0.004440177619483461, 'epoch': 1.66}\n",
            "{'loss': 0.7382, 'grad_norm': 0.025821495801210403, 'learning_rate': 0.004397316598723385, 'epoch': 1.66}\n",
            "{'loss': 0.9851, 'grad_norm': 0.09920037537813187, 'learning_rate': 0.004354500471468217, 'epoch': 1.67}\n",
            "{'loss': 0.5779, 'grad_norm': 0.05281050130724907, 'learning_rate': 0.00431173242706416, 'epoch': 1.68}\n",
            "{'loss': 0.9639, 'grad_norm': 0.06787041574716568, 'learning_rate': 0.004269015651275761, 'epoch': 1.69}\n",
            "{'loss': 0.6133, 'grad_norm': 0.05519745126366615, 'learning_rate': 0.004226353326048593, 'epoch': 1.7}\n",
            "{'loss': 0.7986, 'grad_norm': 0.0867767408490181, 'learning_rate': 0.004183748629272253, 'epoch': 1.7}\n",
            "{'loss': 0.5658, 'grad_norm': 0.06354515254497528, 'learning_rate': 0.004141204734543619, 'epoch': 1.71}\n",
            "{'loss': 0.7554, 'grad_norm': 0.07708585262298584, 'learning_rate': 0.004098724810930472, 'epoch': 1.72}\n",
            "{'loss': 0.7313, 'grad_norm': 0.06890251487493515, 'learning_rate': 0.004056312022735417, 'epoch': 1.73}\n",
            "{'loss': 0.4966, 'grad_norm': 0.032269157469272614, 'learning_rate': 0.00401396952926019, 'epoch': 1.74}\n",
            "{'loss': 0.6728, 'grad_norm': 0.0804487019777298, 'learning_rate': 0.003971700484570318, 'epoch': 1.74}\n",
            "{'loss': 0.5777, 'grad_norm': 0.061023060232400894, 'learning_rate': 0.00392950803726017, 'epoch': 1.75}\n",
            "{'loss': 0.7087, 'grad_norm': 0.05537816882133484, 'learning_rate': 0.003887395330218428, 'epoch': 1.76}\n",
            "{'loss': 0.5766, 'grad_norm': 0.04795050993561745, 'learning_rate': 0.0038453655003939735, 'epoch': 1.77}\n",
            "{'loss': 1.1399, 'grad_norm': 0.11699080467224121, 'learning_rate': 0.003803421678562213, 'epoch': 1.78}\n",
            "{'loss': 0.8259, 'grad_norm': 0.06441118568181992, 'learning_rate': 0.00376156698909187, 'epoch': 1.78}\n",
            "{'loss': 0.8317, 'grad_norm': 0.05346789211034775, 'learning_rate': 0.0037198045497122646, 'epoch': 1.79}\n",
            "{'loss': 0.6619, 'grad_norm': 0.07631535083055496, 'learning_rate': 0.0036781374712810556, 'epoch': 1.8}\n",
            "{'loss': 0.591, 'grad_norm': 0.05632655695080757, 'learning_rate': 0.0036365688575525313, 'epoch': 1.81}\n",
            "{'loss': 1.007, 'grad_norm': 0.10056455433368683, 'learning_rate': 0.003595101804946404, 'epoch': 1.82}\n",
            "{'loss': 0.5662, 'grad_norm': 0.047316234558820724, 'learning_rate': 0.003553739402317162, 'epoch': 1.82}\n",
            "{'loss': 0.6957, 'grad_norm': 0.09474597126245499, 'learning_rate': 0.003512484730723986, 'epoch': 1.83}\n",
            "{'loss': 0.8256, 'grad_norm': 0.06060409173369408, 'learning_rate': 0.0034713408632012365, 'epoch': 1.84}\n",
            "{'loss': 0.9424, 'grad_norm': 0.124965138733387, 'learning_rate': 0.00343031086452955, 'epoch': 1.85}\n",
            "{'loss': 0.7828, 'grad_norm': 0.06950370222330093, 'learning_rate': 0.003389397791007548, 'epoch': 1.86}\n",
            "{'loss': 0.6029, 'grad_norm': 0.06065439060330391, 'learning_rate': 0.0033486046902241663, 'epoch': 1.86}\n",
            "{'loss': 0.5352, 'grad_norm': 0.049062736332416534, 'learning_rate': 0.003307934600831648, 'epoch': 1.87}\n",
            "{'loss': 0.7455, 'grad_norm': 1.1061185598373413, 'learning_rate': 0.0032673905523191997, 'epoch': 1.88}\n",
            "{'loss': 0.6046, 'grad_norm': 0.05025763437151909, 'learning_rate': 0.0032269755647873215, 'epoch': 1.89}\n",
            "{'loss': 0.7491, 'grad_norm': 0.0972532406449318, 'learning_rate': 0.00318669264872284, 'epoch': 1.9}\n",
            "{'loss': 0.631, 'grad_norm': 0.05070377141237259, 'learning_rate': 0.0031465448047746625, 'epoch': 1.9}\n",
            "{'loss': 0.7829, 'grad_norm': 0.08559761196374893, 'learning_rate': 0.003106535023530262, 'epoch': 1.91}\n",
            "{'loss': 0.7618, 'grad_norm': 0.08975421637296677, 'learning_rate': 0.003066666285292906, 'epoch': 1.92}\n",
            "{'loss': 0.7161, 'grad_norm': 0.06479521840810776, 'learning_rate': 0.00302694155985966, 'epoch': 1.93}\n",
            "{'loss': 0.8888, 'grad_norm': 0.10365431755781174, 'learning_rate': 0.0029873638063001627, 'epoch': 1.94}\n",
            "{'loss': 0.5937, 'grad_norm': 0.06934618204832077, 'learning_rate': 0.002947935972736217, 'epoch': 1.94}\n",
            "{'loss': 0.8281, 'grad_norm': 0.12812267243862152, 'learning_rate': 0.0029086609961221756, 'epoch': 1.95}\n",
            "{'loss': 0.7018, 'grad_norm': 0.09600593149662018, 'learning_rate': 0.0028695418020261753, 'epoch': 1.96}\n",
            "{'loss': 0.5881, 'grad_norm': 0.07398734986782074, 'learning_rate': 0.00283058130441221, 'epoch': 1.97}\n",
            "{'loss': 0.7616, 'grad_norm': 0.06959036737680435, 'learning_rate': 0.0027917824054230784, 'epoch': 1.98}\n",
            "{'loss': 0.4571, 'grad_norm': 0.03821122273802757, 'learning_rate': 0.0027531479951641924, 'epoch': 1.98}\n",
            "{'loss': 0.9781, 'grad_norm': 0.09129559993743896, 'learning_rate': 0.002714680951488312, 'epoch': 1.99}\n",
            "{'loss': 0.5842, 'grad_norm': 0.04940292611718178, 'learning_rate': 0.002676384139781157, 'epoch': 2.0}\n",
            "{'loss': 0.8473, 'grad_norm': 0.12454558163881302, 'learning_rate': 0.0026382604127479815, 'epoch': 2.01}\n",
            "{'loss': 0.6462, 'grad_norm': 0.056285541504621506, 'learning_rate': 0.0026003126102010694, 'epoch': 2.02}\n",
            "{'loss': 0.9895, 'grad_norm': 0.12855792045593262, 'learning_rate': 0.0025625435588482017, 'epoch': 2.02}\n",
            "{'loss': 0.4517, 'grad_norm': 0.024516252800822258, 'learning_rate': 0.002524956072082093, 'epoch': 2.03}\n",
            "{'loss': 0.9834, 'grad_norm': 0.11927622556686401, 'learning_rate': 0.0024875529497708354, 'epoch': 2.04}\n",
            "{'loss': 0.7404, 'grad_norm': 0.09454376250505447, 'learning_rate': 0.0024503369780493217, 'epoch': 2.05}\n",
            "{'loss': 1.1053, 'grad_norm': 0.0968085452914238, 'learning_rate': 0.0024133109291117156, 'epoch': 2.06}\n",
            "{'loss': 0.8461, 'grad_norm': 0.09627536684274673, 'learning_rate': 0.00237647756100496, 'epoch': 2.06}\n",
            "{'loss': 0.6496, 'grad_norm': 0.06002824753522873, 'learning_rate': 0.0023398396174233176, 'epoch': 2.07}\n",
            "{'loss': 0.9674, 'grad_norm': 0.11213357001543045, 'learning_rate': 0.002303399827504005, 'epoch': 2.08}\n",
            "{'loss': 0.7812, 'grad_norm': 0.10949504375457764, 'learning_rate': 0.002267160905623895, 'epoch': 2.09}\n",
            "{'loss': 0.734, 'grad_norm': 0.1038150042295456, 'learning_rate': 0.0022311255511973343, 'epoch': 2.1}\n",
            "{'loss': 0.7052, 'grad_norm': 0.09816618263721466, 'learning_rate': 0.0021952964484750525, 'epoch': 2.1}\n",
            "{'loss': 0.4733, 'grad_norm': 0.0439513735473156, 'learning_rate': 0.0021596762663442215, 'epoch': 2.11}\n",
            "{'loss': 0.8261, 'grad_norm': 0.09052415192127228, 'learning_rate': 0.0021242676581296528, 'epoch': 2.12}\n",
            "{'loss': 0.6953, 'grad_norm': 0.04684699699282646, 'learning_rate': 0.0020890732613961477, 'epoch': 2.13}\n",
            "{'loss': 1.0979, 'grad_norm': 0.127188041806221, 'learning_rate': 0.002054095697752032, 'epoch': 2.14}\n",
            "{'loss': 0.5387, 'grad_norm': 0.06315041333436966, 'learning_rate': 0.002019337572653874, 'epoch': 2.14}\n",
            "{'loss': 0.5098, 'grad_norm': 0.04141583666205406, 'learning_rate': 0.0019848014752123977, 'epoch': 2.15}\n",
            "{'loss': 1.2138, 'grad_norm': 0.14174924790859222, 'learning_rate': 0.0019504899779996354, 'epoch': 2.16}\n",
            "{'loss': 0.6296, 'grad_norm': 0.06670281291007996, 'learning_rate': 0.0019164056368572847, 'epoch': 2.17}\n",
            "{'loss': 0.6817, 'grad_norm': 0.05368325486779213, 'learning_rate': 0.0018825509907063327, 'epoch': 2.18}\n",
            "{'loss': 0.5196, 'grad_norm': 0.047247231006622314, 'learning_rate': 0.0018489285613579327, 'epoch': 2.18}\n",
            "{'loss': 0.823, 'grad_norm': 0.07455354183912277, 'learning_rate': 0.0018155408533255552, 'epoch': 2.19}\n",
            "{'loss': 0.6682, 'grad_norm': 0.05389136075973511, 'learning_rate': 0.001782390353638426, 'epoch': 2.2}\n",
            "{'loss': 0.8511, 'grad_norm': 0.07505078613758087, 'learning_rate': 0.0017494795316562789, 'epoch': 2.21}\n",
            "{'loss': 0.5781, 'grad_norm': 0.05292792618274689, 'learning_rate': 0.0017168108388853998, 'epoch': 2.22}\n",
            "{'loss': 0.5499, 'grad_norm': 0.047134507447481155, 'learning_rate': 0.001684386708796025, 'epoch': 2.22}\n",
            "{'loss': 0.7015, 'grad_norm': 0.060459237545728683, 'learning_rate': 0.0016522095566410728, 'epoch': 2.23}\n",
            "{'loss': 0.6991, 'grad_norm': 0.06620561331510544, 'learning_rate': 0.001620281779276228, 'epoch': 2.24}\n",
            "{'loss': 0.7483, 'grad_norm': 0.0671231597661972, 'learning_rate': 0.0015886057549814132, 'epoch': 2.25}\n",
            "{'loss': 0.9572, 'grad_norm': 0.1820785105228424, 'learning_rate': 0.001557183843283614, 'epoch': 2.26}\n",
            "{'loss': 0.8529, 'grad_norm': 0.0917988196015358, 'learning_rate': 0.0015260183847811382, 'epoch': 2.26}\n",
            "{'loss': 0.7346, 'grad_norm': 0.06162787601351738, 'learning_rate': 0.0014951117009692528, 'epoch': 2.27}\n",
            "{'loss': 0.6322, 'grad_norm': 0.08573143184185028, 'learning_rate': 0.0014644660940672626, 'epoch': 2.28}\n",
            "{'loss': 0.7661, 'grad_norm': 0.09489559382200241, 'learning_rate': 0.0014340838468470197, 'epoch': 2.29}\n",
            "{'loss': 0.9055, 'grad_norm': 0.15732386708259583, 'learning_rate': 0.0014039672224628785, 'epoch': 2.3}\n",
            "{'loss': 0.5571, 'grad_norm': 0.05416233837604523, 'learning_rate': 0.001374118464283119, 'epoch': 2.3}\n",
            "{'loss': 0.904, 'grad_norm': 0.10211492329835892, 'learning_rate': 0.0013445397957228338, 'epoch': 2.31}\n",
            "{'loss': 1.0768, 'grad_norm': 0.1374741494655609, 'learning_rate': 0.0013152334200783166, 'epoch': 2.32}\n",
            "{'loss': 0.6184, 'grad_norm': 0.0766003280878067, 'learning_rate': 0.0012862015203629273, 'epoch': 2.33}\n",
            "{'loss': 0.8673, 'grad_norm': 0.08831489086151123, 'learning_rate': 0.001257446259144494, 'epoch': 2.34}\n",
            "{'loss': 0.7047, 'grad_norm': 0.08694159239530563, 'learning_rate': 0.0012289697783842142, 'epoch': 2.34}\n",
            "{'loss': 0.8129, 'grad_norm': 0.07667011767625809, 'learning_rate': 0.0012007741992771065, 'epoch': 2.35}\n",
            "{'loss': 0.8512, 'grad_norm': 0.057331632822752, 'learning_rate': 0.0011728616220940031, 'epoch': 2.36}\n",
            "{'loss': 0.5053, 'grad_norm': 0.04588600993156433, 'learning_rate': 0.001145234126025102, 'epoch': 2.37}\n",
            "{'loss': 0.7871, 'grad_norm': 0.11660188436508179, 'learning_rate': 0.0011178937690250917, 'epoch': 2.38}\n",
            "{'loss': 0.5876, 'grad_norm': 0.08606133610010147, 'learning_rate': 0.001090842587659851, 'epoch': 2.38}\n",
            "{'loss': 0.8177, 'grad_norm': 0.0811668187379837, 'learning_rate': 0.0010640825969547496, 'epoch': 2.39}\n",
            "{'loss': 0.6548, 'grad_norm': 0.06497514992952347, 'learning_rate': 0.0010376157902445488, 'epoch': 2.4}\n",
            "{'loss': 0.8161, 'grad_norm': 0.060457874089479446, 'learning_rate': 0.00101144413902492, 'epoch': 2.41}\n",
            "{'loss': 0.5391, 'grad_norm': 0.053209081292152405, 'learning_rate': 0.000985569592805588, 'epoch': 2.42}\n",
            "{'loss': 0.5936, 'grad_norm': 0.04813089594244957, 'learning_rate': 0.0009599940789651179, 'epoch': 2.42}\n",
            "{'loss': 0.4445, 'grad_norm': 0.02979043498635292, 'learning_rate': 0.0009347195026073368, 'epoch': 2.43}\n",
            "{'loss': 0.7218, 'grad_norm': 0.04637189209461212, 'learning_rate': 0.000909747746419436, 'epoch': 2.44}\n",
            "{'loss': 1.3083, 'grad_norm': 0.21021224558353424, 'learning_rate': 0.0008850806705317183, 'epoch': 2.45}\n",
            "{'loss': 1.0608, 'grad_norm': 0.11109226942062378, 'learning_rate': 0.0008607201123790459, 'epoch': 2.46}\n",
            "{'loss': 0.6241, 'grad_norm': 0.043305277824401855, 'learning_rate': 0.0008366678865639688, 'epoch': 2.46}\n",
            "{'loss': 0.522, 'grad_norm': 0.030110949650406837, 'learning_rate': 0.0008129257847215571, 'epoch': 2.47}\n",
            "{'loss': 0.8818, 'grad_norm': 0.09405113756656647, 'learning_rate': 0.0007894955753859412, 'epoch': 2.48}\n",
            "{'loss': 0.7338, 'grad_norm': 0.08001604676246643, 'learning_rate': 0.0007663790038585794, 'epoch': 2.49}\n",
            "{'loss': 0.6829, 'grad_norm': 0.06570002436637878, 'learning_rate': 0.0007435777920782444, 'epoch': 2.5}\n",
            "{'loss': 0.6632, 'grad_norm': 0.07889652252197266, 'learning_rate': 0.000721093638492763, 'epoch': 2.5}\n",
            "{'loss': 0.6141, 'grad_norm': 0.048431701958179474, 'learning_rate': 0.0006989282179324963, 'epoch': 2.51}\n",
            "{'loss': 0.603, 'grad_norm': 0.07134298235177994, 'learning_rate': 0.0006770831814855883, 'epoch': 2.52}\n",
            "{'loss': 0.8627, 'grad_norm': 0.08615367859601974, 'learning_rate': 0.0006555601563749675, 'epoch': 2.53}\n",
            "{'loss': 0.449, 'grad_norm': 0.04057722166180611, 'learning_rate': 0.0006343607458371459, 'epoch': 2.54}\n",
            "{'loss': 0.8074, 'grad_norm': 0.06126871705055237, 'learning_rate': 0.0006134865290027902, 'epoch': 2.54}\n",
            "{'loss': 0.5794, 'grad_norm': 0.041179534047842026, 'learning_rate': 0.000592939060779093, 'epoch': 2.55}\n",
            "{'loss': 0.872, 'grad_norm': 0.09151362627744675, 'learning_rate': 0.000572719871733951, 'epoch': 2.56}\n",
            "{'loss': 0.6803, 'grad_norm': 0.08536804467439651, 'learning_rate': 0.0005528304679819513, 'epoch': 2.57}\n",
            "{'loss': 0.5487, 'grad_norm': 0.0482928641140461, 'learning_rate': 0.0005332723310721854, 'epoch': 2.58}\n",
            "{'loss': 1.0233, 'grad_norm': 0.10948791354894638, 'learning_rate': 0.0005140469178778845, 'epoch': 2.58}\n",
            "{'loss': 0.6979, 'grad_norm': 0.1157202273607254, 'learning_rate': 0.0004951556604879049, 'epoch': 2.59}\n",
            "{'loss': 0.766, 'grad_norm': 0.06981795281171799, 'learning_rate': 0.00047659996610004417, 'epoch': 2.6}\n",
            "{'loss': 0.5038, 'grad_norm': 0.03804049268364906, 'learning_rate': 0.00045838121691622993, 'epoch': 2.61}\n",
            "{'loss': 0.4495, 'grad_norm': 0.05131709575653076, 'learning_rate': 0.0004405007700395497, 'epoch': 2.62}\n",
            "{'loss': 0.6792, 'grad_norm': 0.07881386578083038, 'learning_rate': 0.0004229599573731685, 'epoch': 2.62}\n",
            "{'loss': 0.5192, 'grad_norm': 0.05233313888311386, 'learning_rate': 0.0004057600855211141, 'epoch': 2.63}\n",
            "{'loss': 0.6596, 'grad_norm': 0.08189950883388519, 'learning_rate': 0.00038890243569094876, 'epoch': 2.64}\n",
            "{'loss': 0.5447, 'grad_norm': 0.05534094199538231, 'learning_rate': 0.0003723882635983328, 'epoch': 2.65}\n",
            "{'loss': 0.8848, 'grad_norm': 0.10903316736221313, 'learning_rate': 0.00035621879937348835, 'epoch': 2.66}\n",
            "{'loss': 0.4884, 'grad_norm': 0.030028782784938812, 'learning_rate': 0.00034039524746956595, 'epoch': 2.66}\n",
            "{'loss': 0.5201, 'grad_norm': 0.02926110476255417, 'learning_rate': 0.0003249187865729264, 'epoch': 2.67}\n",
            "{'loss': 0.8471, 'grad_norm': 0.07864049077033997, 'learning_rate': 0.0003097905695153408, 'epoch': 2.68}\n",
            "{'loss': 0.9451, 'grad_norm': 0.15777446329593658, 'learning_rate': 0.0002950117231881183, 'epoch': 2.69}\n",
            "{'loss': 0.6271, 'grad_norm': 0.04716765508055687, 'learning_rate': 0.0002805833484581621, 'epoch': 2.7}\n",
            "{'loss': 0.4445, 'grad_norm': 0.03074263408780098, 'learning_rate': 0.00026650652008597067, 'epoch': 2.7}\n",
            "{'loss': 0.5185, 'grad_norm': 0.03459468483924866, 'learning_rate': 0.0002527822866455731, 'epoch': 2.71}\n",
            "{'loss': 0.5835, 'grad_norm': 0.07191337645053864, 'learning_rate': 0.00023941167044642941, 'epoch': 2.72}\n",
            "{'loss': 0.6818, 'grad_norm': 0.04392488673329353, 'learning_rate': 0.00022639566745727202, 'epoch': 2.73}\n",
            "{'loss': 0.6578, 'grad_norm': 0.08766612410545349, 'learning_rate': 0.0002137352472319215, 'epoch': 2.74}\n",
            "{'loss': 0.6296, 'grad_norm': 0.04626092314720154, 'learning_rate': 0.0002014313528370626, 'epoch': 2.74}\n",
            "{'loss': 0.5752, 'grad_norm': 0.05494171753525734, 'learning_rate': 0.00018948490078199765, 'epoch': 2.75}\n",
            "{'loss': 0.7844, 'grad_norm': 0.09146192669868469, 'learning_rate': 0.00017789678095037452, 'epoch': 2.76}\n",
            "{'loss': 0.8153, 'grad_norm': 0.10977411270141602, 'learning_rate': 0.0001666678565339025, 'epoch': 2.77}\n",
            "{'loss': 0.655, 'grad_norm': 0.027651652693748474, 'learning_rate': 0.0001557989639680496, 'epoch': 2.78}\n",
            "{'loss': 0.8167, 'grad_norm': 0.05804845690727234, 'learning_rate': 0.00014529091286973994, 'epoch': 2.78}\n",
            "{'loss': 0.7041, 'grad_norm': 0.06162426620721817, 'learning_rate': 0.0001351444859770462, 'epoch': 2.79}\n",
            "{'loss': 0.6774, 'grad_norm': 0.1179576888680458, 'learning_rate': 0.0001253604390908819, 'epoch': 2.8}\n",
            "{'loss': 0.6736, 'grad_norm': 0.07871566712856293, 'learning_rate': 0.0001159395010187042, 'epoch': 2.81}\n",
            "{'loss': 0.809, 'grad_norm': 0.08479037135839462, 'learning_rate': 0.00010688237352022346, 'epoch': 2.82}\n",
            "{'loss': 0.6039, 'grad_norm': 0.05801083520054817, 'learning_rate': 9.818973125513276e-05, 'epoch': 2.82}\n",
            "{'loss': 0.5376, 'grad_norm': 0.03510928899049759, 'learning_rate': 8.986222173284874e-05, 'epoch': 2.83}\n",
            "{'loss': 0.5827, 'grad_norm': 0.04867207258939743, 'learning_rate': 8.190046526428241e-05, 'epoch': 2.84}\n",
            "{'loss': 0.4339, 'grad_norm': 0.0293666310608387, 'learning_rate': 7.4305054915631e-05, 'epoch': 2.85}\n",
            "{'loss': 0.5687, 'grad_norm': 0.035980138927698135, 'learning_rate': 6.707655646420229e-05, 'epoch': 2.86}\n",
            "{'loss': 0.7877, 'grad_norm': 0.08056122809648514, 'learning_rate': 6.0215508356267765e-05, 'epoch': 2.86}\n",
            "{'loss': 0.78, 'grad_norm': 0.09906896948814392, 'learning_rate': 5.372242166695684e-05, 'epoch': 2.87}\n",
            "{'loss': 0.7137, 'grad_norm': 0.0811951532959938, 'learning_rate': 4.759778006218407e-05, 'epoch': 2.88}\n",
            "{'loss': 0.5183, 'grad_norm': 0.03978325054049492, 'learning_rate': 4.184203976262513e-05, 'epoch': 2.89}\n",
            "{'loss': 0.6588, 'grad_norm': 0.06595346331596375, 'learning_rate': 3.645562950973014e-05, 'epoch': 2.9}\n",
            "{'loss': 0.5142, 'grad_norm': 0.04364939406514168, 'learning_rate': 3.143895053378698e-05, 'epoch': 2.9}\n",
            "{'loss': 0.6567, 'grad_norm': 0.058229558169841766, 'learning_rate': 2.6792376524036878e-05, 'epoch': 2.91}\n",
            "{'loss': 0.8351, 'grad_norm': 0.06788686662912369, 'learning_rate': 2.2516253600833868e-05, 'epoch': 2.92}\n",
            "{'loss': 0.5529, 'grad_norm': 0.05154049023985863, 'learning_rate': 1.8610900289867673e-05, 'epoch': 2.93}\n",
            "{'loss': 0.7421, 'grad_norm': 0.08533374965190887, 'learning_rate': 1.5076607498433204e-05, 'epoch': 2.94}\n",
            "{'loss': 0.8294, 'grad_norm': 0.07491135597229004, 'learning_rate': 1.1913638493762369e-05, 'epoch': 2.94}\n",
            "{'loss': 0.8282, 'grad_norm': 0.0740666538476944, 'learning_rate': 9.12222888341252e-06, 'epoch': 2.95}\n",
            "{'loss': 0.9922, 'grad_norm': 0.1072191670536995, 'learning_rate': 6.702586597719385e-06, 'epoch': 2.96}\n",
            "{'loss': 0.5347, 'grad_norm': 0.03133361041545868, 'learning_rate': 4.654891874303346e-06, 'epoch': 2.97}\n",
            "{'loss': 0.5513, 'grad_norm': 0.04475996270775795, 'learning_rate': 2.9792972446479605e-06, 'epoch': 2.98}\n",
            "{'loss': 0.8299, 'grad_norm': 0.12594793736934662, 'learning_rate': 1.6759275227357095e-06, 'epoch': 2.98}\n",
            "{'loss': 0.6151, 'grad_norm': 0.045620255172252655, 'learning_rate': 7.448797957526621e-07, 'epoch': 2.99}\n",
            "{'loss': 0.6796, 'grad_norm': 0.08422479033470154, 'learning_rate': 1.862234168542587e-07, 'epoch': 3.0}\n",
            "{'train_runtime': 67.9763, 'train_samples_per_second': 11.033, 'train_steps_per_second': 5.517, 'train_loss': 1.3396412380536398, 'epoch': 3.0}\n",
            "100% 375/375 [01:07<00:00,  5.52it/s]\n",
            "Training complete.\n",
            "Model saved to loras/self-edit/training_set_iteration_1/8d5021e8/6\n",
            "Training on 250 examples for 2 epochs, lr: 0.001\n",
            "No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n",
            "Starting training...\n",
            "{'loss': 7.387, 'grad_norm': 10.39545726776123, 'learning_rate': 0.0, 'epoch': 0.01}\n",
            "{'loss': 6.5478, 'grad_norm': 7.91605806350708, 'learning_rate': 9.090909090909092e-05, 'epoch': 0.02}\n",
            "{'loss': 5.6327, 'grad_norm': 9.0658597946167, 'learning_rate': 0.00018181818181818183, 'epoch': 0.02}\n",
            "{'loss': 1.444, 'grad_norm': 7.364806175231934, 'learning_rate': 0.00027272727272727274, 'epoch': 0.03}\n",
            "{'loss': 2.6111, 'grad_norm': 18.24998664855957, 'learning_rate': 0.00036363636363636367, 'epoch': 0.04}\n",
            "{'loss': 0.5551, 'grad_norm': 2.486947774887085, 'learning_rate': 0.00045454545454545455, 'epoch': 0.05}\n",
            "{'loss': 0.5211, 'grad_norm': 0.2368614822626114, 'learning_rate': 0.0005454545454545455, 'epoch': 0.06}\n",
            "{'loss': 0.4694, 'grad_norm': 0.21593928337097168, 'learning_rate': 0.0006363636363636364, 'epoch': 0.06}\n",
            "{'loss': 0.448, 'grad_norm': 0.22957146167755127, 'learning_rate': 0.0007272727272727273, 'epoch': 0.07}\n",
            "{'loss': 0.405, 'grad_norm': 0.1402118057012558, 'learning_rate': 0.0008181818181818183, 'epoch': 0.08}\n",
            "{'loss': 0.3478, 'grad_norm': 0.114064060151577, 'learning_rate': 0.0009090909090909091, 'epoch': 0.09}\n",
            "{'loss': 0.297, 'grad_norm': 0.11381310224533081, 'learning_rate': 0.001, 'epoch': 0.1}\n",
            "{'loss': 0.2553, 'grad_norm': 0.09030713140964508, 'learning_rate': 0.0009999568045802217, 'epoch': 0.1}\n",
            "{'loss': 0.2099, 'grad_norm': 0.10581663995981216, 'learning_rate': 0.000999827225784264, 'epoch': 0.11}\n",
            "{'loss': 0.1893, 'grad_norm': 0.10216741263866425, 'learning_rate': 0.0009996112860009686, 'epoch': 0.12}\n",
            "{'loss': 0.1436, 'grad_norm': 0.07344797998666763, 'learning_rate': 0.0009993090225407742, 'epoch': 0.13}\n",
            "{'loss': 0.1195, 'grad_norm': 0.08638165891170502, 'learning_rate': 0.0009989204876292687, 'epoch': 0.14}\n",
            "{'loss': 0.0862, 'grad_norm': 0.06707249581813812, 'learning_rate': 0.0009984457483981667, 'epoch': 0.14}\n",
            "{'loss': 0.0796, 'grad_norm': 0.07297017425298691, 'learning_rate': 0.0009978848868737098, 'epoch': 0.15}\n",
            "{'loss': 0.0701, 'grad_norm': 0.07101356238126755, 'learning_rate': 0.0009972379999624934, 'epoch': 0.16}\n",
            "{'loss': 0.0612, 'grad_norm': 0.06687460839748383, 'learning_rate': 0.000996505199434725, 'epoch': 0.17}\n",
            "{'loss': 0.086, 'grad_norm': 0.15004786849021912, 'learning_rate': 0.0009956866119049095, 'epoch': 0.18}\n",
            "{'loss': 0.062, 'grad_norm': 0.09663016349077225, 'learning_rate': 0.0009947823788099752, 'epoch': 0.18}\n",
            "{'loss': 0.0631, 'grad_norm': 0.10487386584281921, 'learning_rate': 0.0009937926563848346, 'epoch': 0.19}\n",
            "{'loss': 0.1019, 'grad_norm': 0.1975572407245636, 'learning_rate': 0.0009927176156353898, 'epoch': 0.2}\n",
            "{'loss': 0.056, 'grad_norm': 0.0658525675535202, 'learning_rate': 0.000991557442308987, 'epoch': 0.21}\n",
            "{'loss': 0.0648, 'grad_norm': 0.13388659060001373, 'learning_rate': 0.0009903123368623214, 'epoch': 0.22}\n",
            "{'loss': 0.0905, 'grad_norm': 0.10173247754573822, 'learning_rate': 0.0009889825144268028, 'epoch': 0.22}\n",
            "{'loss': 0.0661, 'grad_norm': 0.05375135689973831, 'learning_rate': 0.0009875682047713846, 'epoch': 0.23}\n",
            "{'loss': 0.0509, 'grad_norm': 0.05464256554841995, 'learning_rate': 0.0009860696522628637, 'epoch': 0.24}\n",
            "{'loss': 0.0633, 'grad_norm': 0.04964828118681908, 'learning_rate': 0.000984487115823659, 'epoch': 0.25}\n",
            "{'loss': 0.0568, 'grad_norm': 0.05422334372997284, 'learning_rate': 0.0009828208688870735, 'epoch': 0.26}\n",
            "{'loss': 0.0509, 'grad_norm': 0.04388773441314697, 'learning_rate': 0.0009810711993500506, 'epoch': 0.26}\n",
            "{'loss': 0.0543, 'grad_norm': 0.07756995409727097, 'learning_rate': 0.0009792384095234313, 'epoch': 0.27}\n",
            "{'loss': 0.0519, 'grad_norm': 0.05191599950194359, 'learning_rate': 0.0009773228160797186, 'epoch': 0.28}\n",
            "{'loss': 0.0463, 'grad_norm': 0.04332103207707405, 'learning_rate': 0.0009753247499983648, 'epoch': 0.29}\n",
            "{'loss': 0.0364, 'grad_norm': 0.035949546843767166, 'learning_rate': 0.0009732445565085823, 'epoch': 0.3}\n",
            "{'loss': 0.0472, 'grad_norm': 0.06266546994447708, 'learning_rate': 0.0009710825950296949, 'epoch': 0.3}\n",
            "{'loss': 0.0411, 'grad_norm': 0.06143355742096901, 'learning_rate': 0.0009688392391090372, 'epoch': 0.31}\n",
            "{'loss': 0.041, 'grad_norm': 0.07177369296550751, 'learning_rate': 0.0009665148763574123, 'epoch': 0.32}\n",
            "{'loss': 0.0292, 'grad_norm': 0.03935040161013603, 'learning_rate': 0.000964109908382119, 'epoch': 0.33}\n",
            "{'loss': 0.0424, 'grad_norm': 0.06036412715911865, 'learning_rate': 0.0009616247507175622, 'epoch': 0.34}\n",
            "{'loss': 0.0266, 'grad_norm': 0.05862639844417572, 'learning_rate': 0.0009590598327534563, 'epoch': 0.34}\n",
            "{'loss': 0.0374, 'grad_norm': 0.08064400404691696, 'learning_rate': 0.0009564155976606339, 'epoch': 0.35}\n",
            "{'loss': 0.0216, 'grad_norm': 0.043167296797037125, 'learning_rate': 0.0009536925023144741, 'epoch': 0.36}\n",
            "{'loss': 0.0335, 'grad_norm': 0.062367212027311325, 'learning_rate': 0.0009508910172159635, 'epoch': 0.37}\n",
            "{'loss': 0.0263, 'grad_norm': 0.051768720149993896, 'learning_rate': 0.0009480116264104011, 'epoch': 0.38}\n",
            "{'loss': 0.0253, 'grad_norm': 0.04430693760514259, 'learning_rate': 0.0009450548274037653, 'epoch': 0.38}\n",
            "{'loss': 0.0281, 'grad_norm': 0.04480094835162163, 'learning_rate': 0.0009420211310767532, 'epoch': 0.39}\n",
            "{'loss': 0.0231, 'grad_norm': 0.05149254575371742, 'learning_rate': 0.0009389110615965102, 'epoch': 0.4}\n",
            "{'loss': 0.0207, 'grad_norm': 0.08244547247886658, 'learning_rate': 0.000935725156326063, 'epoch': 0.41}\n",
            "{'loss': 0.0312, 'grad_norm': 0.06662960350513458, 'learning_rate': 0.0009324639657314742, 'epoch': 0.42}\n",
            "{'loss': 0.0265, 'grad_norm': 0.051725659519433975, 'learning_rate': 0.0009291280532867302, 'epoch': 0.42}\n",
            "{'loss': 0.0162, 'grad_norm': 0.029025856405496597, 'learning_rate': 0.0009257179953763846, 'epoch': 0.43}\n",
            "{'loss': 0.0191, 'grad_norm': 0.02859046310186386, 'learning_rate': 0.0009222343811959693, 'epoch': 0.44}\n",
            "{'loss': 0.0189, 'grad_norm': 0.04806183651089668, 'learning_rate': 0.0009186778126501916, 'epoch': 0.45}\n",
            "{'loss': 0.0243, 'grad_norm': 0.07893823087215424, 'learning_rate': 0.0009150489042489367, 'epoch': 0.46}\n",
            "{'loss': 0.0216, 'grad_norm': 0.04148146137595177, 'learning_rate': 0.0009113482830010917, 'epoch': 0.46}\n",
            "{'loss': 0.026, 'grad_norm': 0.059815049171447754, 'learning_rate': 0.0009075765883062093, 'epoch': 0.47}\n",
            "{'loss': 0.0162, 'grad_norm': 0.027062956243753433, 'learning_rate': 0.0009037344718440322, 'epoch': 0.48}\n",
            "{'loss': 0.0249, 'grad_norm': 0.04601219296455383, 'learning_rate': 0.0008998225974618939, 'epoch': 0.49}\n",
            "{'loss': 0.0235, 'grad_norm': 0.04185706377029419, 'learning_rate': 0.0008958416410600187, 'epoch': 0.5}\n",
            "{'loss': 0.023, 'grad_norm': 0.037421051412820816, 'learning_rate': 0.0008917922904747384, 'epoch': 0.5}\n",
            "{'loss': 0.0191, 'grad_norm': 0.019384700804948807, 'learning_rate': 0.0008876752453596462, 'epoch': 0.51}\n",
            "{'loss': 0.0215, 'grad_norm': 0.043572962284088135, 'learning_rate': 0.00088349121706471, 'epoch': 0.52}\n",
            "{'loss': 0.0276, 'grad_norm': 0.060093365609645844, 'learning_rate': 0.0008792409285133643, 'epoch': 0.53}\n",
            "{'loss': 0.0204, 'grad_norm': 0.038675177842378616, 'learning_rate': 0.0008749251140776016, 'epoch': 0.54}\n",
            "{'loss': 0.0274, 'grad_norm': 0.05465592071413994, 'learning_rate': 0.0008705445194510869, 'epoch': 0.54}\n",
            "{'loss': 0.0228, 'grad_norm': 0.04977099969983101, 'learning_rate': 0.000866099901520315, 'epoch': 0.55}\n",
            "{'loss': 0.0173, 'grad_norm': 0.02762187272310257, 'learning_rate': 0.0008615920282338354, 'epoch': 0.56}\n",
            "{'loss': 0.0179, 'grad_norm': 0.023454273119568825, 'learning_rate': 0.0008570216784695636, 'epoch': 0.57}\n",
            "{'loss': 0.0251, 'grad_norm': 0.07051374763250351, 'learning_rate': 0.000852389641900206, 'epoch': 0.58}\n",
            "{'loss': 0.0114, 'grad_norm': 0.01404070295393467, 'learning_rate': 0.0008476967188568188, 'epoch': 0.58}\n",
            "{'loss': 0.0233, 'grad_norm': 0.04028180614113808, 'learning_rate': 0.0008429437201905253, 'epoch': 0.59}\n",
            "{'loss': 0.023, 'grad_norm': 0.04498942941427231, 'learning_rate': 0.000838131467132416, 'epoch': 0.6}\n",
            "{'loss': 0.036, 'grad_norm': 0.06950265169143677, 'learning_rate': 0.0008332607911516546, 'epoch': 0.61}\n",
            "{'loss': 0.016, 'grad_norm': 0.01838885433971882, 'learning_rate': 0.0008283325338118153, 'epoch': 0.62}\n",
            "{'loss': 0.0206, 'grad_norm': 0.04455702751874924, 'learning_rate': 0.0008233475466254765, 'epoch': 0.62}\n",
            "{'loss': 0.0143, 'grad_norm': 0.03662598133087158, 'learning_rate': 0.0008183066909070946, 'epoch': 0.63}\n",
            "{'loss': 0.0158, 'grad_norm': 0.04007729887962341, 'learning_rate': 0.0008132108376241848, 'epoch': 0.64}\n",
            "{'loss': 0.0153, 'grad_norm': 0.027901073917746544, 'learning_rate': 0.0008080608672468339, 'epoch': 0.65}\n",
            "{'loss': 0.0156, 'grad_norm': 0.04918478801846504, 'learning_rate': 0.0008028576695955711, 'epoch': 0.66}\n",
            "{'loss': 0.02, 'grad_norm': 0.05274633690714836, 'learning_rate': 0.0007976021436876231, 'epoch': 0.66}\n",
            "{'loss': 0.0165, 'grad_norm': 0.019313836470246315, 'learning_rate': 0.0007922951975815811, 'epoch': 0.67}\n",
            "{'loss': 0.0192, 'grad_norm': 0.026081228628754616, 'learning_rate': 0.0007869377482205041, 'epoch': 0.68}\n",
            "{'loss': 0.0278, 'grad_norm': 0.07421823590993881, 'learning_rate': 0.0007815307212734888, 'epoch': 0.69}\n",
            "{'loss': 0.0142, 'grad_norm': 0.01683487370610237, 'learning_rate': 0.0007760750509757298, 'epoch': 0.7}\n",
            "{'loss': 0.0129, 'grad_norm': 0.03866836801171303, 'learning_rate': 0.0007705716799671019, 'epoch': 0.7}\n",
            "{'loss': 0.016, 'grad_norm': 0.037348706275224686, 'learning_rate': 0.0007650215591292888, 'epoch': 0.71}\n",
            "{'loss': 0.0157, 'grad_norm': 0.040115151554346085, 'learning_rate': 0.0007594256474214883, 'epoch': 0.72}\n",
            "{'loss': 0.0134, 'grad_norm': 0.03630370274186134, 'learning_rate': 0.0007537849117147212, 'epoch': 0.73}\n",
            "{'loss': 0.0147, 'grad_norm': 0.029531678184866905, 'learning_rate': 0.0007481003266247745, 'epoch': 0.74}\n",
            "{'loss': 0.0207, 'grad_norm': 0.05334261432290077, 'learning_rate': 0.0007423728743438049, 'epoch': 0.74}\n",
            "{'loss': 0.0153, 'grad_norm': 0.032392218708992004, 'learning_rate': 0.0007366035444706345, 'epoch': 0.75}\n",
            "{'loss': 0.0177, 'grad_norm': 0.04610047489404678, 'learning_rate': 0.0007307933338397667, 'epoch': 0.76}\n",
            "{'loss': 0.0169, 'grad_norm': 0.0491875521838665, 'learning_rate': 0.0007249432463491498, 'epoch': 0.77}\n",
            "{'loss': 0.016, 'grad_norm': 0.07989521324634552, 'learning_rate': 0.0007190542927867234, 'epoch': 0.78}\n",
            "{'loss': 0.0153, 'grad_norm': 0.05096728727221489, 'learning_rate': 0.0007131274906557724, 'epoch': 0.78}\n",
            "{'loss': 0.0197, 'grad_norm': 0.03539573773741722, 'learning_rate': 0.0007071638639991206, 'epoch': 0.79}\n",
            "{'loss': 0.0131, 'grad_norm': 0.056990355253219604, 'learning_rate': 0.0007011644432221957, 'epoch': 0.8}\n",
            "{'loss': 0.0139, 'grad_norm': 0.027630407363176346, 'learning_rate': 0.000695130264914993, 'epoch': 0.81}\n",
            "{'loss': 0.0126, 'grad_norm': 0.019824298098683357, 'learning_rate': 0.0006890623716729724, 'epoch': 0.82}\n",
            "{'loss': 0.0241, 'grad_norm': 0.09725978225469589, 'learning_rate': 0.0006829618119169169, 'epoch': 0.82}\n",
            "{'loss': 0.0127, 'grad_norm': 0.014843475073575974, 'learning_rate': 0.0006768296397117848, 'epoch': 0.83}\n",
            "{'loss': 0.02, 'grad_norm': 0.03193162381649017, 'learning_rate': 0.0006706669145845863, 'epoch': 0.84}\n",
            "{'loss': 0.0203, 'grad_norm': 0.061789873987436295, 'learning_rate': 0.0006644747013413168, 'epoch': 0.85}\n",
            "{'loss': 0.0156, 'grad_norm': 0.022982116788625717, 'learning_rate': 0.0006582540698829781, 'epoch': 0.86}\n",
            "{'loss': 0.0204, 'grad_norm': 0.049026839435100555, 'learning_rate': 0.0006520060950207185, 'epoch': 0.86}\n",
            "{'loss': 0.0138, 'grad_norm': 0.02004534937441349, 'learning_rate': 0.0006457318562901257, 'epoch': 0.87}\n",
            "{'loss': 0.0105, 'grad_norm': 0.021224509924650192, 'learning_rate': 0.0006394324377647027, 'epoch': 0.88}\n",
            "{'loss': 0.0177, 'grad_norm': 0.057359252125024796, 'learning_rate': 0.0006331089278685599, 'epoch': 0.89}\n",
            "{'loss': 0.0241, 'grad_norm': 0.05953085049986839, 'learning_rate': 0.000626762419188355, 'epoch': 0.9}\n",
            "{'loss': 0.0154, 'grad_norm': 0.02285964973270893, 'learning_rate': 0.0006203940082845144, 'epoch': 0.9}\n",
            "{'loss': 0.0106, 'grad_norm': 0.01420313399285078, 'learning_rate': 0.0006140047955017671, 'epoch': 0.91}\n",
            "{'loss': 0.0131, 'grad_norm': 0.030019011348485947, 'learning_rate': 0.0006075958847790261, 'epoch': 0.92}\n",
            "{'loss': 0.0161, 'grad_norm': 0.0275148656219244, 'learning_rate': 0.0006011683834586473, 'epoch': 0.93}\n",
            "{'loss': 0.0106, 'grad_norm': 0.01654505357146263, 'learning_rate': 0.0005947234020951015, 'epoch': 0.94}\n",
            "{'loss': 0.0165, 'grad_norm': 0.043539632111787796, 'learning_rate': 0.0005882620542630901, 'epoch': 0.94}\n",
            "{'loss': 0.0148, 'grad_norm': 0.049592938274145126, 'learning_rate': 0.0005817854563651415, 'epoch': 0.95}\n",
            "{'loss': 0.0146, 'grad_norm': 0.07141931354999542, 'learning_rate': 0.0005752947274387147, 'epoch': 0.96}\n",
            "{'loss': 0.0151, 'grad_norm': 0.03606858849525452, 'learning_rate': 0.0005687909889628529, 'epoch': 0.97}\n",
            "{'loss': 0.0118, 'grad_norm': 0.01545324083417654, 'learning_rate': 0.0005622753646644102, 'epoch': 0.98}\n",
            "{'loss': 0.0116, 'grad_norm': 0.014373905025422573, 'learning_rate': 0.0005557489803238934, 'epoch': 0.98}\n",
            "{'loss': 0.0145, 'grad_norm': 0.025170249864459038, 'learning_rate': 0.0005492129635809473, 'epoch': 0.99}\n",
            "{'loss': 0.0158, 'grad_norm': 0.036746978759765625, 'learning_rate': 0.0005426684437395196, 'epoch': 1.0}\n",
            "{'loss': 0.0181, 'grad_norm': 0.04530743882060051, 'learning_rate': 0.0005361165515727375, 'epoch': 1.01}\n",
            "{'loss': 0.0121, 'grad_norm': 0.024575458839535713, 'learning_rate': 0.0005295584191275308, 'epoch': 1.02}\n",
            "{'loss': 0.0123, 'grad_norm': 0.023116741329431534, 'learning_rate': 0.0005229951795290352, 'epoch': 1.02}\n",
            "{'loss': 0.0176, 'grad_norm': 0.050511252135038376, 'learning_rate': 0.0005164279667848094, 'epoch': 1.03}\n",
            "{'loss': 0.0151, 'grad_norm': 0.035310983657836914, 'learning_rate': 0.0005098579155888978, 'epoch': 1.04}\n",
            "{'loss': 0.0094, 'grad_norm': 0.013897654600441456, 'learning_rate': 0.0005032861611257783, 'epoch': 1.05}\n",
            "{'loss': 0.0092, 'grad_norm': 0.018175339326262474, 'learning_rate': 0.0004967138388742218, 'epoch': 1.06}\n",
            "{'loss': 0.0072, 'grad_norm': 0.012373266741633415, 'learning_rate': 0.0004901420844111021, 'epoch': 1.06}\n",
            "{'loss': 0.0154, 'grad_norm': 0.027338793501257896, 'learning_rate': 0.0004835720332151907, 'epoch': 1.07}\n",
            "{'loss': 0.0113, 'grad_norm': 0.01479667704552412, 'learning_rate': 0.00047700482047096477, 'epoch': 1.08}\n",
            "{'loss': 0.0106, 'grad_norm': 0.016052402555942535, 'learning_rate': 0.00047044158087246926, 'epoch': 1.09}\n",
            "{'loss': 0.011, 'grad_norm': 0.019819160923361778, 'learning_rate': 0.00046388344842726267, 'epoch': 1.1}\n",
            "{'loss': 0.0106, 'grad_norm': 0.028374450281262398, 'learning_rate': 0.00045733155626048033, 'epoch': 1.1}\n",
            "{'loss': 0.0157, 'grad_norm': 0.032783664762973785, 'learning_rate': 0.00045078703641905274, 'epoch': 1.11}\n",
            "{'loss': 0.0103, 'grad_norm': 0.016916656866669655, 'learning_rate': 0.00044425101967610677, 'epoch': 1.12}\n",
            "{'loss': 0.0072, 'grad_norm': 0.010953324846923351, 'learning_rate': 0.00043772463533558987, 'epoch': 1.13}\n",
            "{'loss': 0.014, 'grad_norm': 0.01828116364777088, 'learning_rate': 0.00043120901103714727, 'epoch': 1.14}\n",
            "{'loss': 0.0134, 'grad_norm': 0.04039441794157028, 'learning_rate': 0.0004247052725612852, 'epoch': 1.14}\n",
            "{'loss': 0.0105, 'grad_norm': 0.021209802478551865, 'learning_rate': 0.0004182145436348587, 'epoch': 1.15}\n",
            "{'loss': 0.0131, 'grad_norm': 0.017245858907699585, 'learning_rate': 0.0004117379457369099, 'epoch': 1.16}\n",
            "{'loss': 0.0125, 'grad_norm': 0.06262823939323425, 'learning_rate': 0.00040527659790489865, 'epoch': 1.17}\n",
            "{'loss': 0.0134, 'grad_norm': 0.033865101635456085, 'learning_rate': 0.00039883161654135274, 'epoch': 1.18}\n",
            "{'loss': 0.0084, 'grad_norm': 0.008915280923247337, 'learning_rate': 0.0003924041152209739, 'epoch': 1.18}\n",
            "{'loss': 0.0082, 'grad_norm': 0.011043376289308071, 'learning_rate': 0.0003859952044982329, 'epoch': 1.19}\n",
            "{'loss': 0.014, 'grad_norm': 0.027615947648882866, 'learning_rate': 0.0003796059917154857, 'epoch': 1.2}\n",
            "{'loss': 0.0108, 'grad_norm': 0.011961326003074646, 'learning_rate': 0.00037323758081164504, 'epoch': 1.21}\n",
            "{'loss': 0.0152, 'grad_norm': 0.03716212883591652, 'learning_rate': 0.00036689107213144025, 'epoch': 1.22}\n",
            "{'loss': 0.0116, 'grad_norm': 0.013821604661643505, 'learning_rate': 0.0003605675622352973, 'epoch': 1.22}\n",
            "{'loss': 0.014, 'grad_norm': 0.029023796319961548, 'learning_rate': 0.0003542681437098745, 'epoch': 1.23}\n",
            "{'loss': 0.0133, 'grad_norm': 0.01891043595969677, 'learning_rate': 0.00034799390497928167, 'epoch': 1.24}\n",
            "{'loss': 0.0119, 'grad_norm': 0.03798961639404297, 'learning_rate': 0.00034174593011702194, 'epoch': 1.25}\n",
            "{'loss': 0.01, 'grad_norm': 0.015456916764378548, 'learning_rate': 0.0003355252986586832, 'epoch': 1.26}\n",
            "{'loss': 0.013, 'grad_norm': 0.014780716970562935, 'learning_rate': 0.00032933308541541363, 'epoch': 1.26}\n",
            "{'loss': 0.0075, 'grad_norm': 0.009556267410516739, 'learning_rate': 0.00032317036028821523, 'epoch': 1.27}\n",
            "{'loss': 0.0135, 'grad_norm': 0.034571461379528046, 'learning_rate': 0.00031703818808308324, 'epoch': 1.28}\n",
            "{'loss': 0.0095, 'grad_norm': 0.012864700518548489, 'learning_rate': 0.00031093762832702773, 'epoch': 1.29}\n",
            "{'loss': 0.009, 'grad_norm': 0.011475694365799427, 'learning_rate': 0.0003048697350850073, 'epoch': 1.3}\n",
            "{'loss': 0.0101, 'grad_norm': 0.018239373341202736, 'learning_rate': 0.00029883555677780426, 'epoch': 1.3}\n",
            "{'loss': 0.014, 'grad_norm': 0.021910568699240685, 'learning_rate': 0.0002928361360008793, 'epoch': 1.31}\n",
            "{'loss': 0.0129, 'grad_norm': 0.04498625174164772, 'learning_rate': 0.0002868725093442277, 'epoch': 1.32}\n",
            "{'loss': 0.0083, 'grad_norm': 0.008299130946397781, 'learning_rate': 0.0002809457072132766, 'epoch': 1.33}\n",
            "{'loss': 0.0123, 'grad_norm': 0.017101770266890526, 'learning_rate': 0.00027505675365085036, 'epoch': 1.34}\n",
            "{'loss': 0.0078, 'grad_norm': 0.010737006552517414, 'learning_rate': 0.0002692066661602333, 'epoch': 1.34}\n",
            "{'loss': 0.0134, 'grad_norm': 0.021596863865852356, 'learning_rate': 0.00026339645552936536, 'epoch': 1.35}\n",
            "{'loss': 0.0102, 'grad_norm': 0.01062471978366375, 'learning_rate': 0.00025762712565619527, 'epoch': 1.36}\n",
            "{'loss': 0.013, 'grad_norm': 0.017036093398928642, 'learning_rate': 0.00025189967337522573, 'epoch': 1.37}\n",
            "{'loss': 0.015, 'grad_norm': 0.015115419402718544, 'learning_rate': 0.000246215088285279, 'epoch': 1.38}\n",
            "{'loss': 0.0116, 'grad_norm': 0.012364692986011505, 'learning_rate': 0.00024057435257851173, 'epoch': 1.38}\n",
            "{'loss': 0.0143, 'grad_norm': 0.01680678129196167, 'learning_rate': 0.0002349784408707112, 'epoch': 1.39}\n",
            "{'loss': 0.008, 'grad_norm': 0.012084942311048508, 'learning_rate': 0.0002294283200328982, 'epoch': 1.4}\n",
            "{'loss': 0.0095, 'grad_norm': 0.011003663763403893, 'learning_rate': 0.00022392494902427024, 'epoch': 1.41}\n",
            "{'loss': 0.0119, 'grad_norm': 0.015708917751908302, 'learning_rate': 0.00021846927872651135, 'epoch': 1.42}\n",
            "{'loss': 0.0152, 'grad_norm': 0.0179818756878376, 'learning_rate': 0.00021306225177949585, 'epoch': 1.42}\n",
            "{'loss': 0.0139, 'grad_norm': 0.013421489857137203, 'learning_rate': 0.000207704802418419, 'epoch': 1.43}\n",
            "{'loss': 0.0118, 'grad_norm': 0.014125070534646511, 'learning_rate': 0.00020239785631237707, 'epoch': 1.44}\n",
            "{'loss': 0.0099, 'grad_norm': 0.012364456430077553, 'learning_rate': 0.00019714233040442914, 'epoch': 1.45}\n",
            "{'loss': 0.0131, 'grad_norm': 0.012695721350610256, 'learning_rate': 0.00019193913275316625, 'epoch': 1.46}\n",
            "{'loss': 0.012, 'grad_norm': 0.0155739551410079, 'learning_rate': 0.00018678916237581522, 'epoch': 1.46}\n",
            "{'loss': 0.0121, 'grad_norm': 0.012638421729207039, 'learning_rate': 0.00018169330909290548, 'epoch': 1.47}\n",
            "{'loss': 0.0094, 'grad_norm': 0.013132957741618156, 'learning_rate': 0.00017665245337452368, 'epoch': 1.48}\n",
            "{'loss': 0.0152, 'grad_norm': 0.02348143421113491, 'learning_rate': 0.00017166746618818478, 'epoch': 1.49}\n",
            "{'loss': 0.0136, 'grad_norm': 0.01842948980629444, 'learning_rate': 0.0001667392088483456, 'epoch': 1.5}\n",
            "{'loss': 0.0097, 'grad_norm': 0.012681764550507069, 'learning_rate': 0.00016186853286758395, 'epoch': 1.5}\n",
            "{'loss': 0.01, 'grad_norm': 0.013401314616203308, 'learning_rate': 0.00015705627980947467, 'epoch': 1.51}\n",
            "{'loss': 0.0103, 'grad_norm': 0.018268274143338203, 'learning_rate': 0.00015230328114318125, 'epoch': 1.52}\n",
            "{'loss': 0.0135, 'grad_norm': 0.016762275248765945, 'learning_rate': 0.00014761035809979396, 'epoch': 1.53}\n",
            "{'loss': 0.0098, 'grad_norm': 0.012606989592313766, 'learning_rate': 0.00014297832153043654, 'epoch': 1.54}\n",
            "{'loss': 0.01, 'grad_norm': 0.009203698486089706, 'learning_rate': 0.00013840797176616467, 'epoch': 1.54}\n",
            "{'loss': 0.0104, 'grad_norm': 0.021089723333716393, 'learning_rate': 0.00013390009847968505, 'epoch': 1.55}\n",
            "{'loss': 0.0116, 'grad_norm': 0.013295326381921768, 'learning_rate': 0.00012945548054891322, 'epoch': 1.56}\n",
            "{'loss': 0.0086, 'grad_norm': 0.0101632634177804, 'learning_rate': 0.00012507488592239846, 'epoch': 1.57}\n",
            "{'loss': 0.0131, 'grad_norm': 0.011315866373479366, 'learning_rate': 0.00012075907148663578, 'epoch': 1.58}\n",
            "{'loss': 0.0117, 'grad_norm': 0.026478908956050873, 'learning_rate': 0.00011650878293528994, 'epoch': 1.58}\n",
            "{'loss': 0.0087, 'grad_norm': 0.007751167751848698, 'learning_rate': 0.00011232475464035386, 'epoch': 1.59}\n",
            "{'loss': 0.0117, 'grad_norm': 0.01676691509783268, 'learning_rate': 0.00010820770952526154, 'epoch': 1.6}\n",
            "{'loss': 0.0114, 'grad_norm': 0.013462464325129986, 'learning_rate': 0.00010415835893998116, 'epoch': 1.61}\n",
            "{'loss': 0.0124, 'grad_norm': 0.019298112019896507, 'learning_rate': 0.00010017740253810609, 'epoch': 1.62}\n",
            "{'loss': 0.0085, 'grad_norm': 0.011888648383319378, 'learning_rate': 9.62655281559679e-05, 'epoch': 1.62}\n",
            "{'loss': 0.0108, 'grad_norm': 0.040030986070632935, 'learning_rate': 9.242341169379076e-05, 'epoch': 1.63}\n",
            "{'loss': 0.0098, 'grad_norm': 0.01335285883396864, 'learning_rate': 8.865171699890834e-05, 'epoch': 1.64}\n",
            "{'loss': 0.0089, 'grad_norm': 0.012245319783687592, 'learning_rate': 8.49510957510633e-05, 'epoch': 1.65}\n",
            "{'loss': 0.0099, 'grad_norm': 0.009751287288963795, 'learning_rate': 8.132218734980851e-05, 'epoch': 1.66}\n",
            "{'loss': 0.0073, 'grad_norm': 0.010089496150612831, 'learning_rate': 7.776561880403072e-05, 'epoch': 1.66}\n",
            "{'loss': 0.0124, 'grad_norm': 0.016147099435329437, 'learning_rate': 7.428200462361539e-05, 'epoch': 1.67}\n",
            "{'loss': 0.0122, 'grad_norm': 0.01865672692656517, 'learning_rate': 7.087194671326985e-05, 'epoch': 1.68}\n",
            "{'loss': 0.0131, 'grad_norm': 0.015567454509437084, 'learning_rate': 6.75360342685259e-05, 'epoch': 1.69}\n",
            "{'loss': 0.0113, 'grad_norm': 0.013974444009363651, 'learning_rate': 6.427484367393699e-05, 'epoch': 1.7}\n",
            "{'loss': 0.0137, 'grad_norm': 0.01725129969418049, 'learning_rate': 6.108893840348995e-05, 'epoch': 1.7}\n",
            "{'loss': 0.0103, 'grad_norm': 0.01022294256836176, 'learning_rate': 5.797886892324694e-05, 'epoch': 1.71}\n",
            "{'loss': 0.0106, 'grad_norm': 0.0171523354947567, 'learning_rate': 5.494517259623477e-05, 'epoch': 1.72}\n",
            "{'loss': 0.0101, 'grad_norm': 0.013398089446127415, 'learning_rate': 5.198837358959901e-05, 'epoch': 1.73}\n",
            "{'loss': 0.01, 'grad_norm': 0.020795408636331558, 'learning_rate': 4.910898278403669e-05, 'epoch': 1.74}\n",
            "{'loss': 0.0139, 'grad_norm': 0.02060292847454548, 'learning_rate': 4.630749768552589e-05, 'epoch': 1.74}\n",
            "{'loss': 0.0123, 'grad_norm': 0.014332282356917858, 'learning_rate': 4.358440233936617e-05, 'epoch': 1.75}\n",
            "{'loss': 0.0109, 'grad_norm': 0.014590497128665447, 'learning_rate': 4.094016724654359e-05, 'epoch': 1.76}\n",
            "{'loss': 0.0103, 'grad_norm': 0.013401413336396217, 'learning_rate': 3.837524928243774e-05, 'epoch': 1.77}\n",
            "{'loss': 0.0134, 'grad_norm': 0.012233339250087738, 'learning_rate': 3.589009161788104e-05, 'epoch': 1.78}\n",
            "{'loss': 0.0078, 'grad_norm': 0.011933929286897182, 'learning_rate': 3.348512364258765e-05, 'epoch': 1.78}\n",
            "{'loss': 0.0085, 'grad_norm': 0.009692336432635784, 'learning_rate': 3.116076089096265e-05, 'epoch': 1.79}\n",
            "{'loss': 0.01, 'grad_norm': 0.010550943203270435, 'learning_rate': 2.8917404970305094e-05, 'epoch': 1.8}\n",
            "{'loss': 0.0099, 'grad_norm': 0.011547650210559368, 'learning_rate': 2.6755443491417785e-05, 'epoch': 1.81}\n",
            "{'loss': 0.0109, 'grad_norm': 0.013012705370783806, 'learning_rate': 2.467525000163523e-05, 'epoch': 1.82}\n",
            "{'loss': 0.009, 'grad_norm': 0.0115474509075284, 'learning_rate': 2.267718392028134e-05, 'epoch': 1.82}\n",
            "{'loss': 0.0133, 'grad_norm': 0.015501453541219234, 'learning_rate': 2.0761590476568892e-05, 'epoch': 1.83}\n",
            "{'loss': 0.0081, 'grad_norm': 0.007750325836241245, 'learning_rate': 1.892880064994934e-05, 'epoch': 1.84}\n",
            "{'loss': 0.0097, 'grad_norm': 0.011818373575806618, 'learning_rate': 1.7179131112926627e-05, 'epoch': 1.85}\n",
            "{'loss': 0.0123, 'grad_norm': 0.013430241495370865, 'learning_rate': 1.5512884176341056e-05, 'epoch': 1.86}\n",
            "{'loss': 0.0101, 'grad_norm': 0.011589933186769485, 'learning_rate': 1.3930347737136195e-05, 'epoch': 1.86}\n",
            "{'loss': 0.0092, 'grad_norm': 0.01174391619861126, 'learning_rate': 1.2431795228615373e-05, 'epoch': 1.87}\n",
            "{'loss': 0.0099, 'grad_norm': 0.010763222351670265, 'learning_rate': 1.101748557319715e-05, 'epoch': 1.88}\n",
            "{'loss': 0.011, 'grad_norm': 0.01337768416851759, 'learning_rate': 9.687663137678605e-06, 'epoch': 1.89}\n",
            "{'loss': 0.0084, 'grad_norm': 0.010429056361317635, 'learning_rate': 8.442557691013041e-06, 'epoch': 1.9}\n",
            "{'loss': 0.0087, 'grad_norm': 0.012208803556859493, 'learning_rate': 7.282384364610206e-06, 'epoch': 1.9}\n",
            "{'loss': 0.016, 'grad_norm': 0.020478306338191032, 'learning_rate': 6.207343615165561e-06, 'epoch': 1.91}\n",
            "{'loss': 0.0102, 'grad_norm': 0.014647707343101501, 'learning_rate': 5.21762119002478e-06, 'epoch': 1.92}\n",
            "{'loss': 0.011, 'grad_norm': 0.014759979210793972, 'learning_rate': 4.3133880950905205e-06, 'epoch': 1.93}\n",
            "{'loss': 0.0088, 'grad_norm': 0.009468967095017433, 'learning_rate': 3.4948005652751246e-06, 'epoch': 1.94}\n",
            "{'loss': 0.0099, 'grad_norm': 0.0141701465472579, 'learning_rate': 2.7620000375064846e-06, 'epoch': 1.94}\n",
            "{'loss': 0.0081, 'grad_norm': 0.0119014335796237, 'learning_rate': 2.1151131262902577e-06, 'epoch': 1.95}\n",
            "{'loss': 0.0152, 'grad_norm': 0.014717898331582546, 'learning_rate': 1.5542516018332009e-06, 'epoch': 1.96}\n",
            "{'loss': 0.0086, 'grad_norm': 0.010832678526639938, 'learning_rate': 1.0795123707312283e-06, 'epoch': 1.97}\n",
            "{'loss': 0.0094, 'grad_norm': 0.009892074391245842, 'learning_rate': 6.909774592258055e-07, 'epoch': 1.98}\n",
            "{'loss': 0.0075, 'grad_norm': 0.01011562068015337, 'learning_rate': 3.8871399903134265e-07, 'epoch': 1.98}\n",
            "{'loss': 0.014, 'grad_norm': 0.01771530508995056, 'learning_rate': 1.7277421573608232e-07, 'epoch': 1.99}\n",
            "{'loss': 0.0121, 'grad_norm': 0.016482654958963394, 'learning_rate': 4.319541977831909e-08, 'epoch': 2.0}\n",
            "{'train_runtime': 45.3892, 'train_samples_per_second': 11.016, 'train_steps_per_second': 5.508, 'train_loss': 0.12834876069426537, 'epoch': 2.0}\n",
            "100% 250/250 [00:45<00:00,  5.51it/s]\n",
            "Training complete.\n",
            "Model saved to loras/self-edit/training_set_iteration_1/8d5021e8/7\n",
            "Training on 10 examples for 5 epochs, lr: 0.1\n",
            "No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n",
            "Starting training...\n",
            "{'loss': 2.9272, 'grad_norm': 1.9642293453216553, 'learning_rate': 0.0, 'epoch': 0.2}\n",
            "{'loss': 2.9218, 'grad_norm': 1.9470924139022827, 'learning_rate': 0.009090909090909092, 'epoch': 0.4}\n",
            "{'loss': 3.1461, 'grad_norm': 11.366796493530273, 'learning_rate': 0.018181818181818184, 'epoch': 0.6}\n",
            "{'loss': 23.0333, 'grad_norm': 51.49954605102539, 'learning_rate': 0.02727272727272727, 'epoch': 0.8}\n",
            "{'loss': 13.0195, 'grad_norm': 65.54180145263672, 'learning_rate': 0.03636363636363637, 'epoch': 1.0}\n",
            "{'loss': 28.6793, 'grad_norm': 97.20196533203125, 'learning_rate': 0.045454545454545456, 'epoch': 1.2}\n",
            "{'loss': 17.5492, 'grad_norm': 46.42717361450195, 'learning_rate': 0.05454545454545454, 'epoch': 1.4}\n",
            "{'loss': 12.9813, 'grad_norm': 2.3279542922973633, 'learning_rate': 0.06363636363636364, 'epoch': 1.6}\n",
            "{'loss': 12.1307, 'grad_norm': 0.6863025426864624, 'learning_rate': 0.07272727272727274, 'epoch': 1.8}\n",
            "{'loss': 11.7686, 'grad_norm': 1.0420840978622437, 'learning_rate': 0.08181818181818183, 'epoch': 2.0}\n",
            "{'loss': 10.5226, 'grad_norm': 0.8252339959144592, 'learning_rate': 0.09090909090909091, 'epoch': 2.2}\n",
            "{'loss': 7.4831, 'grad_norm': 0.40125685930252075, 'learning_rate': 0.1, 'epoch': 2.4}\n",
            "{'loss': 8.1533, 'grad_norm': 0.4455404579639435, 'learning_rate': 0.09874639560909118, 'epoch': 2.6}\n",
            "{'loss': 6.5741, 'grad_norm': 12.581632614135742, 'learning_rate': 0.09504844339512096, 'epoch': 2.8}\n",
            "{'loss': 5.8965, 'grad_norm': 0.21977519989013672, 'learning_rate': 0.0890915741234015, 'epoch': 3.0}\n",
            "{'loss': 4.7454, 'grad_norm': 0.18483684957027435, 'learning_rate': 0.08117449009293669, 'epoch': 3.2}\n",
            "{'loss': 5.1138, 'grad_norm': 0.23857000470161438, 'learning_rate': 0.07169418695587791, 'epoch': 3.4}\n",
            "{'loss': 4.0885, 'grad_norm': 0.09426677972078323, 'learning_rate': 0.06112604669781572, 'epoch': 3.6}\n",
            "{'loss': 4.3074, 'grad_norm': 0.1628522127866745, 'learning_rate': 0.05, 'epoch': 3.8}\n",
            "{'loss': 4.3655, 'grad_norm': 0.18454377353191376, 'learning_rate': 0.03887395330218429, 'epoch': 4.0}\n",
            "{'loss': 4.0478, 'grad_norm': 0.13483299314975739, 'learning_rate': 0.028305813044122097, 'epoch': 4.2}\n",
            "{'loss': 3.747, 'grad_norm': 0.08403611928224564, 'learning_rate': 0.018825509907063328, 'epoch': 4.4}\n",
            "{'loss': 3.6297, 'grad_norm': 0.13024276494979858, 'learning_rate': 0.01090842587659851, 'epoch': 4.6}\n",
            "{'loss': 3.6213, 'grad_norm': 0.13291841745376587, 'learning_rate': 0.004951556604879049, 'epoch': 4.8}\n",
            "{'loss': 3.676, 'grad_norm': 0.07505901157855988, 'learning_rate': 0.0012536043909088192, 'epoch': 5.0}\n",
            "{'train_runtime': 3.1669, 'train_samples_per_second': 15.788, 'train_steps_per_second': 7.894, 'train_loss': 8.32516284942627, 'epoch': 5.0}\n",
            "100% 25/25 [00:03<00:00,  7.90it/s]\n",
            "Training complete.\n",
            "Model saved to loras/self-edit/training_set_iteration_1/8d5021e8/8\n",
            "Training on 250 examples for 3 epochs, lr: 0.01\n",
            "No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n",
            "Starting training...\n",
            "{'loss': 4.5655, 'grad_norm': 5.244950771331787, 'learning_rate': 0.0, 'epoch': 0.01}\n",
            "{'loss': 5.9031, 'grad_norm': 7.481342315673828, 'learning_rate': 0.0009090909090909091, 'epoch': 0.02}\n",
            "{'loss': 0.6368, 'grad_norm': 0.6220864057540894, 'learning_rate': 0.0018181818181818182, 'epoch': 0.02}\n",
            "{'loss': 0.4647, 'grad_norm': 1.874036431312561, 'learning_rate': 0.002727272727272727, 'epoch': 0.03}\n",
            "{'loss': 0.6454, 'grad_norm': 0.46194788813591003, 'learning_rate': 0.0036363636363636364, 'epoch': 0.04}\n",
            "{'loss': 2.1218, 'grad_norm': 9.035111427307129, 'learning_rate': 0.004545454545454545, 'epoch': 0.05}\n",
            "{'loss': 0.7175, 'grad_norm': 2.2184550762176514, 'learning_rate': 0.005454545454545454, 'epoch': 0.06}\n",
            "{'loss': 0.7343, 'grad_norm': 1.2767724990844727, 'learning_rate': 0.006363636363636364, 'epoch': 0.06}\n",
            "{'loss': 0.6768, 'grad_norm': 1.624119520187378, 'learning_rate': 0.007272727272727273, 'epoch': 0.07}\n",
            "{'loss': 0.8573, 'grad_norm': 1.7179896831512451, 'learning_rate': 0.008181818181818182, 'epoch': 0.08}\n",
            "{'loss': 1.6429, 'grad_norm': 4.015443325042725, 'learning_rate': 0.00909090909090909, 'epoch': 0.09}\n",
            "{'loss': 15.8752, 'grad_norm': 65.18417358398438, 'learning_rate': 0.01, 'epoch': 0.1}\n",
            "{'loss': 10.4048, 'grad_norm': 18.273866653442383, 'learning_rate': 0.009999813776583147, 'epoch': 0.1}\n",
            "{'loss': 8.6541, 'grad_norm': 13.512595176696777, 'learning_rate': 0.009999255120204246, 'epoch': 0.11}\n",
            "{'loss': 5.7042, 'grad_norm': 78.38317108154297, 'learning_rate': 0.009998324072477265, 'epoch': 0.12}\n",
            "{'loss': 6.2016, 'grad_norm': 294.21807861328125, 'learning_rate': 0.009997020702755353, 'epoch': 0.13}\n",
            "{'loss': 4.4188, 'grad_norm': 3.6568121910095215, 'learning_rate': 0.009995345108125697, 'epoch': 0.14}\n",
            "{'loss': 13.447, 'grad_norm': 7.733970642089844, 'learning_rate': 0.009993297413402281, 'epoch': 0.14}\n",
            "{'loss': 11.9202, 'grad_norm': 32.085758209228516, 'learning_rate': 0.009990877771116588, 'epoch': 0.15}\n",
            "{'loss': 12.9139, 'grad_norm': 5.658780574798584, 'learning_rate': 0.009988086361506238, 'epoch': 0.16}\n",
            "{'loss': 8.6469, 'grad_norm': 3.8241515159606934, 'learning_rate': 0.009984923392501567, 'epoch': 0.17}\n",
            "{'loss': 21.1061, 'grad_norm': 4.599471092224121, 'learning_rate': 0.009981389099710133, 'epoch': 0.18}\n",
            "{'loss': 8.5634, 'grad_norm': 2.597576141357422, 'learning_rate': 0.009977483746399167, 'epoch': 0.18}\n",
            "{'loss': 3.5025, 'grad_norm': 2.938067674636841, 'learning_rate': 0.009973207623475963, 'epoch': 0.19}\n",
            "{'loss': 3.8626, 'grad_norm': 1.8516185283660889, 'learning_rate': 0.009968561049466213, 'epoch': 0.2}\n",
            "{'loss': 3.2586, 'grad_norm': 1.2053718566894531, 'learning_rate': 0.00996354437049027, 'epoch': 0.21}\n",
            "{'loss': 3.7972, 'grad_norm': 2.782559871673584, 'learning_rate': 0.009958157960237374, 'epoch': 0.22}\n",
            "{'loss': 3.2461, 'grad_norm': 2.7331416606903076, 'learning_rate': 0.009952402219937815, 'epoch': 0.22}\n",
            "{'loss': 3.4685, 'grad_norm': 1.6651313304901123, 'learning_rate': 0.009946277578333045, 'epoch': 0.23}\n",
            "{'loss': 2.6516, 'grad_norm': 1.1892831325531006, 'learning_rate': 0.009939784491643733, 'epoch': 0.24}\n",
            "{'loss': 2.9243, 'grad_norm': 1.2948871850967407, 'learning_rate': 0.009932923443535798, 'epoch': 0.25}\n",
            "{'loss': 2.0467, 'grad_norm': 0.28715282678604126, 'learning_rate': 0.009925694945084369, 'epoch': 0.26}\n",
            "{'loss': 3.213, 'grad_norm': 0.9583368897438049, 'learning_rate': 0.009918099534735719, 'epoch': 0.26}\n",
            "{'loss': 2.2225, 'grad_norm': 0.7060361504554749, 'learning_rate': 0.009910137778267152, 'epoch': 0.27}\n",
            "{'loss': 2.1153, 'grad_norm': 2.5771875381469727, 'learning_rate': 0.009901810268744867, 'epoch': 0.28}\n",
            "{'loss': 3.0613, 'grad_norm': 1.170093059539795, 'learning_rate': 0.009893117626479776, 'epoch': 0.29}\n",
            "{'loss': 1.9276, 'grad_norm': 0.5575333833694458, 'learning_rate': 0.009884060498981296, 'epoch': 0.3}\n",
            "{'loss': 1.9649, 'grad_norm': 0.655910074710846, 'learning_rate': 0.009874639560909117, 'epoch': 0.3}\n",
            "{'loss': 2.1729, 'grad_norm': 0.6674618721008301, 'learning_rate': 0.009864855514022955, 'epoch': 0.31}\n",
            "{'loss': 1.6224, 'grad_norm': 0.3264979124069214, 'learning_rate': 0.009854709087130261, 'epoch': 0.32}\n",
            "{'loss': 2.3161, 'grad_norm': 0.6822690367698669, 'learning_rate': 0.00984420103603195, 'epoch': 0.33}\n",
            "{'loss': 1.2121, 'grad_norm': 0.21458037197589874, 'learning_rate': 0.009833332143466099, 'epoch': 0.34}\n",
            "{'loss': 2.1951, 'grad_norm': 0.6852259635925293, 'learning_rate': 0.009822103219049624, 'epoch': 0.34}\n",
            "{'loss': 1.7117, 'grad_norm': 0.2490571290254593, 'learning_rate': 0.009810515099218002, 'epoch': 0.35}\n",
            "{'loss': 1.4817, 'grad_norm': 0.2320103794336319, 'learning_rate': 0.009798568647162938, 'epoch': 0.36}\n",
            "{'loss': 1.4102, 'grad_norm': 0.27567529678344727, 'learning_rate': 0.00978626475276808, 'epoch': 0.37}\n",
            "{'loss': 1.9077, 'grad_norm': 1.6139124631881714, 'learning_rate': 0.009773604332542728, 'epoch': 0.38}\n",
            "{'loss': 1.4307, 'grad_norm': 0.30243605375289917, 'learning_rate': 0.00976058832955357, 'epoch': 0.38}\n",
            "{'loss': 2.3512, 'grad_norm': 0.6182196736335754, 'learning_rate': 0.009747217713354427, 'epoch': 0.39}\n",
            "{'loss': 1.2247, 'grad_norm': 0.1673591583967209, 'learning_rate': 0.009733493479914031, 'epoch': 0.4}\n",
            "{'loss': 1.991, 'grad_norm': 0.44272932410240173, 'learning_rate': 0.009719416651541838, 'epoch': 0.41}\n",
            "{'loss': 2.4479, 'grad_norm': 0.3860681354999542, 'learning_rate': 0.009704988276811882, 'epoch': 0.42}\n",
            "{'loss': 1.0602, 'grad_norm': 0.1904882937669754, 'learning_rate': 0.00969020943048466, 'epoch': 0.42}\n",
            "{'loss': 1.2833, 'grad_norm': 0.18443049490451813, 'learning_rate': 0.009675081213427075, 'epoch': 0.43}\n",
            "{'loss': 1.3065, 'grad_norm': 0.28060972690582275, 'learning_rate': 0.009659604752530434, 'epoch': 0.44}\n",
            "{'loss': 1.5211, 'grad_norm': 0.21377553045749664, 'learning_rate': 0.00964378120062651, 'epoch': 0.45}\n",
            "{'loss': 1.0337, 'grad_norm': 0.11305361241102219, 'learning_rate': 0.009627611736401667, 'epoch': 0.46}\n",
            "{'loss': 1.1777, 'grad_norm': 0.18432167172431946, 'learning_rate': 0.009611097564309053, 'epoch': 0.46}\n",
            "{'loss': 1.7835, 'grad_norm': 0.5515055656433105, 'learning_rate': 0.009594239914478886, 'epoch': 0.47}\n",
            "{'loss': 1.0355, 'grad_norm': 0.07838769257068634, 'learning_rate': 0.009577040042626833, 'epoch': 0.48}\n",
            "{'loss': 1.3444, 'grad_norm': 0.11777771264314651, 'learning_rate': 0.00955949922996045, 'epoch': 0.49}\n",
            "{'loss': 1.4321, 'grad_norm': 0.1866026222705841, 'learning_rate': 0.00954161878308377, 'epoch': 0.5}\n",
            "{'loss': 1.1153, 'grad_norm': 0.1268070638179779, 'learning_rate': 0.009523400033899955, 'epoch': 0.5}\n",
            "{'loss': 1.2706, 'grad_norm': 0.21539784967899323, 'learning_rate': 0.009504844339512096, 'epoch': 0.51}\n",
            "{'loss': 1.5899, 'grad_norm': 0.17460083961486816, 'learning_rate': 0.009485953082122116, 'epoch': 0.52}\n",
            "{'loss': 0.7808, 'grad_norm': 0.10740930587053299, 'learning_rate': 0.009466727668927815, 'epoch': 0.53}\n",
            "{'loss': 1.6466, 'grad_norm': 0.3348596394062042, 'learning_rate': 0.00944716953201805, 'epoch': 0.54}\n",
            "{'loss': 0.8224, 'grad_norm': 0.08204606175422668, 'learning_rate': 0.009427280128266049, 'epoch': 0.54}\n",
            "{'loss': 1.1155, 'grad_norm': 149.98446655273438, 'learning_rate': 0.009407060939220908, 'epoch': 0.55}\n",
            "{'loss': 1.0636, 'grad_norm': 40.86983108520508, 'learning_rate': 0.00938651347099721, 'epoch': 0.56}\n",
            "{'loss': 0.7701, 'grad_norm': 0.058366384357213974, 'learning_rate': 0.009365639254162854, 'epoch': 0.57}\n",
            "{'loss': 1.1752, 'grad_norm': 0.172223761677742, 'learning_rate': 0.009344439843625034, 'epoch': 0.58}\n",
            "{'loss': 0.9137, 'grad_norm': 0.08443672209978104, 'learning_rate': 0.009322916818514413, 'epoch': 0.58}\n",
            "{'loss': 1.3119, 'grad_norm': 0.16415973007678986, 'learning_rate': 0.009301071782067504, 'epoch': 0.59}\n",
            "{'loss': 1.4587, 'grad_norm': 0.2153255194425583, 'learning_rate': 0.009278906361507237, 'epoch': 0.6}\n",
            "{'loss': 0.9051, 'grad_norm': 0.06447546184062958, 'learning_rate': 0.009256422207921756, 'epoch': 0.61}\n",
            "{'loss': 1.1889, 'grad_norm': 0.13565810024738312, 'learning_rate': 0.00923362099614142, 'epoch': 0.62}\n",
            "{'loss': 1.1963, 'grad_norm': 0.10974590480327606, 'learning_rate': 0.009210504424614059, 'epoch': 0.62}\n",
            "{'loss': 1.1204, 'grad_norm': 0.11974561959505081, 'learning_rate': 0.009187074215278444, 'epoch': 0.63}\n",
            "{'loss': 1.1153, 'grad_norm': 0.09508254379034042, 'learning_rate': 0.009163332113436031, 'epoch': 0.64}\n",
            "{'loss': 0.9432, 'grad_norm': 0.07768040895462036, 'learning_rate': 0.009139279887620954, 'epoch': 0.65}\n",
            "{'loss': 1.1063, 'grad_norm': 0.11331861466169357, 'learning_rate': 0.009114919329468282, 'epoch': 0.66}\n",
            "{'loss': 1.3941, 'grad_norm': 0.15002889931201935, 'learning_rate': 0.009090252253580565, 'epoch': 0.66}\n",
            "{'loss': 0.9325, 'grad_norm': 0.12894020974636078, 'learning_rate': 0.009065280497392662, 'epoch': 0.67}\n",
            "{'loss': 1.0825, 'grad_norm': 0.1216474324464798, 'learning_rate': 0.009040005921034882, 'epoch': 0.68}\n",
            "{'loss': 1.3277, 'grad_norm': 0.18059679865837097, 'learning_rate': 0.009014430407194412, 'epoch': 0.69}\n",
            "{'loss': 0.6906, 'grad_norm': 0.07272956520318985, 'learning_rate': 0.008988555860975082, 'epoch': 0.7}\n",
            "{'loss': 1.0088, 'grad_norm': 0.12897509336471558, 'learning_rate': 0.008962384209755451, 'epoch': 0.7}\n",
            "{'loss': 1.0603, 'grad_norm': 0.13251769542694092, 'learning_rate': 0.00893591740304525, 'epoch': 0.71}\n",
            "{'loss': 1.1047, 'grad_norm': 0.11619339883327484, 'learning_rate': 0.008909157412340149, 'epoch': 0.72}\n",
            "{'loss': 1.2933, 'grad_norm': 0.10830634832382202, 'learning_rate': 0.008882106230974908, 'epoch': 0.73}\n",
            "{'loss': 1.2351, 'grad_norm': 0.1143377348780632, 'learning_rate': 0.008854765873974898, 'epoch': 0.74}\n",
            "{'loss': 0.875, 'grad_norm': 0.09594759345054626, 'learning_rate': 0.008827138377905998, 'epoch': 0.74}\n",
            "{'loss': 0.9466, 'grad_norm': 0.09864158183336258, 'learning_rate': 0.008799225800722895, 'epoch': 0.75}\n",
            "{'loss': 1.1757, 'grad_norm': 0.3106881380081177, 'learning_rate': 0.008771030221615786, 'epoch': 0.76}\n",
            "{'loss': 0.6862, 'grad_norm': 0.1309797316789627, 'learning_rate': 0.008742553740855506, 'epoch': 0.77}\n",
            "{'loss': 0.8833, 'grad_norm': 0.14165812730789185, 'learning_rate': 0.008713798479637071, 'epoch': 0.78}\n",
            "{'loss': 1.1695, 'grad_norm': 0.18667414784431458, 'learning_rate': 0.008684766579921684, 'epoch': 0.78}\n",
            "{'loss': 1.1583, 'grad_norm': 0.13107262551784515, 'learning_rate': 0.008655460204277167, 'epoch': 0.79}\n",
            "{'loss': 1.0956, 'grad_norm': 0.13917292654514313, 'learning_rate': 0.008625881535716882, 'epoch': 0.8}\n",
            "{'loss': 1.0979, 'grad_norm': 0.1838466376066208, 'learning_rate': 0.008596032777537123, 'epoch': 0.81}\n",
            "{'loss': 1.0132, 'grad_norm': 0.14163143932819366, 'learning_rate': 0.008565916153152981, 'epoch': 0.82}\n",
            "{'loss': 0.9805, 'grad_norm': 0.08604274690151215, 'learning_rate': 0.008535533905932738, 'epoch': 0.82}\n",
            "{'loss': 0.9008, 'grad_norm': 0.117699034512043, 'learning_rate': 0.008504888299030747, 'epoch': 0.83}\n",
            "{'loss': 0.8008, 'grad_norm': 0.12479302287101746, 'learning_rate': 0.008473981615218862, 'epoch': 0.84}\n",
            "{'loss': 0.9041, 'grad_norm': 0.08798234164714813, 'learning_rate': 0.008442816156716385, 'epoch': 0.85}\n",
            "{'loss': 1.1357, 'grad_norm': 0.09241215139627457, 'learning_rate': 0.008411394245018588, 'epoch': 0.86}\n",
            "{'loss': 0.7902, 'grad_norm': 0.1050182431936264, 'learning_rate': 0.008379718220723772, 'epoch': 0.86}\n",
            "{'loss': 0.8548, 'grad_norm': 0.11350716650485992, 'learning_rate': 0.008347790443358928, 'epoch': 0.87}\n",
            "{'loss': 1.026, 'grad_norm': 0.1378825306892395, 'learning_rate': 0.008315613291203975, 'epoch': 0.88}\n",
            "{'loss': 1.0527, 'grad_norm': 0.08662001043558121, 'learning_rate': 0.0082831891611146, 'epoch': 0.89}\n",
            "{'loss': 0.6537, 'grad_norm': 0.037200409919023514, 'learning_rate': 0.00825052046834372, 'epoch': 0.9}\n",
            "{'loss': 0.9548, 'grad_norm': 0.12328914552927017, 'learning_rate': 0.008217609646361573, 'epoch': 0.9}\n",
            "{'loss': 0.9031, 'grad_norm': 0.06445799767971039, 'learning_rate': 0.008184459146674447, 'epoch': 0.91}\n",
            "{'loss': 0.7772, 'grad_norm': 0.07381441444158554, 'learning_rate': 0.008151071438642068, 'epoch': 0.92}\n",
            "{'loss': 1.4081, 'grad_norm': 0.11517333984375, 'learning_rate': 0.008117449009293669, 'epoch': 0.93}\n",
            "{'loss': 1.1367, 'grad_norm': 0.15201057493686676, 'learning_rate': 0.008083594363142717, 'epoch': 0.94}\n",
            "{'loss': 0.6635, 'grad_norm': 0.060288265347480774, 'learning_rate': 0.008049510022000364, 'epoch': 0.94}\n",
            "{'loss': 0.6757, 'grad_norm': 0.08049138635396957, 'learning_rate': 0.008015198524787602, 'epoch': 0.95}\n",
            "{'loss': 0.6758, 'grad_norm': 0.08276671916246414, 'learning_rate': 0.007980662427346127, 'epoch': 0.96}\n",
            "{'loss': 0.829, 'grad_norm': 0.0838857963681221, 'learning_rate': 0.007945904302247968, 'epoch': 0.97}\n",
            "{'loss': 0.8885, 'grad_norm': 0.0841725766658783, 'learning_rate': 0.007910926738603854, 'epoch': 0.98}\n",
            "{'loss': 0.8475, 'grad_norm': 0.06194471940398216, 'learning_rate': 0.007875732341870348, 'epoch': 0.98}\n",
            "{'loss': 0.987, 'grad_norm': 0.18853743374347687, 'learning_rate': 0.007840323733655778, 'epoch': 0.99}\n",
            "{'loss': 0.8273, 'grad_norm': 0.07424018532037735, 'learning_rate': 0.007804703551524948, 'epoch': 1.0}\n",
            "{'loss': 0.9377, 'grad_norm': 0.08610037714242935, 'learning_rate': 0.0077688744488026654, 'epoch': 1.01}\n",
            "{'loss': 0.7583, 'grad_norm': 0.07439021021127701, 'learning_rate': 0.007732839094376105, 'epoch': 1.02}\n",
            "{'loss': 0.9867, 'grad_norm': 7.55096435546875, 'learning_rate': 0.007696600172495996, 'epoch': 1.02}\n",
            "{'loss': 0.6658, 'grad_norm': 0.08675279468297958, 'learning_rate': 0.007660160382576683, 'epoch': 1.03}\n",
            "{'loss': 0.8597, 'grad_norm': 0.11330577731132507, 'learning_rate': 0.00762352243899504, 'epoch': 1.04}\n",
            "{'loss': 1.0273, 'grad_norm': 0.12447299808263779, 'learning_rate': 0.007586689070888284, 'epoch': 1.05}\n",
            "{'loss': 1.0259, 'grad_norm': 0.11678755283355713, 'learning_rate': 0.00754966302195068, 'epoch': 1.06}\n",
            "{'loss': 0.7969, 'grad_norm': 0.10357663035392761, 'learning_rate': 0.007512447050229166, 'epoch': 1.06}\n",
            "{'loss': 0.9377, 'grad_norm': 0.18988901376724243, 'learning_rate': 0.007475043927917907, 'epoch': 1.07}\n",
            "{'loss': 0.8756, 'grad_norm': 0.12687446177005768, 'learning_rate': 0.007437456441151799, 'epoch': 1.08}\n",
            "{'loss': 0.8865, 'grad_norm': 0.09996326267719269, 'learning_rate': 0.007399687389798932, 'epoch': 1.09}\n",
            "{'loss': 0.554, 'grad_norm': 0.06308994442224503, 'learning_rate': 0.007361739587252019, 'epoch': 1.1}\n",
            "{'loss': 0.8823, 'grad_norm': 0.13263261318206787, 'learning_rate': 0.007323615860218843, 'epoch': 1.1}\n",
            "{'loss': 0.8521, 'grad_norm': 0.08749815076589584, 'learning_rate': 0.00728531904851169, 'epoch': 1.11}\n",
            "{'loss': 1.0031, 'grad_norm': 0.10948415845632553, 'learning_rate': 0.007246852004835807, 'epoch': 1.12}\n",
            "{'loss': 1.0378, 'grad_norm': 23.927560806274414, 'learning_rate': 0.007208217594576923, 'epoch': 1.13}\n",
            "{'loss': 0.9364, 'grad_norm': 0.3221834897994995, 'learning_rate': 0.007169418695587791, 'epoch': 1.14}\n",
            "{'loss': 0.6814, 'grad_norm': 0.7433553338050842, 'learning_rate': 0.007130458197973828, 'epoch': 1.14}\n",
            "{'loss': 0.7241, 'grad_norm': 0.5181288719177246, 'learning_rate': 0.0070913390038778255, 'epoch': 1.15}\n",
            "{'loss': 1.7519, 'grad_norm': 4.232927322387695, 'learning_rate': 0.007052064027263785, 'epoch': 1.16}\n",
            "{'loss': 1.1048, 'grad_norm': 13.11436653137207, 'learning_rate': 0.0070126361936998375, 'epoch': 1.17}\n",
            "{'loss': 1.42, 'grad_norm': 0.3251841068267822, 'learning_rate': 0.006973058440140341, 'epoch': 1.18}\n",
            "{'loss': 1.6342, 'grad_norm': 9.678915023803711, 'learning_rate': 0.006933333714707094, 'epoch': 1.18}\n",
            "{'loss': 0.8753, 'grad_norm': 0.24758392572402954, 'learning_rate': 0.006893464976469739, 'epoch': 1.19}\n",
            "{'loss': 0.8775, 'grad_norm': 0.17382319271564484, 'learning_rate': 0.006853455195225339, 'epoch': 1.2}\n",
            "{'loss': 1.0587, 'grad_norm': 0.46235257387161255, 'learning_rate': 0.00681330735127716, 'epoch': 1.21}\n",
            "{'loss': 1.0019, 'grad_norm': 0.4095155596733093, 'learning_rate': 0.006773024435212678, 'epoch': 1.22}\n",
            "{'loss': 1.1791, 'grad_norm': 0.4318028390407562, 'learning_rate': 0.0067326094476808, 'epoch': 1.22}\n",
            "{'loss': 1.3823, 'grad_norm': 0.8862547278404236, 'learning_rate': 0.0066920653991683525, 'epoch': 1.23}\n",
            "{'loss': 1.0378, 'grad_norm': 0.34071728587150574, 'learning_rate': 0.006651395309775836, 'epoch': 1.24}\n",
            "{'loss': 1.0661, 'grad_norm': 0.18325361609458923, 'learning_rate': 0.006610602208992454, 'epoch': 1.25}\n",
            "{'loss': 0.6852, 'grad_norm': 0.06790848076343536, 'learning_rate': 0.00656968913547045, 'epoch': 1.26}\n",
            "{'loss': 0.6272, 'grad_norm': 0.09581004083156586, 'learning_rate': 0.006528659136798765, 'epoch': 1.26}\n",
            "{'loss': 1.2347, 'grad_norm': 0.34725600481033325, 'learning_rate': 0.006487515269276016, 'epoch': 1.27}\n",
            "{'loss': 0.9204, 'grad_norm': 0.10157798230648041, 'learning_rate': 0.0064462605976828395, 'epoch': 1.28}\n",
            "{'loss': 0.9318, 'grad_norm': 0.10811315476894379, 'learning_rate': 0.0064048981950535966, 'epoch': 1.29}\n",
            "{'loss': 0.7397, 'grad_norm': 0.09997887164354324, 'learning_rate': 0.006363431142447469, 'epoch': 1.3}\n",
            "{'loss': 1.2676, 'grad_norm': 0.1773674339056015, 'learning_rate': 0.006321862528718945, 'epoch': 1.3}\n",
            "{'loss': 0.8766, 'grad_norm': 0.11990977078676224, 'learning_rate': 0.006280195450287736, 'epoch': 1.31}\n",
            "{'loss': 1.0887, 'grad_norm': 0.14327648282051086, 'learning_rate': 0.00623843301090813, 'epoch': 1.32}\n",
            "{'loss': 0.821, 'grad_norm': 0.12717264890670776, 'learning_rate': 0.006196578321437789, 'epoch': 1.33}\n",
            "{'loss': 0.5976, 'grad_norm': 0.06308142095804214, 'learning_rate': 0.006154634499606029, 'epoch': 1.34}\n",
            "{'loss': 0.9065, 'grad_norm': 0.10675735771656036, 'learning_rate': 0.006112604669781572, 'epoch': 1.34}\n",
            "{'loss': 0.8277, 'grad_norm': 0.0967002734541893, 'learning_rate': 0.0060704919627398305, 'epoch': 1.35}\n",
            "{'loss': 0.7585, 'grad_norm': 0.10192244499921799, 'learning_rate': 0.006028299515429682, 'epoch': 1.36}\n",
            "{'loss': 0.8491, 'grad_norm': 0.1367199867963791, 'learning_rate': 0.005986030470739811, 'epoch': 1.37}\n",
            "{'loss': 0.9687, 'grad_norm': 0.13036426901817322, 'learning_rate': 0.005943687977264584, 'epoch': 1.38}\n",
            "{'loss': 0.6805, 'grad_norm': 0.05934462323784828, 'learning_rate': 0.005901275189069529, 'epoch': 1.38}\n",
            "{'loss': 1.1205, 'grad_norm': 0.26590439677238464, 'learning_rate': 0.005858795265456382, 'epoch': 1.39}\n",
            "{'loss': 0.8162, 'grad_norm': 0.07896192371845245, 'learning_rate': 0.005816251370727748, 'epoch': 1.4}\n",
            "{'loss': 0.7179, 'grad_norm': 0.09681221097707748, 'learning_rate': 0.005773646673951406, 'epoch': 1.41}\n",
            "{'loss': 0.8356, 'grad_norm': 0.11715125292539597, 'learning_rate': 0.005730984348724242, 'epoch': 1.42}\n",
            "{'loss': 0.8648, 'grad_norm': 0.13337554037570953, 'learning_rate': 0.005688267572935842, 'epoch': 1.42}\n",
            "{'loss': 1.0034, 'grad_norm': 0.10283800214529037, 'learning_rate': 0.005645499528531784, 'epoch': 1.43}\n",
            "{'loss': 0.6403, 'grad_norm': 0.0512806735932827, 'learning_rate': 0.005602683401276615, 'epoch': 1.44}\n",
            "{'loss': 0.7846, 'grad_norm': 0.052145395427942276, 'learning_rate': 0.005559822380516539, 'epoch': 1.45}\n",
            "{'loss': 0.6274, 'grad_norm': 0.0867193341255188, 'learning_rate': 0.00551691965894185, 'epoch': 1.46}\n",
            "{'loss': 0.7363, 'grad_norm': 0.09092836081981659, 'learning_rate': 0.005473978432349111, 'epoch': 1.46}\n",
            "{'loss': 1.0257, 'grad_norm': 0.2396700233221054, 'learning_rate': 0.0054310018994030975, 'epoch': 1.47}\n",
            "{'loss': 0.7008, 'grad_norm': 0.07291615009307861, 'learning_rate': 0.005387993261398532, 'epoch': 1.48}\n",
            "{'loss': 1.0775, 'grad_norm': 0.1292189508676529, 'learning_rate': 0.005344955722021624, 'epoch': 1.49}\n",
            "{'loss': 0.5323, 'grad_norm': 0.06177082285284996, 'learning_rate': 0.00530189248711143, 'epoch': 1.5}\n",
            "{'loss': 1.1603, 'grad_norm': 0.14560756087303162, 'learning_rate': 0.005258806764421048, 'epoch': 1.5}\n",
            "{'loss': 0.736, 'grad_norm': 0.10812705010175705, 'learning_rate': 0.005215701763378673, 'epoch': 1.51}\n",
            "{'loss': 0.8638, 'grad_norm': 0.09187109768390656, 'learning_rate': 0.005172580694848541, 'epoch': 1.52}\n",
            "{'loss': 0.8199, 'grad_norm': 0.07893180102109909, 'learning_rate': 0.005129446770891738, 'epoch': 1.53}\n",
            "{'loss': 0.777, 'grad_norm': 0.202488973736763, 'learning_rate': 0.0050863032045269435, 'epoch': 1.54}\n",
            "{'loss': 1.0133, 'grad_norm': 0.15844270586967468, 'learning_rate': 0.0050431532094910945, 'epoch': 1.54}\n",
            "{'loss': 0.8203, 'grad_norm': 0.08410622179508209, 'learning_rate': 0.005, 'epoch': 1.55}\n",
            "{'loss': 1.2299, 'grad_norm': 0.1687406599521637, 'learning_rate': 0.004956846790508906, 'epoch': 1.56}\n",
            "{'loss': 0.6486, 'grad_norm': 0.07742056995630264, 'learning_rate': 0.004913696795473058, 'epoch': 1.57}\n",
            "{'loss': 0.9073, 'grad_norm': 0.09923951327800751, 'learning_rate': 0.004870553229108264, 'epoch': 1.58}\n",
            "{'loss': 0.5302, 'grad_norm': 0.0452771820127964, 'learning_rate': 0.004827419305151461, 'epoch': 1.58}\n",
            "{'loss': 0.7531, 'grad_norm': 0.07512634247541428, 'learning_rate': 0.004784298236621327, 'epoch': 1.59}\n",
            "{'loss': 0.8346, 'grad_norm': 0.07637398689985275, 'learning_rate': 0.0047411932355789525, 'epoch': 1.6}\n",
            "{'loss': 0.8464, 'grad_norm': 0.08160337060689926, 'learning_rate': 0.004698107512888569, 'epoch': 1.61}\n",
            "{'loss': 0.5672, 'grad_norm': 0.05337720736861229, 'learning_rate': 0.004655044277978375, 'epoch': 1.62}\n",
            "{'loss': 0.8084, 'grad_norm': 0.0691579058766365, 'learning_rate': 0.004612006738601469, 'epoch': 1.62}\n",
            "{'loss': 0.6294, 'grad_norm': 0.07411883771419525, 'learning_rate': 0.004568998100596903, 'epoch': 1.63}\n",
            "{'loss': 0.9227, 'grad_norm': 0.09711574763059616, 'learning_rate': 0.004526021567650889, 'epoch': 1.64}\n",
            "{'loss': 0.7082, 'grad_norm': 0.09863676130771637, 'learning_rate': 0.00448308034105815, 'epoch': 1.65}\n",
            "{'loss': 0.9984, 'grad_norm': 0.13657602667808533, 'learning_rate': 0.004440177619483461, 'epoch': 1.66}\n",
            "{'loss': 0.5333, 'grad_norm': 0.062166158109903336, 'learning_rate': 0.004397316598723385, 'epoch': 1.66}\n",
            "{'loss': 0.7335, 'grad_norm': 0.09945476055145264, 'learning_rate': 0.004354500471468217, 'epoch': 1.67}\n",
            "{'loss': 0.6088, 'grad_norm': 0.07076175510883331, 'learning_rate': 0.00431173242706416, 'epoch': 1.68}\n",
            "{'loss': 0.6786, 'grad_norm': 0.08045303821563721, 'learning_rate': 0.004269015651275761, 'epoch': 1.69}\n",
            "{'loss': 0.6193, 'grad_norm': 0.06418100744485855, 'learning_rate': 0.004226353326048593, 'epoch': 1.7}\n",
            "{'loss': 0.4428, 'grad_norm': 0.035473696887493134, 'learning_rate': 0.004183748629272253, 'epoch': 1.7}\n",
            "{'loss': 0.7039, 'grad_norm': 0.06056949868798256, 'learning_rate': 0.004141204734543619, 'epoch': 1.71}\n",
            "{'loss': 0.5945, 'grad_norm': 0.05750435218214989, 'learning_rate': 0.004098724810930472, 'epoch': 1.72}\n",
            "{'loss': 0.4682, 'grad_norm': 0.028862711042165756, 'learning_rate': 0.004056312022735417, 'epoch': 1.73}\n",
            "{'loss': 0.6604, 'grad_norm': 0.05628682300448418, 'learning_rate': 0.00401396952926019, 'epoch': 1.74}\n",
            "{'loss': 0.6315, 'grad_norm': 0.09460903704166412, 'learning_rate': 0.003971700484570318, 'epoch': 1.74}\n",
            "{'loss': 0.772, 'grad_norm': 0.11792309582233429, 'learning_rate': 0.00392950803726017, 'epoch': 1.75}\n",
            "{'loss': 0.633, 'grad_norm': 0.06354423612356186, 'learning_rate': 0.003887395330218428, 'epoch': 1.76}\n",
            "{'loss': 0.7042, 'grad_norm': 0.0669848844408989, 'learning_rate': 0.0038453655003939735, 'epoch': 1.77}\n",
            "{'loss': 1.3219, 'grad_norm': 0.15199513733386993, 'learning_rate': 0.003803421678562213, 'epoch': 1.78}\n",
            "{'loss': 0.8917, 'grad_norm': 0.10371463745832443, 'learning_rate': 0.00376156698909187, 'epoch': 1.78}\n",
            "{'loss': 0.5532, 'grad_norm': 0.059340331703424454, 'learning_rate': 0.0037198045497122646, 'epoch': 1.79}\n",
            "{'loss': 1.1398, 'grad_norm': 0.1156945750117302, 'learning_rate': 0.0036781374712810556, 'epoch': 1.8}\n",
            "{'loss': 0.8367, 'grad_norm': 0.05858650803565979, 'learning_rate': 0.0036365688575525313, 'epoch': 1.81}\n",
            "{'loss': 0.5789, 'grad_norm': 0.034153424203395844, 'learning_rate': 0.003595101804946404, 'epoch': 1.82}\n",
            "{'loss': 0.5707, 'grad_norm': 0.05736871436238289, 'learning_rate': 0.003553739402317162, 'epoch': 1.82}\n",
            "{'loss': 0.5086, 'grad_norm': 0.03859268128871918, 'learning_rate': 0.003512484730723986, 'epoch': 1.83}\n",
            "{'loss': 0.5942, 'grad_norm': 0.04235918074846268, 'learning_rate': 0.0034713408632012365, 'epoch': 1.84}\n",
            "{'loss': 0.8282, 'grad_norm': 0.16217689216136932, 'learning_rate': 0.00343031086452955, 'epoch': 1.85}\n",
            "{'loss': 0.7955, 'grad_norm': 0.11465112119913101, 'learning_rate': 0.003389397791007548, 'epoch': 1.86}\n",
            "{'loss': 1.0343, 'grad_norm': 0.15521258115768433, 'learning_rate': 0.0033486046902241663, 'epoch': 1.86}\n",
            "{'loss': 1.0309, 'grad_norm': 0.13726715743541718, 'learning_rate': 0.003307934600831648, 'epoch': 1.87}\n",
            "{'loss': 0.6776, 'grad_norm': 0.08551153540611267, 'learning_rate': 0.0032673905523191997, 'epoch': 1.88}\n",
            "{'loss': 0.6819, 'grad_norm': 0.09586115181446075, 'learning_rate': 0.0032269755647873215, 'epoch': 1.89}\n",
            "{'loss': 0.7165, 'grad_norm': 0.20855316519737244, 'learning_rate': 0.00318669264872284, 'epoch': 1.9}\n",
            "{'loss': 0.5274, 'grad_norm': 0.09718185663223267, 'learning_rate': 0.0031465448047746625, 'epoch': 1.9}\n",
            "{'loss': 0.8298, 'grad_norm': 0.09338673204183578, 'learning_rate': 0.003106535023530262, 'epoch': 1.91}\n",
            "{'loss': 0.4749, 'grad_norm': 0.24127469956874847, 'learning_rate': 0.003066666285292906, 'epoch': 1.92}\n",
            "{'loss': 0.592, 'grad_norm': 0.06270243227481842, 'learning_rate': 0.00302694155985966, 'epoch': 1.93}\n",
            "{'loss': 0.5488, 'grad_norm': 0.05115104466676712, 'learning_rate': 0.0029873638063001627, 'epoch': 1.94}\n",
            "{'loss': 0.6014, 'grad_norm': 0.043459419161081314, 'learning_rate': 0.002947935972736217, 'epoch': 1.94}\n",
            "{'loss': 0.5333, 'grad_norm': 0.04546047002077103, 'learning_rate': 0.0029086609961221756, 'epoch': 1.95}\n",
            "{'loss': 0.7777, 'grad_norm': 0.08746926486492157, 'learning_rate': 0.0028695418020261753, 'epoch': 1.96}\n",
            "{'loss': 0.4428, 'grad_norm': 0.02824270725250244, 'learning_rate': 0.00283058130441221, 'epoch': 1.97}\n",
            "{'loss': 0.643, 'grad_norm': 0.06581327319145203, 'learning_rate': 0.0027917824054230784, 'epoch': 1.98}\n",
            "{'loss': 0.8182, 'grad_norm': 0.08668319880962372, 'learning_rate': 0.0027531479951641924, 'epoch': 1.98}\n",
            "{'loss': 0.6422, 'grad_norm': 0.07730206102132797, 'learning_rate': 0.002714680951488312, 'epoch': 1.99}\n",
            "{'loss': 0.9563, 'grad_norm': 0.10100806504487991, 'learning_rate': 0.002676384139781157, 'epoch': 2.0}\n",
            "{'loss': 0.6782, 'grad_norm': 0.09239041060209274, 'learning_rate': 0.0026382604127479815, 'epoch': 2.01}\n",
            "{'loss': 0.6976, 'grad_norm': 0.09042662382125854, 'learning_rate': 0.0026003126102010694, 'epoch': 2.02}\n",
            "{'loss': 0.703, 'grad_norm': 0.06170322000980377, 'learning_rate': 0.0025625435588482017, 'epoch': 2.02}\n",
            "{'loss': 0.5293, 'grad_norm': 0.04664481058716774, 'learning_rate': 0.002524956072082093, 'epoch': 2.03}\n",
            "{'loss': 0.7916, 'grad_norm': 0.07948343455791473, 'learning_rate': 0.0024875529497708354, 'epoch': 2.04}\n",
            "{'loss': 1.0061, 'grad_norm': 0.1878359317779541, 'learning_rate': 0.0024503369780493217, 'epoch': 2.05}\n",
            "{'loss': 0.989, 'grad_norm': 0.12016770243644714, 'learning_rate': 0.0024133109291117156, 'epoch': 2.06}\n",
            "{'loss': 0.6361, 'grad_norm': 0.058125533163547516, 'learning_rate': 0.00237647756100496, 'epoch': 2.06}\n",
            "{'loss': 0.6664, 'grad_norm': 0.09085877239704132, 'learning_rate': 0.0023398396174233176, 'epoch': 2.07}\n",
            "{'loss': 0.7588, 'grad_norm': 0.14254657924175262, 'learning_rate': 0.002303399827504005, 'epoch': 2.08}\n",
            "{'loss': 0.5096, 'grad_norm': 0.049980200827121735, 'learning_rate': 0.002267160905623895, 'epoch': 2.09}\n",
            "{'loss': 0.6212, 'grad_norm': 0.06987476348876953, 'learning_rate': 0.0022311255511973343, 'epoch': 2.1}\n",
            "{'loss': 0.5103, 'grad_norm': 0.04705401882529259, 'learning_rate': 0.0021952964484750525, 'epoch': 2.1}\n",
            "{'loss': 0.8522, 'grad_norm': 0.07595008611679077, 'learning_rate': 0.0021596762663442215, 'epoch': 2.11}\n",
            "{'loss': 0.9117, 'grad_norm': 0.10620903223752975, 'learning_rate': 0.0021242676581296528, 'epoch': 2.12}\n",
            "{'loss': 0.7152, 'grad_norm': 0.10463523119688034, 'learning_rate': 0.0020890732613961477, 'epoch': 2.13}\n",
            "{'loss': 0.7945, 'grad_norm': 0.06173386052250862, 'learning_rate': 0.002054095697752032, 'epoch': 2.14}\n",
            "{'loss': 0.7616, 'grad_norm': 0.10415427386760712, 'learning_rate': 0.002019337572653874, 'epoch': 2.14}\n",
            "{'loss': 0.775, 'grad_norm': 0.11243218183517456, 'learning_rate': 0.0019848014752123977, 'epoch': 2.15}\n",
            "{'loss': 1.0032, 'grad_norm': 0.10803517699241638, 'learning_rate': 0.0019504899779996354, 'epoch': 2.16}\n",
            "{'loss': 0.6848, 'grad_norm': 0.0952313169836998, 'learning_rate': 0.0019164056368572847, 'epoch': 2.17}\n",
            "{'loss': 0.6508, 'grad_norm': 0.08897209912538528, 'learning_rate': 0.0018825509907063327, 'epoch': 2.18}\n",
            "{'loss': 0.856, 'grad_norm': 0.09807763248682022, 'learning_rate': 0.0018489285613579327, 'epoch': 2.18}\n",
            "{'loss': 0.6077, 'grad_norm': 0.044967953115701675, 'learning_rate': 0.0018155408533255552, 'epoch': 2.19}\n",
            "{'loss': 0.7052, 'grad_norm': 0.10244230180978775, 'learning_rate': 0.001782390353638426, 'epoch': 2.2}\n",
            "{'loss': 0.6424, 'grad_norm': 0.07361122220754623, 'learning_rate': 0.0017494795316562789, 'epoch': 2.21}\n",
            "{'loss': 0.865, 'grad_norm': 0.13715636730194092, 'learning_rate': 0.0017168108388853998, 'epoch': 2.22}\n",
            "{'loss': 0.5048, 'grad_norm': 0.03500232845544815, 'learning_rate': 0.001684386708796025, 'epoch': 2.22}\n",
            "{'loss': 0.6219, 'grad_norm': 0.06460845470428467, 'learning_rate': 0.0016522095566410728, 'epoch': 2.23}\n",
            "{'loss': 0.8399, 'grad_norm': 0.13492977619171143, 'learning_rate': 0.001620281779276228, 'epoch': 2.24}\n",
            "{'loss': 0.5281, 'grad_norm': 0.060806773602962494, 'learning_rate': 0.0015886057549814132, 'epoch': 2.25}\n",
            "{'loss': 0.5122, 'grad_norm': 0.07307994365692139, 'learning_rate': 0.001557183843283614, 'epoch': 2.26}\n",
            "{'loss': 1.002, 'grad_norm': 0.10539936274290085, 'learning_rate': 0.0015260183847811382, 'epoch': 2.26}\n",
            "{'loss': 0.5733, 'grad_norm': 0.04439222440123558, 'learning_rate': 0.0014951117009692528, 'epoch': 2.27}\n",
            "{'loss': 0.608, 'grad_norm': 0.04892466589808464, 'learning_rate': 0.0014644660940672626, 'epoch': 2.28}\n",
            "{'loss': 0.6854, 'grad_norm': 0.09032008796930313, 'learning_rate': 0.0014340838468470197, 'epoch': 2.29}\n",
            "{'loss': 0.8427, 'grad_norm': 0.088962122797966, 'learning_rate': 0.0014039672224628785, 'epoch': 2.3}\n",
            "{'loss': 0.4738, 'grad_norm': 0.02597537636756897, 'learning_rate': 0.001374118464283119, 'epoch': 2.3}\n",
            "{'loss': 0.5265, 'grad_norm': 0.03938587009906769, 'learning_rate': 0.0013445397957228338, 'epoch': 2.31}\n",
            "{'loss': 0.6143, 'grad_norm': 0.04994433745741844, 'learning_rate': 0.0013152334200783166, 'epoch': 2.32}\n",
            "{'loss': 0.7892, 'grad_norm': 0.07709919661283493, 'learning_rate': 0.0012862015203629273, 'epoch': 2.33}\n",
            "{'loss': 0.4786, 'grad_norm': 0.03407351300120354, 'learning_rate': 0.001257446259144494, 'epoch': 2.34}\n",
            "{'loss': 0.6988, 'grad_norm': 0.05743688717484474, 'learning_rate': 0.0012289697783842142, 'epoch': 2.34}\n",
            "{'loss': 0.5851, 'grad_norm': 0.07021281868219376, 'learning_rate': 0.0012007741992771065, 'epoch': 2.35}\n",
            "{'loss': 0.4872, 'grad_norm': 0.04437173157930374, 'learning_rate': 0.0011728616220940031, 'epoch': 2.36}\n",
            "{'loss': 0.7945, 'grad_norm': 0.06500142067670822, 'learning_rate': 0.001145234126025102, 'epoch': 2.37}\n",
            "{'loss': 0.6969, 'grad_norm': 0.0872720256447792, 'learning_rate': 0.0011178937690250917, 'epoch': 2.38}\n",
            "{'loss': 1.0797, 'grad_norm': 0.09525375068187714, 'learning_rate': 0.001090842587659851, 'epoch': 2.38}\n",
            "{'loss': 0.5521, 'grad_norm': 0.06170133501291275, 'learning_rate': 0.0010640825969547496, 'epoch': 2.39}\n",
            "{'loss': 0.8699, 'grad_norm': 0.073295958340168, 'learning_rate': 0.0010376157902445488, 'epoch': 2.4}\n",
            "{'loss': 1.0096, 'grad_norm': 0.09243690967559814, 'learning_rate': 0.00101144413902492, 'epoch': 2.41}\n",
            "{'loss': 1.0579, 'grad_norm': 0.09516268223524094, 'learning_rate': 0.000985569592805588, 'epoch': 2.42}\n",
            "{'loss': 0.7273, 'grad_norm': 0.0860133171081543, 'learning_rate': 0.0009599940789651179, 'epoch': 2.42}\n",
            "{'loss': 0.6816, 'grad_norm': 0.10059727728366852, 'learning_rate': 0.0009347195026073368, 'epoch': 2.43}\n",
            "{'loss': 0.573, 'grad_norm': 0.04686173424124718, 'learning_rate': 0.000909747746419436, 'epoch': 2.44}\n",
            "{'loss': 0.4371, 'grad_norm': 0.03395360708236694, 'learning_rate': 0.0008850806705317183, 'epoch': 2.45}\n",
            "{'loss': 0.8072, 'grad_norm': 0.13862983882427216, 'learning_rate': 0.0008607201123790459, 'epoch': 2.46}\n",
            "{'loss': 0.4472, 'grad_norm': 0.0406930148601532, 'learning_rate': 0.0008366678865639688, 'epoch': 2.46}\n",
            "{'loss': 0.5035, 'grad_norm': 0.03510449081659317, 'learning_rate': 0.0008129257847215571, 'epoch': 2.47}\n",
            "{'loss': 0.5069, 'grad_norm': 0.04482687637209892, 'learning_rate': 0.0007894955753859412, 'epoch': 2.48}\n",
            "{'loss': 0.489, 'grad_norm': 0.04774913191795349, 'learning_rate': 0.0007663790038585794, 'epoch': 2.49}\n",
            "{'loss': 0.7497, 'grad_norm': 0.08000639826059341, 'learning_rate': 0.0007435777920782444, 'epoch': 2.5}\n",
            "{'loss': 0.5278, 'grad_norm': 0.04803040623664856, 'learning_rate': 0.000721093638492763, 'epoch': 2.5}\n",
            "{'loss': 0.4874, 'grad_norm': 0.04177581146359444, 'learning_rate': 0.0006989282179324963, 'epoch': 2.51}\n",
            "{'loss': 0.9209, 'grad_norm': 0.14828170835971832, 'learning_rate': 0.0006770831814855883, 'epoch': 2.52}\n",
            "{'loss': 0.6903, 'grad_norm': 0.09367841482162476, 'learning_rate': 0.0006555601563749675, 'epoch': 2.53}\n",
            "{'loss': 0.5531, 'grad_norm': 0.03856675326824188, 'learning_rate': 0.0006343607458371459, 'epoch': 2.54}\n",
            "{'loss': 0.627, 'grad_norm': 0.03144349902868271, 'learning_rate': 0.0006134865290027902, 'epoch': 2.54}\n",
            "{'loss': 0.675, 'grad_norm': 0.11000874638557434, 'learning_rate': 0.000592939060779093, 'epoch': 2.55}\n",
            "{'loss': 0.4756, 'grad_norm': 0.030614394694566727, 'learning_rate': 0.000572719871733951, 'epoch': 2.56}\n",
            "{'loss': 0.4199, 'grad_norm': 0.035722434520721436, 'learning_rate': 0.0005528304679819513, 'epoch': 2.57}\n",
            "{'loss': 0.7547, 'grad_norm': 0.09233201295137405, 'learning_rate': 0.0005332723310721854, 'epoch': 2.58}\n",
            "{'loss': 0.8346, 'grad_norm': 0.06846392899751663, 'learning_rate': 0.0005140469178778845, 'epoch': 2.58}\n",
            "{'loss': 0.7286, 'grad_norm': 0.07912420481443405, 'learning_rate': 0.0004951556604879049, 'epoch': 2.59}\n",
            "{'loss': 0.7091, 'grad_norm': 0.09031970798969269, 'learning_rate': 0.00047659996610004417, 'epoch': 2.6}\n",
            "{'loss': 0.8547, 'grad_norm': 0.08170560002326965, 'learning_rate': 0.00045838121691622993, 'epoch': 2.61}\n",
            "{'loss': 0.9319, 'grad_norm': 0.07106147706508636, 'learning_rate': 0.0004405007700395497, 'epoch': 2.62}\n",
            "{'loss': 0.7672, 'grad_norm': 0.1035757064819336, 'learning_rate': 0.0004229599573731685, 'epoch': 2.62}\n",
            "{'loss': 0.9585, 'grad_norm': 0.13762956857681274, 'learning_rate': 0.0004057600855211141, 'epoch': 2.63}\n",
            "{'loss': 0.5561, 'grad_norm': 0.0585806705057621, 'learning_rate': 0.00038890243569094876, 'epoch': 2.64}\n",
            "{'loss': 0.6114, 'grad_norm': 0.0593905933201313, 'learning_rate': 0.0003723882635983328, 'epoch': 2.65}\n",
            "{'loss': 0.6558, 'grad_norm': 0.06223208084702492, 'learning_rate': 0.00035621879937348835, 'epoch': 2.66}\n",
            "{'loss': 0.5301, 'grad_norm': 0.05547632277011871, 'learning_rate': 0.00034039524746956595, 'epoch': 2.66}\n",
            "{'loss': 0.8832, 'grad_norm': 0.08297756314277649, 'learning_rate': 0.0003249187865729264, 'epoch': 2.67}\n",
            "{'loss': 0.9689, 'grad_norm': 0.1189231127500534, 'learning_rate': 0.0003097905695153408, 'epoch': 2.68}\n",
            "{'loss': 0.7749, 'grad_norm': 0.10120752453804016, 'learning_rate': 0.0002950117231881183, 'epoch': 2.69}\n",
            "{'loss': 0.695, 'grad_norm': 0.07592735439538956, 'learning_rate': 0.0002805833484581621, 'epoch': 2.7}\n",
            "{'loss': 0.5648, 'grad_norm': 0.026261432096362114, 'learning_rate': 0.00026650652008597067, 'epoch': 2.7}\n",
            "{'loss': 0.6026, 'grad_norm': 0.0768183171749115, 'learning_rate': 0.0002527822866455731, 'epoch': 2.71}\n",
            "{'loss': 0.6261, 'grad_norm': 0.06482557952404022, 'learning_rate': 0.00023941167044642941, 'epoch': 2.72}\n",
            "{'loss': 1.0931, 'grad_norm': 0.13050754368305206, 'learning_rate': 0.00022639566745727202, 'epoch': 2.73}\n",
            "{'loss': 0.8832, 'grad_norm': 0.12193478643894196, 'learning_rate': 0.0002137352472319215, 'epoch': 2.74}\n",
            "{'loss': 0.4961, 'grad_norm': 0.05950853228569031, 'learning_rate': 0.0002014313528370626, 'epoch': 2.74}\n",
            "{'loss': 0.7216, 'grad_norm': 0.07076854258775711, 'learning_rate': 0.00018948490078199765, 'epoch': 2.75}\n",
            "{'loss': 0.4742, 'grad_norm': 0.037785228341817856, 'learning_rate': 0.00017789678095037452, 'epoch': 2.76}\n",
            "{'loss': 0.7631, 'grad_norm': 0.05712540075182915, 'learning_rate': 0.0001666678565339025, 'epoch': 2.77}\n",
            "{'loss': 0.8138, 'grad_norm': 0.08366157859563828, 'learning_rate': 0.0001557989639680496, 'epoch': 2.78}\n",
            "{'loss': 0.5787, 'grad_norm': 0.05914333090186119, 'learning_rate': 0.00014529091286973994, 'epoch': 2.78}\n",
            "{'loss': 0.7443, 'grad_norm': 0.0495062954723835, 'learning_rate': 0.0001351444859770462, 'epoch': 2.79}\n",
            "{'loss': 0.8838, 'grad_norm': 0.07130412012338638, 'learning_rate': 0.0001253604390908819, 'epoch': 2.8}\n",
            "{'loss': 0.627, 'grad_norm': 0.09401743113994598, 'learning_rate': 0.0001159395010187042, 'epoch': 2.81}\n",
            "{'loss': 0.7565, 'grad_norm': 0.07865975797176361, 'learning_rate': 0.00010688237352022346, 'epoch': 2.82}\n",
            "{'loss': 0.9998, 'grad_norm': 0.0953499898314476, 'learning_rate': 9.818973125513276e-05, 'epoch': 2.82}\n",
            "{'loss': 0.8806, 'grad_norm': 0.11414788663387299, 'learning_rate': 8.986222173284874e-05, 'epoch': 2.83}\n",
            "{'loss': 0.7445, 'grad_norm': 0.04568527638912201, 'learning_rate': 8.190046526428241e-05, 'epoch': 2.84}\n",
            "{'loss': 1.0269, 'grad_norm': 0.10624265670776367, 'learning_rate': 7.4305054915631e-05, 'epoch': 2.85}\n",
            "{'loss': 0.6681, 'grad_norm': 0.05248740687966347, 'learning_rate': 6.707655646420229e-05, 'epoch': 2.86}\n",
            "{'loss': 0.8352, 'grad_norm': 0.09868314862251282, 'learning_rate': 6.0215508356267765e-05, 'epoch': 2.86}\n",
            "{'loss': 0.3921, 'grad_norm': 0.024036230519413948, 'learning_rate': 5.372242166695684e-05, 'epoch': 2.87}\n",
            "{'loss': 0.5241, 'grad_norm': 0.048713043332099915, 'learning_rate': 4.759778006218407e-05, 'epoch': 2.88}\n",
            "{'loss': 0.9071, 'grad_norm': 0.08991561830043793, 'learning_rate': 4.184203976262513e-05, 'epoch': 2.89}\n",
            "{'loss': 0.4123, 'grad_norm': 0.03647613897919655, 'learning_rate': 3.645562950973014e-05, 'epoch': 2.9}\n",
            "{'loss': 0.7197, 'grad_norm': 0.11864694952964783, 'learning_rate': 3.143895053378698e-05, 'epoch': 2.9}\n",
            "{'loss': 0.4019, 'grad_norm': 0.03611496090888977, 'learning_rate': 2.6792376524036878e-05, 'epoch': 2.91}\n",
            "{'loss': 0.7963, 'grad_norm': 0.07644661515951157, 'learning_rate': 2.2516253600833868e-05, 'epoch': 2.92}\n",
            "{'loss': 0.7657, 'grad_norm': 0.05722372978925705, 'learning_rate': 1.8610900289867673e-05, 'epoch': 2.93}\n",
            "{'loss': 0.5661, 'grad_norm': 0.07176367938518524, 'learning_rate': 1.5076607498433204e-05, 'epoch': 2.94}\n",
            "{'loss': 0.6086, 'grad_norm': 0.0540834441781044, 'learning_rate': 1.1913638493762369e-05, 'epoch': 2.94}\n",
            "{'loss': 0.4128, 'grad_norm': 0.03540078178048134, 'learning_rate': 9.12222888341252e-06, 'epoch': 2.95}\n",
            "{'loss': 0.6231, 'grad_norm': 0.06927669793367386, 'learning_rate': 6.702586597719385e-06, 'epoch': 2.96}\n",
            "{'loss': 0.6828, 'grad_norm': 0.08369327336549759, 'learning_rate': 4.654891874303346e-06, 'epoch': 2.97}\n",
            "{'loss': 0.8382, 'grad_norm': 0.09032104909420013, 'learning_rate': 2.9792972446479605e-06, 'epoch': 2.98}\n",
            "{'loss': 0.6813, 'grad_norm': 0.08934947848320007, 'learning_rate': 1.6759275227357095e-06, 'epoch': 2.98}\n",
            "{'loss': 0.5963, 'grad_norm': 0.04318905249238014, 'learning_rate': 7.448797957526621e-07, 'epoch': 2.99}\n",
            "{'loss': 0.8703, 'grad_norm': 0.06679540872573853, 'learning_rate': 1.862234168542587e-07, 'epoch': 3.0}\n",
            "{'train_runtime': 67.9657, 'train_samples_per_second': 11.035, 'train_steps_per_second': 5.517, 'train_loss': 1.2909221575260161, 'epoch': 3.0}\n",
            "100% 375/375 [01:07<00:00,  5.52it/s]\n",
            "Training complete.\n",
            "Model saved to loras/self-edit/training_set_iteration_1/8d5021e8/9\n",
            "Training on 250 examples for 3 epochs, lr: 0.001\n",
            "No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n",
            "Starting training...\n",
            "{'loss': 9.3081, 'grad_norm': 13.361322402954102, 'learning_rate': 0.0, 'epoch': 0.01}\n",
            "{'loss': 7.0598, 'grad_norm': 9.681258201599121, 'learning_rate': 9.090909090909092e-05, 'epoch': 0.02}\n",
            "{'loss': 6.1683, 'grad_norm': 9.950617790222168, 'learning_rate': 0.00018181818181818183, 'epoch': 0.02}\n",
            "{'loss': 1.1545, 'grad_norm': 9.590618133544922, 'learning_rate': 0.00027272727272727274, 'epoch': 0.03}\n",
            "{'loss': 2.4424, 'grad_norm': 29.46978187561035, 'learning_rate': 0.00036363636363636367, 'epoch': 0.04}\n",
            "{'loss': 0.2948, 'grad_norm': 3.3068783283233643, 'learning_rate': 0.00045454545454545455, 'epoch': 0.05}\n",
            "{'loss': 0.0917, 'grad_norm': 0.12904813885688782, 'learning_rate': 0.0005454545454545455, 'epoch': 0.06}\n",
            "{'loss': 0.0872, 'grad_norm': 0.16333499550819397, 'learning_rate': 0.0006363636363636364, 'epoch': 0.06}\n",
            "{'loss': 0.0828, 'grad_norm': 0.17202772200107574, 'learning_rate': 0.0007272727272727273, 'epoch': 0.07}\n",
            "{'loss': 0.0398, 'grad_norm': 0.06204494088888168, 'learning_rate': 0.0008181818181818183, 'epoch': 0.08}\n",
            "{'loss': 0.042, 'grad_norm': 0.1006861999630928, 'learning_rate': 0.0009090909090909091, 'epoch': 0.09}\n",
            "{'loss': 0.0324, 'grad_norm': 0.08301661908626556, 'learning_rate': 0.001, 'epoch': 0.1}\n",
            "{'loss': 0.0264, 'grad_norm': 0.046479012817144394, 'learning_rate': 0.0009999813776583146, 'epoch': 0.1}\n",
            "{'loss': 0.0315, 'grad_norm': 0.07356024533510208, 'learning_rate': 0.0009999255120204248, 'epoch': 0.11}\n",
            "{'loss': 0.0227, 'grad_norm': 0.06849493831396103, 'learning_rate': 0.0009998324072477264, 'epoch': 0.12}\n",
            "{'loss': 0.013, 'grad_norm': 0.038063500076532364, 'learning_rate': 0.0009997020702755353, 'epoch': 0.13}\n",
            "{'loss': 0.0329, 'grad_norm': 0.08550228923559189, 'learning_rate': 0.0009995345108125698, 'epoch': 0.14}\n",
            "{'loss': 0.0325, 'grad_norm': 0.06390471756458282, 'learning_rate': 0.0009993297413402281, 'epoch': 0.14}\n",
            "{'loss': 0.0116, 'grad_norm': 0.06777160614728928, 'learning_rate': 0.0009990877771116587, 'epoch': 0.15}\n",
            "{'loss': 0.0141, 'grad_norm': 0.06667200475931168, 'learning_rate': 0.0009988086361506238, 'epoch': 0.16}\n",
            "{'loss': 0.0199, 'grad_norm': 0.08050884306430817, 'learning_rate': 0.0009984923392501567, 'epoch': 0.17}\n",
            "{'loss': 0.0226, 'grad_norm': 0.09435240924358368, 'learning_rate': 0.0009981389099710132, 'epoch': 0.18}\n",
            "{'loss': 0.0281, 'grad_norm': 0.05317247286438942, 'learning_rate': 0.0009977483746399167, 'epoch': 0.18}\n",
            "{'loss': 0.0179, 'grad_norm': 0.04708085581660271, 'learning_rate': 0.0009973207623475964, 'epoch': 0.19}\n",
            "{'loss': 0.0167, 'grad_norm': 0.03345721960067749, 'learning_rate': 0.0009968561049466214, 'epoch': 0.2}\n",
            "{'loss': 0.0126, 'grad_norm': 0.04112924262881279, 'learning_rate': 0.000996354437049027, 'epoch': 0.21}\n",
            "{'loss': 0.0197, 'grad_norm': 0.05423581600189209, 'learning_rate': 0.0009958157960237375, 'epoch': 0.22}\n",
            "{'loss': 0.0163, 'grad_norm': 0.05815080925822258, 'learning_rate': 0.0009952402219937815, 'epoch': 0.22}\n",
            "{'loss': 0.0075, 'grad_norm': 0.03996925801038742, 'learning_rate': 0.0009946277578333045, 'epoch': 0.23}\n",
            "{'loss': 0.0038, 'grad_norm': 0.024563366547226906, 'learning_rate': 0.0009939784491643732, 'epoch': 0.24}\n",
            "{'loss': 0.0301, 'grad_norm': 0.10162139683961868, 'learning_rate': 0.0009932923443535797, 'epoch': 0.25}\n",
            "{'loss': 0.0082, 'grad_norm': 0.05176051706075668, 'learning_rate': 0.000992569494508437, 'epoch': 0.26}\n",
            "{'loss': 0.0079, 'grad_norm': 0.09184184670448303, 'learning_rate': 0.0009918099534735718, 'epoch': 0.26}\n",
            "{'loss': 0.0181, 'grad_norm': 0.13921774923801422, 'learning_rate': 0.0009910137778267152, 'epoch': 0.27}\n",
            "{'loss': 0.0102, 'grad_norm': 0.06349461525678635, 'learning_rate': 0.0009901810268744867, 'epoch': 0.28}\n",
            "{'loss': 0.0045, 'grad_norm': 0.040090952068567276, 'learning_rate': 0.0009893117626479776, 'epoch': 0.29}\n",
            "{'loss': 0.0017, 'grad_norm': 0.013521847315132618, 'learning_rate': 0.0009884060498981295, 'epoch': 0.3}\n",
            "{'loss': 0.0045, 'grad_norm': 0.05690561980009079, 'learning_rate': 0.0009874639560909118, 'epoch': 0.3}\n",
            "{'loss': 0.013, 'grad_norm': 0.09044423699378967, 'learning_rate': 0.0009864855514022954, 'epoch': 0.31}\n",
            "{'loss': 0.0179, 'grad_norm': 0.1744617223739624, 'learning_rate': 0.000985470908713026, 'epoch': 0.32}\n",
            "{'loss': 0.0094, 'grad_norm': 0.08009448647499084, 'learning_rate': 0.0009844201036031952, 'epoch': 0.33}\n",
            "{'loss': 0.0068, 'grad_norm': 0.04287039861083031, 'learning_rate': 0.0009833332143466098, 'epoch': 0.34}\n",
            "{'loss': 0.0096, 'grad_norm': 0.058852214366197586, 'learning_rate': 0.0009822103219049626, 'epoch': 0.34}\n",
            "{'loss': 0.0135, 'grad_norm': 0.09422604739665985, 'learning_rate': 0.0009810515099218002, 'epoch': 0.35}\n",
            "{'loss': 0.0047, 'grad_norm': 0.05359087139368057, 'learning_rate': 0.0009798568647162937, 'epoch': 0.36}\n",
            "{'loss': 0.003, 'grad_norm': 0.025572244077920914, 'learning_rate': 0.000978626475276808, 'epoch': 0.37}\n",
            "{'loss': 0.0157, 'grad_norm': 0.11479727923870087, 'learning_rate': 0.0009773604332542728, 'epoch': 0.38}\n",
            "{'loss': 0.0168, 'grad_norm': 0.11531487107276917, 'learning_rate': 0.0009760588329553571, 'epoch': 0.38}\n",
            "{'loss': 0.0045, 'grad_norm': 0.030981477349996567, 'learning_rate': 0.0009747217713354427, 'epoch': 0.39}\n",
            "{'loss': 0.0056, 'grad_norm': 0.04553993046283722, 'learning_rate': 0.000973349347991403, 'epoch': 0.4}\n",
            "{'loss': 0.0159, 'grad_norm': 0.10804042220115662, 'learning_rate': 0.0009719416651541838, 'epoch': 0.41}\n",
            "{'loss': 0.0035, 'grad_norm': 0.047174159437417984, 'learning_rate': 0.0009704988276811882, 'epoch': 0.42}\n",
            "{'loss': 0.007, 'grad_norm': 0.04342389851808548, 'learning_rate': 0.000969020943048466, 'epoch': 0.42}\n",
            "{'loss': 0.0039, 'grad_norm': 0.03147612884640694, 'learning_rate': 0.0009675081213427075, 'epoch': 0.43}\n",
            "{'loss': 0.0114, 'grad_norm': 0.20055021345615387, 'learning_rate': 0.0009659604752530434, 'epoch': 0.44}\n",
            "{'loss': 0.0078, 'grad_norm': 0.03586061671376228, 'learning_rate': 0.0009643781200626511, 'epoch': 0.45}\n",
            "{'loss': 0.0102, 'grad_norm': 0.03597011789679527, 'learning_rate': 0.0009627611736401667, 'epoch': 0.46}\n",
            "{'loss': 0.0206, 'grad_norm': 0.0935809314250946, 'learning_rate': 0.0009611097564309052, 'epoch': 0.46}\n",
            "{'loss': 0.0058, 'grad_norm': 0.03818667680025101, 'learning_rate': 0.0009594239914478886, 'epoch': 0.47}\n",
            "{'loss': 0.0042, 'grad_norm': 0.02010575495660305, 'learning_rate': 0.0009577040042626832, 'epoch': 0.48}\n",
            "{'loss': 0.0044, 'grad_norm': 0.019945085048675537, 'learning_rate': 0.0009559499229960451, 'epoch': 0.49}\n",
            "{'loss': 0.0154, 'grad_norm': 0.09618846327066422, 'learning_rate': 0.000954161878308377, 'epoch': 0.5}\n",
            "{'loss': 0.0026, 'grad_norm': 0.03219273313879967, 'learning_rate': 0.0009523400033899956, 'epoch': 0.5}\n",
            "{'loss': 0.0049, 'grad_norm': 0.022169960662722588, 'learning_rate': 0.0009504844339512095, 'epoch': 0.51}\n",
            "{'loss': 0.0098, 'grad_norm': 0.07411886006593704, 'learning_rate': 0.0009485953082122116, 'epoch': 0.52}\n",
            "{'loss': 0.0085, 'grad_norm': 0.06059817969799042, 'learning_rate': 0.0009466727668927816, 'epoch': 0.53}\n",
            "{'loss': 0.0153, 'grad_norm': 0.0907546728849411, 'learning_rate': 0.000944716953201805, 'epoch': 0.54}\n",
            "{'loss': 0.0038, 'grad_norm': 0.03846509009599686, 'learning_rate': 0.0009427280128266049, 'epoch': 0.54}\n",
            "{'loss': 0.0053, 'grad_norm': 0.04430879279971123, 'learning_rate': 0.0009407060939220907, 'epoch': 0.55}\n",
            "{'loss': 0.0041, 'grad_norm': 0.052024539560079575, 'learning_rate': 0.000938651347099721, 'epoch': 0.56}\n",
            "{'loss': 0.0114, 'grad_norm': 0.04844033345580101, 'learning_rate': 0.0009365639254162854, 'epoch': 0.57}\n",
            "{'loss': 0.0092, 'grad_norm': 0.0853547528386116, 'learning_rate': 0.0009344439843625034, 'epoch': 0.58}\n",
            "{'loss': 0.0037, 'grad_norm': 0.04686705023050308, 'learning_rate': 0.0009322916818514413, 'epoch': 0.58}\n",
            "{'loss': 0.0079, 'grad_norm': 0.09075221419334412, 'learning_rate': 0.0009301071782067504, 'epoch': 0.59}\n",
            "{'loss': 0.0031, 'grad_norm': 0.030797462910413742, 'learning_rate': 0.0009278906361507238, 'epoch': 0.6}\n",
            "{'loss': 0.0014, 'grad_norm': 0.02743210457265377, 'learning_rate': 0.0009256422207921756, 'epoch': 0.61}\n",
            "{'loss': 0.0004, 'grad_norm': 0.018291011452674866, 'learning_rate': 0.0009233620996141421, 'epoch': 0.62}\n",
            "{'loss': 0.0105, 'grad_norm': 0.08419925719499588, 'learning_rate': 0.0009210504424614059, 'epoch': 0.62}\n",
            "{'loss': 0.0123, 'grad_norm': 0.06058143079280853, 'learning_rate': 0.0009187074215278444, 'epoch': 0.63}\n",
            "{'loss': 0.0041, 'grad_norm': 0.04407087340950966, 'learning_rate': 0.0009163332113436032, 'epoch': 0.64}\n",
            "{'loss': 0.0013, 'grad_norm': 0.01726227067410946, 'learning_rate': 0.0009139279887620955, 'epoch': 0.65}\n",
            "{'loss': 0.0016, 'grad_norm': 0.023208437487483025, 'learning_rate': 0.0009114919329468282, 'epoch': 0.66}\n",
            "{'loss': 0.0019, 'grad_norm': 0.0315345823764801, 'learning_rate': 0.0009090252253580565, 'epoch': 0.66}\n",
            "{'loss': 0.0078, 'grad_norm': 0.032427895814180374, 'learning_rate': 0.0009065280497392663, 'epoch': 0.67}\n",
            "{'loss': 0.0014, 'grad_norm': 0.023845955729484558, 'learning_rate': 0.0009040005921034883, 'epoch': 0.68}\n",
            "{'loss': 0.0024, 'grad_norm': 0.061228856444358826, 'learning_rate': 0.0009014430407194413, 'epoch': 0.69}\n",
            "{'loss': 0.0023, 'grad_norm': 0.038323961198329926, 'learning_rate': 0.0008988555860975081, 'epoch': 0.7}\n",
            "{'loss': 0.0018, 'grad_norm': 0.042717866599559784, 'learning_rate': 0.0008962384209755452, 'epoch': 0.7}\n",
            "{'loss': 0.0044, 'grad_norm': 0.049289509654045105, 'learning_rate': 0.000893591740304525, 'epoch': 0.71}\n",
            "{'loss': 0.0023, 'grad_norm': 0.028348250314593315, 'learning_rate': 0.000890915741234015, 'epoch': 0.72}\n",
            "{'loss': 0.0049, 'grad_norm': 0.057769373059272766, 'learning_rate': 0.0008882106230974909, 'epoch': 0.73}\n",
            "{'loss': 0.0018, 'grad_norm': 0.03369555622339249, 'learning_rate': 0.0008854765873974899, 'epoch': 0.74}\n",
            "{'loss': 0.0058, 'grad_norm': 0.08912675082683563, 'learning_rate': 0.0008827138377905998, 'epoch': 0.74}\n",
            "{'loss': 0.0057, 'grad_norm': 0.05431757867336273, 'learning_rate': 0.0008799225800722895, 'epoch': 0.75}\n",
            "{'loss': 0.0029, 'grad_norm': 0.021900949999690056, 'learning_rate': 0.0008771030221615785, 'epoch': 0.76}\n",
            "{'loss': 0.0052, 'grad_norm': 0.02712608501315117, 'learning_rate': 0.0008742553740855505, 'epoch': 0.77}\n",
            "{'loss': 0.0016, 'grad_norm': 0.020322978496551514, 'learning_rate': 0.0008713798479637072, 'epoch': 0.78}\n",
            "{'loss': 0.0049, 'grad_norm': 0.07318715751171112, 'learning_rate': 0.0008684766579921683, 'epoch': 0.78}\n",
            "{'loss': 0.0097, 'grad_norm': 0.11992085725069046, 'learning_rate': 0.0008655460204277166, 'epoch': 0.79}\n",
            "{'loss': 0.0038, 'grad_norm': 0.03970145806670189, 'learning_rate': 0.0008625881535716883, 'epoch': 0.8}\n",
            "{'loss': 0.0075, 'grad_norm': 0.04374038055539131, 'learning_rate': 0.0008596032777537123, 'epoch': 0.81}\n",
            "{'loss': 0.02, 'grad_norm': 0.12556666135787964, 'learning_rate': 0.0008565916153152981, 'epoch': 0.82}\n",
            "{'loss': 0.005, 'grad_norm': 0.02813154272735119, 'learning_rate': 0.0008535533905932737, 'epoch': 0.82}\n",
            "{'loss': 0.0049, 'grad_norm': 0.024711325764656067, 'learning_rate': 0.0008504888299030747, 'epoch': 0.83}\n",
            "{'loss': 0.0029, 'grad_norm': 0.03302336111664772, 'learning_rate': 0.0008473981615218862, 'epoch': 0.84}\n",
            "{'loss': 0.0004, 'grad_norm': 0.010244674980640411, 'learning_rate': 0.0008442816156716386, 'epoch': 0.85}\n",
            "{'loss': 0.007, 'grad_norm': 0.054446086287498474, 'learning_rate': 0.0008411394245018588, 'epoch': 0.86}\n",
            "{'loss': 0.0077, 'grad_norm': 0.1371724009513855, 'learning_rate': 0.0008379718220723773, 'epoch': 0.86}\n",
            "{'loss': 0.0005, 'grad_norm': 0.012012897990643978, 'learning_rate': 0.0008347790443358929, 'epoch': 0.87}\n",
            "{'loss': 0.0054, 'grad_norm': 0.04868004471063614, 'learning_rate': 0.0008315613291203976, 'epoch': 0.88}\n",
            "{'loss': 0.0083, 'grad_norm': 0.11945395916700363, 'learning_rate': 0.0008283189161114601, 'epoch': 0.89}\n",
            "{'loss': 0.0074, 'grad_norm': 0.08565093576908112, 'learning_rate': 0.000825052046834372, 'epoch': 0.9}\n",
            "{'loss': 0.0021, 'grad_norm': 0.02309431880712509, 'learning_rate': 0.0008217609646361573, 'epoch': 0.9}\n",
            "{'loss': 0.001, 'grad_norm': 0.013584121130406857, 'learning_rate': 0.0008184459146674447, 'epoch': 0.91}\n",
            "{'loss': 0.0034, 'grad_norm': 0.039699919521808624, 'learning_rate': 0.0008151071438642068, 'epoch': 0.92}\n",
            "{'loss': 0.0078, 'grad_norm': 0.024657053872942924, 'learning_rate': 0.0008117449009293668, 'epoch': 0.93}\n",
            "{'loss': 0.0018, 'grad_norm': 0.029863249510526657, 'learning_rate': 0.0008083594363142716, 'epoch': 0.94}\n",
            "{'loss': 0.0018, 'grad_norm': 0.01483838353306055, 'learning_rate': 0.0008049510022000364, 'epoch': 0.94}\n",
            "{'loss': 0.0002, 'grad_norm': 0.0025772899389266968, 'learning_rate': 0.0008015198524787601, 'epoch': 0.95}\n",
            "{'loss': 0.0017, 'grad_norm': 0.020321454852819443, 'learning_rate': 0.0007980662427346127, 'epoch': 0.96}\n",
            "{'loss': 0.0015, 'grad_norm': 0.017932020127773285, 'learning_rate': 0.0007945904302247968, 'epoch': 0.97}\n",
            "{'loss': 0.0009, 'grad_norm': 0.037094246596097946, 'learning_rate': 0.0007910926738603854, 'epoch': 0.98}\n",
            "{'loss': 0.0102, 'grad_norm': 0.12158370763063431, 'learning_rate': 0.0007875732341870349, 'epoch': 0.98}\n",
            "{'loss': 0.0183, 'grad_norm': 0.10018627345561981, 'learning_rate': 0.0007840323733655779, 'epoch': 0.99}\n",
            "{'loss': 0.004, 'grad_norm': 0.027630235999822617, 'learning_rate': 0.0007804703551524948, 'epoch': 1.0}\n",
            "{'loss': 0.0037, 'grad_norm': 0.050748735666275024, 'learning_rate': 0.0007768874448802665, 'epoch': 1.01}\n",
            "{'loss': 0.0093, 'grad_norm': 0.06200820952653885, 'learning_rate': 0.0007732839094376105, 'epoch': 1.02}\n",
            "{'loss': 0.0061, 'grad_norm': 0.04487968981266022, 'learning_rate': 0.0007696600172495997, 'epoch': 1.02}\n",
            "{'loss': 0.0037, 'grad_norm': 0.043379850685596466, 'learning_rate': 0.0007660160382576683, 'epoch': 1.03}\n",
            "{'loss': 0.0019, 'grad_norm': 0.057424500584602356, 'learning_rate': 0.000762352243899504, 'epoch': 1.04}\n",
            "{'loss': 0.0105, 'grad_norm': 0.03351230174303055, 'learning_rate': 0.0007586689070888284, 'epoch': 1.05}\n",
            "{'loss': 0.0003, 'grad_norm': 0.0071091665886342525, 'learning_rate': 0.000754966302195068, 'epoch': 1.06}\n",
            "{'loss': 0.0008, 'grad_norm': 0.009691186249256134, 'learning_rate': 0.0007512447050229165, 'epoch': 1.06}\n",
            "{'loss': 0.0006, 'grad_norm': 0.008850337006151676, 'learning_rate': 0.0007475043927917907, 'epoch': 1.07}\n",
            "{'loss': 0.0002, 'grad_norm': 0.002061746083199978, 'learning_rate': 0.00074374564411518, 'epoch': 1.08}\n",
            "{'loss': 0.0036, 'grad_norm': 0.04951908439397812, 'learning_rate': 0.0007399687389798933, 'epoch': 1.09}\n",
            "{'loss': 0.0015, 'grad_norm': 0.05628904700279236, 'learning_rate': 0.0007361739587252019, 'epoch': 1.1}\n",
            "{'loss': 0.0002, 'grad_norm': 0.007166530936956406, 'learning_rate': 0.0007323615860218843, 'epoch': 1.1}\n",
            "{'loss': 0.0013, 'grad_norm': 0.028265904635190964, 'learning_rate': 0.000728531904851169, 'epoch': 1.11}\n",
            "{'loss': 0.0001, 'grad_norm': 0.007799752056598663, 'learning_rate': 0.0007246852004835807, 'epoch': 1.12}\n",
            "{'loss': 0.0008, 'grad_norm': 0.012781552970409393, 'learning_rate': 0.0007208217594576922, 'epoch': 1.13}\n",
            "{'loss': 0.0054, 'grad_norm': 0.0721728652715683, 'learning_rate': 0.0007169418695587791, 'epoch': 1.14}\n",
            "{'loss': 0.0058, 'grad_norm': 0.08783703297376633, 'learning_rate': 0.0007130458197973828, 'epoch': 1.14}\n",
            "{'loss': 0.0044, 'grad_norm': 0.03433586284518242, 'learning_rate': 0.0007091339003877826, 'epoch': 1.15}\n",
            "{'loss': 0.0005, 'grad_norm': 0.012872450985014439, 'learning_rate': 0.0007052064027263785, 'epoch': 1.16}\n",
            "{'loss': 0.0094, 'grad_norm': 0.04478228837251663, 'learning_rate': 0.0007012636193699837, 'epoch': 1.17}\n",
            "{'loss': 0.0013, 'grad_norm': 0.010964981280267239, 'learning_rate': 0.0006973058440140341, 'epoch': 1.18}\n",
            "{'loss': 0.0016, 'grad_norm': 0.021227043122053146, 'learning_rate': 0.0006933333714707094, 'epoch': 1.18}\n",
            "{'loss': 0.0066, 'grad_norm': 0.025003911927342415, 'learning_rate': 0.0006893464976469738, 'epoch': 1.19}\n",
            "{'loss': 0.0161, 'grad_norm': 0.0587838739156723, 'learning_rate': 0.0006853455195225339, 'epoch': 1.2}\n",
            "{'loss': 0.0003, 'grad_norm': 0.003093802137300372, 'learning_rate': 0.000681330735127716, 'epoch': 1.21}\n",
            "{'loss': 0.006, 'grad_norm': 0.05734887346625328, 'learning_rate': 0.0006773024435212678, 'epoch': 1.22}\n",
            "{'loss': 0.0005, 'grad_norm': 0.006336049642413855, 'learning_rate': 0.00067326094476808, 'epoch': 1.22}\n",
            "{'loss': 0.0022, 'grad_norm': 0.014276859350502491, 'learning_rate': 0.0006692065399168352, 'epoch': 1.23}\n",
            "{'loss': 0.0027, 'grad_norm': 0.023725410923361778, 'learning_rate': 0.0006651395309775837, 'epoch': 1.24}\n",
            "{'loss': 0.0051, 'grad_norm': 0.03549179434776306, 'learning_rate': 0.0006610602208992453, 'epoch': 1.25}\n",
            "{'loss': 0.0005, 'grad_norm': 0.005946178920567036, 'learning_rate': 0.000656968913547045, 'epoch': 1.26}\n",
            "{'loss': 0.0016, 'grad_norm': 0.016235683113336563, 'learning_rate': 0.0006528659136798764, 'epoch': 1.26}\n",
            "{'loss': 0.0023, 'grad_norm': 0.03499165549874306, 'learning_rate': 0.0006487515269276015, 'epoch': 1.27}\n",
            "{'loss': 0.0135, 'grad_norm': 0.06857674568891525, 'learning_rate': 0.0006446260597682839, 'epoch': 1.28}\n",
            "{'loss': 0.0003, 'grad_norm': 0.0027790633030235767, 'learning_rate': 0.0006404898195053597, 'epoch': 1.29}\n",
            "{'loss': 0.0065, 'grad_norm': 0.03378574922680855, 'learning_rate': 0.0006363431142447468, 'epoch': 1.3}\n",
            "{'loss': 0.0015, 'grad_norm': 0.009590511210262775, 'learning_rate': 0.0006321862528718945, 'epoch': 1.3}\n",
            "{'loss': 0.0008, 'grad_norm': 0.009277798235416412, 'learning_rate': 0.0006280195450287736, 'epoch': 1.31}\n",
            "{'loss': 0.0018, 'grad_norm': 0.01457014586776495, 'learning_rate': 0.000623843301090813, 'epoch': 1.32}\n",
            "{'loss': 0.0078, 'grad_norm': 0.045257896184921265, 'learning_rate': 0.0006196578321437789, 'epoch': 1.33}\n",
            "{'loss': 0.001, 'grad_norm': 0.007977969944477081, 'learning_rate': 0.0006154634499606029, 'epoch': 1.34}\n",
            "{'loss': 0.0013, 'grad_norm': 0.012112502008676529, 'learning_rate': 0.0006112604669781572, 'epoch': 1.34}\n",
            "{'loss': 0.0003, 'grad_norm': 0.003417725907638669, 'learning_rate': 0.000607049196273983, 'epoch': 1.35}\n",
            "{'loss': 0.0023, 'grad_norm': 0.015524319373071194, 'learning_rate': 0.0006028299515429683, 'epoch': 1.36}\n",
            "{'loss': 0.0013, 'grad_norm': 0.013336418196558952, 'learning_rate': 0.0005986030470739811, 'epoch': 1.37}\n",
            "{'loss': 0.0006, 'grad_norm': 0.006203228607773781, 'learning_rate': 0.0005943687977264583, 'epoch': 1.38}\n",
            "{'loss': 0.0006, 'grad_norm': 0.009192163124680519, 'learning_rate': 0.000590127518906953, 'epoch': 1.38}\n",
            "{'loss': 0.0043, 'grad_norm': 0.10727531462907791, 'learning_rate': 0.0005858795265456381, 'epoch': 1.39}\n",
            "{'loss': 0.0001, 'grad_norm': 0.0008741750498302281, 'learning_rate': 0.0005816251370727748, 'epoch': 1.4}\n",
            "{'loss': 0.0007, 'grad_norm': 0.007538235746324062, 'learning_rate': 0.0005773646673951406, 'epoch': 1.41}\n",
            "{'loss': 0.0009, 'grad_norm': 0.010118752717971802, 'learning_rate': 0.0005730984348724242, 'epoch': 1.42}\n",
            "{'loss': 0.0001, 'grad_norm': 0.0013833754928782582, 'learning_rate': 0.0005688267572935842, 'epoch': 1.42}\n",
            "{'loss': 0.0003, 'grad_norm': 0.005904692225158215, 'learning_rate': 0.0005645499528531784, 'epoch': 1.43}\n",
            "{'loss': 0.001, 'grad_norm': 0.025736737996339798, 'learning_rate': 0.0005602683401276614, 'epoch': 1.44}\n",
            "{'loss': 0.0002, 'grad_norm': 0.010531743988394737, 'learning_rate': 0.0005559822380516539, 'epoch': 1.45}\n",
            "{'loss': 0.002, 'grad_norm': 0.049693502485752106, 'learning_rate': 0.000551691965894185, 'epoch': 1.46}\n",
            "{'loss': 0.0001, 'grad_norm': 0.002060514409095049, 'learning_rate': 0.0005473978432349112, 'epoch': 1.46}\n",
            "{'loss': 0.0002, 'grad_norm': 0.013908646069467068, 'learning_rate': 0.0005431001899403097, 'epoch': 1.47}\n",
            "{'loss': 0.0063, 'grad_norm': 0.13450182974338531, 'learning_rate': 0.0005387993261398532, 'epoch': 1.48}\n",
            "{'loss': 0.0004, 'grad_norm': 0.017892424017190933, 'learning_rate': 0.0005344955722021623, 'epoch': 1.49}\n",
            "{'loss': 0.0017, 'grad_norm': 0.03284508362412453, 'learning_rate': 0.0005301892487111431, 'epoch': 1.5}\n",
            "{'loss': 0.0, 'grad_norm': 0.0003442872839514166, 'learning_rate': 0.0005258806764421047, 'epoch': 1.5}\n",
            "{'loss': 0.0001, 'grad_norm': 0.0014639708679169416, 'learning_rate': 0.0005215701763378673, 'epoch': 1.51}\n",
            "{'loss': 0.0002, 'grad_norm': 0.008373907767236233, 'learning_rate': 0.0005172580694848541, 'epoch': 1.52}\n",
            "{'loss': 0.0013, 'grad_norm': 0.03623543307185173, 'learning_rate': 0.0005129446770891738, 'epoch': 1.53}\n",
            "{'loss': 0.008, 'grad_norm': 0.06516332179307938, 'learning_rate': 0.0005086303204526943, 'epoch': 1.54}\n",
            "{'loss': 0.0021, 'grad_norm': 0.042495936155319214, 'learning_rate': 0.0005043153209491095, 'epoch': 1.54}\n",
            "{'loss': 0.0084, 'grad_norm': 0.03630127012729645, 'learning_rate': 0.0005, 'epoch': 1.55}\n",
            "{'loss': 0.0016, 'grad_norm': 0.016901176422834396, 'learning_rate': 0.0004956846790508906, 'epoch': 1.56}\n",
            "{'loss': 0.0003, 'grad_norm': 0.004565004725009203, 'learning_rate': 0.0004913696795473058, 'epoch': 1.57}\n",
            "{'loss': 0.0004, 'grad_norm': 0.005941737908869982, 'learning_rate': 0.0004870553229108264, 'epoch': 1.58}\n",
            "{'loss': 0.0003, 'grad_norm': 0.004210222512483597, 'learning_rate': 0.0004827419305151461, 'epoch': 1.58}\n",
            "{'loss': 0.0066, 'grad_norm': 0.09214271605014801, 'learning_rate': 0.00047842982366213274, 'epoch': 1.59}\n",
            "{'loss': 0.0005, 'grad_norm': 0.006071476265788078, 'learning_rate': 0.0004741193235578952, 'epoch': 1.6}\n",
            "{'loss': 0.0001, 'grad_norm': 0.002634159056469798, 'learning_rate': 0.0004698107512888569, 'epoch': 1.61}\n",
            "{'loss': 0.0004, 'grad_norm': 0.0059360540471971035, 'learning_rate': 0.0004655044277978375, 'epoch': 1.62}\n",
            "{'loss': 0.0015, 'grad_norm': 0.017273925244808197, 'learning_rate': 0.0004612006738601469, 'epoch': 1.62}\n",
            "{'loss': 0.0, 'grad_norm': 0.00017202187154907733, 'learning_rate': 0.00045689981005969026, 'epoch': 1.63}\n",
            "{'loss': 0.0006, 'grad_norm': 0.009037824347615242, 'learning_rate': 0.00045260215676508895, 'epoch': 1.64}\n",
            "{'loss': 0.0001, 'grad_norm': 0.0012328880839049816, 'learning_rate': 0.000448308034105815, 'epoch': 1.65}\n",
            "{'loss': 0.0001, 'grad_norm': 0.0017562301363795996, 'learning_rate': 0.0004440177619483461, 'epoch': 1.66}\n",
            "{'loss': 0.0001, 'grad_norm': 0.0029116689693182707, 'learning_rate': 0.00043973165987233853, 'epoch': 1.66}\n",
            "{'loss': 0.0032, 'grad_norm': 0.024874679744243622, 'learning_rate': 0.0004354500471468217, 'epoch': 1.67}\n",
            "{'loss': 0.0001, 'grad_norm': 0.0039850082248449326, 'learning_rate': 0.00043117324270641603, 'epoch': 1.68}\n",
            "{'loss': 0.0004, 'grad_norm': 0.006795158609747887, 'learning_rate': 0.00042690156512757607, 'epoch': 1.69}\n",
            "{'loss': 0.001, 'grad_norm': 0.039723820984363556, 'learning_rate': 0.0004226353326048593, 'epoch': 1.7}\n",
            "{'loss': 0.0002, 'grad_norm': 0.0038542388938367367, 'learning_rate': 0.00041837486292722534, 'epoch': 1.7}\n",
            "{'loss': 0.0005, 'grad_norm': 0.00448913499712944, 'learning_rate': 0.00041412047345436195, 'epoch': 1.71}\n",
            "{'loss': 0.0004, 'grad_norm': 0.0046922690235078335, 'learning_rate': 0.00040987248109304716, 'epoch': 1.72}\n",
            "{'loss': 0.0001, 'grad_norm': 0.004176496993750334, 'learning_rate': 0.0004056312022735417, 'epoch': 1.73}\n",
            "{'loss': 0.0001, 'grad_norm': 0.001243698294274509, 'learning_rate': 0.000401396952926019, 'epoch': 1.74}\n",
            "{'loss': 0.0048, 'grad_norm': 0.026259632781147957, 'learning_rate': 0.00039717004845703176, 'epoch': 1.74}\n",
            "{'loss': 0.0011, 'grad_norm': 0.02945091761648655, 'learning_rate': 0.000392950803726017, 'epoch': 1.75}\n",
            "{'loss': 0.0, 'grad_norm': 0.0006298983353190124, 'learning_rate': 0.00038873953302184284, 'epoch': 1.76}\n",
            "{'loss': 0.0007, 'grad_norm': 0.011292871087789536, 'learning_rate': 0.0003845365500393974, 'epoch': 1.77}\n",
            "{'loss': 0.0, 'grad_norm': 0.0015578307211399078, 'learning_rate': 0.00038034216785622126, 'epoch': 1.78}\n",
            "{'loss': 0.0022, 'grad_norm': 0.02164064347743988, 'learning_rate': 0.00037615669890918703, 'epoch': 1.78}\n",
            "{'loss': 0.0, 'grad_norm': 0.005220745224505663, 'learning_rate': 0.00037198045497122644, 'epoch': 1.79}\n",
            "{'loss': 0.0002, 'grad_norm': 0.0033608863595873117, 'learning_rate': 0.00036781374712810557, 'epoch': 1.8}\n",
            "{'loss': 0.0034, 'grad_norm': 0.05073753371834755, 'learning_rate': 0.0003636568857552531, 'epoch': 1.81}\n",
            "{'loss': 0.0003, 'grad_norm': 0.0027868819888681173, 'learning_rate': 0.0003595101804946404, 'epoch': 1.82}\n",
            "{'loss': 0.0002, 'grad_norm': 0.001973160542547703, 'learning_rate': 0.0003553739402317162, 'epoch': 1.82}\n",
            "{'loss': 0.0048, 'grad_norm': 0.15103204548358917, 'learning_rate': 0.0003512484730723986, 'epoch': 1.83}\n",
            "{'loss': 0.0004, 'grad_norm': 0.0181364044547081, 'learning_rate': 0.00034713408632012366, 'epoch': 1.84}\n",
            "{'loss': 0.0008, 'grad_norm': 0.015924306586384773, 'learning_rate': 0.00034303108645295497, 'epoch': 1.85}\n",
            "{'loss': 0.0001, 'grad_norm': 0.017155691981315613, 'learning_rate': 0.0003389397791007548, 'epoch': 1.86}\n",
            "{'loss': 0.0001, 'grad_norm': 0.00885235145688057, 'learning_rate': 0.00033486046902241664, 'epoch': 1.86}\n",
            "{'loss': 0.0, 'grad_norm': 0.00022495414305012673, 'learning_rate': 0.0003307934600831648, 'epoch': 1.87}\n",
            "{'loss': 0.0018, 'grad_norm': 0.012073560617864132, 'learning_rate': 0.00032673905523192, 'epoch': 1.88}\n",
            "{'loss': 0.0001, 'grad_norm': 0.004087785258889198, 'learning_rate': 0.00032269755647873217, 'epoch': 1.89}\n",
            "{'loss': 0.0001, 'grad_norm': 0.0011857858626171947, 'learning_rate': 0.000318669264872284, 'epoch': 1.9}\n",
            "{'loss': 0.0002, 'grad_norm': 0.0025455455761402845, 'learning_rate': 0.00031465448047746623, 'epoch': 1.9}\n",
            "{'loss': 0.0003, 'grad_norm': 0.0029861205257475376, 'learning_rate': 0.0003106535023530262, 'epoch': 1.91}\n",
            "{'loss': 0.0027, 'grad_norm': 0.013648719526827335, 'learning_rate': 0.0003066666285292906, 'epoch': 1.92}\n",
            "{'loss': 0.0006, 'grad_norm': 0.02510787732899189, 'learning_rate': 0.000302694155985966, 'epoch': 1.93}\n",
            "{'loss': 0.0001, 'grad_norm': 0.0018471118528395891, 'learning_rate': 0.0002987363806300163, 'epoch': 1.94}\n",
            "{'loss': 0.001, 'grad_norm': 0.006024093832820654, 'learning_rate': 0.0002947935972736217, 'epoch': 1.94}\n",
            "{'loss': 0.0032, 'grad_norm': 0.15652531385421753, 'learning_rate': 0.00029086609961221754, 'epoch': 1.95}\n",
            "{'loss': 0.0004, 'grad_norm': 0.004024057649075985, 'learning_rate': 0.00028695418020261755, 'epoch': 1.96}\n",
            "{'loss': 0.0004, 'grad_norm': 0.007695500738918781, 'learning_rate': 0.00028305813044122096, 'epoch': 1.97}\n",
            "{'loss': 0.0018, 'grad_norm': 0.009569675661623478, 'learning_rate': 0.00027917824054230785, 'epoch': 1.98}\n",
            "{'loss': 0.0009, 'grad_norm': 0.017691589891910553, 'learning_rate': 0.00027531479951641924, 'epoch': 1.98}\n",
            "{'loss': 0.0003, 'grad_norm': 0.0052108452655375, 'learning_rate': 0.0002714680951488312, 'epoch': 1.99}\n",
            "{'loss': 0.0048, 'grad_norm': 0.04145464301109314, 'learning_rate': 0.00026763841397811573, 'epoch': 2.0}\n",
            "{'loss': 0.0006, 'grad_norm': 0.014037292450666428, 'learning_rate': 0.00026382604127479813, 'epoch': 2.01}\n",
            "{'loss': 0.0001, 'grad_norm': 0.004003004636615515, 'learning_rate': 0.00026003126102010693, 'epoch': 2.02}\n",
            "{'loss': 0.0003, 'grad_norm': 0.004135430790483952, 'learning_rate': 0.0002562543558848202, 'epoch': 2.02}\n",
            "{'loss': 0.0001, 'grad_norm': 0.0026399169582873583, 'learning_rate': 0.0002524956072082093, 'epoch': 2.03}\n",
            "{'loss': 0.0042, 'grad_norm': 0.15247024595737457, 'learning_rate': 0.00024875529497708353, 'epoch': 2.04}\n",
            "{'loss': 0.0003, 'grad_norm': 0.0026884241960942745, 'learning_rate': 0.0002450336978049322, 'epoch': 2.05}\n",
            "{'loss': 0.0001, 'grad_norm': 0.0015066413907334208, 'learning_rate': 0.00024133109291117155, 'epoch': 2.06}\n",
            "{'loss': 0.0008, 'grad_norm': 0.005301160272210836, 'learning_rate': 0.000237647756100496, 'epoch': 2.06}\n",
            "{'loss': 0.0004, 'grad_norm': 0.01341890636831522, 'learning_rate': 0.00023398396174233177, 'epoch': 2.07}\n",
            "{'loss': 0.0001, 'grad_norm': 0.0014255748828873038, 'learning_rate': 0.00023033998275040046, 'epoch': 2.08}\n",
            "{'loss': 0.0, 'grad_norm': 0.00026013620663434267, 'learning_rate': 0.0002267160905623895, 'epoch': 2.09}\n",
            "{'loss': 0.0012, 'grad_norm': 0.013823455199599266, 'learning_rate': 0.00022311255511973344, 'epoch': 2.1}\n",
            "{'loss': 0.0009, 'grad_norm': 0.010075457394123077, 'learning_rate': 0.00021952964484750527, 'epoch': 2.1}\n",
            "{'loss': 0.0009, 'grad_norm': 0.00330300722271204, 'learning_rate': 0.00021596762663442215, 'epoch': 2.11}\n",
            "{'loss': 0.0, 'grad_norm': 0.0002458373492117971, 'learning_rate': 0.00021242676581296528, 'epoch': 2.12}\n",
            "{'loss': 0.0001, 'grad_norm': 0.008975144475698471, 'learning_rate': 0.00020890732613961478, 'epoch': 2.13}\n",
            "{'loss': 0.0003, 'grad_norm': 0.011782647110521793, 'learning_rate': 0.00020540956977520319, 'epoch': 2.14}\n",
            "{'loss': 0.0011, 'grad_norm': 0.011642226949334145, 'learning_rate': 0.00020193375726538737, 'epoch': 2.14}\n",
            "{'loss': 0.0001, 'grad_norm': 0.0009555373108014464, 'learning_rate': 0.00019848014752123978, 'epoch': 2.15}\n",
            "{'loss': 0.0005, 'grad_norm': 0.014092404395341873, 'learning_rate': 0.00019504899779996355, 'epoch': 2.16}\n",
            "{'loss': 0.0001, 'grad_norm': 0.002739080460742116, 'learning_rate': 0.00019164056368572847, 'epoch': 2.17}\n",
            "{'loss': 0.0, 'grad_norm': 0.0006811858038417995, 'learning_rate': 0.00018825509907063325, 'epoch': 2.18}\n",
            "{'loss': 0.0002, 'grad_norm': 0.0034676387440413237, 'learning_rate': 0.00018489285613579326, 'epoch': 2.18}\n",
            "{'loss': 0.0, 'grad_norm': 0.0005635337438434362, 'learning_rate': 0.0001815540853325555, 'epoch': 2.19}\n",
            "{'loss': 0.0001, 'grad_norm': 0.0044851587153971195, 'learning_rate': 0.00017823903536384262, 'epoch': 2.2}\n",
            "{'loss': 0.0002, 'grad_norm': 0.011056794784963131, 'learning_rate': 0.0001749479531656279, 'epoch': 2.21}\n",
            "{'loss': 0.0001, 'grad_norm': 0.0037305443547666073, 'learning_rate': 0.00017168108388853997, 'epoch': 2.22}\n",
            "{'loss': 0.0001, 'grad_norm': 0.0014432150637730956, 'learning_rate': 0.00016843867087960252, 'epoch': 2.22}\n",
            "{'loss': 0.0, 'grad_norm': 0.0005018512019887567, 'learning_rate': 0.00016522095566410728, 'epoch': 2.23}\n",
            "{'loss': 0.0004, 'grad_norm': 0.005731129087507725, 'learning_rate': 0.00016202817792762282, 'epoch': 2.24}\n",
            "{'loss': 0.0001, 'grad_norm': 0.0038225934840738773, 'learning_rate': 0.0001588605754981413, 'epoch': 2.25}\n",
            "{'loss': 0.0002, 'grad_norm': 0.008317472413182259, 'learning_rate': 0.00015571838432836137, 'epoch': 2.26}\n",
            "{'loss': 0.0002, 'grad_norm': 0.002589249750599265, 'learning_rate': 0.00015260183847811383, 'epoch': 2.26}\n",
            "{'loss': 0.0001, 'grad_norm': 0.0018642779905349016, 'learning_rate': 0.00014951117009692527, 'epoch': 2.27}\n",
            "{'loss': 0.0, 'grad_norm': 7.698793342569843e-05, 'learning_rate': 0.00014644660940672628, 'epoch': 2.28}\n",
            "{'loss': 0.0001, 'grad_norm': 0.005134114995598793, 'learning_rate': 0.00014340838468470196, 'epoch': 2.29}\n",
            "{'loss': 0.0001, 'grad_norm': 0.00077547796536237, 'learning_rate': 0.00014039672224628786, 'epoch': 2.3}\n",
            "{'loss': 0.0003, 'grad_norm': 0.003483861917629838, 'learning_rate': 0.0001374118464283119, 'epoch': 2.3}\n",
            "{'loss': 0.0, 'grad_norm': 0.00011657707364065573, 'learning_rate': 0.0001344539795722834, 'epoch': 2.31}\n",
            "{'loss': 0.0, 'grad_norm': 0.0013367731589823961, 'learning_rate': 0.00013152334200783168, 'epoch': 2.32}\n",
            "{'loss': 0.0, 'grad_norm': 0.002071373164653778, 'learning_rate': 0.00012862015203629273, 'epoch': 2.33}\n",
            "{'loss': 0.0, 'grad_norm': 0.00046877871500328183, 'learning_rate': 0.0001257446259144494, 'epoch': 2.34}\n",
            "{'loss': 0.0, 'grad_norm': 0.00021300086518749595, 'learning_rate': 0.0001228969778384214, 'epoch': 2.34}\n",
            "{'loss': 0.0, 'grad_norm': 0.0004688119515776634, 'learning_rate': 0.00012007741992771066, 'epoch': 2.35}\n",
            "{'loss': 0.0, 'grad_norm': 0.00023437626077793539, 'learning_rate': 0.0001172861622094003, 'epoch': 2.36}\n",
            "{'loss': 0.0003, 'grad_norm': 0.003212342271581292, 'learning_rate': 0.0001145234126025102, 'epoch': 2.37}\n",
            "{'loss': 0.0, 'grad_norm': 0.00010589772136881948, 'learning_rate': 0.00011178937690250917, 'epoch': 2.38}\n",
            "{'loss': 0.0, 'grad_norm': 6.548925011884421e-05, 'learning_rate': 0.0001090842587659851, 'epoch': 2.38}\n",
            "{'loss': 0.0001, 'grad_norm': 0.0016525238752365112, 'learning_rate': 0.00010640825969547497, 'epoch': 2.39}\n",
            "{'loss': 0.0, 'grad_norm': 0.0010626435978338122, 'learning_rate': 0.00010376157902445487, 'epoch': 2.4}\n",
            "{'loss': 0.0, 'grad_norm': 0.00016792841779533774, 'learning_rate': 0.00010114441390249201, 'epoch': 2.41}\n",
            "{'loss': 0.0, 'grad_norm': 0.000455408327979967, 'learning_rate': 9.85569592805588e-05, 'epoch': 2.42}\n",
            "{'loss': 0.0, 'grad_norm': 0.00026439118664711714, 'learning_rate': 9.599940789651179e-05, 'epoch': 2.42}\n",
            "{'loss': 0.0015, 'grad_norm': 0.011560658924281597, 'learning_rate': 9.347195026073368e-05, 'epoch': 2.43}\n",
            "{'loss': 0.0, 'grad_norm': 0.00012833085202146322, 'learning_rate': 9.09747746419436e-05, 'epoch': 2.44}\n",
            "{'loss': 0.0023, 'grad_norm': 0.022679634392261505, 'learning_rate': 8.850806705317183e-05, 'epoch': 2.45}\n",
            "{'loss': 0.0, 'grad_norm': 0.0004307939962018281, 'learning_rate': 8.60720112379046e-05, 'epoch': 2.46}\n",
            "{'loss': 0.0001, 'grad_norm': 0.002351823030039668, 'learning_rate': 8.366678865639687e-05, 'epoch': 2.46}\n",
            "{'loss': 0.0, 'grad_norm': 0.0005474826321005821, 'learning_rate': 8.129257847215571e-05, 'epoch': 2.47}\n",
            "{'loss': 0.0, 'grad_norm': 0.00013361017045099288, 'learning_rate': 7.894955753859412e-05, 'epoch': 2.48}\n",
            "{'loss': 0.0006, 'grad_norm': 0.0061658453196287155, 'learning_rate': 7.663790038585794e-05, 'epoch': 2.49}\n",
            "{'loss': 0.0, 'grad_norm': 0.0004917619517073035, 'learning_rate': 7.435777920782444e-05, 'epoch': 2.5}\n",
            "{'loss': 0.0001, 'grad_norm': 0.0008148343185894191, 'learning_rate': 7.21093638492763e-05, 'epoch': 2.5}\n",
            "{'loss': 0.0017, 'grad_norm': 0.011243201792240143, 'learning_rate': 6.989282179324962e-05, 'epoch': 2.51}\n",
            "{'loss': 0.0, 'grad_norm': 0.00015159652684815228, 'learning_rate': 6.770831814855882e-05, 'epoch': 2.52}\n",
            "{'loss': 0.0001, 'grad_norm': 0.001636530039831996, 'learning_rate': 6.555601563749674e-05, 'epoch': 2.53}\n",
            "{'loss': 0.0, 'grad_norm': 4.394433199195191e-05, 'learning_rate': 6.343607458371459e-05, 'epoch': 2.54}\n",
            "{'loss': 0.0005, 'grad_norm': 0.004870537668466568, 'learning_rate': 6.134865290027902e-05, 'epoch': 2.54}\n",
            "{'loss': 0.0, 'grad_norm': 0.0006244978867471218, 'learning_rate': 5.92939060779093e-05, 'epoch': 2.55}\n",
            "{'loss': 0.0003, 'grad_norm': 0.005598414223641157, 'learning_rate': 5.72719871733951e-05, 'epoch': 2.56}\n",
            "{'loss': 0.0001, 'grad_norm': 0.0034477796871215105, 'learning_rate': 5.5283046798195126e-05, 'epoch': 2.57}\n",
            "{'loss': 0.001, 'grad_norm': 0.01484801433980465, 'learning_rate': 5.3327233107218545e-05, 'epoch': 2.58}\n",
            "{'loss': 0.0001, 'grad_norm': 0.002895863028243184, 'learning_rate': 5.140469178778845e-05, 'epoch': 2.58}\n",
            "{'loss': 0.0002, 'grad_norm': 0.0029542737174779177, 'learning_rate': 4.9515566048790485e-05, 'epoch': 2.59}\n",
            "{'loss': 0.0, 'grad_norm': 0.00014722638297826052, 'learning_rate': 4.765999661000442e-05, 'epoch': 2.6}\n",
            "{'loss': 0.0, 'grad_norm': 0.00036850725882686675, 'learning_rate': 4.583812169162299e-05, 'epoch': 2.61}\n",
            "{'loss': 0.0, 'grad_norm': 0.000174868997419253, 'learning_rate': 4.405007700395497e-05, 'epoch': 2.62}\n",
            "{'loss': 0.0, 'grad_norm': 0.0005116716492921114, 'learning_rate': 4.2295995737316854e-05, 'epoch': 2.62}\n",
            "{'loss': 0.0, 'grad_norm': 2.7341582608642057e-05, 'learning_rate': 4.057600855211141e-05, 'epoch': 2.63}\n",
            "{'loss': 0.0001, 'grad_norm': 0.0014280261239036918, 'learning_rate': 3.8890243569094874e-05, 'epoch': 2.64}\n",
            "{'loss': 0.0011, 'grad_norm': 0.010620621033012867, 'learning_rate': 3.7238826359833275e-05, 'epoch': 2.65}\n",
            "{'loss': 0.0, 'grad_norm': 5.060649709776044e-05, 'learning_rate': 3.562187993734883e-05, 'epoch': 2.66}\n",
            "{'loss': 0.0, 'grad_norm': 0.0002943835861515254, 'learning_rate': 3.40395247469566e-05, 'epoch': 2.66}\n",
            "{'loss': 0.0001, 'grad_norm': 0.0026644226163625717, 'learning_rate': 3.249187865729264e-05, 'epoch': 2.67}\n",
            "{'loss': 0.0, 'grad_norm': 0.0001334633561782539, 'learning_rate': 3.097905695153408e-05, 'epoch': 2.68}\n",
            "{'loss': 0.0, 'grad_norm': 0.00047665071906521916, 'learning_rate': 2.9501172318811832e-05, 'epoch': 2.69}\n",
            "{'loss': 0.0, 'grad_norm': 0.00018329967861063778, 'learning_rate': 2.8058334845816213e-05, 'epoch': 2.7}\n",
            "{'loss': 0.0, 'grad_norm': 0.00029790960252285004, 'learning_rate': 2.6650652008597063e-05, 'epoch': 2.7}\n",
            "{'loss': 0.0004, 'grad_norm': 0.007414755877107382, 'learning_rate': 2.527822866455731e-05, 'epoch': 2.71}\n",
            "{'loss': 0.0, 'grad_norm': 0.0002680910693015903, 'learning_rate': 2.3941167044642943e-05, 'epoch': 2.72}\n",
            "{'loss': 0.0001, 'grad_norm': 0.002090105088427663, 'learning_rate': 2.2639566745727203e-05, 'epoch': 2.73}\n",
            "{'loss': 0.003, 'grad_norm': 0.0177779458463192, 'learning_rate': 2.137352472319215e-05, 'epoch': 2.74}\n",
            "{'loss': 0.0, 'grad_norm': 6.930488598300144e-05, 'learning_rate': 2.0143135283706258e-05, 'epoch': 2.74}\n",
            "{'loss': 0.0, 'grad_norm': 0.00010410817776573822, 'learning_rate': 1.8948490078199765e-05, 'epoch': 2.75}\n",
            "{'loss': 0.0, 'grad_norm': 0.0003422175068408251, 'learning_rate': 1.7789678095037452e-05, 'epoch': 2.76}\n",
            "{'loss': 0.0, 'grad_norm': 0.00040966400410979986, 'learning_rate': 1.6666785653390248e-05, 'epoch': 2.77}\n",
            "{'loss': 0.0002, 'grad_norm': 0.004074236378073692, 'learning_rate': 1.557989639680496e-05, 'epoch': 2.78}\n",
            "{'loss': 0.0, 'grad_norm': 8.364949462702498e-05, 'learning_rate': 1.4529091286973995e-05, 'epoch': 2.78}\n",
            "{'loss': 0.0, 'grad_norm': 0.0005809830618090928, 'learning_rate': 1.351444859770462e-05, 'epoch': 2.79}\n",
            "{'loss': 0.0001, 'grad_norm': 0.0046938383020460606, 'learning_rate': 1.2536043909088191e-05, 'epoch': 2.8}\n",
            "{'loss': 0.0, 'grad_norm': 3.561651101335883e-05, 'learning_rate': 1.159395010187042e-05, 'epoch': 2.81}\n",
            "{'loss': 0.0001, 'grad_norm': 0.0011605476029217243, 'learning_rate': 1.0688237352022346e-05, 'epoch': 2.82}\n",
            "{'loss': 0.0013, 'grad_norm': 0.023560423403978348, 'learning_rate': 9.818973125513276e-06, 'epoch': 2.82}\n",
            "{'loss': 0.0012, 'grad_norm': 0.012025288306176662, 'learning_rate': 8.986222173284874e-06, 'epoch': 2.83}\n",
            "{'loss': 0.0, 'grad_norm': 0.0009458151180297136, 'learning_rate': 8.190046526428241e-06, 'epoch': 2.84}\n",
            "{'loss': 0.0001, 'grad_norm': 0.0019235857762396336, 'learning_rate': 7.4305054915631e-06, 'epoch': 2.85}\n",
            "{'loss': 0.0, 'grad_norm': 0.0003442248562350869, 'learning_rate': 6.7076556464202296e-06, 'epoch': 2.86}\n",
            "{'loss': 0.0001, 'grad_norm': 0.0007880982011556625, 'learning_rate': 6.021550835626777e-06, 'epoch': 2.86}\n",
            "{'loss': 0.0, 'grad_norm': 0.00023543392308056355, 'learning_rate': 5.372242166695684e-06, 'epoch': 2.87}\n",
            "{'loss': 0.0, 'grad_norm': 0.0009468578500673175, 'learning_rate': 4.759778006218407e-06, 'epoch': 2.88}\n",
            "{'loss': 0.0, 'grad_norm': 2.6512378099141642e-05, 'learning_rate': 4.184203976262513e-06, 'epoch': 2.89}\n",
            "{'loss': 0.0009, 'grad_norm': 0.007844056934118271, 'learning_rate': 3.645562950973014e-06, 'epoch': 2.9}\n",
            "{'loss': 0.0, 'grad_norm': 2.022726221184712e-05, 'learning_rate': 3.143895053378698e-06, 'epoch': 2.9}\n",
            "{'loss': 0.0, 'grad_norm': 0.00031583939562551677, 'learning_rate': 2.6792376524036878e-06, 'epoch': 2.91}\n",
            "{'loss': 0.0, 'grad_norm': 0.00041507798596285284, 'learning_rate': 2.251625360083387e-06, 'epoch': 2.92}\n",
            "{'loss': 0.0, 'grad_norm': 8.723988139536232e-05, 'learning_rate': 1.8610900289867672e-06, 'epoch': 2.93}\n",
            "{'loss': 0.0, 'grad_norm': 5.714144936064258e-05, 'learning_rate': 1.5076607498433204e-06, 'epoch': 2.94}\n",
            "{'loss': 0.0, 'grad_norm': 0.0021319491788744926, 'learning_rate': 1.1913638493762368e-06, 'epoch': 2.94}\n",
            "{'loss': 0.0, 'grad_norm': 0.0006297254003584385, 'learning_rate': 9.12222888341252e-07, 'epoch': 2.95}\n",
            "{'loss': 0.0, 'grad_norm': 0.00014434951299335808, 'learning_rate': 6.702586597719384e-07, 'epoch': 2.96}\n",
            "{'loss': 0.0001, 'grad_norm': 0.004335390869528055, 'learning_rate': 4.6548918743033465e-07, 'epoch': 2.97}\n",
            "{'loss': 0.0, 'grad_norm': 8.940239058574662e-05, 'learning_rate': 2.9792972446479607e-07, 'epoch': 2.98}\n",
            "{'loss': 0.0, 'grad_norm': 0.0002948155743069947, 'learning_rate': 1.6759275227357095e-07, 'epoch': 2.98}\n",
            "{'loss': 0.0, 'grad_norm': 4.896734390058555e-05, 'learning_rate': 7.448797957526621e-08, 'epoch': 2.99}\n",
            "{'loss': 0.0002, 'grad_norm': 0.00448807654902339, 'learning_rate': 1.862234168542587e-08, 'epoch': 3.0}\n",
            "{'train_runtime': 68.009, 'train_samples_per_second': 11.028, 'train_steps_per_second': 5.514, 'train_loss': 0.07487554584740974, 'epoch': 3.0}\n",
            "100% 375/375 [01:08<00:00,  5.51it/s]\n",
            "Training complete.\n",
            "Model saved to loras/self-edit/training_set_iteration_1/8d5021e8/10\n",
            "Training on 250 examples for 3 epochs, lr: 0.01\n",
            "No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n",
            "Starting training...\n",
            "{'loss': 7.387, 'grad_norm': 10.396124839782715, 'learning_rate': 0.0, 'epoch': 0.01}\n",
            "{'loss': 6.5478, 'grad_norm': 7.9159088134765625, 'learning_rate': 0.0009090909090909091, 'epoch': 0.02}\n",
            "{'loss': 2.5402, 'grad_norm': 13.447990417480469, 'learning_rate': 0.0018181818181818182, 'epoch': 0.02}\n",
            "{'loss': 2.7879, 'grad_norm': 13.090558052062988, 'learning_rate': 0.002727272727272727, 'epoch': 0.03}\n",
            "{'loss': 0.9527, 'grad_norm': 1.0222463607788086, 'learning_rate': 0.0036363636363636364, 'epoch': 0.04}\n",
            "{'loss': 3.8958, 'grad_norm': 17.0720157623291, 'learning_rate': 0.004545454545454545, 'epoch': 0.05}\n",
            "{'loss': 0.6404, 'grad_norm': 0.7042794823646545, 'learning_rate': 0.005454545454545454, 'epoch': 0.06}\n",
            "{'loss': 0.9555, 'grad_norm': 3.0482594966888428, 'learning_rate': 0.006363636363636364, 'epoch': 0.06}\n",
            "{'loss': 0.8143, 'grad_norm': 2.908266544342041, 'learning_rate': 0.007272727272727273, 'epoch': 0.07}\n",
            "{'loss': 1.3304, 'grad_norm': 3.884225368499756, 'learning_rate': 0.008181818181818182, 'epoch': 0.08}\n",
            "{'loss': 2.7472, 'grad_norm': 18.00657844543457, 'learning_rate': 0.00909090909090909, 'epoch': 0.09}\n",
            "{'loss': 2.8506, 'grad_norm': 11.996451377868652, 'learning_rate': 0.01, 'epoch': 0.1}\n",
            "{'loss': 8.1585, 'grad_norm': 78.07996368408203, 'learning_rate': 0.009999813776583147, 'epoch': 0.1}\n",
            "{'loss': 5.6302, 'grad_norm': 13.581624984741211, 'learning_rate': 0.009999255120204246, 'epoch': 0.11}\n",
            "{'loss': 4.5348, 'grad_norm': 4.440925598144531, 'learning_rate': 0.009998324072477265, 'epoch': 0.12}\n",
            "{'loss': 17.6114, 'grad_norm': 39.034271240234375, 'learning_rate': 0.009997020702755353, 'epoch': 0.13}\n",
            "{'loss': 8.5573, 'grad_norm': 3.5743236541748047, 'learning_rate': 0.009995345108125697, 'epoch': 0.14}\n",
            "{'loss': 10.1106, 'grad_norm': 8.59424877166748, 'learning_rate': 0.009993297413402281, 'epoch': 0.14}\n",
            "{'loss': 4.8537, 'grad_norm': 7.178743362426758, 'learning_rate': 0.009990877771116588, 'epoch': 0.15}\n",
            "{'loss': 4.9629, 'grad_norm': 2.2305712699890137, 'learning_rate': 0.009988086361506238, 'epoch': 0.16}\n",
            "{'loss': 3.3828, 'grad_norm': 1.2105952501296997, 'learning_rate': 0.009984923392501567, 'epoch': 0.17}\n",
            "{'loss': 3.9511, 'grad_norm': 1.3973954916000366, 'learning_rate': 0.009981389099710133, 'epoch': 0.18}\n",
            "{'loss': 9.1166, 'grad_norm': 7.711798667907715, 'learning_rate': 0.009977483746399167, 'epoch': 0.18}\n",
            "{'loss': 10.4098, 'grad_norm': 6.489821434020996, 'learning_rate': 0.009973207623475963, 'epoch': 0.19}\n",
            "{'loss': 4.4918, 'grad_norm': 3.482985019683838, 'learning_rate': 0.009968561049466213, 'epoch': 0.2}\n",
            "{'loss': 2.2315, 'grad_norm': 2.5467817783355713, 'learning_rate': 0.00996354437049027, 'epoch': 0.21}\n",
            "{'loss': 3.292, 'grad_norm': 1.4403551816940308, 'learning_rate': 0.009958157960237374, 'epoch': 0.22}\n",
            "{'loss': 6.1033, 'grad_norm': 2.6095094680786133, 'learning_rate': 0.009952402219937815, 'epoch': 0.22}\n",
            "{'loss': 2.9509, 'grad_norm': 0.6754335761070251, 'learning_rate': 0.009946277578333045, 'epoch': 0.23}\n",
            "{'loss': 2.8834, 'grad_norm': 1.0165115594863892, 'learning_rate': 0.009939784491643733, 'epoch': 0.24}\n",
            "{'loss': 2.6271, 'grad_norm': 36.58938217163086, 'learning_rate': 0.009932923443535798, 'epoch': 0.25}\n",
            "{'loss': 4.4377, 'grad_norm': 3.6162686347961426, 'learning_rate': 0.009925694945084369, 'epoch': 0.26}\n",
            "{'loss': 3.5785, 'grad_norm': 1.1662391424179077, 'learning_rate': 0.009918099534735719, 'epoch': 0.26}\n",
            "{'loss': 2.8595, 'grad_norm': 1.016111135482788, 'learning_rate': 0.009910137778267152, 'epoch': 0.27}\n",
            "{'loss': 1.9581, 'grad_norm': 0.41762253642082214, 'learning_rate': 0.009901810268744867, 'epoch': 0.28}\n",
            "{'loss': 2.8274, 'grad_norm': 0.7251468300819397, 'learning_rate': 0.009893117626479776, 'epoch': 0.29}\n",
            "{'loss': 1.8583, 'grad_norm': 0.3643249571323395, 'learning_rate': 0.009884060498981296, 'epoch': 0.3}\n",
            "{'loss': 2.5305, 'grad_norm': 0.5925977230072021, 'learning_rate': 0.009874639560909117, 'epoch': 0.3}\n",
            "{'loss': 2.4937, 'grad_norm': 0.5554486513137817, 'learning_rate': 0.009864855514022955, 'epoch': 0.31}\n",
            "{'loss': 1.3964, 'grad_norm': 1.5547598600387573, 'learning_rate': 0.009854709087130261, 'epoch': 0.32}\n",
            "{'loss': 1.869, 'grad_norm': 0.2685551643371582, 'learning_rate': 0.00984420103603195, 'epoch': 0.33}\n",
            "{'loss': 2.2943, 'grad_norm': 0.5191192030906677, 'learning_rate': 0.009833332143466099, 'epoch': 0.34}\n",
            "{'loss': 2.0014, 'grad_norm': 0.7037935853004456, 'learning_rate': 0.009822103219049624, 'epoch': 0.34}\n",
            "{'loss': 2.4607, 'grad_norm': 0.3835189938545227, 'learning_rate': 0.009810515099218002, 'epoch': 0.35}\n",
            "{'loss': 1.8766, 'grad_norm': 0.3266684412956238, 'learning_rate': 0.009798568647162938, 'epoch': 0.36}\n",
            "{'loss': 2.4984, 'grad_norm': 0.48958396911621094, 'learning_rate': 0.00978626475276808, 'epoch': 0.37}\n",
            "{'loss': 1.5405, 'grad_norm': 0.15438967943191528, 'learning_rate': 0.009773604332542728, 'epoch': 0.38}\n",
            "{'loss': 1.4534, 'grad_norm': 0.18550962209701538, 'learning_rate': 0.00976058832955357, 'epoch': 0.38}\n",
            "{'loss': 1.5256, 'grad_norm': 0.2101186066865921, 'learning_rate': 0.009747217713354427, 'epoch': 0.39}\n",
            "{'loss': 1.5189, 'grad_norm': 0.2632756531238556, 'learning_rate': 0.009733493479914031, 'epoch': 0.4}\n",
            "{'loss': 1.5992, 'grad_norm': 0.22686178982257843, 'learning_rate': 0.009719416651541838, 'epoch': 0.41}\n",
            "{'loss': 1.5684, 'grad_norm': 0.17323802411556244, 'learning_rate': 0.009704988276811882, 'epoch': 0.42}\n",
            "{'loss': 1.19, 'grad_norm': 0.1040702760219574, 'learning_rate': 0.00969020943048466, 'epoch': 0.42}\n",
            "{'loss': 1.384, 'grad_norm': 0.14979130029678345, 'learning_rate': 0.009675081213427075, 'epoch': 0.43}\n",
            "{'loss': 1.2646, 'grad_norm': 0.1216355636715889, 'learning_rate': 0.009659604752530434, 'epoch': 0.44}\n",
            "{'loss': 1.1747, 'grad_norm': 0.09542287141084671, 'learning_rate': 0.00964378120062651, 'epoch': 0.45}\n",
            "{'loss': 1.2155, 'grad_norm': 0.093008853495121, 'learning_rate': 0.009627611736401667, 'epoch': 0.46}\n",
            "{'loss': 1.2305, 'grad_norm': 0.09327863156795502, 'learning_rate': 0.009611097564309053, 'epoch': 0.46}\n",
            "{'loss': 1.3695, 'grad_norm': 0.10545093566179276, 'learning_rate': 0.009594239914478886, 'epoch': 0.47}\n",
            "{'loss': 1.1033, 'grad_norm': 0.10696522891521454, 'learning_rate': 0.009577040042626833, 'epoch': 0.48}\n",
            "{'loss': 1.3312, 'grad_norm': 0.10685316473245621, 'learning_rate': 0.00955949922996045, 'epoch': 0.49}\n",
            "{'loss': 1.3257, 'grad_norm': 0.10766349732875824, 'learning_rate': 0.00954161878308377, 'epoch': 0.5}\n",
            "{'loss': 1.254, 'grad_norm': 0.09417016804218292, 'learning_rate': 0.009523400033899955, 'epoch': 0.5}\n",
            "{'loss': 1.3854, 'grad_norm': 0.126922607421875, 'learning_rate': 0.009504844339512096, 'epoch': 0.51}\n",
            "{'loss': 1.1077, 'grad_norm': 0.0694923847913742, 'learning_rate': 0.009485953082122116, 'epoch': 0.52}\n",
            "{'loss': 1.7574, 'grad_norm': 0.15598315000534058, 'learning_rate': 0.009466727668927815, 'epoch': 0.53}\n",
            "{'loss': 1.2226, 'grad_norm': 0.05001123249530792, 'learning_rate': 0.00944716953201805, 'epoch': 0.54}\n",
            "{'loss': 0.9798, 'grad_norm': 0.048594772815704346, 'learning_rate': 0.009427280128266049, 'epoch': 0.54}\n",
            "{'loss': 0.995, 'grad_norm': 0.06627723574638367, 'learning_rate': 0.009407060939220908, 'epoch': 0.55}\n",
            "{'loss': 1.044, 'grad_norm': 0.05610319599509239, 'learning_rate': 0.00938651347099721, 'epoch': 0.56}\n",
            "{'loss': 0.9673, 'grad_norm': 0.06650684028863907, 'learning_rate': 0.009365639254162854, 'epoch': 0.57}\n",
            "{'loss': 1.3931, 'grad_norm': 0.10663730651140213, 'learning_rate': 0.009344439843625034, 'epoch': 0.58}\n",
            "{'loss': 1.1247, 'grad_norm': 0.06804198771715164, 'learning_rate': 0.009322916818514413, 'epoch': 0.58}\n",
            "{'loss': 1.4893, 'grad_norm': 0.1451239436864853, 'learning_rate': 0.009301071782067504, 'epoch': 0.59}\n",
            "{'loss': 1.1291, 'grad_norm': 0.06393976509571075, 'learning_rate': 0.009278906361507237, 'epoch': 0.6}\n",
            "{'loss': 1.5708, 'grad_norm': 0.1330232322216034, 'learning_rate': 0.009256422207921756, 'epoch': 0.61}\n",
            "{'loss': 1.1614, 'grad_norm': 0.06126439943909645, 'learning_rate': 0.00923362099614142, 'epoch': 0.62}\n",
            "{'loss': 1.2546, 'grad_norm': 0.04912950471043587, 'learning_rate': 0.009210504424614059, 'epoch': 0.62}\n",
            "{'loss': 1.0962, 'grad_norm': 0.05941886827349663, 'learning_rate': 0.009187074215278444, 'epoch': 0.63}\n",
            "{'loss': 1.2193, 'grad_norm': 0.0710734874010086, 'learning_rate': 0.009163332113436031, 'epoch': 0.64}\n",
            "{'loss': 1.1678, 'grad_norm': 0.04529877007007599, 'learning_rate': 0.009139279887620954, 'epoch': 0.65}\n",
            "{'loss': 0.8987, 'grad_norm': 0.03302770107984543, 'learning_rate': 0.009114919329468282, 'epoch': 0.66}\n",
            "{'loss': 1.1285, 'grad_norm': 0.05514837056398392, 'learning_rate': 0.009090252253580565, 'epoch': 0.66}\n",
            "{'loss': 1.2687, 'grad_norm': 0.04379108548164368, 'learning_rate': 0.009065280497392662, 'epoch': 0.67}\n",
            "{'loss': 1.025, 'grad_norm': 0.0475340411067009, 'learning_rate': 0.009040005921034882, 'epoch': 0.68}\n",
            "{'loss': 1.479, 'grad_norm': 0.1541265994310379, 'learning_rate': 0.009014430407194412, 'epoch': 0.69}\n",
            "{'loss': 1.2988, 'grad_norm': 0.0673183873295784, 'learning_rate': 0.008988555860975082, 'epoch': 0.7}\n",
            "{'loss': 1.0612, 'grad_norm': 0.06053946912288666, 'learning_rate': 0.008962384209755451, 'epoch': 0.7}\n",
            "{'loss': 1.0097, 'grad_norm': 0.05689637362957001, 'learning_rate': 0.00893591740304525, 'epoch': 0.71}\n",
            "{'loss': 1.3275, 'grad_norm': 0.05772651731967926, 'learning_rate': 0.008909157412340149, 'epoch': 0.72}\n",
            "{'loss': 1.2928, 'grad_norm': 0.05340886116027832, 'learning_rate': 0.008882106230974908, 'epoch': 0.73}\n",
            "{'loss': 1.474, 'grad_norm': 0.09937749058008194, 'learning_rate': 0.008854765873974898, 'epoch': 0.74}\n",
            "{'loss': 1.4843, 'grad_norm': 0.09875018149614334, 'learning_rate': 0.008827138377905998, 'epoch': 0.74}\n",
            "{'loss': 1.5424, 'grad_norm': 0.11258962750434875, 'learning_rate': 0.008799225800722895, 'epoch': 0.75}\n",
            "{'loss': 1.1605, 'grad_norm': 0.06397926062345505, 'learning_rate': 0.008771030221615786, 'epoch': 0.76}\n",
            "{'loss': 1.0274, 'grad_norm': 0.0734136700630188, 'learning_rate': 0.008742553740855506, 'epoch': 0.77}\n",
            "{'loss': 1.175, 'grad_norm': 0.0468442365527153, 'learning_rate': 0.008713798479637071, 'epoch': 0.78}\n",
            "{'loss': 1.6878, 'grad_norm': 0.12942786514759064, 'learning_rate': 0.008684766579921684, 'epoch': 0.78}\n",
            "{'loss': 1.5821, 'grad_norm': 0.07949265837669373, 'learning_rate': 0.008655460204277167, 'epoch': 0.79}\n",
            "{'loss': 1.0562, 'grad_norm': 0.060854941606521606, 'learning_rate': 0.008625881535716882, 'epoch': 0.8}\n",
            "{'loss': 1.196, 'grad_norm': 0.06326951086521149, 'learning_rate': 0.008596032777537123, 'epoch': 0.81}\n",
            "{'loss': 1.0176, 'grad_norm': 0.07365372776985168, 'learning_rate': 0.008565916153152981, 'epoch': 0.82}\n",
            "{'loss': 1.1288, 'grad_norm': 0.056963808834552765, 'learning_rate': 0.008535533905932738, 'epoch': 0.82}\n",
            "{'loss': 1.2708, 'grad_norm': 0.07113838940858841, 'learning_rate': 0.008504888299030747, 'epoch': 0.83}\n",
            "{'loss': 1.2639, 'grad_norm': 0.08298974484205246, 'learning_rate': 0.008473981615218862, 'epoch': 0.84}\n",
            "{'loss': 1.2889, 'grad_norm': 0.0549037829041481, 'learning_rate': 0.008442816156716385, 'epoch': 0.85}\n",
            "{'loss': 0.9895, 'grad_norm': 0.05084127187728882, 'learning_rate': 0.008411394245018588, 'epoch': 0.86}\n",
            "{'loss': 1.2544, 'grad_norm': 0.0682242214679718, 'learning_rate': 0.008379718220723772, 'epoch': 0.86}\n",
            "{'loss': 1.2296, 'grad_norm': 0.08088970929384232, 'learning_rate': 0.008347790443358928, 'epoch': 0.87}\n",
            "{'loss': 1.0198, 'grad_norm': 0.049244605004787445, 'learning_rate': 0.008315613291203975, 'epoch': 0.88}\n",
            "{'loss': 1.2054, 'grad_norm': 0.053072281181812286, 'learning_rate': 0.0082831891611146, 'epoch': 0.89}\n",
            "{'loss': 1.3776, 'grad_norm': 0.14060769975185394, 'learning_rate': 0.00825052046834372, 'epoch': 0.9}\n",
            "{'loss': 1.1554, 'grad_norm': 0.04429859295487404, 'learning_rate': 0.008217609646361573, 'epoch': 0.9}\n",
            "{'loss': 1.0124, 'grad_norm': 0.052567560225725174, 'learning_rate': 0.008184459146674447, 'epoch': 0.91}\n",
            "{'loss': 0.8772, 'grad_norm': 0.08800263702869415, 'learning_rate': 0.008151071438642068, 'epoch': 0.92}\n",
            "{'loss': 0.9069, 'grad_norm': 0.07989349216222763, 'learning_rate': 0.008117449009293669, 'epoch': 0.93}\n",
            "{'loss': 1.3153, 'grad_norm': 0.13417595624923706, 'learning_rate': 0.008083594363142717, 'epoch': 0.94}\n",
            "{'loss': 1.1912, 'grad_norm': 0.09491074085235596, 'learning_rate': 0.008049510022000364, 'epoch': 0.94}\n",
            "{'loss': 1.1833, 'grad_norm': 0.05788439139723778, 'learning_rate': 0.008015198524787602, 'epoch': 0.95}\n",
            "{'loss': 1.5929, 'grad_norm': 4.150522708892822, 'learning_rate': 0.007980662427346127, 'epoch': 0.96}\n",
            "{'loss': 0.8836, 'grad_norm': 0.042956627905368805, 'learning_rate': 0.007945904302247968, 'epoch': 0.97}\n",
            "{'loss': 1.1434, 'grad_norm': 0.1279129981994629, 'learning_rate': 0.007910926738603854, 'epoch': 0.98}\n",
            "{'loss': 1.0409, 'grad_norm': 0.06380948424339294, 'learning_rate': 0.007875732341870348, 'epoch': 0.98}\n",
            "{'loss': 1.0363, 'grad_norm': 0.06321994215250015, 'learning_rate': 0.007840323733655778, 'epoch': 0.99}\n",
            "{'loss': 0.8575, 'grad_norm': 0.0697237104177475, 'learning_rate': 0.007804703551524948, 'epoch': 1.0}\n",
            "{'loss': 1.8517, 'grad_norm': 0.15124721825122833, 'learning_rate': 0.0077688744488026654, 'epoch': 1.01}\n",
            "{'loss': 1.3205, 'grad_norm': 0.0600009486079216, 'learning_rate': 0.007732839094376105, 'epoch': 1.02}\n",
            "{'loss': 1.7656, 'grad_norm': 0.11956646293401718, 'learning_rate': 0.007696600172495996, 'epoch': 1.02}\n",
            "{'loss': 1.0632, 'grad_norm': 0.0846979022026062, 'learning_rate': 0.007660160382576683, 'epoch': 1.03}\n",
            "{'loss': 1.2947, 'grad_norm': 0.3284558951854706, 'learning_rate': 0.00762352243899504, 'epoch': 1.04}\n",
            "{'loss': 1.101, 'grad_norm': 0.09335313737392426, 'learning_rate': 0.007586689070888284, 'epoch': 1.05}\n",
            "{'loss': 1.1562, 'grad_norm': 0.08131108433008194, 'learning_rate': 0.00754966302195068, 'epoch': 1.06}\n",
            "{'loss': 1.1399, 'grad_norm': 0.09248800575733185, 'learning_rate': 0.007512447050229166, 'epoch': 1.06}\n",
            "{'loss': 1.4933, 'grad_norm': 0.12487131357192993, 'learning_rate': 0.007475043927917907, 'epoch': 1.07}\n",
            "{'loss': 1.215, 'grad_norm': 0.09452759474515915, 'learning_rate': 0.007437456441151799, 'epoch': 1.08}\n",
            "{'loss': 1.3789, 'grad_norm': 0.10636163502931595, 'learning_rate': 0.007399687389798932, 'epoch': 1.09}\n",
            "{'loss': 1.3854, 'grad_norm': 0.09926614910364151, 'learning_rate': 0.007361739587252019, 'epoch': 1.1}\n",
            "{'loss': 1.7983, 'grad_norm': 1.002946376800537, 'learning_rate': 0.007323615860218843, 'epoch': 1.1}\n",
            "{'loss': 4.5873, 'grad_norm': 4.085697174072266, 'learning_rate': 0.00728531904851169, 'epoch': 1.11}\n",
            "{'loss': 3.4159, 'grad_norm': 2.111107110977173, 'learning_rate': 0.007246852004835807, 'epoch': 1.12}\n",
            "{'loss': 2.8428, 'grad_norm': 1.1175510883331299, 'learning_rate': 0.007208217594576923, 'epoch': 1.13}\n",
            "{'loss': 1.7235, 'grad_norm': 0.31792446970939636, 'learning_rate': 0.007169418695587791, 'epoch': 1.14}\n",
            "{'loss': 2.4216, 'grad_norm': 0.6604006886482239, 'learning_rate': 0.007130458197973828, 'epoch': 1.14}\n",
            "{'loss': 3.2659, 'grad_norm': 0.8139411211013794, 'learning_rate': 0.0070913390038778255, 'epoch': 1.15}\n",
            "{'loss': 3.8187, 'grad_norm': 1.004911184310913, 'learning_rate': 0.007052064027263785, 'epoch': 1.16}\n",
            "{'loss': 2.435, 'grad_norm': 0.6873995065689087, 'learning_rate': 0.0070126361936998375, 'epoch': 1.17}\n",
            "{'loss': 2.0061, 'grad_norm': 0.2763557434082031, 'learning_rate': 0.006973058440140341, 'epoch': 1.18}\n",
            "{'loss': 2.5876, 'grad_norm': 1.9705190658569336, 'learning_rate': 0.006933333714707094, 'epoch': 1.18}\n",
            "{'loss': 2.7865, 'grad_norm': 2.0550684928894043, 'learning_rate': 0.006893464976469739, 'epoch': 1.19}\n",
            "{'loss': 2.3909, 'grad_norm': 0.8078384399414062, 'learning_rate': 0.006853455195225339, 'epoch': 1.2}\n",
            "{'loss': 1.7316, 'grad_norm': 0.550558865070343, 'learning_rate': 0.00681330735127716, 'epoch': 1.21}\n",
            "{'loss': 2.7206, 'grad_norm': 0.7299516201019287, 'learning_rate': 0.006773024435212678, 'epoch': 1.22}\n",
            "{'loss': 2.0615, 'grad_norm': 0.47581666707992554, 'learning_rate': 0.0067326094476808, 'epoch': 1.22}\n",
            "{'loss': 1.6316, 'grad_norm': 0.30880603194236755, 'learning_rate': 0.0066920653991683525, 'epoch': 1.23}\n",
            "{'loss': 2.0099, 'grad_norm': 0.4337596893310547, 'learning_rate': 0.006651395309775836, 'epoch': 1.24}\n",
            "{'loss': 1.7751, 'grad_norm': 0.2959526777267456, 'learning_rate': 0.006610602208992454, 'epoch': 1.25}\n",
            "{'loss': 2.0126, 'grad_norm': 0.2355775535106659, 'learning_rate': 0.00656968913547045, 'epoch': 1.26}\n",
            "{'loss': 2.1128, 'grad_norm': 0.3450571894645691, 'learning_rate': 0.006528659136798765, 'epoch': 1.26}\n",
            "{'loss': 2.1183, 'grad_norm': 0.43305733799934387, 'learning_rate': 0.006487515269276016, 'epoch': 1.27}\n",
            "{'loss': 1.9273, 'grad_norm': 0.9600780010223389, 'learning_rate': 0.0064462605976828395, 'epoch': 1.28}\n",
            "{'loss': 1.7508, 'grad_norm': 0.45592957735061646, 'learning_rate': 0.0064048981950535966, 'epoch': 1.29}\n",
            "{'loss': 1.6522, 'grad_norm': 0.160909503698349, 'learning_rate': 0.006363431142447469, 'epoch': 1.3}\n",
            "{'loss': 1.6116, 'grad_norm': 0.30409112572669983, 'learning_rate': 0.006321862528718945, 'epoch': 1.3}\n",
            "{'loss': 2.1038, 'grad_norm': 0.5350548028945923, 'learning_rate': 0.006280195450287736, 'epoch': 1.31}\n",
            "{'loss': 1.9492, 'grad_norm': 0.44365304708480835, 'learning_rate': 0.00623843301090813, 'epoch': 1.32}\n",
            "{'loss': 1.7711, 'grad_norm': 0.3539944887161255, 'learning_rate': 0.006196578321437789, 'epoch': 1.33}\n",
            "{'loss': 1.3735, 'grad_norm': 0.09910944104194641, 'learning_rate': 0.006154634499606029, 'epoch': 1.34}\n",
            "{'loss': 2.0341, 'grad_norm': 0.12334033101797104, 'learning_rate': 0.006112604669781572, 'epoch': 1.34}\n",
            "{'loss': 2.4415, 'grad_norm': 0.17894554138183594, 'learning_rate': 0.0060704919627398305, 'epoch': 1.35}\n",
            "{'loss': 2.1343, 'grad_norm': 0.814289391040802, 'learning_rate': 0.006028299515429682, 'epoch': 1.36}\n",
            "{'loss': 2.0312, 'grad_norm': 0.7267826795578003, 'learning_rate': 0.005986030470739811, 'epoch': 1.37}\n",
            "{'loss': 1.6376, 'grad_norm': 0.3763136565685272, 'learning_rate': 0.005943687977264584, 'epoch': 1.38}\n",
            "{'loss': 1.5938, 'grad_norm': 0.13374269008636475, 'learning_rate': 0.005901275189069529, 'epoch': 1.38}\n",
            "{'loss': 2.4942, 'grad_norm': 0.6285902857780457, 'learning_rate': 0.005858795265456382, 'epoch': 1.39}\n",
            "{'loss': 1.4389, 'grad_norm': 0.255227267742157, 'learning_rate': 0.005816251370727748, 'epoch': 1.4}\n",
            "{'loss': 1.636, 'grad_norm': 0.32743921875953674, 'learning_rate': 0.005773646673951406, 'epoch': 1.41}\n",
            "{'loss': 2.4595, 'grad_norm': 0.685154139995575, 'learning_rate': 0.005730984348724242, 'epoch': 1.42}\n",
            "{'loss': 1.9174, 'grad_norm': 0.33043956756591797, 'learning_rate': 0.005688267572935842, 'epoch': 1.42}\n",
            "{'loss': 1.9481, 'grad_norm': 0.11293762177228928, 'learning_rate': 0.005645499528531784, 'epoch': 1.43}\n",
            "{'loss': 1.8869, 'grad_norm': 0.9128175973892212, 'learning_rate': 0.005602683401276615, 'epoch': 1.44}\n",
            "{'loss': 2.0813, 'grad_norm': 0.5281254649162292, 'learning_rate': 0.005559822380516539, 'epoch': 1.45}\n",
            "{'loss': 1.8833, 'grad_norm': 0.4936414062976837, 'learning_rate': 0.00551691965894185, 'epoch': 1.46}\n",
            "{'loss': 1.89, 'grad_norm': 0.07656809687614441, 'learning_rate': 0.005473978432349111, 'epoch': 1.46}\n",
            "{'loss': 1.7142, 'grad_norm': 0.2595210373401642, 'learning_rate': 0.0054310018994030975, 'epoch': 1.47}\n",
            "{'loss': 1.3252, 'grad_norm': 0.10382209718227386, 'learning_rate': 0.005387993261398532, 'epoch': 1.48}\n",
            "{'loss': 2.2718, 'grad_norm': 0.5489388108253479, 'learning_rate': 0.005344955722021624, 'epoch': 1.49}\n",
            "{'loss': 3.2646, 'grad_norm': 1.0570919513702393, 'learning_rate': 0.00530189248711143, 'epoch': 1.5}\n",
            "{'loss': 1.9052, 'grad_norm': 0.21492399275302887, 'learning_rate': 0.005258806764421048, 'epoch': 1.5}\n",
            "{'loss': 1.6063, 'grad_norm': 0.5578036308288574, 'learning_rate': 0.005215701763378673, 'epoch': 1.51}\n",
            "{'loss': 1.9564, 'grad_norm': 0.5241007208824158, 'learning_rate': 0.005172580694848541, 'epoch': 1.52}\n",
            "{'loss': 1.9095, 'grad_norm': 0.5302554965019226, 'learning_rate': 0.005129446770891738, 'epoch': 1.53}\n",
            "{'loss': 1.938, 'grad_norm': 0.17092357575893402, 'learning_rate': 0.0050863032045269435, 'epoch': 1.54}\n",
            "{'loss': 1.9596, 'grad_norm': 0.14034393429756165, 'learning_rate': 0.0050431532094910945, 'epoch': 1.54}\n",
            "{'loss': 1.5268, 'grad_norm': 0.07301726937294006, 'learning_rate': 0.005, 'epoch': 1.55}\n",
            "{'loss': 1.7175, 'grad_norm': 0.18447138369083405, 'learning_rate': 0.004956846790508906, 'epoch': 1.56}\n",
            "{'loss': 2.7282, 'grad_norm': 0.9140179753303528, 'learning_rate': 0.004913696795473058, 'epoch': 1.57}\n",
            "{'loss': 1.7137, 'grad_norm': 0.18457914888858795, 'learning_rate': 0.004870553229108264, 'epoch': 1.58}\n",
            "{'loss': 1.6628, 'grad_norm': 0.2165016233921051, 'learning_rate': 0.004827419305151461, 'epoch': 1.58}\n",
            "{'loss': 1.7224, 'grad_norm': 0.39773744344711304, 'learning_rate': 0.004784298236621327, 'epoch': 1.59}\n",
            "{'loss': 1.5721, 'grad_norm': 0.6475229859352112, 'learning_rate': 0.0047411932355789525, 'epoch': 1.6}\n",
            "{'loss': 1.3706, 'grad_norm': 0.43196919560432434, 'learning_rate': 0.004698107512888569, 'epoch': 1.61}\n",
            "{'loss': 1.2909, 'grad_norm': 0.12260882556438446, 'learning_rate': 0.004655044277978375, 'epoch': 1.62}\n",
            "{'loss': 1.3512, 'grad_norm': 0.20594578981399536, 'learning_rate': 0.004612006738601469, 'epoch': 1.62}\n",
            "{'loss': 1.9091, 'grad_norm': 0.6093848347663879, 'learning_rate': 0.004568998100596903, 'epoch': 1.63}\n",
            "{'loss': 1.8756, 'grad_norm': 0.47078174352645874, 'learning_rate': 0.004526021567650889, 'epoch': 1.64}\n",
            "{'loss': 1.4529, 'grad_norm': 0.2913035750389099, 'learning_rate': 0.00448308034105815, 'epoch': 1.65}\n",
            "{'loss': 1.2296, 'grad_norm': 0.2388308048248291, 'learning_rate': 0.004440177619483461, 'epoch': 1.66}\n",
            "{'loss': 1.3555, 'grad_norm': 0.4691060185432434, 'learning_rate': 0.004397316598723385, 'epoch': 1.66}\n",
            "{'loss': 1.6885, 'grad_norm': 0.19464951753616333, 'learning_rate': 0.004354500471468217, 'epoch': 1.67}\n",
            "{'loss': 1.4721, 'grad_norm': 0.4349812865257263, 'learning_rate': 0.00431173242706416, 'epoch': 1.68}\n",
            "{'loss': 1.1542, 'grad_norm': 0.3125106990337372, 'learning_rate': 0.004269015651275761, 'epoch': 1.69}\n",
            "{'loss': 1.5294, 'grad_norm': 0.27810555696487427, 'learning_rate': 0.004226353326048593, 'epoch': 1.7}\n",
            "{'loss': 1.0327, 'grad_norm': 0.09078282117843628, 'learning_rate': 0.004183748629272253, 'epoch': 1.7}\n",
            "{'loss': 1.185, 'grad_norm': 0.2318810671567917, 'learning_rate': 0.004141204734543619, 'epoch': 1.71}\n",
            "{'loss': 1.4212, 'grad_norm': 0.28307968378067017, 'learning_rate': 0.004098724810930472, 'epoch': 1.72}\n",
            "{'loss': 0.9062, 'grad_norm': 0.0715063065290451, 'learning_rate': 0.004056312022735417, 'epoch': 1.73}\n",
            "{'loss': 1.0531, 'grad_norm': 0.1220521405339241, 'learning_rate': 0.00401396952926019, 'epoch': 1.74}\n",
            "{'loss': 1.051, 'grad_norm': 0.0950484573841095, 'learning_rate': 0.003971700484570318, 'epoch': 1.74}\n",
            "{'loss': 1.6434, 'grad_norm': 0.2769889533519745, 'learning_rate': 0.00392950803726017, 'epoch': 1.75}\n",
            "{'loss': 1.0851, 'grad_norm': 0.1133999228477478, 'learning_rate': 0.003887395330218428, 'epoch': 1.76}\n",
            "{'loss': 1.076, 'grad_norm': 0.15627267956733704, 'learning_rate': 0.0038453655003939735, 'epoch': 1.77}\n",
            "{'loss': 1.1833, 'grad_norm': 0.12199762463569641, 'learning_rate': 0.003803421678562213, 'epoch': 1.78}\n",
            "{'loss': 0.9436, 'grad_norm': 0.09750226140022278, 'learning_rate': 0.00376156698909187, 'epoch': 1.78}\n",
            "{'loss': 1.0849, 'grad_norm': 0.12468156218528748, 'learning_rate': 0.0037198045497122646, 'epoch': 1.79}\n",
            "{'loss': 1.0421, 'grad_norm': 0.09576047211885452, 'learning_rate': 0.0036781374712810556, 'epoch': 1.8}\n",
            "{'loss': 1.1671, 'grad_norm': 0.13663692772388458, 'learning_rate': 0.0036365688575525313, 'epoch': 1.81}\n",
            "{'loss': 0.8303, 'grad_norm': 0.11837776750326157, 'learning_rate': 0.003595101804946404, 'epoch': 1.82}\n",
            "{'loss': 1.3932, 'grad_norm': 0.14199820160865784, 'learning_rate': 0.003553739402317162, 'epoch': 1.82}\n",
            "{'loss': 0.8091, 'grad_norm': 0.06160188093781471, 'learning_rate': 0.003512484730723986, 'epoch': 1.83}\n",
            "{'loss': 0.909, 'grad_norm': 0.08046326786279678, 'learning_rate': 0.0034713408632012365, 'epoch': 1.84}\n",
            "{'loss': 0.9397, 'grad_norm': 0.09543135017156601, 'learning_rate': 0.00343031086452955, 'epoch': 1.85}\n",
            "{'loss': 0.9498, 'grad_norm': 0.09034917503595352, 'learning_rate': 0.003389397791007548, 'epoch': 1.86}\n",
            "{'loss': 0.9236, 'grad_norm': 0.06478691101074219, 'learning_rate': 0.0033486046902241663, 'epoch': 1.86}\n",
            "{'loss': 0.8039, 'grad_norm': 0.043272148817777634, 'learning_rate': 0.003307934600831648, 'epoch': 1.87}\n",
            "{'loss': 1.1418, 'grad_norm': 0.10073107481002808, 'learning_rate': 0.0032673905523191997, 'epoch': 1.88}\n",
            "{'loss': 0.8528, 'grad_norm': 0.03942655026912689, 'learning_rate': 0.0032269755647873215, 'epoch': 1.89}\n",
            "{'loss': 0.8025, 'grad_norm': 0.05625496432185173, 'learning_rate': 0.00318669264872284, 'epoch': 1.9}\n",
            "{'loss': 0.8158, 'grad_norm': 0.0590687096118927, 'learning_rate': 0.0031465448047746625, 'epoch': 1.9}\n",
            "{'loss': 0.9211, 'grad_norm': 0.18001368641853333, 'learning_rate': 0.003106535023530262, 'epoch': 1.91}\n",
            "{'loss': 0.8413, 'grad_norm': 0.06143394857645035, 'learning_rate': 0.003066666285292906, 'epoch': 1.92}\n",
            "{'loss': 1.4607, 'grad_norm': 0.17954806983470917, 'learning_rate': 0.00302694155985966, 'epoch': 1.93}\n",
            "{'loss': 0.7832, 'grad_norm': 0.045857518911361694, 'learning_rate': 0.0029873638063001627, 'epoch': 1.94}\n",
            "{'loss': 1.025, 'grad_norm': 0.10090295225381851, 'learning_rate': 0.002947935972736217, 'epoch': 1.94}\n",
            "{'loss': 1.1178, 'grad_norm': 0.13669843971729279, 'learning_rate': 0.0029086609961221756, 'epoch': 1.95}\n",
            "{'loss': 0.8567, 'grad_norm': 0.0585518516600132, 'learning_rate': 0.0028695418020261753, 'epoch': 1.96}\n",
            "{'loss': 0.8948, 'grad_norm': 0.04949059337377548, 'learning_rate': 0.00283058130441221, 'epoch': 1.97}\n",
            "{'loss': 0.9037, 'grad_norm': 0.0661129504442215, 'learning_rate': 0.0027917824054230784, 'epoch': 1.98}\n",
            "{'loss': 0.8128, 'grad_norm': 0.07709669321775436, 'learning_rate': 0.0027531479951641924, 'epoch': 1.98}\n",
            "{'loss': 1.2751, 'grad_norm': 0.12230564653873444, 'learning_rate': 0.002714680951488312, 'epoch': 1.99}\n",
            "{'loss': 0.7796, 'grad_norm': 0.07135757803916931, 'learning_rate': 0.002676384139781157, 'epoch': 2.0}\n",
            "{'loss': 1.18, 'grad_norm': 0.11586493253707886, 'learning_rate': 0.0026382604127479815, 'epoch': 2.01}\n",
            "{'loss': 1.0283, 'grad_norm': 0.05800537019968033, 'learning_rate': 0.0026003126102010694, 'epoch': 2.02}\n",
            "{'loss': 0.7342, 'grad_norm': 0.03344269469380379, 'learning_rate': 0.0025625435588482017, 'epoch': 2.02}\n",
            "{'loss': 0.9921, 'grad_norm': 0.06040789559483528, 'learning_rate': 0.002524956072082093, 'epoch': 2.03}\n",
            "{'loss': 0.689, 'grad_norm': 0.03629177063703537, 'learning_rate': 0.0024875529497708354, 'epoch': 2.04}\n",
            "{'loss': 0.7671, 'grad_norm': 0.04510544613003731, 'learning_rate': 0.0024503369780493217, 'epoch': 2.05}\n",
            "{'loss': 0.9257, 'grad_norm': 0.058569543063640594, 'learning_rate': 0.0024133109291117156, 'epoch': 2.06}\n",
            "{'loss': 0.7611, 'grad_norm': 0.0384635366499424, 'learning_rate': 0.00237647756100496, 'epoch': 2.06}\n",
            "{'loss': 0.9095, 'grad_norm': 0.06477142125368118, 'learning_rate': 0.0023398396174233176, 'epoch': 2.07}\n",
            "{'loss': 0.7597, 'grad_norm': 0.05576081573963165, 'learning_rate': 0.002303399827504005, 'epoch': 2.08}\n",
            "{'loss': 0.7234, 'grad_norm': 0.03786275163292885, 'learning_rate': 0.002267160905623895, 'epoch': 2.09}\n",
            "{'loss': 0.7913, 'grad_norm': 0.035769689828157425, 'learning_rate': 0.0022311255511973343, 'epoch': 2.1}\n",
            "{'loss': 0.8899, 'grad_norm': 0.07561207562685013, 'learning_rate': 0.0021952964484750525, 'epoch': 2.1}\n",
            "{'loss': 0.889, 'grad_norm': 0.049074236303567886, 'learning_rate': 0.0021596762663442215, 'epoch': 2.11}\n",
            "{'loss': 0.7008, 'grad_norm': 0.047176290303468704, 'learning_rate': 0.0021242676581296528, 'epoch': 2.12}\n",
            "{'loss': 1.0483, 'grad_norm': 0.08282799273729324, 'learning_rate': 0.0020890732613961477, 'epoch': 2.13}\n",
            "{'loss': 0.8303, 'grad_norm': 0.03576870262622833, 'learning_rate': 0.002054095697752032, 'epoch': 2.14}\n",
            "{'loss': 0.7332, 'grad_norm': 0.04691050201654434, 'learning_rate': 0.002019337572653874, 'epoch': 2.14}\n",
            "{'loss': 0.7311, 'grad_norm': 0.02954426035284996, 'learning_rate': 0.0019848014752123977, 'epoch': 2.15}\n",
            "{'loss': 0.9107, 'grad_norm': 0.06879512220621109, 'learning_rate': 0.0019504899779996354, 'epoch': 2.16}\n",
            "{'loss': 1.2568, 'grad_norm': 0.0873977318406105, 'learning_rate': 0.0019164056368572847, 'epoch': 2.17}\n",
            "{'loss': 0.8403, 'grad_norm': 0.05280006304383278, 'learning_rate': 0.0018825509907063327, 'epoch': 2.18}\n",
            "{'loss': 0.9773, 'grad_norm': 0.07555610686540604, 'learning_rate': 0.0018489285613579327, 'epoch': 2.18}\n",
            "{'loss': 0.714, 'grad_norm': 0.03506246954202652, 'learning_rate': 0.0018155408533255552, 'epoch': 2.19}\n",
            "{'loss': 0.8242, 'grad_norm': 0.03702569380402565, 'learning_rate': 0.001782390353638426, 'epoch': 2.2}\n",
            "{'loss': 0.7443, 'grad_norm': 0.03857685253024101, 'learning_rate': 0.0017494795316562789, 'epoch': 2.21}\n",
            "{'loss': 0.8781, 'grad_norm': 0.09136930853128433, 'learning_rate': 0.0017168108388853998, 'epoch': 2.22}\n",
            "{'loss': 0.7758, 'grad_norm': 0.03933399170637131, 'learning_rate': 0.001684386708796025, 'epoch': 2.22}\n",
            "{'loss': 0.8597, 'grad_norm': 0.04749927297234535, 'learning_rate': 0.0016522095566410728, 'epoch': 2.23}\n",
            "{'loss': 0.7032, 'grad_norm': 0.0527079775929451, 'learning_rate': 0.001620281779276228, 'epoch': 2.24}\n",
            "{'loss': 0.7306, 'grad_norm': 0.038709692656993866, 'learning_rate': 0.0015886057549814132, 'epoch': 2.25}\n",
            "{'loss': 0.9154, 'grad_norm': 0.07150906324386597, 'learning_rate': 0.001557183843283614, 'epoch': 2.26}\n",
            "{'loss': 0.7284, 'grad_norm': 0.05149819329380989, 'learning_rate': 0.0015260183847811382, 'epoch': 2.26}\n",
            "{'loss': 0.9362, 'grad_norm': 0.056459635496139526, 'learning_rate': 0.0014951117009692528, 'epoch': 2.27}\n",
            "{'loss': 0.7514, 'grad_norm': 0.04402795433998108, 'learning_rate': 0.0014644660940672626, 'epoch': 2.28}\n",
            "{'loss': 0.8649, 'grad_norm': 0.05239589139819145, 'learning_rate': 0.0014340838468470197, 'epoch': 2.29}\n",
            "{'loss': 0.8227, 'grad_norm': 0.039934758096933365, 'learning_rate': 0.0014039672224628785, 'epoch': 2.3}\n",
            "{'loss': 0.8235, 'grad_norm': 0.060490917414426804, 'learning_rate': 0.001374118464283119, 'epoch': 2.3}\n",
            "{'loss': 0.8127, 'grad_norm': 0.0729823037981987, 'learning_rate': 0.0013445397957228338, 'epoch': 2.31}\n",
            "{'loss': 0.7228, 'grad_norm': 0.041048627346754074, 'learning_rate': 0.0013152334200783166, 'epoch': 2.32}\n",
            "{'loss': 0.8298, 'grad_norm': 0.051940299570560455, 'learning_rate': 0.0012862015203629273, 'epoch': 2.33}\n",
            "{'loss': 0.7226, 'grad_norm': 0.03596721962094307, 'learning_rate': 0.001257446259144494, 'epoch': 2.34}\n",
            "{'loss': 0.8441, 'grad_norm': 0.06226436421275139, 'learning_rate': 0.0012289697783842142, 'epoch': 2.34}\n",
            "{'loss': 0.7608, 'grad_norm': 0.0315125435590744, 'learning_rate': 0.0012007741992771065, 'epoch': 2.35}\n",
            "{'loss': 1.2655, 'grad_norm': 0.12268095463514328, 'learning_rate': 0.0011728616220940031, 'epoch': 2.36}\n",
            "{'loss': 0.7757, 'grad_norm': 0.039747245609760284, 'learning_rate': 0.001145234126025102, 'epoch': 2.37}\n",
            "{'loss': 0.6703, 'grad_norm': 0.03142644092440605, 'learning_rate': 0.0011178937690250917, 'epoch': 2.38}\n",
            "{'loss': 0.8372, 'grad_norm': 0.04977569356560707, 'learning_rate': 0.001090842587659851, 'epoch': 2.38}\n",
            "{'loss': 0.7233, 'grad_norm': 0.06023411080241203, 'learning_rate': 0.0010640825969547496, 'epoch': 2.39}\n",
            "{'loss': 0.5557, 'grad_norm': 0.02980218641459942, 'learning_rate': 0.0010376157902445488, 'epoch': 2.4}\n",
            "{'loss': 0.8365, 'grad_norm': 0.06458635628223419, 'learning_rate': 0.00101144413902492, 'epoch': 2.41}\n",
            "{'loss': 0.7157, 'grad_norm': 0.029369188472628593, 'learning_rate': 0.000985569592805588, 'epoch': 2.42}\n",
            "{'loss': 0.6936, 'grad_norm': 0.04314807429909706, 'learning_rate': 0.0009599940789651179, 'epoch': 2.42}\n",
            "{'loss': 1.1437, 'grad_norm': 0.0919480174779892, 'learning_rate': 0.0009347195026073368, 'epoch': 2.43}\n",
            "{'loss': 0.7393, 'grad_norm': 0.03218881040811539, 'learning_rate': 0.000909747746419436, 'epoch': 2.44}\n",
            "{'loss': 0.6749, 'grad_norm': 0.02852863445878029, 'learning_rate': 0.0008850806705317183, 'epoch': 2.45}\n",
            "{'loss': 0.721, 'grad_norm': 0.04301150143146515, 'learning_rate': 0.0008607201123790459, 'epoch': 2.46}\n",
            "{'loss': 0.6567, 'grad_norm': 0.030232666060328484, 'learning_rate': 0.0008366678865639688, 'epoch': 2.46}\n",
            "{'loss': 0.6167, 'grad_norm': 0.019396420568227768, 'learning_rate': 0.0008129257847215571, 'epoch': 2.47}\n",
            "{'loss': 0.7148, 'grad_norm': 0.04192497581243515, 'learning_rate': 0.0007894955753859412, 'epoch': 2.48}\n",
            "{'loss': 0.5883, 'grad_norm': 0.028515489771962166, 'learning_rate': 0.0007663790038585794, 'epoch': 2.49}\n",
            "{'loss': 0.6378, 'grad_norm': 0.03625668212771416, 'learning_rate': 0.0007435777920782444, 'epoch': 2.5}\n",
            "{'loss': 0.6703, 'grad_norm': 0.05092150717973709, 'learning_rate': 0.000721093638492763, 'epoch': 2.5}\n",
            "{'loss': 1.1621, 'grad_norm': 0.10194937139749527, 'learning_rate': 0.0006989282179324963, 'epoch': 2.51}\n",
            "{'loss': 0.7867, 'grad_norm': 0.04901197552680969, 'learning_rate': 0.0006770831814855883, 'epoch': 2.52}\n",
            "{'loss': 0.7118, 'grad_norm': 0.05883951485157013, 'learning_rate': 0.0006555601563749675, 'epoch': 2.53}\n",
            "{'loss': 0.8855, 'grad_norm': 0.05940796434879303, 'learning_rate': 0.0006343607458371459, 'epoch': 2.54}\n",
            "{'loss': 0.6744, 'grad_norm': 0.048098281025886536, 'learning_rate': 0.0006134865290027902, 'epoch': 2.54}\n",
            "{'loss': 0.6612, 'grad_norm': 0.03983994573354721, 'learning_rate': 0.000592939060779093, 'epoch': 2.55}\n",
            "{'loss': 0.8166, 'grad_norm': 0.050171807408332825, 'learning_rate': 0.000572719871733951, 'epoch': 2.56}\n",
            "{'loss': 0.6566, 'grad_norm': 0.0338958203792572, 'learning_rate': 0.0005528304679819513, 'epoch': 2.57}\n",
            "{'loss': 0.7317, 'grad_norm': 0.05149698257446289, 'learning_rate': 0.0005332723310721854, 'epoch': 2.58}\n",
            "{'loss': 1.1298, 'grad_norm': 0.10114804655313492, 'learning_rate': 0.0005140469178778845, 'epoch': 2.58}\n",
            "{'loss': 0.8774, 'grad_norm': 0.07829593122005463, 'learning_rate': 0.0004951556604879049, 'epoch': 2.59}\n",
            "{'loss': 0.868, 'grad_norm': 0.07921858876943588, 'learning_rate': 0.00047659996610004417, 'epoch': 2.6}\n",
            "{'loss': 0.5665, 'grad_norm': 0.03668167442083359, 'learning_rate': 0.00045838121691622993, 'epoch': 2.61}\n",
            "{'loss': 0.7613, 'grad_norm': 0.04976184666156769, 'learning_rate': 0.0004405007700395497, 'epoch': 2.62}\n",
            "{'loss': 0.8454, 'grad_norm': 0.06012560799717903, 'learning_rate': 0.0004229599573731685, 'epoch': 2.62}\n",
            "{'loss': 0.9437, 'grad_norm': 0.06933027505874634, 'learning_rate': 0.0004057600855211141, 'epoch': 2.63}\n",
            "{'loss': 0.6679, 'grad_norm': 0.032553013414144516, 'learning_rate': 0.00038890243569094876, 'epoch': 2.64}\n",
            "{'loss': 0.8474, 'grad_norm': 0.06397470831871033, 'learning_rate': 0.0003723882635983328, 'epoch': 2.65}\n",
            "{'loss': 0.7683, 'grad_norm': 0.06576401740312576, 'learning_rate': 0.00035621879937348835, 'epoch': 2.66}\n",
            "{'loss': 0.7906, 'grad_norm': 0.07828734070062637, 'learning_rate': 0.00034039524746956595, 'epoch': 2.66}\n",
            "{'loss': 0.7184, 'grad_norm': 0.04722196236252785, 'learning_rate': 0.0003249187865729264, 'epoch': 2.67}\n",
            "{'loss': 1.1263, 'grad_norm': 0.08248329162597656, 'learning_rate': 0.0003097905695153408, 'epoch': 2.68}\n",
            "{'loss': 0.8884, 'grad_norm': 0.0792134553194046, 'learning_rate': 0.0002950117231881183, 'epoch': 2.69}\n",
            "{'loss': 1.0034, 'grad_norm': 0.06315246224403381, 'learning_rate': 0.0002805833484581621, 'epoch': 2.7}\n",
            "{'loss': 0.8144, 'grad_norm': 0.03965245559811592, 'learning_rate': 0.00026650652008597067, 'epoch': 2.7}\n",
            "{'loss': 1.0425, 'grad_norm': 0.07636931538581848, 'learning_rate': 0.0002527822866455731, 'epoch': 2.71}\n",
            "{'loss': 0.6481, 'grad_norm': 0.04989210143685341, 'learning_rate': 0.00023941167044642941, 'epoch': 2.72}\n",
            "{'loss': 0.7906, 'grad_norm': 0.05009781941771507, 'learning_rate': 0.00022639566745727202, 'epoch': 2.73}\n",
            "{'loss': 0.7558, 'grad_norm': 0.03806023672223091, 'learning_rate': 0.0002137352472319215, 'epoch': 2.74}\n",
            "{'loss': 0.7893, 'grad_norm': 0.05212438851594925, 'learning_rate': 0.0002014313528370626, 'epoch': 2.74}\n",
            "{'loss': 0.8844, 'grad_norm': 0.0714246854186058, 'learning_rate': 0.00018948490078199765, 'epoch': 2.75}\n",
            "{'loss': 0.5539, 'grad_norm': 0.02276705950498581, 'learning_rate': 0.00017789678095037452, 'epoch': 2.76}\n",
            "{'loss': 0.7581, 'grad_norm': 0.049165718257427216, 'learning_rate': 0.0001666678565339025, 'epoch': 2.77}\n",
            "{'loss': 0.6256, 'grad_norm': 0.02628217823803425, 'learning_rate': 0.0001557989639680496, 'epoch': 2.78}\n",
            "{'loss': 0.6066, 'grad_norm': 0.025956090539693832, 'learning_rate': 0.00014529091286973994, 'epoch': 2.78}\n",
            "{'loss': 0.6046, 'grad_norm': 0.0341573990881443, 'learning_rate': 0.0001351444859770462, 'epoch': 2.79}\n",
            "{'loss': 0.7812, 'grad_norm': 0.0761772021651268, 'learning_rate': 0.0001253604390908819, 'epoch': 2.8}\n",
            "{'loss': 0.72, 'grad_norm': 0.03620615974068642, 'learning_rate': 0.0001159395010187042, 'epoch': 2.81}\n",
            "{'loss': 0.6258, 'grad_norm': 0.03569693863391876, 'learning_rate': 0.00010688237352022346, 'epoch': 2.82}\n",
            "{'loss': 0.5795, 'grad_norm': 0.028808169066905975, 'learning_rate': 9.818973125513276e-05, 'epoch': 2.82}\n",
            "{'loss': 0.5825, 'grad_norm': 0.0370308980345726, 'learning_rate': 8.986222173284874e-05, 'epoch': 2.83}\n",
            "{'loss': 0.793, 'grad_norm': 0.08691959828138351, 'learning_rate': 8.190046526428241e-05, 'epoch': 2.84}\n",
            "{'loss': 0.7378, 'grad_norm': 0.0414193719625473, 'learning_rate': 7.4305054915631e-05, 'epoch': 2.85}\n",
            "{'loss': 0.5831, 'grad_norm': 0.030177967622876167, 'learning_rate': 6.707655646420229e-05, 'epoch': 2.86}\n",
            "{'loss': 0.6415, 'grad_norm': 0.029980983585119247, 'learning_rate': 6.0215508356267765e-05, 'epoch': 2.86}\n",
            "{'loss': 0.6417, 'grad_norm': 0.03186111897230148, 'learning_rate': 5.372242166695684e-05, 'epoch': 2.87}\n",
            "{'loss': 0.7731, 'grad_norm': 0.05507785454392433, 'learning_rate': 4.759778006218407e-05, 'epoch': 2.88}\n",
            "{'loss': 0.5426, 'grad_norm': 0.025817200541496277, 'learning_rate': 4.184203976262513e-05, 'epoch': 2.89}\n",
            "{'loss': 0.6139, 'grad_norm': 0.02830682136118412, 'learning_rate': 3.645562950973014e-05, 'epoch': 2.9}\n",
            "{'loss': 0.6261, 'grad_norm': 0.03197234869003296, 'learning_rate': 3.143895053378698e-05, 'epoch': 2.9}\n",
            "{'loss': 0.573, 'grad_norm': 0.026161298155784607, 'learning_rate': 2.6792376524036878e-05, 'epoch': 2.91}\n",
            "{'loss': 0.7491, 'grad_norm': 0.04240553826093674, 'learning_rate': 2.2516253600833868e-05, 'epoch': 2.92}\n",
            "{'loss': 0.579, 'grad_norm': 0.029977567493915558, 'learning_rate': 1.8610900289867673e-05, 'epoch': 2.93}\n",
            "{'loss': 0.7127, 'grad_norm': 0.03616742789745331, 'learning_rate': 1.5076607498433204e-05, 'epoch': 2.94}\n",
            "{'loss': 0.7177, 'grad_norm': 0.04454083368182182, 'learning_rate': 1.1913638493762369e-05, 'epoch': 2.94}\n",
            "{'loss': 0.6442, 'grad_norm': 0.03788711130619049, 'learning_rate': 9.12222888341252e-06, 'epoch': 2.95}\n",
            "{'loss': 0.7716, 'grad_norm': 0.05826518312096596, 'learning_rate': 6.702586597719385e-06, 'epoch': 2.96}\n",
            "{'loss': 0.618, 'grad_norm': 0.02817576378583908, 'learning_rate': 4.654891874303346e-06, 'epoch': 2.97}\n",
            "{'loss': 0.6342, 'grad_norm': 0.04228748381137848, 'learning_rate': 2.9792972446479605e-06, 'epoch': 2.98}\n",
            "{'loss': 0.8228, 'grad_norm': 0.040751297026872635, 'learning_rate': 1.6759275227357095e-06, 'epoch': 2.98}\n",
            "{'loss': 0.7784, 'grad_norm': 0.04306267946958542, 'learning_rate': 7.448797957526621e-07, 'epoch': 2.99}\n",
            "{'loss': 0.6602, 'grad_norm': 0.04019474983215332, 'learning_rate': 1.862234168542587e-07, 'epoch': 3.0}\n",
            "{'train_runtime': 67.9717, 'train_samples_per_second': 11.034, 'train_steps_per_second': 5.517, 'train_loss': 1.562878168741862, 'epoch': 3.0}\n",
            "100% 375/375 [01:07<00:00,  5.52it/s]\n",
            "Training complete.\n",
            "Model saved to loras/self-edit/training_set_iteration_1/8d5021e8/11\n",
            "Training on 200 examples for 3 epochs, lr: 0.001\n",
            "No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n",
            "Starting training...\n",
            "{'loss': 6.3894, 'grad_norm': 6.897727966308594, 'learning_rate': 0.0, 'epoch': 0.01}\n",
            "{'loss': 7.3193, 'grad_norm': 8.249114990234375, 'learning_rate': 9.090909090909092e-05, 'epoch': 0.02}\n",
            "{'loss': 3.2459, 'grad_norm': 3.682124376296997, 'learning_rate': 0.00018181818181818183, 'epoch': 0.03}\n",
            "{'loss': 1.641, 'grad_norm': 8.002100944519043, 'learning_rate': 0.00027272727272727274, 'epoch': 0.04}\n",
            "{'loss': 1.9023, 'grad_norm': 10.045609474182129, 'learning_rate': 0.00036363636363636367, 'epoch': 0.05}\n",
            "{'loss': 0.8738, 'grad_norm': 0.8488099575042725, 'learning_rate': 0.00045454545454545455, 'epoch': 0.06}\n",
            "{'loss': 0.8403, 'grad_norm': 0.32730087637901306, 'learning_rate': 0.0005454545454545455, 'epoch': 0.07}\n",
            "{'loss': 0.7213, 'grad_norm': 0.30521124601364136, 'learning_rate': 0.0006363636363636364, 'epoch': 0.08}\n",
            "{'loss': 0.5903, 'grad_norm': 0.2651054263114929, 'learning_rate': 0.0007272727272727273, 'epoch': 0.09}\n",
            "{'loss': 0.5242, 'grad_norm': 0.266370952129364, 'learning_rate': 0.0008181818181818183, 'epoch': 0.1}\n",
            "{'loss': 0.4422, 'grad_norm': 0.1753331571817398, 'learning_rate': 0.0009090909090909091, 'epoch': 0.11}\n",
            "{'loss': 0.3645, 'grad_norm': 0.18203774094581604, 'learning_rate': 0.001, 'epoch': 0.12}\n",
            "{'loss': 0.2968, 'grad_norm': 0.1311141699552536, 'learning_rate': 0.0009999704580069347, 'epoch': 0.13}\n",
            "{'loss': 0.2623, 'grad_norm': 0.16209709644317627, 'learning_rate': 0.0009998818355186558, 'epoch': 0.14}\n",
            "{'loss': 0.2153, 'grad_norm': 0.1400684416294098, 'learning_rate': 0.0009997341430075036, 'epoch': 0.15}\n",
            "{'loss': 0.1408, 'grad_norm': 0.15176576375961304, 'learning_rate': 0.0009995273979260023, 'epoch': 0.16}\n",
            "{'loss': 0.1169, 'grad_norm': 0.2034439742565155, 'learning_rate': 0.000999261624704799, 'epoch': 0.17}\n",
            "{'loss': 0.1247, 'grad_norm': 0.18036913871765137, 'learning_rate': 0.0009989368547497763, 'epoch': 0.18}\n",
            "{'loss': 0.094, 'grad_norm': 0.12397713959217072, 'learning_rate': 0.0009985531264383412, 'epoch': 0.19}\n",
            "{'loss': 0.106, 'grad_norm': 0.11257781833410263, 'learning_rate': 0.0009981104851148903, 'epoch': 0.2}\n",
            "{'loss': 0.1139, 'grad_norm': 0.15134766697883606, 'learning_rate': 0.0009976089830854512, 'epoch': 0.21}\n",
            "{'loss': 0.1133, 'grad_norm': 0.1339862048625946, 'learning_rate': 0.000997048679611502, 'epoch': 0.22}\n",
            "{'loss': 0.1074, 'grad_norm': 0.13418832421302795, 'learning_rate': 0.0009964296409029675, 'epoch': 0.23}\n",
            "{'loss': 0.0812, 'grad_norm': 0.10015180706977844, 'learning_rate': 0.000995751940110397, 'epoch': 0.24}\n",
            "{'loss': 0.0719, 'grad_norm': 0.086690753698349, 'learning_rate': 0.0009950156573163191, 'epoch': 0.25}\n",
            "{'loss': 0.0973, 'grad_norm': 0.12099787592887878, 'learning_rate': 0.0009942208795257785, 'epoch': 0.26}\n",
            "{'loss': 0.1122, 'grad_norm': 0.1515742689371109, 'learning_rate': 0.0009933677006560549, 'epoch': 0.27}\n",
            "{'loss': 0.0995, 'grad_norm': 0.1274726837873459, 'learning_rate': 0.0009924562215255655, 'epoch': 0.28}\n",
            "{'loss': 0.08, 'grad_norm': 0.08767817914485931, 'learning_rate': 0.000991486549841951, 'epoch': 0.29}\n",
            "{'loss': 0.0742, 'grad_norm': 0.08057528734207153, 'learning_rate': 0.0009904588001893476, 'epoch': 0.3}\n",
            "{'loss': 0.0701, 'grad_norm': 0.0775483250617981, 'learning_rate': 0.0009893730940148482, 'epoch': 0.31}\n",
            "{'loss': 0.0895, 'grad_norm': 0.10349702835083008, 'learning_rate': 0.0009882295596141497, 'epoch': 0.32}\n",
            "{'loss': 0.0699, 'grad_norm': 0.0632128119468689, 'learning_rate': 0.0009870283321163932, 'epoch': 0.33}\n",
            "{'loss': 0.0935, 'grad_norm': 0.12959104776382446, 'learning_rate': 0.000985769553468197, 'epoch': 0.34}\n",
            "{'loss': 0.0913, 'grad_norm': 0.1718398779630661, 'learning_rate': 0.000984453372416881, 'epoch': 0.35}\n",
            "{'loss': 0.0611, 'grad_norm': 0.08890198171138763, 'learning_rate': 0.000983079944492891, 'epoch': 0.36}\n",
            "{'loss': 0.0772, 'grad_norm': 0.24213023483753204, 'learning_rate': 0.0009816494319914203, 'epoch': 0.37}\n",
            "{'loss': 0.0536, 'grad_norm': 0.07067927718162537, 'learning_rate': 0.0009801620039532302, 'epoch': 0.38}\n",
            "{'loss': 0.0549, 'grad_norm': 0.07903669774532318, 'learning_rate': 0.0009786178361446758, 'epoch': 0.39}\n",
            "{'loss': 0.0484, 'grad_norm': 0.09818506985902786, 'learning_rate': 0.0009770171110369363, 'epoch': 0.4}\n",
            "{'loss': 0.0441, 'grad_norm': 0.061726126819849014, 'learning_rate': 0.0009753600177844513, 'epoch': 0.41}\n",
            "{'loss': 0.0415, 'grad_norm': 0.05677396431565285, 'learning_rate': 0.0009736467522025705, 'epoch': 0.42}\n",
            "{'loss': 0.0453, 'grad_norm': 0.07556934654712677, 'learning_rate': 0.0009718775167444139, 'epoch': 0.43}\n",
            "{'loss': 0.0409, 'grad_norm': 0.08021283894777298, 'learning_rate': 0.0009700525204769475, 'epoch': 0.44}\n",
            "{'loss': 0.0716, 'grad_norm': 0.1719978004693985, 'learning_rate': 0.00096817197905628, 'epoch': 0.45}\n",
            "{'loss': 0.0292, 'grad_norm': 0.05648215487599373, 'learning_rate': 0.0009662361147021779, 'epoch': 0.46}\n",
            "{'loss': 0.0388, 'grad_norm': 0.10567335039377213, 'learning_rate': 0.0009642451561718064, 'epoch': 0.47}\n",
            "{'loss': 0.0339, 'grad_norm': 0.08006414026021957, 'learning_rate': 0.0009621993387326978, 'epoch': 0.48}\n",
            "{'loss': 0.0347, 'grad_norm': 0.05821341276168823, 'learning_rate': 0.0009600989041349503, 'epoch': 0.49}\n",
            "{'loss': 0.0444, 'grad_norm': 0.16095158457756042, 'learning_rate': 0.0009579441005826617, 'epoch': 0.5}\n",
            "{'loss': 0.0486, 'grad_norm': 0.18200865387916565, 'learning_rate': 0.0009557351827045981, 'epoch': 0.51}\n",
            "{'loss': 0.031, 'grad_norm': 0.09977298229932785, 'learning_rate': 0.0009534724115241059, 'epoch': 0.52}\n",
            "{'loss': 0.0847, 'grad_norm': 0.291396826505661, 'learning_rate': 0.0009511560544282675, 'epoch': 0.53}\n",
            "{'loss': 0.042, 'grad_norm': 0.17737023532390594, 'learning_rate': 0.0009487863851363038, 'epoch': 0.54}\n",
            "{'loss': 0.0629, 'grad_norm': 0.14730221033096313, 'learning_rate': 0.0009463636836672299, 'epoch': 0.55}\n",
            "{'loss': 0.0442, 'grad_norm': 0.07662220299243927, 'learning_rate': 0.000943888236306766, 'epoch': 0.56}\n",
            "{'loss': 0.044, 'grad_norm': 0.08346999436616898, 'learning_rate': 0.0009413603355735068, 'epoch': 0.57}\n",
            "{'loss': 0.0502, 'grad_norm': 0.09072345495223999, 'learning_rate': 0.0009387802801843564, 'epoch': 0.58}\n",
            "{'loss': 0.0259, 'grad_norm': 0.0436747670173645, 'learning_rate': 0.0009361483750192283, 'epoch': 0.59}\n",
            "{'loss': 0.0331, 'grad_norm': 0.057140082120895386, 'learning_rate': 0.0009334649310850188, 'epoch': 0.6}\n",
            "{'loss': 0.0399, 'grad_norm': 0.06766264885663986, 'learning_rate': 0.0009307302654788567, 'epoch': 0.61}\n",
            "{'loss': 0.0352, 'grad_norm': 0.052533380687236786, 'learning_rate': 0.0009279447013506312, 'epoch': 0.62}\n",
            "{'loss': 0.0313, 'grad_norm': 0.05689240247011185, 'learning_rate': 0.0009251085678648072, 'epoch': 0.63}\n",
            "{'loss': 0.0269, 'grad_norm': 0.03984684869647026, 'learning_rate': 0.0009222222001615274, 'epoch': 0.64}\n",
            "{'loss': 0.051, 'grad_norm': 0.15146230161190033, 'learning_rate': 0.0009192859393170107, 'epoch': 0.65}\n",
            "{'loss': 0.0295, 'grad_norm': 0.042031656950712204, 'learning_rate': 0.0009163001323032473, 'epoch': 0.66}\n",
            "{'loss': 0.0254, 'grad_norm': 0.031164836138486862, 'learning_rate': 0.0009132651319469974, 'epoch': 0.67}\n",
            "{'loss': 0.0236, 'grad_norm': 0.07256247103214264, 'learning_rate': 0.000910181296888099, 'epoch': 0.68}\n",
            "{'loss': 0.0374, 'grad_norm': 0.049657367169857025, 'learning_rate': 0.0009070489915370876, 'epoch': 0.69}\n",
            "{'loss': 0.05, 'grad_norm': 0.0998590812087059, 'learning_rate': 0.0009038685860321354, 'epoch': 0.7}\n",
            "{'loss': 0.0562, 'grad_norm': 0.1502714902162552, 'learning_rate': 0.0009006404561953114, 'epoch': 0.71}\n",
            "{'loss': 0.0407, 'grad_norm': 0.0961606353521347, 'learning_rate': 0.000897364983488173, 'epoch': 0.72}\n",
            "{'loss': 0.0244, 'grad_norm': 0.03483002260327339, 'learning_rate': 0.0008940425549666881, 'epoch': 0.73}\n",
            "{'loss': 0.0238, 'grad_norm': 0.04385492205619812, 'learning_rate': 0.0008906735632354979, 'epoch': 0.74}\n",
            "{'loss': 0.039, 'grad_norm': 0.08759690076112747, 'learning_rate': 0.0008872584064015241, 'epoch': 0.75}\n",
            "{'loss': 0.0538, 'grad_norm': 0.12076983600854874, 'learning_rate': 0.0008837974880269246, 'epoch': 0.76}\n",
            "{'loss': 0.0237, 'grad_norm': 0.033415913581848145, 'learning_rate': 0.0008802912170814059, 'epoch': 0.77}\n",
            "{'loss': 0.0285, 'grad_norm': 0.04761066287755966, 'learning_rate': 0.0008767400078938958, 'epoch': 0.78}\n",
            "{'loss': 0.0243, 'grad_norm': 0.034468717873096466, 'learning_rate': 0.0008731442801035832, 'epoch': 0.79}\n",
            "{'loss': 0.0238, 'grad_norm': 0.054456498473882675, 'learning_rate': 0.0008695044586103295, 'epoch': 0.8}\n",
            "{'loss': 0.0148, 'grad_norm': 0.02819674275815487, 'learning_rate': 0.0008658209735244605, 'epoch': 0.81}\n",
            "{'loss': 0.0274, 'grad_norm': 0.05200010538101196, 'learning_rate': 0.0008620942601159394, 'epoch': 0.82}\n",
            "{'loss': 0.0442, 'grad_norm': 0.07344307005405426, 'learning_rate': 0.0008583247587629326, 'epoch': 0.83}\n",
            "{'loss': 0.0177, 'grad_norm': 0.04088979214429855, 'learning_rate': 0.0008545129148997719, 'epoch': 0.84}\n",
            "{'loss': 0.0343, 'grad_norm': 0.0784716084599495, 'learning_rate': 0.000850659178964317, 'epoch': 0.85}\n",
            "{'loss': 0.0268, 'grad_norm': 0.08903136104345322, 'learning_rate': 0.0008467640063447288, 'epoch': 0.86}\n",
            "{'loss': 0.0176, 'grad_norm': 0.03800121322274208, 'learning_rate': 0.0008428278573256578, 'epoch': 0.87}\n",
            "{'loss': 0.0353, 'grad_norm': 0.06331953406333923, 'learning_rate': 0.0008388511970338517, 'epoch': 0.88}\n",
            "{'loss': 0.0136, 'grad_norm': 0.024799594655632973, 'learning_rate': 0.0008348344953831939, 'epoch': 0.89}\n",
            "{'loss': 0.0281, 'grad_norm': 0.07635900378227234, 'learning_rate': 0.0008307782270191733, 'epoch': 0.9}\n",
            "{'loss': 0.0247, 'grad_norm': 0.05063774436712265, 'learning_rate': 0.0008266828712627976, 'epoch': 0.91}\n",
            "{'loss': 0.0143, 'grad_norm': 0.02366248518228531, 'learning_rate': 0.0008225489120539522, 'epoch': 0.92}\n",
            "{'loss': 0.0351, 'grad_norm': 0.06560476124286652, 'learning_rate': 0.0008183768378942143, 'epoch': 0.93}\n",
            "{'loss': 0.0199, 'grad_norm': 0.030744077637791634, 'learning_rate': 0.0008141671417891274, 'epoch': 0.94}\n",
            "{'loss': 0.0247, 'grad_norm': 0.10144032537937164, 'learning_rate': 0.0008099203211899441, 'epoch': 0.95}\n",
            "{'loss': 0.0349, 'grad_norm': 0.05024157091975212, 'learning_rate': 0.0008056368779348431, 'epoch': 0.96}\n",
            "{'loss': 0.0288, 'grad_norm': 0.10500442236661911, 'learning_rate': 0.0008013173181896282, 'epoch': 0.97}\n",
            "{'loss': 0.0249, 'grad_norm': 0.04914872720837593, 'learning_rate': 0.0007969621523879156, 'epoch': 0.98}\n",
            "{'loss': 0.0331, 'grad_norm': 0.09011738747358322, 'learning_rate': 0.000792571895170817, 'epoch': 0.99}\n",
            "{'loss': 0.028, 'grad_norm': 0.07122895866632462, 'learning_rate': 0.0007881470653261252, 'epoch': 1.0}\n",
            "{'loss': 0.0252, 'grad_norm': 0.03537484630942345, 'learning_rate': 0.0007836881857270106, 'epoch': 1.01}\n",
            "{'loss': 0.0291, 'grad_norm': 0.04493638500571251, 'learning_rate': 0.0007791957832702344, 'epoch': 1.02}\n",
            "{'loss': 0.0224, 'grad_norm': 0.05894972383975983, 'learning_rate': 0.0007746703888138848, 'epoch': 1.03}\n",
            "{'loss': 0.0279, 'grad_norm': 0.06628638505935669, 'learning_rate': 0.0007701125371146491, 'epoch': 1.04}\n",
            "{'loss': 0.0165, 'grad_norm': 0.02509702369570732, 'learning_rate': 0.00076552276676462, 'epoch': 1.05}\n",
            "{'loss': 0.0189, 'grad_norm': 0.05956092104315758, 'learning_rate': 0.0007609016201276532, 'epoch': 1.06}\n",
            "{'loss': 0.0388, 'grad_norm': 0.08906977623701096, 'learning_rate': 0.0007562496432752761, 'epoch': 1.07}\n",
            "{'loss': 0.0205, 'grad_norm': 0.02128695324063301, 'learning_rate': 0.0007515673859221605, 'epoch': 1.08}\n",
            "{'loss': 0.0303, 'grad_norm': 0.059410203248262405, 'learning_rate': 0.0007468554013611632, 'epoch': 1.09}\n",
            "{'loss': 0.0216, 'grad_norm': 0.028087187558412552, 'learning_rate': 0.0007421142463979453, 'epoch': 1.1}\n",
            "{'loss': 0.0272, 'grad_norm': 0.03845207765698433, 'learning_rate': 0.000737344481285175, 'epoch': 1.11}\n",
            "{'loss': 0.0209, 'grad_norm': 0.030028928071260452, 'learning_rate': 0.0007325466696563238, 'epoch': 1.12}\n",
            "{'loss': 0.0234, 'grad_norm': 0.039261966943740845, 'learning_rate': 0.000727721378459063, 'epoch': 1.13}\n",
            "{'loss': 0.0215, 'grad_norm': 0.06945036351680756, 'learning_rate': 0.0007228691778882692, 'epoch': 1.14}\n",
            "{'loss': 0.025, 'grad_norm': 0.0591258779168129, 'learning_rate': 0.0007179906413186446, 'epoch': 1.15}\n",
            "{'loss': 0.0165, 'grad_norm': 0.03428204357624054, 'learning_rate': 0.0007130863452369636, 'epoch': 1.16}\n",
            "{'loss': 0.0263, 'grad_norm': 0.04795435816049576, 'learning_rate': 0.0007081568691739492, 'epoch': 1.17}\n",
            "{'loss': 0.0393, 'grad_norm': 0.1499861627817154, 'learning_rate': 0.0007032027956357923, 'epoch': 1.18}\n",
            "{'loss': 0.0279, 'grad_norm': 0.05005223676562309, 'learning_rate': 0.0006982247100353172, 'epoch': 1.19}\n",
            "{'loss': 0.0182, 'grad_norm': 0.03773834928870201, 'learning_rate': 0.0006932232006228051, 'epoch': 1.2}\n",
            "{'loss': 0.0286, 'grad_norm': 0.0725579783320427, 'learning_rate': 0.0006881988584164816, 'epoch': 1.21}\n",
            "{'loss': 0.017, 'grad_norm': 0.02485853247344494, 'learning_rate': 0.000683152277132677, 'epoch': 1.22}\n",
            "{'loss': 0.0244, 'grad_norm': 0.04495255649089813, 'learning_rate': 0.0006780840531156685, 'epoch': 1.23}\n",
            "{'loss': 0.0337, 'grad_norm': 0.13800260424613953, 'learning_rate': 0.0006729947852672114, 'epoch': 1.24}\n",
            "{'loss': 0.0286, 'grad_norm': 0.05326689034700394, 'learning_rate': 0.0006678850749757672, 'epoch': 1.25}\n",
            "{'loss': 0.0137, 'grad_norm': 0.014833264984190464, 'learning_rate': 0.0006627555260454403, 'epoch': 1.26}\n",
            "{'loss': 0.0153, 'grad_norm': 0.019064174965023994, 'learning_rate': 0.0006576067446246262, 'epoch': 1.27}\n",
            "{'loss': 0.02, 'grad_norm': 0.02186976559460163, 'learning_rate': 0.0006524393391343853, 'epoch': 1.28}\n",
            "{'loss': 0.0257, 'grad_norm': 0.0232993271201849, 'learning_rate': 0.0006472539201965457, 'epoch': 1.29}\n",
            "{'loss': 0.0319, 'grad_norm': 0.035782452672719955, 'learning_rate': 0.000642051100561549, 'epoch': 1.3}\n",
            "{'loss': 0.0379, 'grad_norm': 0.04522364214062691, 'learning_rate': 0.0006368314950360416, 'epoch': 1.31}\n",
            "{'loss': 0.0179, 'grad_norm': 0.01823851466178894, 'learning_rate': 0.0006315957204102241, 'epoch': 1.32}\n",
            "{'loss': 0.0178, 'grad_norm': 0.02826620265841484, 'learning_rate': 0.0006263443953849674, 'epoch': 1.33}\n",
            "{'loss': 0.019, 'grad_norm': 0.0281868577003479, 'learning_rate': 0.0006210781404987016, 'epoch': 1.34}\n",
            "{'loss': 0.0257, 'grad_norm': 0.022693973034620285, 'learning_rate': 0.0006157975780540876, 'epoch': 1.35}\n",
            "{'loss': 0.0209, 'grad_norm': 0.0238312017172575, 'learning_rate': 0.0006105033320444824, 'epoch': 1.36}\n",
            "{'loss': 0.0242, 'grad_norm': 0.031742341816425323, 'learning_rate': 0.0006051960280802014, 'epoch': 1.37}\n",
            "{'loss': 0.0178, 'grad_norm': 0.018317436799407005, 'learning_rate': 0.0005998762933145921, 'epoch': 1.38}\n",
            "{'loss': 0.0189, 'grad_norm': 0.02606678195297718, 'learning_rate': 0.0005945447563699248, 'epoch': 1.39}\n",
            "{'loss': 0.0227, 'grad_norm': 0.024763524532318115, 'learning_rate': 0.0005892020472631093, 'epoch': 1.4}\n",
            "{'loss': 0.0193, 'grad_norm': 0.021238336339592934, 'learning_rate': 0.0005838487973312472, 'epoch': 1.41}\n",
            "{'loss': 0.0249, 'grad_norm': 0.039012741297483444, 'learning_rate': 0.0005784856391570279, 'epoch': 1.42}\n",
            "{'loss': 0.0186, 'grad_norm': 0.03619903326034546, 'learning_rate': 0.0005731132064939777, 'epoch': 1.43}\n",
            "{'loss': 0.0183, 'grad_norm': 0.02143486775457859, 'learning_rate': 0.0005677321341915707, 'epoch': 1.44}\n",
            "{'loss': 0.0216, 'grad_norm': 0.02211022935807705, 'learning_rate': 0.0005623430581202091, 'epoch': 1.45}\n",
            "{'loss': 0.0173, 'grad_norm': 0.02041442319750786, 'learning_rate': 0.0005569466150960852, 'epoch': 1.46}\n",
            "{'loss': 0.0271, 'grad_norm': 0.022609615698456764, 'learning_rate': 0.0005515434428059279, 'epoch': 1.47}\n",
            "{'loss': 0.0272, 'grad_norm': 0.045874085277318954, 'learning_rate': 0.000546134179731651, 'epoch': 1.48}\n",
            "{'loss': 0.0162, 'grad_norm': 0.024714861065149307, 'learning_rate': 0.0005407194650749033, 'epoch': 1.49}\n",
            "{'loss': 0.0231, 'grad_norm': 0.032211076468229294, 'learning_rate': 0.0005352999386815361, 'epoch': 1.5}\n",
            "{'loss': 0.0173, 'grad_norm': 0.022150639444589615, 'learning_rate': 0.000529876240965994, 'epoch': 1.51}\n",
            "{'loss': 0.0254, 'grad_norm': 0.04331808537244797, 'learning_rate': 0.000524449012835638, 'epoch': 1.52}\n",
            "{'loss': 0.0171, 'grad_norm': 0.032518912106752396, 'learning_rate': 0.0005190188956150115, 'epoch': 1.53}\n",
            "{'loss': 0.0221, 'grad_norm': 0.026206979528069496, 'learning_rate': 0.0005135865309700556, 'epoch': 1.54}\n",
            "{'loss': 0.014, 'grad_norm': 0.015094452537596226, 'learning_rate': 0.0005081525608322847, 'epoch': 1.55}\n",
            "{'loss': 0.0207, 'grad_norm': 0.04364120960235596, 'learning_rate': 0.0005027176273229317, 'epoch': 1.56}\n",
            "{'loss': 0.0169, 'grad_norm': 0.032674022018909454, 'learning_rate': 0.0004972823726770684, 'epoch': 1.57}\n",
            "{'loss': 0.0256, 'grad_norm': 0.03944098576903343, 'learning_rate': 0.0004918474391677154, 'epoch': 1.58}\n",
            "{'loss': 0.0282, 'grad_norm': 0.039260443300008774, 'learning_rate': 0.00048641346902994454, 'epoch': 1.59}\n",
            "{'loss': 0.0241, 'grad_norm': 0.023481111973524094, 'learning_rate': 0.0004809811043849887, 'epoch': 1.6}\n",
            "{'loss': 0.019, 'grad_norm': 0.020040515810251236, 'learning_rate': 0.00047555098716436207, 'epoch': 1.61}\n",
            "{'loss': 0.0227, 'grad_norm': 0.050159137696027756, 'learning_rate': 0.0004701237590340063, 'epoch': 1.62}\n",
            "{'loss': 0.0202, 'grad_norm': 0.021710839122533798, 'learning_rate': 0.00046470006131846405, 'epoch': 1.63}\n",
            "{'loss': 0.0161, 'grad_norm': 0.022171488031744957, 'learning_rate': 0.00045928053492509685, 'epoch': 1.64}\n",
            "{'loss': 0.0255, 'grad_norm': 0.023032749071717262, 'learning_rate': 0.00045386582026834903, 'epoch': 1.65}\n",
            "{'loss': 0.0201, 'grad_norm': 0.022507641464471817, 'learning_rate': 0.0004484565571940722, 'epoch': 1.66}\n",
            "{'loss': 0.0148, 'grad_norm': 0.016860734671354294, 'learning_rate': 0.000443053384903915, 'epoch': 1.67}\n",
            "{'loss': 0.02, 'grad_norm': 0.030269445851445198, 'learning_rate': 0.0004376569418797908, 'epoch': 1.68}\n",
            "{'loss': 0.0198, 'grad_norm': 0.01936907134950161, 'learning_rate': 0.0004322678658084294, 'epoch': 1.69}\n",
            "{'loss': 0.0221, 'grad_norm': 0.023135632276535034, 'learning_rate': 0.0004268867935060223, 'epoch': 1.7}\n",
            "{'loss': 0.0233, 'grad_norm': 0.01957106962800026, 'learning_rate': 0.00042151436084297215, 'epoch': 1.71}\n",
            "{'loss': 0.0204, 'grad_norm': 0.020127562806010246, 'learning_rate': 0.0004161512026687528, 'epoch': 1.72}\n",
            "{'loss': 0.0203, 'grad_norm': 0.02382688596844673, 'learning_rate': 0.0004107979527368908, 'epoch': 1.73}\n",
            "{'loss': 0.0162, 'grad_norm': 0.015773208811879158, 'learning_rate': 0.0004054552436300752, 'epoch': 1.74}\n",
            "{'loss': 0.0264, 'grad_norm': 0.026448966935276985, 'learning_rate': 0.0004001237066854081, 'epoch': 1.75}\n",
            "{'loss': 0.0146, 'grad_norm': 0.012423824518918991, 'learning_rate': 0.0003948039719197987, 'epoch': 1.76}\n",
            "{'loss': 0.0178, 'grad_norm': 0.016834432259202003, 'learning_rate': 0.0003894966679555177, 'epoch': 1.77}\n",
            "{'loss': 0.0132, 'grad_norm': 0.011647114530205727, 'learning_rate': 0.0003842024219459124, 'epoch': 1.78}\n",
            "{'loss': 0.0177, 'grad_norm': 0.021537188440561295, 'learning_rate': 0.0003789218595012986, 'epoch': 1.79}\n",
            "{'loss': 0.0237, 'grad_norm': 0.02366955205798149, 'learning_rate': 0.00037365560461503265, 'epoch': 1.8}\n",
            "{'loss': 0.0121, 'grad_norm': 0.013521997258067131, 'learning_rate': 0.00036840427958977605, 'epoch': 1.81}\n",
            "{'loss': 0.0255, 'grad_norm': 0.022975176572799683, 'learning_rate': 0.0003631685049639586, 'epoch': 1.82}\n",
            "{'loss': 0.0172, 'grad_norm': 0.012219604104757309, 'learning_rate': 0.00035794889943845115, 'epoch': 1.83}\n",
            "{'loss': 0.0186, 'grad_norm': 0.016027415171265602, 'learning_rate': 0.0003527460798034543, 'epoch': 1.84}\n",
            "{'loss': 0.0181, 'grad_norm': 0.01586356945335865, 'learning_rate': 0.000347560660865615, 'epoch': 1.85}\n",
            "{'loss': 0.0202, 'grad_norm': 0.019964171573519707, 'learning_rate': 0.00034239325537537387, 'epoch': 1.86}\n",
            "{'loss': 0.0251, 'grad_norm': 0.0216840673238039, 'learning_rate': 0.00033724447395455984, 'epoch': 1.87}\n",
            "{'loss': 0.0161, 'grad_norm': 0.012884292751550674, 'learning_rate': 0.00033211492502423283, 'epoch': 1.88}\n",
            "{'loss': 0.0214, 'grad_norm': 0.020567961037158966, 'learning_rate': 0.0003270052147327889, 'epoch': 1.89}\n",
            "{'loss': 0.0258, 'grad_norm': 0.0215437188744545, 'learning_rate': 0.00032191594688433156, 'epoch': 1.9}\n",
            "{'loss': 0.0172, 'grad_norm': 0.021574437618255615, 'learning_rate': 0.0003168477228673231, 'epoch': 1.91}\n",
            "{'loss': 0.0195, 'grad_norm': 0.017896093428134918, 'learning_rate': 0.00031180114158351857, 'epoch': 1.92}\n",
            "{'loss': 0.0193, 'grad_norm': 0.021487407386302948, 'learning_rate': 0.00030677679937719495, 'epoch': 1.93}\n",
            "{'loss': 0.0116, 'grad_norm': 0.011279857717454433, 'learning_rate': 0.00030177528996468286, 'epoch': 1.94}\n",
            "{'loss': 0.0192, 'grad_norm': 0.02456044778227806, 'learning_rate': 0.0002967972043642077, 'epoch': 1.95}\n",
            "{'loss': 0.02, 'grad_norm': 0.018613725900650024, 'learning_rate': 0.0002918431308260508, 'epoch': 1.96}\n",
            "{'loss': 0.0148, 'grad_norm': 0.013288090005517006, 'learning_rate': 0.0002869136547630364, 'epoch': 1.97}\n",
            "{'loss': 0.0215, 'grad_norm': 0.02416822873055935, 'learning_rate': 0.00028200935868135545, 'epoch': 1.98}\n",
            "{'loss': 0.0147, 'grad_norm': 0.016057653352618217, 'learning_rate': 0.0002771308221117309, 'epoch': 1.99}\n",
            "{'loss': 0.0183, 'grad_norm': 0.01664433628320694, 'learning_rate': 0.0002722786215409372, 'epoch': 2.0}\n",
            "{'loss': 0.0159, 'grad_norm': 0.014631290920078754, 'learning_rate': 0.00026745333034367626, 'epoch': 2.01}\n",
            "{'loss': 0.0124, 'grad_norm': 0.00988193042576313, 'learning_rate': 0.0002626555187148251, 'epoch': 2.02}\n",
            "{'loss': 0.0189, 'grad_norm': 0.01502386387437582, 'learning_rate': 0.0002578857536020547, 'epoch': 2.03}\n",
            "{'loss': 0.019, 'grad_norm': 0.01823081448674202, 'learning_rate': 0.0002531445986388369, 'epoch': 2.04}\n",
            "{'loss': 0.0132, 'grad_norm': 0.014653407037258148, 'learning_rate': 0.00024843261407783967, 'epoch': 2.05}\n",
            "{'loss': 0.0159, 'grad_norm': 0.014977929182350636, 'learning_rate': 0.00024375035672472394, 'epoch': 2.06}\n",
            "{'loss': 0.0175, 'grad_norm': 0.018702952191233635, 'learning_rate': 0.00023909837987234677, 'epoch': 2.07}\n",
            "{'loss': 0.022, 'grad_norm': 0.022475965321063995, 'learning_rate': 0.00023447723323538, 'epoch': 2.08}\n",
            "{'loss': 0.0179, 'grad_norm': 0.018397018313407898, 'learning_rate': 0.00022988746288535094, 'epoch': 2.09}\n",
            "{'loss': 0.0152, 'grad_norm': 0.019154051318764687, 'learning_rate': 0.00022532961118611528, 'epoch': 2.1}\n",
            "{'loss': 0.0148, 'grad_norm': 0.016233723610639572, 'learning_rate': 0.0002208042167297657, 'epoch': 2.11}\n",
            "{'loss': 0.0147, 'grad_norm': 0.016398046165704727, 'learning_rate': 0.00021631181427298946, 'epoch': 2.12}\n",
            "{'loss': 0.0166, 'grad_norm': 0.023398973047733307, 'learning_rate': 0.00021185293467387495, 'epoch': 2.13}\n",
            "{'loss': 0.0215, 'grad_norm': 0.01999037340283394, 'learning_rate': 0.00020742810482918313, 'epoch': 2.14}\n",
            "{'loss': 0.0141, 'grad_norm': 0.011887944303452969, 'learning_rate': 0.00020303784761208454, 'epoch': 2.15}\n",
            "{'loss': 0.018, 'grad_norm': 0.01507837139070034, 'learning_rate': 0.00019868268181037185, 'epoch': 2.16}\n",
            "{'loss': 0.0212, 'grad_norm': 0.02019266039133072, 'learning_rate': 0.00019436312206515694, 'epoch': 2.17}\n",
            "{'loss': 0.0167, 'grad_norm': 0.014382211491465569, 'learning_rate': 0.0001900796788100559, 'epoch': 2.18}\n",
            "{'loss': 0.0167, 'grad_norm': 0.0169685035943985, 'learning_rate': 0.0001858328582108727, 'epoch': 2.19}\n",
            "{'loss': 0.0215, 'grad_norm': 0.01981711946427822, 'learning_rate': 0.00018162316210578572, 'epoch': 2.2}\n",
            "{'loss': 0.0159, 'grad_norm': 0.016255468130111694, 'learning_rate': 0.00017745108794604776, 'epoch': 2.21}\n",
            "{'loss': 0.0178, 'grad_norm': 0.018840298056602478, 'learning_rate': 0.00017331712873720236, 'epoch': 2.22}\n",
            "{'loss': 0.0145, 'grad_norm': 0.015306239947676659, 'learning_rate': 0.0001692217729808268, 'epoch': 2.23}\n",
            "{'loss': 0.0164, 'grad_norm': 0.021242603659629822, 'learning_rate': 0.00016516550461680623, 'epoch': 2.24}\n",
            "{'loss': 0.0151, 'grad_norm': 0.012722770683467388, 'learning_rate': 0.00016114880296614842, 'epoch': 2.25}\n",
            "{'loss': 0.0168, 'grad_norm': 0.018547873944044113, 'learning_rate': 0.00015717214267434233, 'epoch': 2.26}\n",
            "{'loss': 0.0173, 'grad_norm': 0.01764865592122078, 'learning_rate': 0.0001532359936552712, 'epoch': 2.27}\n",
            "{'loss': 0.0164, 'grad_norm': 0.017811138182878494, 'learning_rate': 0.00014934082103568307, 'epoch': 2.28}\n",
            "{'loss': 0.0178, 'grad_norm': 0.019479362294077873, 'learning_rate': 0.00014548708510022824, 'epoch': 2.29}\n",
            "{'loss': 0.0163, 'grad_norm': 0.018362363800406456, 'learning_rate': 0.00014167524123706742, 'epoch': 2.3}\n",
            "{'loss': 0.0127, 'grad_norm': 0.015023229643702507, 'learning_rate': 0.00013790573988406075, 'epoch': 2.31}\n",
            "{'loss': 0.0122, 'grad_norm': 0.015436608344316483, 'learning_rate': 0.00013417902647553948, 'epoch': 2.32}\n",
            "{'loss': 0.0139, 'grad_norm': 0.012693505734205246, 'learning_rate': 0.0001304955413896705, 'epoch': 2.33}\n",
            "{'loss': 0.022, 'grad_norm': 0.024838745594024658, 'learning_rate': 0.00012685571989641696, 'epoch': 2.34}\n",
            "{'loss': 0.0155, 'grad_norm': 0.016313539817929268, 'learning_rate': 0.0001232599921061042, 'epoch': 2.35}\n",
            "{'loss': 0.0139, 'grad_norm': 0.017213353887200356, 'learning_rate': 0.00011970878291859421, 'epoch': 2.36}\n",
            "{'loss': 0.0163, 'grad_norm': 0.017029155045747757, 'learning_rate': 0.00011620251197307535, 'epoch': 2.37}\n",
            "{'loss': 0.0132, 'grad_norm': 0.018678024411201477, 'learning_rate': 0.00011274159359847591, 'epoch': 2.38}\n",
            "{'loss': 0.0171, 'grad_norm': 0.022792983800172806, 'learning_rate': 0.00010932643676450205, 'epoch': 2.39}\n",
            "{'loss': 0.0125, 'grad_norm': 0.013072574511170387, 'learning_rate': 0.00010595744503331206, 'epoch': 2.4}\n",
            "{'loss': 0.019, 'grad_norm': 0.01823445037007332, 'learning_rate': 0.00010263501651182704, 'epoch': 2.41}\n",
            "{'loss': 0.0136, 'grad_norm': 0.016266606748104095, 'learning_rate': 9.935954380468859e-05, 'epoch': 2.42}\n",
            "{'loss': 0.0131, 'grad_norm': 0.014034413732588291, 'learning_rate': 9.613141396786462e-05, 'epoch': 2.43}\n",
            "{'loss': 0.0131, 'grad_norm': 0.017379799857735634, 'learning_rate': 9.295100846291238e-05, 'epoch': 2.44}\n",
            "{'loss': 0.0159, 'grad_norm': 0.022124649956822395, 'learning_rate': 8.981870311190099e-05, 'epoch': 2.45}\n",
            "{'loss': 0.0177, 'grad_norm': 0.027786890044808388, 'learning_rate': 8.673486805300262e-05, 'epoch': 2.46}\n",
            "{'loss': 0.0159, 'grad_norm': 0.019576994702219963, 'learning_rate': 8.369986769675269e-05, 'epoch': 2.47}\n",
            "{'loss': 0.0186, 'grad_norm': 0.01928422413766384, 'learning_rate': 8.071406068298926e-05, 'epoch': 2.48}\n",
            "{'loss': 0.0149, 'grad_norm': 0.01453244686126709, 'learning_rate': 7.77777998384726e-05, 'epoch': 2.49}\n",
            "{'loss': 0.0159, 'grad_norm': 0.022466080263257027, 'learning_rate': 7.489143213519301e-05, 'epoch': 2.5}\n",
            "{'loss': 0.0143, 'grad_norm': 0.01605081744492054, 'learning_rate': 7.205529864936883e-05, 'epoch': 2.51}\n",
            "{'loss': 0.018, 'grad_norm': 0.01982211507856846, 'learning_rate': 6.926973452114338e-05, 'epoch': 2.52}\n",
            "{'loss': 0.0219, 'grad_norm': 0.0258510522544384, 'learning_rate': 6.653506891498118e-05, 'epoch': 2.53}\n",
            "{'loss': 0.0211, 'grad_norm': 0.02369019016623497, 'learning_rate': 6.385162498077191e-05, 'epoch': 2.54}\n",
            "{'loss': 0.0208, 'grad_norm': 0.03623172268271446, 'learning_rate': 6.121971981564367e-05, 'epoch': 2.55}\n",
            "{'loss': 0.0143, 'grad_norm': 0.014663285575807095, 'learning_rate': 5.863966442649327e-05, 'epoch': 2.56}\n",
            "{'loss': 0.0122, 'grad_norm': 0.013990877196192741, 'learning_rate': 5.611176369323412e-05, 'epoch': 2.57}\n",
            "{'loss': 0.0127, 'grad_norm': 0.01373976282775402, 'learning_rate': 5.363631633277005e-05, 'epoch': 2.58}\n",
            "{'loss': 0.0108, 'grad_norm': 0.009375793859362602, 'learning_rate': 5.1213614863696246e-05, 'epoch': 2.59}\n",
            "{'loss': 0.019, 'grad_norm': 0.02265114337205887, 'learning_rate': 4.884394557173249e-05, 'epoch': 2.6}\n",
            "{'loss': 0.0148, 'grad_norm': 0.015545833855867386, 'learning_rate': 4.6527588475894164e-05, 'epoch': 2.61}\n",
            "{'loss': 0.0165, 'grad_norm': 0.020534828305244446, 'learning_rate': 4.4264817295402046e-05, 'epoch': 2.62}\n",
            "{'loss': 0.0188, 'grad_norm': 0.02338384836912155, 'learning_rate': 4.205589941733834e-05, 'epoch': 2.63}\n",
            "{'loss': 0.0162, 'grad_norm': 0.01950131729245186, 'learning_rate': 3.990109586504964e-05, 'epoch': 2.64}\n",
            "{'loss': 0.0152, 'grad_norm': 0.017708795145154, 'learning_rate': 3.7800661267302414e-05, 'epoch': 2.65}\n",
            "{'loss': 0.0186, 'grad_norm': 0.020489517599344254, 'learning_rate': 3.575484382819372e-05, 'epoch': 2.66}\n",
            "{'loss': 0.0184, 'grad_norm': 0.02166702039539814, 'learning_rate': 3.376388529782215e-05, 'epoch': 2.67}\n",
            "{'loss': 0.0177, 'grad_norm': 0.01943741925060749, 'learning_rate': 3.182802094371989e-05, 'epoch': 2.68}\n",
            "{'loss': 0.0174, 'grad_norm': 0.019071782007813454, 'learning_rate': 2.9947479523052545e-05, 'epoch': 2.69}\n",
            "{'loss': 0.024, 'grad_norm': 0.028515560552477837, 'learning_rate': 2.812248325558625e-05, 'epoch': 2.7}\n",
            "{'loss': 0.0178, 'grad_norm': 0.02015354484319687, 'learning_rate': 2.6353247797429535e-05, 'epoch': 2.71}\n",
            "{'loss': 0.0173, 'grad_norm': 0.019288169220089912, 'learning_rate': 2.4639982215548752e-05, 'epoch': 2.72}\n",
            "{'loss': 0.0139, 'grad_norm': 0.014117201790213585, 'learning_rate': 2.2982888963063776e-05, 'epoch': 2.73}\n",
            "{'loss': 0.0168, 'grad_norm': 0.016740156337618828, 'learning_rate': 2.13821638553241e-05, 'epoch': 2.74}\n",
            "{'loss': 0.0131, 'grad_norm': 0.01438459288328886, 'learning_rate': 1.9837996046769833e-05, 'epoch': 2.75}\n",
            "{'loss': 0.0162, 'grad_norm': 0.015291471965610981, 'learning_rate': 1.8350568008579704e-05, 'epoch': 2.76}\n",
            "{'loss': 0.0169, 'grad_norm': 0.01841564103960991, 'learning_rate': 1.692005550710901e-05, 'epoch': 2.77}\n",
            "{'loss': 0.0158, 'grad_norm': 0.019765449687838554, 'learning_rate': 1.554662758311909e-05, 'epoch': 2.78}\n",
            "{'loss': 0.0123, 'grad_norm': 0.016209015622735023, 'learning_rate': 1.4230446531802998e-05, 'epoch': 2.79}\n",
            "{'loss': 0.012, 'grad_norm': 0.018827075138688087, 'learning_rate': 1.2971667883606652e-05, 'epoch': 2.8}\n",
            "{'loss': 0.0134, 'grad_norm': 0.013543309643864632, 'learning_rate': 1.17704403858504e-05, 'epoch': 2.81}\n",
            "{'loss': 0.0144, 'grad_norm': 0.016403092071413994, 'learning_rate': 1.062690598515187e-05, 'epoch': 2.82}\n",
            "{'loss': 0.0219, 'grad_norm': 0.022736141458153725, 'learning_rate': 9.541199810652379e-06, 'epoch': 2.83}\n",
            "{'loss': 0.02, 'grad_norm': 0.01961020566523075, 'learning_rate': 8.513450158049108e-06, 'epoch': 2.84}\n",
            "{'loss': 0.016, 'grad_norm': 0.01746472902595997, 'learning_rate': 7.543778474434437e-06, 'epoch': 2.85}\n",
            "{'loss': 0.0178, 'grad_norm': 0.02249824069440365, 'learning_rate': 6.632299343945103e-06, 'epoch': 2.86}\n",
            "{'loss': 0.0166, 'grad_norm': 0.015850834548473358, 'learning_rate': 5.779120474221522e-06, 'epoch': 2.87}\n",
            "{'loss': 0.0165, 'grad_norm': 0.01813691295683384, 'learning_rate': 4.984342683680809e-06, 'epoch': 2.88}\n",
            "{'loss': 0.0155, 'grad_norm': 0.016984006389975548, 'learning_rate': 4.248059889602862e-06, 'epoch': 2.89}\n",
            "{'loss': 0.0121, 'grad_norm': 0.016689324751496315, 'learning_rate': 3.5703590970325162e-06, 'epoch': 2.9}\n",
            "{'loss': 0.0169, 'grad_norm': 0.016151994466781616, 'learning_rate': 2.9513203884981577e-06, 'epoch': 2.91}\n",
            "{'loss': 0.0151, 'grad_norm': 0.01855357177555561, 'learning_rate': 2.3910169145487937e-06, 'epoch': 2.92}\n",
            "{'loss': 0.0147, 'grad_norm': 0.015424896962940693, 'learning_rate': 1.8895148851096888e-06, 'epoch': 2.93}\n",
            "{'loss': 0.0133, 'grad_norm': 0.014913331717252731, 'learning_rate': 1.4468735616587902e-06, 'epoch': 2.94}\n",
            "{'loss': 0.0175, 'grad_norm': 0.01833672635257244, 'learning_rate': 1.0631452502237737e-06, 'epoch': 2.95}\n",
            "{'loss': 0.0117, 'grad_norm': 0.012460392899811268, 'learning_rate': 7.383752952010991e-07, 'epoch': 2.96}\n",
            "{'loss': 0.0125, 'grad_norm': 0.017513860017061234, 'learning_rate': 4.72602073997741e-07, 'epoch': 2.97}\n",
            "{'loss': 0.0189, 'grad_norm': 0.019104428589344025, 'learning_rate': 2.6585699249642713e-07, 'epoch': 2.98}\n",
            "{'loss': 0.0164, 'grad_norm': 0.0218438059091568, 'learning_rate': 1.181644813441074e-07, 'epoch': 2.99}\n",
            "{'loss': 0.0113, 'grad_norm': 0.013399888761341572, 'learning_rate': 2.954199306537397e-08, 'epoch': 3.0}\n",
            "{'train_runtime': 37.6457, 'train_samples_per_second': 15.938, 'train_steps_per_second': 7.969, 'train_loss': 0.1125196691788733, 'epoch': 3.0}\n",
            "100% 300/300 [00:37<00:00,  7.97it/s]\n",
            "Training complete.\n",
            "Model saved to loras/self-edit/training_set_iteration_1/8d5021e8/12\n",
            "Training on 250 examples for 3 epochs, lr: 1.0\n",
            "No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n",
            "Starting training...\n",
            "{'loss': 4.5655, 'grad_norm': 5.244950771331787, 'learning_rate': 0.0, 'epoch': 0.01}\n",
            "{'loss': 5.9031, 'grad_norm': 7.480905055999756, 'learning_rate': 0.09090909090909091, 'epoch': 0.02}\n",
            "{'loss': 6.9114, 'grad_norm': 71.62918090820312, 'learning_rate': 0.18181818181818182, 'epoch': 0.02}\n",
            "{'loss': 12.3126, 'grad_norm': 183.8063507080078, 'learning_rate': 0.2727272727272727, 'epoch': 0.03}\n",
            "{'loss': 13.4612, 'grad_norm': 8.557480812072754, 'learning_rate': 0.36363636363636365, 'epoch': 0.04}\n",
            "{'loss': 8.6576, 'grad_norm': 0.6910697221755981, 'learning_rate': 0.45454545454545453, 'epoch': 0.05}\n",
            "{'loss': 18.8168, 'grad_norm': 40.88840103149414, 'learning_rate': 0.5454545454545454, 'epoch': 0.06}\n",
            "{'loss': 18.7066, 'grad_norm': 4.6584153175354, 'learning_rate': 0.6363636363636364, 'epoch': 0.06}\n",
            "{'loss': 23.3533, 'grad_norm': 0.3653225898742676, 'learning_rate': 0.7272727272727273, 'epoch': 0.07}\n",
            "{'loss': 4.3549, 'grad_norm': 0.5139626264572144, 'learning_rate': 0.8181818181818182, 'epoch': 0.08}\n",
            "{'loss': 2.5922, 'grad_norm': 0.020792735740542412, 'learning_rate': 0.9090909090909091, 'epoch': 0.09}\n",
            "{'loss': 6.2161, 'grad_norm': 0.043339803814888, 'learning_rate': 1.0, 'epoch': 0.1}\n",
            "{'loss': 4.9522, 'grad_norm': 0.07034703344106674, 'learning_rate': 0.9999813776583146, 'epoch': 0.1}\n",
            "{'loss': 4.3381, 'grad_norm': 0.02427557110786438, 'learning_rate': 0.9999255120204247, 'epoch': 0.11}\n",
            "{'loss': 5.0149, 'grad_norm': 0.03634945675730705, 'learning_rate': 0.9998324072477265, 'epoch': 0.12}\n",
            "{'loss': 5.4461, 'grad_norm': 0.04333369433879852, 'learning_rate': 0.9997020702755353, 'epoch': 0.13}\n",
            "{'loss': 3.1265, 'grad_norm': 0.015366388484835625, 'learning_rate': 0.9995345108125697, 'epoch': 0.14}\n",
            "{'loss': 3.4328, 'grad_norm': 0.026521654799580574, 'learning_rate': 0.999329741340228, 'epoch': 0.14}\n",
            "{'loss': 3.8076, 'grad_norm': 0.035465680062770844, 'learning_rate': 0.9990877771116587, 'epoch': 0.15}\n",
            "{'loss': 3.3818, 'grad_norm': 0.03340880572795868, 'learning_rate': 0.9988086361506239, 'epoch': 0.16}\n",
            "{'loss': 2.9042, 'grad_norm': 0.04807488992810249, 'learning_rate': 0.9984923392501567, 'epoch': 0.17}\n",
            "{'loss': 2.0804, 'grad_norm': 0.00901359785348177, 'learning_rate': 0.9981389099710132, 'epoch': 0.18}\n",
            "{'loss': 4.3168, 'grad_norm': 0.03387903794646263, 'learning_rate': 0.9977483746399166, 'epoch': 0.18}\n",
            "{'loss': 3.108, 'grad_norm': 0.021202275529503822, 'learning_rate': 0.9973207623475964, 'epoch': 0.19}\n",
            "{'loss': 2.8436, 'grad_norm': 0.019924070686101913, 'learning_rate': 0.9968561049466214, 'epoch': 0.2}\n",
            "{'loss': 2.9034, 'grad_norm': 0.020545288920402527, 'learning_rate': 0.9963544370490269, 'epoch': 0.21}\n",
            "{'loss': 3.5991, 'grad_norm': 0.054905783385038376, 'learning_rate': 0.9958157960237375, 'epoch': 0.22}\n",
            "{'loss': 3.1007, 'grad_norm': 0.029858389869332314, 'learning_rate': 0.9952402219937816, 'epoch': 0.22}\n",
            "{'loss': 5.0006, 'grad_norm': 0.2515377998352051, 'learning_rate': 0.9946277578333044, 'epoch': 0.23}\n",
            "{'loss': 12.7323, 'grad_norm': 0.40757542848587036, 'learning_rate': 0.9939784491643733, 'epoch': 0.24}\n",
            "{'loss': 6.8211, 'grad_norm': 0.05157967656850815, 'learning_rate': 0.9932923443535797, 'epoch': 0.25}\n",
            "{'loss': 5.159, 'grad_norm': 0.042407579720020294, 'learning_rate': 0.9925694945084369, 'epoch': 0.26}\n",
            "{'loss': 11.024, 'grad_norm': 0.1357150673866272, 'learning_rate': 0.9918099534735718, 'epoch': 0.26}\n",
            "{'loss': 4.8188, 'grad_norm': 0.06539619714021683, 'learning_rate': 0.9910137778267152, 'epoch': 0.27}\n",
            "{'loss': 8.9505, 'grad_norm': 0.29947787523269653, 'learning_rate': 0.9901810268744867, 'epoch': 0.28}\n",
            "{'loss': 5.6017, 'grad_norm': 0.035421889275312424, 'learning_rate': 0.9893117626479776, 'epoch': 0.29}\n",
            "{'loss': 2.9951, 'grad_norm': 0.03821943327784538, 'learning_rate': 0.9884060498981295, 'epoch': 0.3}\n",
            "{'loss': 3.466, 'grad_norm': 0.14624515175819397, 'learning_rate': 0.9874639560909118, 'epoch': 0.3}\n",
            "{'loss': 3.8529, 'grad_norm': 0.049068596214056015, 'learning_rate': 0.9864855514022954, 'epoch': 0.31}\n",
            "{'loss': 3.9665, 'grad_norm': 0.05428317189216614, 'learning_rate': 0.985470908713026, 'epoch': 0.32}\n",
            "{'loss': 2.8175, 'grad_norm': 0.12414722144603729, 'learning_rate': 0.9844201036031951, 'epoch': 0.33}\n",
            "{'loss': 1.4618, 'grad_norm': 0.006080920808017254, 'learning_rate': 0.9833332143466098, 'epoch': 0.34}\n",
            "{'loss': 3.4394, 'grad_norm': 0.06225168704986572, 'learning_rate': 0.9822103219049625, 'epoch': 0.34}\n",
            "{'loss': 3.0775, 'grad_norm': 0.07756318151950836, 'learning_rate': 0.9810515099218002, 'epoch': 0.35}\n",
            "{'loss': 2.3768, 'grad_norm': 0.05062198266386986, 'learning_rate': 0.9798568647162937, 'epoch': 0.36}\n",
            "{'loss': 1.9874, 'grad_norm': 0.03158292919397354, 'learning_rate': 0.9786264752768079, 'epoch': 0.37}\n",
            "{'loss': 2.5432, 'grad_norm': 0.017167171463370323, 'learning_rate': 0.9773604332542728, 'epoch': 0.38}\n",
            "{'loss': 2.3588, 'grad_norm': 0.029339078813791275, 'learning_rate': 0.976058832955357, 'epoch': 0.38}\n",
            "{'loss': 2.602, 'grad_norm': 0.05111341178417206, 'learning_rate': 0.9747217713354427, 'epoch': 0.39}\n",
            "{'loss': 2.0187, 'grad_norm': 0.04946513473987579, 'learning_rate': 0.973349347991403, 'epoch': 0.4}\n",
            "{'loss': 2.823, 'grad_norm': 0.05451937019824982, 'learning_rate': 0.9719416651541838, 'epoch': 0.41}\n",
            "{'loss': 3.0544, 'grad_norm': 0.06045696511864662, 'learning_rate': 0.9704988276811882, 'epoch': 0.42}\n",
            "{'loss': 1.6496, 'grad_norm': 0.06220627203583717, 'learning_rate': 0.969020943048466, 'epoch': 0.42}\n",
            "{'loss': 1.9783, 'grad_norm': 0.022984344512224197, 'learning_rate': 0.9675081213427075, 'epoch': 0.43}\n",
            "{'loss': 1.8621, 'grad_norm': 0.027089249342679977, 'learning_rate': 0.9659604752530434, 'epoch': 0.44}\n",
            "{'loss': 2.4869, 'grad_norm': 0.023568402975797653, 'learning_rate': 0.9643781200626511, 'epoch': 0.45}\n",
            "{'loss': 1.6011, 'grad_norm': 0.006440544500946999, 'learning_rate': 0.9627611736401667, 'epoch': 0.46}\n",
            "{'loss': 1.7516, 'grad_norm': 0.015083511359989643, 'learning_rate': 0.9611097564309052, 'epoch': 0.46}\n",
            "{'loss': 2.2881, 'grad_norm': 0.03968286141753197, 'learning_rate': 0.9594239914478886, 'epoch': 0.47}\n",
            "{'loss': 1.7574, 'grad_norm': 0.05059643089771271, 'learning_rate': 0.9577040042626832, 'epoch': 0.48}\n",
            "{'loss': 2.0958, 'grad_norm': 0.012668571434915066, 'learning_rate': 0.9559499229960451, 'epoch': 0.49}\n",
            "{'loss': 2.1142, 'grad_norm': 58.239654541015625, 'learning_rate': 0.954161878308377, 'epoch': 0.5}\n",
            "{'loss': 1.9142, 'grad_norm': 0.011184945702552795, 'learning_rate': 0.9523400033899956, 'epoch': 0.5}\n",
            "{'loss': 2.0766, 'grad_norm': 0.05270369350910187, 'learning_rate': 0.9504844339512095, 'epoch': 0.51}\n",
            "{'loss': 2.5655, 'grad_norm': 0.01897340454161167, 'learning_rate': 0.9485953082122116, 'epoch': 0.52}\n",
            "{'loss': 1.5224, 'grad_norm': 0.03434785082936287, 'learning_rate': 0.9466727668927816, 'epoch': 0.53}\n",
            "{'loss': 2.5057, 'grad_norm': 0.028369281440973282, 'learning_rate': 0.9447169532018049, 'epoch': 0.54}\n",
            "{'loss': 1.4648, 'grad_norm': 0.05102189630270004, 'learning_rate': 0.9427280128266049, 'epoch': 0.54}\n",
            "{'loss': 1.7842, 'grad_norm': 0.20364806056022644, 'learning_rate': 0.9407060939220907, 'epoch': 0.55}\n",
            "{'loss': 1.7068, 'grad_norm': 0.005975367501378059, 'learning_rate': 0.938651347099721, 'epoch': 0.56}\n",
            "{'loss': 1.2969, 'grad_norm': 0.008446061052381992, 'learning_rate': 0.9365639254162854, 'epoch': 0.57}\n",
            "{'loss': 1.9769, 'grad_norm': 0.013683305121958256, 'learning_rate': 0.9344439843625033, 'epoch': 0.58}\n",
            "{'loss': 1.6075, 'grad_norm': 0.03396975249052048, 'learning_rate': 0.9322916818514413, 'epoch': 0.58}\n",
            "{'loss': 2.4759, 'grad_norm': 0.025112919509410858, 'learning_rate': 0.9301071782067504, 'epoch': 0.59}\n",
            "{'loss': 2.6678, 'grad_norm': 0.03530266135931015, 'learning_rate': 0.9278906361507238, 'epoch': 0.6}\n",
            "{'loss': 1.8265, 'grad_norm': 0.032021135091781616, 'learning_rate': 0.9256422207921756, 'epoch': 0.61}\n",
            "{'loss': 2.4278, 'grad_norm': 0.013447578996419907, 'learning_rate': 0.9233620996141421, 'epoch': 0.62}\n",
            "{'loss': 2.4594, 'grad_norm': 0.041497718542814255, 'learning_rate': 0.9210504424614059, 'epoch': 0.62}\n",
            "{'loss': 2.4251, 'grad_norm': 0.123726487159729, 'learning_rate': 0.9187074215278443, 'epoch': 0.63}\n",
            "{'loss': 9.1951, 'grad_norm': 0.06435724347829819, 'learning_rate': 0.9163332113436031, 'epoch': 0.64}\n",
            "{'loss': 7.0151, 'grad_norm': 0.024448776617646217, 'learning_rate': 0.9139279887620955, 'epoch': 0.65}\n",
            "{'loss': 6.9895, 'grad_norm': 0.06269414722919464, 'learning_rate': 0.9114919329468282, 'epoch': 0.66}\n",
            "{'loss': 8.5178, 'grad_norm': 15.013642311096191, 'learning_rate': 0.9090252253580564, 'epoch': 0.66}\n",
            "{'loss': 5.5783, 'grad_norm': 0.033939965069293976, 'learning_rate': 0.9065280497392663, 'epoch': 0.67}\n",
            "{'loss': 5.4914, 'grad_norm': 0.020139452069997787, 'learning_rate': 0.9040005921034883, 'epoch': 0.68}\n",
            "{'loss': 5.596, 'grad_norm': 0.022522857412695885, 'learning_rate': 0.9014430407194413, 'epoch': 0.69}\n",
            "{'loss': 2.6647, 'grad_norm': 3.426035165786743, 'learning_rate': 0.8988555860975082, 'epoch': 0.7}\n",
            "{'loss': 5.4333, 'grad_norm': 0.027312273159623146, 'learning_rate': 0.8962384209755452, 'epoch': 0.7}\n",
            "{'loss': 6.5623, 'grad_norm': 0.10080116242170334, 'learning_rate': 0.893591740304525, 'epoch': 0.71}\n",
            "{'loss': 7.7909, 'grad_norm': 1.713844895362854, 'learning_rate': 0.890915741234015, 'epoch': 0.72}\n",
            "{'loss': 3.9413, 'grad_norm': 0.0513538233935833, 'learning_rate': 0.8882106230974909, 'epoch': 0.73}\n",
            "{'loss': 4.2198, 'grad_norm': 0.5466984510421753, 'learning_rate': 0.8854765873974898, 'epoch': 0.74}\n",
            "{'loss': 3.3689, 'grad_norm': 0.042543571442365646, 'learning_rate': 0.8827138377905999, 'epoch': 0.74}\n",
            "{'loss': 3.478, 'grad_norm': 0.09734660387039185, 'learning_rate': 0.8799225800722894, 'epoch': 0.75}\n",
            "{'loss': 3.9087, 'grad_norm': 0.08465630561113358, 'learning_rate': 0.8771030221615785, 'epoch': 0.76}\n",
            "{'loss': 2.1916, 'grad_norm': 0.07034764438867569, 'learning_rate': 0.8742553740855505, 'epoch': 0.77}\n",
            "{'loss': 2.745, 'grad_norm': 0.017290014773607254, 'learning_rate': 0.8713798479637072, 'epoch': 0.78}\n",
            "{'loss': 3.4168, 'grad_norm': 0.06439939886331558, 'learning_rate': 0.8684766579921683, 'epoch': 0.78}\n",
            "{'loss': 3.3541, 'grad_norm': 0.6262925863265991, 'learning_rate': 0.8655460204277166, 'epoch': 0.79}\n",
            "{'loss': 3.0676, 'grad_norm': 0.020006099715828896, 'learning_rate': 0.8625881535716883, 'epoch': 0.8}\n",
            "{'loss': 2.7851, 'grad_norm': 0.023247044533491135, 'learning_rate': 0.8596032777537123, 'epoch': 0.81}\n",
            "{'loss': 2.7179, 'grad_norm': 0.06308601051568985, 'learning_rate': 0.8565916153152981, 'epoch': 0.82}\n",
            "{'loss': 2.3927, 'grad_norm': 0.4632495045661926, 'learning_rate': 0.8535533905932737, 'epoch': 0.82}\n",
            "{'loss': 2.7915, 'grad_norm': 0.032541003078222275, 'learning_rate': 0.8504888299030747, 'epoch': 0.83}\n",
            "{'loss': 3.5691, 'grad_norm': 0.18855039775371552, 'learning_rate': 0.8473981615218862, 'epoch': 0.84}\n",
            "{'loss': 4.5427, 'grad_norm': 0.049303364008665085, 'learning_rate': 0.8442816156716385, 'epoch': 0.85}\n",
            "{'loss': 3.6548, 'grad_norm': 0.09293490648269653, 'learning_rate': 0.8411394245018587, 'epoch': 0.86}\n",
            "{'loss': 2.5674, 'grad_norm': 0.04175829142332077, 'learning_rate': 0.8379718220723772, 'epoch': 0.86}\n",
            "{'loss': 2.4828, 'grad_norm': 0.056101392954587936, 'learning_rate': 0.8347790443358929, 'epoch': 0.87}\n",
            "{'loss': 2.8611, 'grad_norm': 0.3255392909049988, 'learning_rate': 0.8315613291203976, 'epoch': 0.88}\n",
            "{'loss': 2.9885, 'grad_norm': 0.021079199388623238, 'learning_rate': 0.8283189161114601, 'epoch': 0.89}\n",
            "{'loss': 2.3462, 'grad_norm': 0.032299041748046875, 'learning_rate': 0.825052046834372, 'epoch': 0.9}\n",
            "{'loss': 2.8499, 'grad_norm': 0.01728871837258339, 'learning_rate': 0.8217609646361573, 'epoch': 0.9}\n",
            "{'loss': 3.0489, 'grad_norm': 0.05866095423698425, 'learning_rate': 0.8184459146674447, 'epoch': 0.91}\n",
            "{'loss': 2.6481, 'grad_norm': 0.010876726359128952, 'learning_rate': 0.8151071438642068, 'epoch': 0.92}\n",
            "{'loss': 5.2733, 'grad_norm': 0.04951205849647522, 'learning_rate': 0.8117449009293668, 'epoch': 0.93}\n",
            "{'loss': 3.4878, 'grad_norm': 0.029988132417201996, 'learning_rate': 0.8083594363142717, 'epoch': 0.94}\n",
            "{'loss': 2.5303, 'grad_norm': 0.03802222013473511, 'learning_rate': 0.8049510022000363, 'epoch': 0.94}\n",
            "{'loss': 2.8465, 'grad_norm': 0.028030425310134888, 'learning_rate': 0.8015198524787601, 'epoch': 0.95}\n",
            "{'loss': 2.227, 'grad_norm': 0.014704546891152859, 'learning_rate': 0.7980662427346127, 'epoch': 0.96}\n",
            "{'loss': 3.0979, 'grad_norm': 0.05106660723686218, 'learning_rate': 0.7945904302247968, 'epoch': 0.97}\n",
            "{'loss': 3.2936, 'grad_norm': 0.011816735379397869, 'learning_rate': 0.7910926738603854, 'epoch': 0.98}\n",
            "{'loss': 2.6891, 'grad_norm': 0.03784966096282005, 'learning_rate': 0.7875732341870348, 'epoch': 0.98}\n",
            "{'loss': 2.7623, 'grad_norm': 0.014349759556353092, 'learning_rate': 0.7840323733655779, 'epoch': 0.99}\n",
            "{'loss': 2.4245, 'grad_norm': 0.016220709308981895, 'learning_rate': 0.7804703551524947, 'epoch': 1.0}\n",
            "{'loss': 2.6251, 'grad_norm': 0.18642234802246094, 'learning_rate': 0.7768874448802665, 'epoch': 1.01}\n",
            "{'loss': 2.1283, 'grad_norm': 0.018508626148104668, 'learning_rate': 0.7732839094376105, 'epoch': 1.02}\n",
            "{'loss': 2.4199, 'grad_norm': 0.013602130115032196, 'learning_rate': 0.7696600172495996, 'epoch': 1.02}\n",
            "{'loss': 1.9033, 'grad_norm': 0.006009331904351711, 'learning_rate': 0.7660160382576683, 'epoch': 1.03}\n",
            "{'loss': 2.1252, 'grad_norm': 0.04676323011517525, 'learning_rate': 0.762352243899504, 'epoch': 1.04}\n",
            "{'loss': 2.5329, 'grad_norm': 0.031004760414361954, 'learning_rate': 0.7586689070888284, 'epoch': 1.05}\n",
            "{'loss': 2.3184, 'grad_norm': 0.017656583338975906, 'learning_rate': 0.754966302195068, 'epoch': 1.06}\n",
            "{'loss': 1.9903, 'grad_norm': 0.01868915744125843, 'learning_rate': 0.7512447050229165, 'epoch': 1.06}\n",
            "{'loss': 2.1959, 'grad_norm': 0.10690921545028687, 'learning_rate': 0.7475043927917907, 'epoch': 1.07}\n",
            "{'loss': 2.0885, 'grad_norm': 0.1711452752351761, 'learning_rate': 0.74374564411518, 'epoch': 1.08}\n",
            "{'loss': 2.262, 'grad_norm': 0.031783752143383026, 'learning_rate': 0.7399687389798932, 'epoch': 1.09}\n",
            "{'loss': 1.5862, 'grad_norm': 0.36900755763053894, 'learning_rate': 0.7361739587252019, 'epoch': 1.1}\n",
            "{'loss': 2.0498, 'grad_norm': 0.08388639241456985, 'learning_rate': 0.7323615860218843, 'epoch': 1.1}\n",
            "{'loss': 2.0365, 'grad_norm': 0.0123878950253129, 'learning_rate': 0.7285319048511689, 'epoch': 1.11}\n",
            "{'loss': 2.1027, 'grad_norm': 0.009035435505211353, 'learning_rate': 0.7246852004835806, 'epoch': 1.12}\n",
            "{'loss': 2.2845, 'grad_norm': 0.019371289759874344, 'learning_rate': 0.7208217594576922, 'epoch': 1.13}\n",
            "{'loss': 1.7192, 'grad_norm': 0.10111146420240402, 'learning_rate': 0.716941869558779, 'epoch': 1.14}\n",
            "{'loss': 1.3822, 'grad_norm': 0.27039453387260437, 'learning_rate': 0.7130458197973828, 'epoch': 1.14}\n",
            "{'loss': 1.4276, 'grad_norm': 0.06081031635403633, 'learning_rate': 0.7091339003877826, 'epoch': 1.15}\n",
            "{'loss': 1.6521, 'grad_norm': 0.17322468757629395, 'learning_rate': 0.7052064027263785, 'epoch': 1.16}\n",
            "{'loss': 1.7124, 'grad_norm': 0.11172497272491455, 'learning_rate': 0.7012636193699837, 'epoch': 1.17}\n",
            "{'loss': 2.0666, 'grad_norm': 0.00615835003554821, 'learning_rate': 0.6973058440140341, 'epoch': 1.18}\n",
            "{'loss': 2.6646, 'grad_norm': 0.010191015899181366, 'learning_rate': 0.6933333714707094, 'epoch': 1.18}\n",
            "{'loss': 1.4793, 'grad_norm': 0.013092915527522564, 'learning_rate': 0.6893464976469739, 'epoch': 1.19}\n",
            "{'loss': 1.527, 'grad_norm': 0.0053326948545873165, 'learning_rate': 0.6853455195225339, 'epoch': 1.2}\n",
            "{'loss': 1.9182, 'grad_norm': 0.006028430536389351, 'learning_rate': 0.681330735127716, 'epoch': 1.21}\n",
            "{'loss': 1.7065, 'grad_norm': 0.0069831544533371925, 'learning_rate': 0.6773024435212678, 'epoch': 1.22}\n",
            "{'loss': 2.1226, 'grad_norm': 0.014877025038003922, 'learning_rate': 0.67326094476808, 'epoch': 1.22}\n",
            "{'loss': 2.1699, 'grad_norm': 0.009630787186324596, 'learning_rate': 0.6692065399168352, 'epoch': 1.23}\n",
            "{'loss': 1.611, 'grad_norm': 0.1795792430639267, 'learning_rate': 0.6651395309775836, 'epoch': 1.24}\n",
            "{'loss': 1.7222, 'grad_norm': 0.005433731712400913, 'learning_rate': 0.6610602208992453, 'epoch': 1.25}\n",
            "{'loss': 1.3141, 'grad_norm': 0.0058196550235152245, 'learning_rate': 0.656968913547045, 'epoch': 1.26}\n",
            "{'loss': 1.2464, 'grad_norm': 0.007307492196559906, 'learning_rate': 0.6528659136798765, 'epoch': 1.26}\n",
            "{'loss': 1.8942, 'grad_norm': 0.005097758024930954, 'learning_rate': 0.6487515269276015, 'epoch': 1.27}\n",
            "{'loss': 1.6034, 'grad_norm': 0.25035691261291504, 'learning_rate': 0.6446260597682839, 'epoch': 1.28}\n",
            "{'loss': 1.5683, 'grad_norm': 0.004313270561397076, 'learning_rate': 0.6404898195053597, 'epoch': 1.29}\n",
            "{'loss': 1.2582, 'grad_norm': 0.02409134805202484, 'learning_rate': 0.6363431142447469, 'epoch': 1.3}\n",
            "{'loss': 2.1154, 'grad_norm': 0.11285598576068878, 'learning_rate': 0.6321862528718944, 'epoch': 1.3}\n",
            "{'loss': 1.5412, 'grad_norm': 0.009539910592138767, 'learning_rate': 0.6280195450287736, 'epoch': 1.31}\n",
            "{'loss': 1.8585, 'grad_norm': 0.0032770910765975714, 'learning_rate': 0.623843301090813, 'epoch': 1.32}\n",
            "{'loss': 1.3935, 'grad_norm': 0.18761208653450012, 'learning_rate': 0.6196578321437789, 'epoch': 1.33}\n",
            "{'loss': 1.1545, 'grad_norm': 0.010364183224737644, 'learning_rate': 0.6154634499606029, 'epoch': 1.34}\n",
            "{'loss': 1.6449, 'grad_norm': 0.03626209869980812, 'learning_rate': 0.6112604669781572, 'epoch': 1.34}\n",
            "{'loss': 1.4768, 'grad_norm': 0.01371876709163189, 'learning_rate': 0.607049196273983, 'epoch': 1.35}\n",
            "{'loss': 1.3221, 'grad_norm': 0.05959295108914375, 'learning_rate': 0.6028299515429683, 'epoch': 1.36}\n",
            "{'loss': 1.4251, 'grad_norm': 0.007600206881761551, 'learning_rate': 0.598603047073981, 'epoch': 1.37}\n",
            "{'loss': 1.6101, 'grad_norm': 0.03221412003040314, 'learning_rate': 0.5943687977264583, 'epoch': 1.38}\n",
            "{'loss': 1.2567, 'grad_norm': 0.060208648443222046, 'learning_rate': 0.5901275189069529, 'epoch': 1.38}\n",
            "{'loss': 2.1228, 'grad_norm': 0.007866661064326763, 'learning_rate': 0.5858795265456381, 'epoch': 1.39}\n",
            "{'loss': 1.464, 'grad_norm': 0.5194249153137207, 'learning_rate': 0.5816251370727747, 'epoch': 1.4}\n",
            "{'loss': 1.2772, 'grad_norm': 0.004218601156026125, 'learning_rate': 0.5773646673951406, 'epoch': 1.41}\n",
            "{'loss': 1.5231, 'grad_norm': 0.005062946118414402, 'learning_rate': 0.5730984348724242, 'epoch': 1.42}\n",
            "{'loss': 1.5604, 'grad_norm': 0.23227843642234802, 'learning_rate': 0.5688267572935842, 'epoch': 1.42}\n",
            "{'loss': 1.8203, 'grad_norm': 0.0193268321454525, 'learning_rate': 0.5645499528531784, 'epoch': 1.43}\n",
            "{'loss': 1.1933, 'grad_norm': 0.008351948112249374, 'learning_rate': 0.5602683401276615, 'epoch': 1.44}\n",
            "{'loss': 1.4578, 'grad_norm': 0.007195191457867622, 'learning_rate': 0.5559822380516539, 'epoch': 1.45}\n",
            "{'loss': 1.2528, 'grad_norm': 0.023586327210068703, 'learning_rate': 0.551691965894185, 'epoch': 1.46}\n",
            "{'loss': 1.389, 'grad_norm': 0.07171004265546799, 'learning_rate': 0.5473978432349111, 'epoch': 1.46}\n",
            "{'loss': 1.8387, 'grad_norm': 0.045215047895908356, 'learning_rate': 0.5431001899403097, 'epoch': 1.47}\n",
            "{'loss': 1.356, 'grad_norm': 0.005491698160767555, 'learning_rate': 0.5387993261398532, 'epoch': 1.48}\n",
            "{'loss': 2.0505, 'grad_norm': 0.007214027922600508, 'learning_rate': 0.5344955722021624, 'epoch': 1.49}\n",
            "{'loss': 1.0511, 'grad_norm': 0.003978552296757698, 'learning_rate': 0.530189248711143, 'epoch': 1.5}\n",
            "{'loss': 2.1072, 'grad_norm': 0.009231136180460453, 'learning_rate': 0.5258806764421048, 'epoch': 1.5}\n",
            "{'loss': 1.377, 'grad_norm': 0.14946460723876953, 'learning_rate': 0.5215701763378673, 'epoch': 1.51}\n",
            "{'loss': 1.6052, 'grad_norm': 0.004366231616586447, 'learning_rate': 0.5172580694848541, 'epoch': 1.52}\n",
            "{'loss': 1.5358, 'grad_norm': 0.008443103171885014, 'learning_rate': 0.5129446770891738, 'epoch': 1.53}\n",
            "{'loss': 1.4268, 'grad_norm': 0.006651968229562044, 'learning_rate': 0.5086303204526943, 'epoch': 1.54}\n",
            "{'loss': 1.9036, 'grad_norm': 0.018084708601236343, 'learning_rate': 0.5043153209491095, 'epoch': 1.54}\n",
            "{'loss': 1.6186, 'grad_norm': 0.0025064453948289156, 'learning_rate': 0.5, 'epoch': 1.55}\n",
            "{'loss': 2.0639, 'grad_norm': 0.03877818584442139, 'learning_rate': 0.4956846790508906, 'epoch': 1.56}\n",
            "{'loss': 1.295, 'grad_norm': 0.010031702928245068, 'learning_rate': 0.49136967954730576, 'epoch': 1.57}\n",
            "{'loss': 1.7435, 'grad_norm': 0.016835276037454605, 'learning_rate': 0.48705532291082637, 'epoch': 1.58}\n",
            "{'loss': 1.149, 'grad_norm': 0.002802605042234063, 'learning_rate': 0.4827419305151461, 'epoch': 1.58}\n",
            "{'loss': 1.4707, 'grad_norm': 0.16402794420719147, 'learning_rate': 0.4784298236621327, 'epoch': 1.59}\n",
            "{'loss': 1.7241, 'grad_norm': 0.06987429410219193, 'learning_rate': 0.4741193235578952, 'epoch': 1.6}\n",
            "{'loss': 1.6124, 'grad_norm': 0.0036081129219383, 'learning_rate': 0.4698107512888569, 'epoch': 1.61}\n",
            "{'loss': 1.2158, 'grad_norm': 0.0029271466191858053, 'learning_rate': 0.4655044277978375, 'epoch': 1.62}\n",
            "{'loss': 1.5321, 'grad_norm': 0.03718329593539238, 'learning_rate': 0.4612006738601469, 'epoch': 1.62}\n",
            "{'loss': 1.345, 'grad_norm': 0.00907558761537075, 'learning_rate': 0.45689981005969027, 'epoch': 1.63}\n",
            "{'loss': 1.7732, 'grad_norm': 0.08810757100582123, 'learning_rate': 0.4526021567650889, 'epoch': 1.64}\n",
            "{'loss': 1.4952, 'grad_norm': 0.029860474169254303, 'learning_rate': 0.448308034105815, 'epoch': 1.65}\n",
            "{'loss': 1.7312, 'grad_norm': 0.3044670820236206, 'learning_rate': 0.4440177619483461, 'epoch': 1.66}\n",
            "{'loss': 1.2167, 'grad_norm': 0.006246536038815975, 'learning_rate': 0.43973165987233853, 'epoch': 1.66}\n",
            "{'loss': 1.5835, 'grad_norm': 0.11264427751302719, 'learning_rate': 0.4354500471468217, 'epoch': 1.67}\n",
            "{'loss': 1.3417, 'grad_norm': 0.008965430781245232, 'learning_rate': 0.431173242706416, 'epoch': 1.68}\n",
            "{'loss': 1.4261, 'grad_norm': 0.03507969155907631, 'learning_rate': 0.42690156512757604, 'epoch': 1.69}\n",
            "{'loss': 1.2921, 'grad_norm': 0.00791245885193348, 'learning_rate': 0.4226353326048593, 'epoch': 1.7}\n",
            "{'loss': 1.0691, 'grad_norm': 0.0032227174378931522, 'learning_rate': 0.4183748629272253, 'epoch': 1.7}\n",
            "{'loss': 1.4639, 'grad_norm': 0.1143517792224884, 'learning_rate': 0.4141204734543619, 'epoch': 1.71}\n",
            "{'loss': 1.2667, 'grad_norm': 0.2706587016582489, 'learning_rate': 0.40987248109304714, 'epoch': 1.72}\n",
            "{'loss': 1.0713, 'grad_norm': 0.0027918859850615263, 'learning_rate': 0.4056312022735417, 'epoch': 1.73}\n",
            "{'loss': 1.3459, 'grad_norm': 0.41669750213623047, 'learning_rate': 0.401396952926019, 'epoch': 1.74}\n",
            "{'loss': 1.2996, 'grad_norm': 251.15438842773438, 'learning_rate': 0.39717004845703174, 'epoch': 1.74}\n",
            "{'loss': 1.508, 'grad_norm': 0.016821861267089844, 'learning_rate': 0.392950803726017, 'epoch': 1.75}\n",
            "{'loss': 1.385, 'grad_norm': 0.36725255846977234, 'learning_rate': 0.38873953302184283, 'epoch': 1.76}\n",
            "{'loss': 1.4236, 'grad_norm': 0.0022623625118285418, 'learning_rate': 0.38453655003939735, 'epoch': 1.77}\n",
            "{'loss': 2.4538, 'grad_norm': 0.022747764363884926, 'learning_rate': 0.38034216785622127, 'epoch': 1.78}\n",
            "{'loss': 1.6501, 'grad_norm': 0.014744463376700878, 'learning_rate': 0.376156698909187, 'epoch': 1.78}\n",
            "{'loss': 1.1976, 'grad_norm': 0.1801632195711136, 'learning_rate': 0.37198045497122645, 'epoch': 1.79}\n",
            "{'loss': 2.2313, 'grad_norm': 0.0033667709212750196, 'learning_rate': 0.36781374712810555, 'epoch': 1.8}\n",
            "{'loss': 1.689, 'grad_norm': 0.0024833502247929573, 'learning_rate': 0.3636568857552531, 'epoch': 1.81}\n",
            "{'loss': 1.2371, 'grad_norm': 0.006246209144592285, 'learning_rate': 0.3595101804946404, 'epoch': 1.82}\n",
            "{'loss': 1.236, 'grad_norm': 0.004134104121476412, 'learning_rate': 0.3553739402317162, 'epoch': 1.82}\n",
            "{'loss': 1.1435, 'grad_norm': 0.009468290023505688, 'learning_rate': 0.3512484730723986, 'epoch': 1.83}\n",
            "{'loss': 1.2572, 'grad_norm': 0.04602126032114029, 'learning_rate': 0.34713408632012366, 'epoch': 1.84}\n",
            "{'loss': 1.499, 'grad_norm': 0.0035710737574845552, 'learning_rate': 0.343031086452955, 'epoch': 1.85}\n",
            "{'loss': 1.5417, 'grad_norm': 0.02301666885614395, 'learning_rate': 0.3389397791007548, 'epoch': 1.86}\n",
            "{'loss': 1.8491, 'grad_norm': 0.003417458850890398, 'learning_rate': 0.3348604690224166, 'epoch': 1.86}\n",
            "{'loss': 1.8782, 'grad_norm': 0.064576156437397, 'learning_rate': 0.3307934600831648, 'epoch': 1.87}\n",
            "{'loss': 1.3629, 'grad_norm': 0.004801489412784576, 'learning_rate': 0.32673905523192, 'epoch': 1.88}\n",
            "{'loss': 1.3838, 'grad_norm': 0.013435319997370243, 'learning_rate': 0.32269755647873216, 'epoch': 1.89}\n",
            "{'loss': 1.4024, 'grad_norm': 0.0018005016027018428, 'learning_rate': 0.318669264872284, 'epoch': 1.9}\n",
            "{'loss': 1.0709, 'grad_norm': 0.005734065547585487, 'learning_rate': 0.31465448047746625, 'epoch': 1.9}\n",
            "{'loss': 1.6287, 'grad_norm': 0.001867845538072288, 'learning_rate': 0.3106535023530262, 'epoch': 1.91}\n",
            "{'loss': 1.0026, 'grad_norm': 0.04832335561513901, 'learning_rate': 0.3066666285292906, 'epoch': 1.92}\n",
            "{'loss': 1.1821, 'grad_norm': 0.10618635267019272, 'learning_rate': 0.302694155985966, 'epoch': 1.93}\n",
            "{'loss': 1.085, 'grad_norm': 0.01064256951212883, 'learning_rate': 0.2987363806300163, 'epoch': 1.94}\n",
            "{'loss': 1.1701, 'grad_norm': 0.012920049019157887, 'learning_rate': 0.2947935972736217, 'epoch': 1.94}\n",
            "{'loss': 1.0987, 'grad_norm': 0.0036992570385336876, 'learning_rate': 0.29086609961221754, 'epoch': 1.95}\n",
            "{'loss': 1.5702, 'grad_norm': 0.0395706444978714, 'learning_rate': 0.28695418020261754, 'epoch': 1.96}\n",
            "{'loss': 0.9345, 'grad_norm': 0.0027789694722741842, 'learning_rate': 0.28305813044122097, 'epoch': 1.97}\n",
            "{'loss': 1.3546, 'grad_norm': 0.0033896106760948896, 'learning_rate': 0.27917824054230783, 'epoch': 1.98}\n",
            "{'loss': 1.538, 'grad_norm': 0.004487219732254744, 'learning_rate': 0.27531479951641924, 'epoch': 1.98}\n",
            "{'loss': 1.3373, 'grad_norm': 0.006902171764522791, 'learning_rate': 0.2714680951488312, 'epoch': 1.99}\n",
            "{'loss': 1.832, 'grad_norm': 0.0042574345134198666, 'learning_rate': 0.2676384139781157, 'epoch': 2.0}\n",
            "{'loss': 1.3767, 'grad_norm': 0.04586733505129814, 'learning_rate': 0.26382604127479814, 'epoch': 2.01}\n",
            "{'loss': 1.4331, 'grad_norm': 0.013861426152288914, 'learning_rate': 0.26003126102010693, 'epoch': 2.02}\n",
            "{'loss': 1.399, 'grad_norm': 0.1197611466050148, 'learning_rate': 0.25625435588482015, 'epoch': 2.02}\n",
            "{'loss': 1.123, 'grad_norm': 0.13226795196533203, 'learning_rate': 0.2524956072082093, 'epoch': 2.03}\n",
            "{'loss': 1.5865, 'grad_norm': 0.0066739520989358425, 'learning_rate': 0.24875529497708354, 'epoch': 2.04}\n",
            "{'loss': 1.9182, 'grad_norm': 0.007618039380759001, 'learning_rate': 0.24503369780493217, 'epoch': 2.05}\n",
            "{'loss': 1.7975, 'grad_norm': 0.003626640420407057, 'learning_rate': 0.24133109291117155, 'epoch': 2.06}\n",
            "{'loss': 1.2693, 'grad_norm': 0.0018036188557744026, 'learning_rate': 0.237647756100496, 'epoch': 2.06}\n",
            "{'loss': 1.3183, 'grad_norm': 0.001415751175954938, 'learning_rate': 0.23398396174233177, 'epoch': 2.07}\n",
            "{'loss': 1.4209, 'grad_norm': 0.018355000764131546, 'learning_rate': 0.23033998275040046, 'epoch': 2.08}\n",
            "{'loss': 1.0779, 'grad_norm': 0.0025665631983429193, 'learning_rate': 0.2267160905623895, 'epoch': 2.09}\n",
            "{'loss': 1.3687, 'grad_norm': 0.07252476364374161, 'learning_rate': 0.22311255511973344, 'epoch': 2.1}\n",
            "{'loss': 1.1156, 'grad_norm': 0.19735030829906464, 'learning_rate': 0.21952964484750526, 'epoch': 2.1}\n",
            "{'loss': 1.7087, 'grad_norm': 0.005257697775959969, 'learning_rate': 0.21596762663442215, 'epoch': 2.11}\n",
            "{'loss': 1.7834, 'grad_norm': 0.004771912004798651, 'learning_rate': 0.21242676581296527, 'epoch': 2.12}\n",
            "{'loss': 1.4524, 'grad_norm': 0.008757079020142555, 'learning_rate': 0.20890732613961477, 'epoch': 2.13}\n",
            "{'loss': 1.5336, 'grad_norm': 0.0015960049349814653, 'learning_rate': 0.2054095697752032, 'epoch': 2.14}\n",
            "{'loss': 1.5064, 'grad_norm': 0.003228193148970604, 'learning_rate': 0.20193375726538737, 'epoch': 2.14}\n",
            "{'loss': 1.5745, 'grad_norm': 0.007341674529016018, 'learning_rate': 0.19848014752123977, 'epoch': 2.15}\n",
            "{'loss': 1.9631, 'grad_norm': 0.025977449491620064, 'learning_rate': 0.19504899779996354, 'epoch': 2.16}\n",
            "{'loss': 1.3528, 'grad_norm': 0.0021617456804960966, 'learning_rate': 0.19164056368572846, 'epoch': 2.17}\n",
            "{'loss': 1.2687, 'grad_norm': 0.037268053740262985, 'learning_rate': 0.18825509907063326, 'epoch': 2.18}\n",
            "{'loss': 1.6242, 'grad_norm': 0.0022257044911384583, 'learning_rate': 0.18489285613579326, 'epoch': 2.18}\n",
            "{'loss': 1.3192, 'grad_norm': 0.16221481561660767, 'learning_rate': 0.18155408533255551, 'epoch': 2.19}\n",
            "{'loss': 1.4162, 'grad_norm': 0.00313273211941123, 'learning_rate': 0.1782390353638426, 'epoch': 2.2}\n",
            "{'loss': 1.3407, 'grad_norm': 0.0026233212556689978, 'learning_rate': 0.1749479531656279, 'epoch': 2.21}\n",
            "{'loss': 1.6589, 'grad_norm': 0.002220321213826537, 'learning_rate': 0.17168108388853998, 'epoch': 2.22}\n",
            "{'loss': 1.0724, 'grad_norm': 0.0027759340591728687, 'learning_rate': 0.16843867087960251, 'epoch': 2.22}\n",
            "{'loss': 1.2152, 'grad_norm': 0.0031375784892588854, 'learning_rate': 0.16522095566410727, 'epoch': 2.23}\n",
            "{'loss': 1.6047, 'grad_norm': 0.004826871678233147, 'learning_rate': 0.1620281779276228, 'epoch': 2.24}\n",
            "{'loss': 1.084, 'grad_norm': 0.030437510460615158, 'learning_rate': 0.1588605754981413, 'epoch': 2.25}\n",
            "{'loss': 1.0838, 'grad_norm': 0.0012103962944820523, 'learning_rate': 0.15571838432836138, 'epoch': 2.26}\n",
            "{'loss': 1.8977, 'grad_norm': 0.005453848745673895, 'learning_rate': 0.15260183847811382, 'epoch': 2.26}\n",
            "{'loss': 1.148, 'grad_norm': 0.004683513659983873, 'learning_rate': 0.14951117009692527, 'epoch': 2.27}\n",
            "{'loss': 1.2078, 'grad_norm': 0.004577468149363995, 'learning_rate': 0.14644660940672627, 'epoch': 2.28}\n",
            "{'loss': 1.357, 'grad_norm': 0.0015934754628688097, 'learning_rate': 0.14340838468470196, 'epoch': 2.29}\n",
            "{'loss': 1.7109, 'grad_norm': 0.0025148934219032526, 'learning_rate': 0.14039672224628785, 'epoch': 2.3}\n",
            "{'loss': 0.9992, 'grad_norm': 0.0030863876454532146, 'learning_rate': 0.1374118464283119, 'epoch': 2.3}\n",
            "{'loss': 1.0884, 'grad_norm': 0.002266074065119028, 'learning_rate': 0.1344539795722834, 'epoch': 2.31}\n",
            "{'loss': 1.2264, 'grad_norm': 0.005049360450357199, 'learning_rate': 0.13152334200783167, 'epoch': 2.32}\n",
            "{'loss': 1.5775, 'grad_norm': 0.017992515116930008, 'learning_rate': 0.12862015203629273, 'epoch': 2.33}\n",
            "{'loss': 1.0144, 'grad_norm': 0.0022515859454870224, 'learning_rate': 0.1257446259144494, 'epoch': 2.34}\n",
            "{'loss': 1.4161, 'grad_norm': 0.0012904498726129532, 'learning_rate': 0.1228969778384214, 'epoch': 2.34}\n",
            "{'loss': 1.1424, 'grad_norm': 0.019076216965913773, 'learning_rate': 0.12007741992771065, 'epoch': 2.35}\n",
            "{'loss': 1.0114, 'grad_norm': 0.013503889553248882, 'learning_rate': 0.1172861622094003, 'epoch': 2.36}\n",
            "{'loss': 1.5988, 'grad_norm': 0.0019485491793602705, 'learning_rate': 0.1145234126025102, 'epoch': 2.37}\n",
            "{'loss': 1.3625, 'grad_norm': 0.005138861481100321, 'learning_rate': 0.11178937690250917, 'epoch': 2.38}\n",
            "{'loss': 2.0294, 'grad_norm': 0.00340273673646152, 'learning_rate': 0.1090842587659851, 'epoch': 2.38}\n",
            "{'loss': 1.1283, 'grad_norm': 0.005220996215939522, 'learning_rate': 0.10640825969547496, 'epoch': 2.39}\n",
            "{'loss': 1.6789, 'grad_norm': 0.0037979099433869123, 'learning_rate': 0.10376157902445488, 'epoch': 2.4}\n",
            "{'loss': 1.9735, 'grad_norm': 0.007039386313408613, 'learning_rate': 0.10114441390249201, 'epoch': 2.41}\n",
            "{'loss': 1.9735, 'grad_norm': 0.018781913444399834, 'learning_rate': 0.0985569592805588, 'epoch': 2.42}\n",
            "{'loss': 1.3526, 'grad_norm': 0.001280576572753489, 'learning_rate': 0.09599940789651179, 'epoch': 2.42}\n",
            "{'loss': 1.3203, 'grad_norm': 0.002642360283061862, 'learning_rate': 0.09347195026073368, 'epoch': 2.43}\n",
            "{'loss': 1.1252, 'grad_norm': 0.0012004714226350188, 'learning_rate': 0.09097477464194359, 'epoch': 2.44}\n",
            "{'loss': 0.9808, 'grad_norm': 0.003398122498765588, 'learning_rate': 0.08850806705317182, 'epoch': 2.45}\n",
            "{'loss': 1.619, 'grad_norm': 0.0031244915444403887, 'learning_rate': 0.08607201123790459, 'epoch': 2.46}\n",
            "{'loss': 0.9754, 'grad_norm': 0.002771030878648162, 'learning_rate': 0.08366678865639687, 'epoch': 2.46}\n",
            "{'loss': 1.0543, 'grad_norm': 0.008922139182686806, 'learning_rate': 0.08129257847215571, 'epoch': 2.47}\n",
            "{'loss': 1.0566, 'grad_norm': 0.002243590308353305, 'learning_rate': 0.07894955753859412, 'epoch': 2.48}\n",
            "{'loss': 1.026, 'grad_norm': 0.0019372331444174051, 'learning_rate': 0.07663790038585794, 'epoch': 2.49}\n",
            "{'loss': 1.4401, 'grad_norm': 0.001638186164200306, 'learning_rate': 0.07435777920782444, 'epoch': 2.5}\n",
            "{'loss': 1.0979, 'grad_norm': 0.007286707870662212, 'learning_rate': 0.0721093638492763, 'epoch': 2.5}\n",
            "{'loss': 1.0575, 'grad_norm': 0.0015654617454856634, 'learning_rate': 0.06989282179324963, 'epoch': 2.51}\n",
            "{'loss': 1.7534, 'grad_norm': 0.004887062590569258, 'learning_rate': 0.06770831814855882, 'epoch': 2.52}\n",
            "{'loss': 1.4158, 'grad_norm': 0.0020765287335962057, 'learning_rate': 0.06555601563749675, 'epoch': 2.53}\n",
            "{'loss': 1.1483, 'grad_norm': 0.0015097102150321007, 'learning_rate': 0.06343607458371459, 'epoch': 2.54}\n",
            "{'loss': 1.2436, 'grad_norm': 0.03411957249045372, 'learning_rate': 0.06134865290027902, 'epoch': 2.54}\n",
            "{'loss': 1.3309, 'grad_norm': 0.0023162702564150095, 'learning_rate': 0.0592939060779093, 'epoch': 2.55}\n",
            "{'loss': 1.0006, 'grad_norm': 0.0008142843144014478, 'learning_rate': 0.0572719871733951, 'epoch': 2.56}\n",
            "{'loss': 0.9083, 'grad_norm': 0.004488065838813782, 'learning_rate': 0.05528304679819512, 'epoch': 2.57}\n",
            "{'loss': 1.4657, 'grad_norm': 0.07513821870088577, 'learning_rate': 0.05332723310721854, 'epoch': 2.58}\n",
            "{'loss': 1.6423, 'grad_norm': 0.06532174348831177, 'learning_rate': 0.05140469178778845, 'epoch': 2.58}\n",
            "{'loss': 1.4128, 'grad_norm': 0.005460561718791723, 'learning_rate': 0.04951556604879048, 'epoch': 2.59}\n",
            "{'loss': 1.3815, 'grad_norm': 0.0014743913197889924, 'learning_rate': 0.04765999661000442, 'epoch': 2.6}\n",
            "{'loss': 1.7052, 'grad_norm': 0.00441736588254571, 'learning_rate': 0.04583812169162299, 'epoch': 2.61}\n",
            "{'loss': 1.8995, 'grad_norm': 0.019481388852000237, 'learning_rate': 0.04405007700395497, 'epoch': 2.62}\n",
            "{'loss': 1.4529, 'grad_norm': 0.001697626430541277, 'learning_rate': 0.04229599573731685, 'epoch': 2.62}\n",
            "{'loss': 1.8611, 'grad_norm': 0.008851434104144573, 'learning_rate': 0.04057600855211141, 'epoch': 2.63}\n",
            "{'loss': 1.1428, 'grad_norm': 0.0011899371165782213, 'learning_rate': 0.03889024356909487, 'epoch': 2.64}\n",
            "{'loss': 1.2393, 'grad_norm': 0.0011782782385125756, 'learning_rate': 0.03723882635983328, 'epoch': 2.65}\n",
            "{'loss': 1.3347, 'grad_norm': 0.011121569201350212, 'learning_rate': 0.03562187993734883, 'epoch': 2.66}\n",
            "{'loss': 1.0748, 'grad_norm': 0.06914802640676498, 'learning_rate': 0.034039524746956595, 'epoch': 2.66}\n",
            "{'loss': 1.6787, 'grad_norm': 0.039315346628427505, 'learning_rate': 0.03249187865729264, 'epoch': 2.67}\n",
            "{'loss': 1.9263, 'grad_norm': 0.0024552769027650356, 'learning_rate': 0.03097905695153408, 'epoch': 2.68}\n",
            "{'loss': 1.5832, 'grad_norm': 0.03967843949794769, 'learning_rate': 0.02950117231881183, 'epoch': 2.69}\n",
            "{'loss': 1.3907, 'grad_norm': 0.001955392537638545, 'learning_rate': 0.028058334845816213, 'epoch': 2.7}\n",
            "{'loss': 1.2104, 'grad_norm': 0.004313151817768812, 'learning_rate': 0.026650652008597064, 'epoch': 2.7}\n",
            "{'loss': 1.1886, 'grad_norm': 0.00828598253428936, 'learning_rate': 0.025278228664557312, 'epoch': 2.71}\n",
            "{'loss': 1.2952, 'grad_norm': 0.007023222278803587, 'learning_rate': 0.02394116704464294, 'epoch': 2.72}\n",
            "{'loss': 2.0387, 'grad_norm': 0.022120347246527672, 'learning_rate': 0.022639566745727202, 'epoch': 2.73}\n",
            "{'loss': 1.6745, 'grad_norm': 0.0016622061375528574, 'learning_rate': 0.02137352472319215, 'epoch': 2.74}\n",
            "{'loss': 1.0981, 'grad_norm': 0.01409695390611887, 'learning_rate': 0.02014313528370626, 'epoch': 2.74}\n",
            "{'loss': 1.4968, 'grad_norm': 0.023849129676818848, 'learning_rate': 0.018948490078199764, 'epoch': 2.75}\n",
            "{'loss': 1.0704, 'grad_norm': 0.06838323175907135, 'learning_rate': 0.017789678095037453, 'epoch': 2.76}\n",
            "{'loss': 1.5214, 'grad_norm': 0.0530061200261116, 'learning_rate': 0.016666785653390248, 'epoch': 2.77}\n",
            "{'loss': 1.5687, 'grad_norm': 0.0016557443886995316, 'learning_rate': 0.01557989639680496, 'epoch': 2.78}\n",
            "{'loss': 1.1934, 'grad_norm': 0.0026498993393033743, 'learning_rate': 0.014529091286973994, 'epoch': 2.78}\n",
            "{'loss': 1.5673, 'grad_norm': 0.010580996051430702, 'learning_rate': 0.01351444859770462, 'epoch': 2.79}\n",
            "{'loss': 1.7738, 'grad_norm': 0.06508570909500122, 'learning_rate': 0.01253604390908819, 'epoch': 2.8}\n",
            "{'loss': 1.2914, 'grad_norm': 0.004545300267636776, 'learning_rate': 0.01159395010187042, 'epoch': 2.81}\n",
            "{'loss': 1.4841, 'grad_norm': 0.0020437464118003845, 'learning_rate': 0.010688237352022345, 'epoch': 2.82}\n",
            "{'loss': 1.9469, 'grad_norm': 0.01888827048242092, 'learning_rate': 0.009818973125513275, 'epoch': 2.82}\n",
            "{'loss': 1.7571, 'grad_norm': 0.02637444995343685, 'learning_rate': 0.008986222173284875, 'epoch': 2.83}\n",
            "{'loss': 1.5769, 'grad_norm': 0.004732027649879456, 'learning_rate': 0.00819004652642824, 'epoch': 2.84}\n",
            "{'loss': 1.9958, 'grad_norm': 0.0023408317938447, 'learning_rate': 0.0074305054915631, 'epoch': 2.85}\n",
            "{'loss': 1.2985, 'grad_norm': 0.09309998899698257, 'learning_rate': 0.00670765564642023, 'epoch': 2.86}\n",
            "{'loss': 1.615, 'grad_norm': 0.026063978672027588, 'learning_rate': 0.006021550835626777, 'epoch': 2.86}\n",
            "{'loss': 0.999, 'grad_norm': 0.004563177935779095, 'learning_rate': 0.005372242166695684, 'epoch': 2.87}\n",
            "{'loss': 1.0999, 'grad_norm': 0.061442237347364426, 'learning_rate': 0.004759778006218407, 'epoch': 2.88}\n",
            "{'loss': 1.8536, 'grad_norm': 0.00395776005461812, 'learning_rate': 0.004184203976262513, 'epoch': 2.89}\n",
            "{'loss': 0.9699, 'grad_norm': 0.035560492426157, 'learning_rate': 0.0036455629509730136, 'epoch': 2.9}\n",
            "{'loss': 1.4082, 'grad_norm': 0.0026260714512318373, 'learning_rate': 0.003143895053378698, 'epoch': 2.9}\n",
            "{'loss': 1.0116, 'grad_norm': 0.08700662851333618, 'learning_rate': 0.0026792376524036876, 'epoch': 2.91}\n",
            "{'loss': 1.6124, 'grad_norm': 0.002360258251428604, 'learning_rate': 0.002251625360083387, 'epoch': 2.92}\n",
            "{'loss': 1.5362, 'grad_norm': 0.009385012090206146, 'learning_rate': 0.0018610900289867671, 'epoch': 2.93}\n",
            "{'loss': 1.2234, 'grad_norm': 0.0015271359588950872, 'learning_rate': 0.0015076607498433203, 'epoch': 2.94}\n",
            "{'loss': 1.3247, 'grad_norm': 0.0023048731964081526, 'learning_rate': 0.0011913638493762368, 'epoch': 2.94}\n",
            "{'loss': 0.9611, 'grad_norm': 0.005762200802564621, 'learning_rate': 0.000912222888341252, 'epoch': 2.95}\n",
            "{'loss': 1.2969, 'grad_norm': 0.002101094229146838, 'learning_rate': 0.0006702586597719384, 'epoch': 2.96}\n",
            "{'loss': 1.3752, 'grad_norm': 0.0019471963169053197, 'learning_rate': 0.00046548918743033463, 'epoch': 2.97}\n",
            "{'loss': 1.5992, 'grad_norm': 0.0023501815740019083, 'learning_rate': 0.00029792972446479604, 'epoch': 2.98}\n",
            "{'loss': 1.3641, 'grad_norm': 0.00185765465721488, 'learning_rate': 0.00016759275227357096, 'epoch': 2.98}\n",
            "{'loss': 1.2392, 'grad_norm': 0.008843687362968922, 'learning_rate': 7.44879795752662e-05, 'epoch': 2.99}\n",
            "{'loss': 1.7242, 'grad_norm': 0.0016505467938259244, 'learning_rate': 1.862234168542587e-05, 'epoch': 3.0}\n",
            "{'train_runtime': 68.0271, 'train_samples_per_second': 11.025, 'train_steps_per_second': 5.513, 'train_loss': 2.3982064633369444, 'epoch': 3.0}\n",
            "100% 375/375 [01:08<00:00,  5.51it/s]\n",
            "Training complete.\n",
            "Model saved to loras/self-edit/training_set_iteration_1/8d5021e8/13\n",
            "Training on 10 examples for 5 epochs, lr: 0.001\n",
            "No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n",
            "Starting training...\n",
            "{'loss': 2.9272, 'grad_norm': 1.9642293453216553, 'learning_rate': 0.0, 'epoch': 0.2}\n",
            "{'loss': 2.9218, 'grad_norm': 1.9470924139022827, 'learning_rate': 9.090909090909092e-05, 'epoch': 0.4}\n",
            "{'loss': 3.9872, 'grad_norm': 4.231925964355469, 'learning_rate': 0.00018181818181818183, 'epoch': 0.6}\n",
            "{'loss': 1.718, 'grad_norm': 2.0826568603515625, 'learning_rate': 0.00027272727272727274, 'epoch': 0.8}\n",
            "{'loss': 1.7957, 'grad_norm': 3.3423118591308594, 'learning_rate': 0.00036363636363636367, 'epoch': 1.0}\n",
            "{'loss': 1.263, 'grad_norm': 0.4638728201389313, 'learning_rate': 0.00045454545454545455, 'epoch': 1.2}\n",
            "{'loss': 1.1336, 'grad_norm': 0.3684758245944977, 'learning_rate': 0.0005454545454545455, 'epoch': 1.4}\n",
            "{'loss': 0.9809, 'grad_norm': 0.443525493144989, 'learning_rate': 0.0006363636363636364, 'epoch': 1.6}\n",
            "{'loss': 0.7703, 'grad_norm': 0.3648627698421478, 'learning_rate': 0.0007272727272727273, 'epoch': 1.8}\n",
            "{'loss': 0.6718, 'grad_norm': 0.31210023164749146, 'learning_rate': 0.0008181818181818183, 'epoch': 2.0}\n",
            "{'loss': 0.4623, 'grad_norm': 0.28215712308883667, 'learning_rate': 0.0009090909090909091, 'epoch': 2.2}\n",
            "{'loss': 0.2986, 'grad_norm': 0.35296061635017395, 'learning_rate': 0.001, 'epoch': 2.4}\n",
            "{'loss': 0.1815, 'grad_norm': 0.33620962500572205, 'learning_rate': 0.0009874639560909118, 'epoch': 2.6}\n",
            "{'loss': 0.1291, 'grad_norm': 0.25509628653526306, 'learning_rate': 0.0009504844339512095, 'epoch': 2.8}\n",
            "{'loss': 0.113, 'grad_norm': 0.2324182242155075, 'learning_rate': 0.000890915741234015, 'epoch': 3.0}\n",
            "{'loss': 0.0947, 'grad_norm': 0.1300569474697113, 'learning_rate': 0.0008117449009293668, 'epoch': 3.2}\n",
            "{'loss': 0.0921, 'grad_norm': 0.19562098383903503, 'learning_rate': 0.0007169418695587791, 'epoch': 3.4}\n",
            "{'loss': 0.0899, 'grad_norm': 0.08331912010908127, 'learning_rate': 0.0006112604669781572, 'epoch': 3.6}\n",
            "{'loss': 0.0798, 'grad_norm': 0.07186613976955414, 'learning_rate': 0.0005, 'epoch': 3.8}\n",
            "{'loss': 0.084, 'grad_norm': 0.10979004204273224, 'learning_rate': 0.00038873953302184284, 'epoch': 4.0}\n",
            "{'loss': 0.0776, 'grad_norm': 0.06814641505479813, 'learning_rate': 0.00028305813044122096, 'epoch': 4.2}\n",
            "{'loss': 0.0767, 'grad_norm': 0.06320352107286453, 'learning_rate': 0.00018825509907063325, 'epoch': 4.4}\n",
            "{'loss': 0.0842, 'grad_norm': 0.1128847673535347, 'learning_rate': 0.0001090842587659851, 'epoch': 4.6}\n",
            "{'loss': 0.0815, 'grad_norm': 0.09929850697517395, 'learning_rate': 4.9515566048790485e-05, 'epoch': 4.8}\n",
            "{'loss': 0.0789, 'grad_norm': 0.09224535524845123, 'learning_rate': 1.2536043909088191e-05, 'epoch': 5.0}\n",
            "{'train_runtime': 3.1599, 'train_samples_per_second': 15.823, 'train_steps_per_second': 7.912, 'train_loss': 0.80773457467556, 'epoch': 5.0}\n",
            "100% 25/25 [00:03<00:00,  7.92it/s]\n",
            "Training complete.\n",
            "Model saved to loras/self-edit/training_set_iteration_1/8d5021e8/14\n",
            "Training complete. Final configs and indices saved to: loras/self-edit/training_set_iteration_1/final_configs_and_indices.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python /content/SEAL/few-shot/ttt.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mNzfXwY7Ipqu",
        "outputId": "bde22808-c332-4987-8ff6-a081743df4e5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-07-03 10:10:26.564160: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
            "2025-07-03 10:10:26.581375: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1751537426.602583   52488 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1751537426.609044   52488 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2025-07-03 10:10:26.630323: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "Augmenters to apply:  [Rotate(90), Rotate(270), Rotate(180), Flip(0), Flip(1), Reflect(0, reverse=True), Reflect(1, reverse=True), Reflect(0, reverse=False), Reflect(1, reverse=False), RandomTranslateXY(), Transpose(), IncreaseResolution(2), IncreaseHeight(2), IncreaseWidth(2), Chain([Rotate(90), IncreaseResolution(2)]), Chain([Rotate(270), IncreaseResolution(2)]), Chain([Rotate(180), IncreaseResolution(2)]), Chain([Flip(0), IncreaseResolution(2)]), Chain([Flip(1), IncreaseResolution(2)]), Chain([Transpose(), IncreaseResolution(2)]), Repeat(0, 2), Repeat(1, 2), Repeat(2, 2)] len:  23\n",
            "Training on 250 examples for 2 epochs, lr: 0.0001\n",
            "No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n",
            "Starting training...\n",
            "{'loss': 7.7871, 'grad_norm': 8.410064697265625, 'learning_rate': 0.0, 'epoch': 0.01}\n",
            "{'loss': 9.4136, 'grad_norm': 10.546051025390625, 'learning_rate': 9.090909090909091e-06, 'epoch': 0.02}\n",
            "{'loss': 10.0717, 'grad_norm': 12.728787422180176, 'learning_rate': 1.8181818181818182e-05, 'epoch': 0.02}\n",
            "{'loss': 10.0478, 'grad_norm': 13.1729154586792, 'learning_rate': 2.7272727272727273e-05, 'epoch': 0.03}\n",
            "{'loss': 9.4653, 'grad_norm': 12.067549705505371, 'learning_rate': 3.6363636363636364e-05, 'epoch': 0.04}\n",
            "{'loss': 9.0421, 'grad_norm': 13.461298942565918, 'learning_rate': 4.545454545454546e-05, 'epoch': 0.05}\n",
            "{'loss': 7.8474, 'grad_norm': 17.779983520507812, 'learning_rate': 5.4545454545454546e-05, 'epoch': 0.06}\n",
            "{'loss': 5.931, 'grad_norm': 16.81303596496582, 'learning_rate': 6.363636363636364e-05, 'epoch': 0.06}\n",
            "{'loss': 2.1363, 'grad_norm': 10.385688781738281, 'learning_rate': 7.272727272727273e-05, 'epoch': 0.07}\n",
            "{'loss': 1.1809, 'grad_norm': 11.884110450744629, 'learning_rate': 8.181818181818183e-05, 'epoch': 0.08}\n",
            "{'loss': 0.8985, 'grad_norm': 12.101494789123535, 'learning_rate': 9.090909090909092e-05, 'epoch': 0.09}\n",
            "{'loss': 0.8467, 'grad_norm': 15.73975658416748, 'learning_rate': 0.0001, 'epoch': 0.1}\n",
            "{'loss': 0.1081, 'grad_norm': 0.7408696413040161, 'learning_rate': 9.999568045802217e-05, 'epoch': 0.1}\n",
            "{'loss': 0.0416, 'grad_norm': 0.08308401703834534, 'learning_rate': 9.998272257842641e-05, 'epoch': 0.11}\n",
            "{'loss': 0.0637, 'grad_norm': 0.058302439749240875, 'learning_rate': 9.996112860009688e-05, 'epoch': 0.12}\n",
            "{'loss': 0.0682, 'grad_norm': 0.06380689144134521, 'learning_rate': 9.993090225407743e-05, 'epoch': 0.13}\n",
            "{'loss': 0.0559, 'grad_norm': 0.051368940621614456, 'learning_rate': 9.989204876292688e-05, 'epoch': 0.14}\n",
            "{'loss': 0.0354, 'grad_norm': 0.03685760125517845, 'learning_rate': 9.984457483981669e-05, 'epoch': 0.14}\n",
            "{'loss': 0.0607, 'grad_norm': 0.0534287765622139, 'learning_rate': 9.978848868737098e-05, 'epoch': 0.15}\n",
            "{'loss': 0.0458, 'grad_norm': 0.046096786856651306, 'learning_rate': 9.972379999624936e-05, 'epoch': 0.16}\n",
            "{'loss': 0.0255, 'grad_norm': 0.025661848485469818, 'learning_rate': 9.96505199434725e-05, 'epoch': 0.17}\n",
            "{'loss': 0.0381, 'grad_norm': 0.02827545441687107, 'learning_rate': 9.956866119049095e-05, 'epoch': 0.18}\n",
            "{'loss': 0.0502, 'grad_norm': 0.047536056488752365, 'learning_rate': 9.947823788099753e-05, 'epoch': 0.18}\n",
            "{'loss': 0.0348, 'grad_norm': 0.029072079807519913, 'learning_rate': 9.937926563848346e-05, 'epoch': 0.19}\n",
            "{'loss': 0.052, 'grad_norm': 0.04273561015725136, 'learning_rate': 9.927176156353899e-05, 'epoch': 0.2}\n",
            "{'loss': 0.0424, 'grad_norm': 0.03353680670261383, 'learning_rate': 9.91557442308987e-05, 'epoch': 0.21}\n",
            "{'loss': 0.0172, 'grad_norm': 0.0240757018327713, 'learning_rate': 9.903123368623216e-05, 'epoch': 0.22}\n",
            "{'loss': 0.0879, 'grad_norm': 0.0795273706316948, 'learning_rate': 9.889825144268029e-05, 'epoch': 0.22}\n",
            "{'loss': 0.0232, 'grad_norm': 0.02265949919819832, 'learning_rate': 9.875682047713846e-05, 'epoch': 0.23}\n",
            "{'loss': 0.0158, 'grad_norm': 0.01775791309773922, 'learning_rate': 9.860696522628639e-05, 'epoch': 0.24}\n",
            "{'loss': 0.0326, 'grad_norm': 0.030418716371059418, 'learning_rate': 9.844871158236591e-05, 'epoch': 0.25}\n",
            "{'loss': 0.0317, 'grad_norm': 0.0291956327855587, 'learning_rate': 9.828208688870735e-05, 'epoch': 0.26}\n",
            "{'loss': 0.0198, 'grad_norm': 0.02204747125506401, 'learning_rate': 9.810711993500507e-05, 'epoch': 0.26}\n",
            "{'loss': 0.0204, 'grad_norm': 0.018437562510371208, 'learning_rate': 9.792384095234313e-05, 'epoch': 0.27}\n",
            "{'loss': 0.0234, 'grad_norm': 0.024486687034368515, 'learning_rate': 9.773228160797188e-05, 'epoch': 0.28}\n",
            "{'loss': 0.0287, 'grad_norm': 0.02401404082775116, 'learning_rate': 9.753247499983649e-05, 'epoch': 0.29}\n",
            "{'loss': 0.0734, 'grad_norm': 0.06839337199926376, 'learning_rate': 9.732445565085824e-05, 'epoch': 0.3}\n",
            "{'loss': 0.0184, 'grad_norm': 0.018117755651474, 'learning_rate': 9.71082595029695e-05, 'epoch': 0.3}\n",
            "{'loss': 0.0205, 'grad_norm': 0.019096316769719124, 'learning_rate': 9.688392391090373e-05, 'epoch': 0.31}\n",
            "{'loss': 0.0156, 'grad_norm': 0.016802193596959114, 'learning_rate': 9.665148763574123e-05, 'epoch': 0.32}\n",
            "{'loss': 0.0334, 'grad_norm': 0.026172088459134102, 'learning_rate': 9.64109908382119e-05, 'epoch': 0.33}\n",
            "{'loss': 0.0709, 'grad_norm': 0.06760276854038239, 'learning_rate': 9.616247507175623e-05, 'epoch': 0.34}\n",
            "{'loss': 0.0256, 'grad_norm': 0.022640949115157127, 'learning_rate': 9.590598327534564e-05, 'epoch': 0.34}\n",
            "{'loss': 0.0342, 'grad_norm': 0.035401370376348495, 'learning_rate': 9.564155976606339e-05, 'epoch': 0.35}\n",
            "{'loss': 0.0441, 'grad_norm': 0.036486174911260605, 'learning_rate': 9.536925023144742e-05, 'epoch': 0.36}\n",
            "{'loss': 0.027, 'grad_norm': 0.026058712974190712, 'learning_rate': 9.508910172159635e-05, 'epoch': 0.37}\n",
            "{'loss': 0.0298, 'grad_norm': 0.017843637615442276, 'learning_rate': 9.480116264104011e-05, 'epoch': 0.38}\n",
            "{'loss': 0.0129, 'grad_norm': 0.010393747128546238, 'learning_rate': 9.450548274037653e-05, 'epoch': 0.38}\n",
            "{'loss': 0.0196, 'grad_norm': 0.01827719807624817, 'learning_rate': 9.420211310767533e-05, 'epoch': 0.39}\n",
            "{'loss': 0.0172, 'grad_norm': 0.015688994899392128, 'learning_rate': 9.389110615965102e-05, 'epoch': 0.4}\n",
            "{'loss': 0.0189, 'grad_norm': 0.016151662915945053, 'learning_rate': 9.35725156326063e-05, 'epoch': 0.41}\n",
            "{'loss': 0.0233, 'grad_norm': 0.01646750047802925, 'learning_rate': 9.324639657314742e-05, 'epoch': 0.42}\n",
            "{'loss': 0.0197, 'grad_norm': 0.01962289586663246, 'learning_rate': 9.291280532867302e-05, 'epoch': 0.42}\n",
            "{'loss': 0.0234, 'grad_norm': 0.02475697733461857, 'learning_rate': 9.257179953763845e-05, 'epoch': 0.43}\n",
            "{'loss': 0.0094, 'grad_norm': 0.009240160696208477, 'learning_rate': 9.222343811959693e-05, 'epoch': 0.44}\n",
            "{'loss': 0.0198, 'grad_norm': 0.014373310841619968, 'learning_rate': 9.186778126501916e-05, 'epoch': 0.45}\n",
            "{'loss': 0.0162, 'grad_norm': 0.014137103222310543, 'learning_rate': 9.150489042489367e-05, 'epoch': 0.46}\n",
            "{'loss': 0.0073, 'grad_norm': 0.009561222977936268, 'learning_rate': 9.113482830010918e-05, 'epoch': 0.46}\n",
            "{'loss': 0.0173, 'grad_norm': 0.010789575055241585, 'learning_rate': 9.075765883062093e-05, 'epoch': 0.47}\n",
            "{'loss': 0.0326, 'grad_norm': 0.03292740136384964, 'learning_rate': 9.037344718440322e-05, 'epoch': 0.48}\n",
            "{'loss': 0.0219, 'grad_norm': 0.01405759435147047, 'learning_rate': 8.99822597461894e-05, 'epoch': 0.49}\n",
            "{'loss': 0.0234, 'grad_norm': 0.014510457403957844, 'learning_rate': 8.958416410600187e-05, 'epoch': 0.5}\n",
            "{'loss': 0.052, 'grad_norm': 0.04757215082645416, 'learning_rate': 8.917922904747384e-05, 'epoch': 0.5}\n",
            "{'loss': 0.0303, 'grad_norm': 0.012961151078343391, 'learning_rate': 8.876752453596462e-05, 'epoch': 0.51}\n",
            "{'loss': 0.0373, 'grad_norm': 0.033211302012205124, 'learning_rate': 8.834912170647101e-05, 'epoch': 0.52}\n",
            "{'loss': 0.0167, 'grad_norm': 0.01157433446496725, 'learning_rate': 8.792409285133642e-05, 'epoch': 0.53}\n",
            "{'loss': 0.0194, 'grad_norm': 0.017027178779244423, 'learning_rate': 8.749251140776016e-05, 'epoch': 0.54}\n",
            "{'loss': 0.0266, 'grad_norm': 0.017654454335570335, 'learning_rate': 8.705445194510868e-05, 'epoch': 0.54}\n",
            "{'loss': 0.0144, 'grad_norm': 0.014481401070952415, 'learning_rate': 8.66099901520315e-05, 'epoch': 0.55}\n",
            "{'loss': 0.0291, 'grad_norm': 0.021821068599820137, 'learning_rate': 8.615920282338355e-05, 'epoch': 0.56}\n",
            "{'loss': 0.0115, 'grad_norm': 0.009801234118640423, 'learning_rate': 8.570216784695637e-05, 'epoch': 0.57}\n",
            "{'loss': 0.0128, 'grad_norm': 0.011543283239006996, 'learning_rate': 8.52389641900206e-05, 'epoch': 0.58}\n",
            "{'loss': 0.0228, 'grad_norm': 0.019819501787424088, 'learning_rate': 8.476967188568188e-05, 'epoch': 0.58}\n",
            "{'loss': 0.0193, 'grad_norm': 0.01529158465564251, 'learning_rate': 8.429437201905254e-05, 'epoch': 0.59}\n",
            "{'loss': 0.032, 'grad_norm': 0.03352361172437668, 'learning_rate': 8.381314671324159e-05, 'epoch': 0.6}\n",
            "{'loss': 0.0136, 'grad_norm': 0.011989912018179893, 'learning_rate': 8.332607911516545e-05, 'epoch': 0.61}\n",
            "{'loss': 0.0081, 'grad_norm': 0.010002180933952332, 'learning_rate': 8.283325338118153e-05, 'epoch': 0.62}\n",
            "{'loss': 0.0121, 'grad_norm': 0.01670202426612377, 'learning_rate': 8.233475466254765e-05, 'epoch': 0.62}\n",
            "{'loss': 0.0183, 'grad_norm': 0.021176699548959732, 'learning_rate': 8.183066909070947e-05, 'epoch': 0.63}\n",
            "{'loss': 0.0154, 'grad_norm': 0.012540100142359734, 'learning_rate': 8.132108376241849e-05, 'epoch': 0.64}\n",
            "{'loss': 0.0124, 'grad_norm': 0.012108741328120232, 'learning_rate': 8.08060867246834e-05, 'epoch': 0.65}\n",
            "{'loss': 0.0116, 'grad_norm': 0.012780298478901386, 'learning_rate': 8.028576695955711e-05, 'epoch': 0.66}\n",
            "{'loss': 0.0234, 'grad_norm': 0.020650319755077362, 'learning_rate': 7.97602143687623e-05, 'epoch': 0.66}\n",
            "{'loss': 0.0127, 'grad_norm': 0.013491443358361721, 'learning_rate': 7.922951975815811e-05, 'epoch': 0.67}\n",
            "{'loss': 0.0169, 'grad_norm': 0.014433326199650764, 'learning_rate': 7.869377482205042e-05, 'epoch': 0.68}\n",
            "{'loss': 0.0228, 'grad_norm': 0.022601744160056114, 'learning_rate': 7.815307212734888e-05, 'epoch': 0.69}\n",
            "{'loss': 0.0183, 'grad_norm': 0.018755845725536346, 'learning_rate': 7.760750509757298e-05, 'epoch': 0.7}\n",
            "{'loss': 0.0132, 'grad_norm': 0.016537334769964218, 'learning_rate': 7.705716799671019e-05, 'epoch': 0.7}\n",
            "{'loss': 0.0181, 'grad_norm': 0.012911801226437092, 'learning_rate': 7.650215591292888e-05, 'epoch': 0.71}\n",
            "{'loss': 0.0154, 'grad_norm': 0.013783413916826248, 'learning_rate': 7.594256474214882e-05, 'epoch': 0.72}\n",
            "{'loss': 0.0184, 'grad_norm': 0.0196548979729414, 'learning_rate': 7.537849117147212e-05, 'epoch': 0.73}\n",
            "{'loss': 0.0214, 'grad_norm': 0.019487908110022545, 'learning_rate': 7.481003266247744e-05, 'epoch': 0.74}\n",
            "{'loss': 0.0199, 'grad_norm': 0.02236580289900303, 'learning_rate': 7.423728743438048e-05, 'epoch': 0.74}\n",
            "{'loss': 0.0229, 'grad_norm': 0.02964715100824833, 'learning_rate': 7.366035444706347e-05, 'epoch': 0.75}\n",
            "{'loss': 0.0107, 'grad_norm': 0.017474975436925888, 'learning_rate': 7.307933338397667e-05, 'epoch': 0.76}\n",
            "{'loss': 0.0139, 'grad_norm': 0.01771118864417076, 'learning_rate': 7.249432463491498e-05, 'epoch': 0.77}\n",
            "{'loss': 0.0132, 'grad_norm': 0.014555064029991627, 'learning_rate': 7.190542927867234e-05, 'epoch': 0.78}\n",
            "{'loss': 0.0216, 'grad_norm': 0.020266076549887657, 'learning_rate': 7.131274906557725e-05, 'epoch': 0.78}\n",
            "{'loss': 0.0144, 'grad_norm': 0.014371001161634922, 'learning_rate': 7.071638639991207e-05, 'epoch': 0.79}\n",
            "{'loss': 0.0397, 'grad_norm': 0.03372188284993172, 'learning_rate': 7.011644432221958e-05, 'epoch': 0.8}\n",
            "{'loss': 0.0194, 'grad_norm': 0.018466701731085777, 'learning_rate': 6.95130264914993e-05, 'epoch': 0.81}\n",
            "{'loss': 0.0105, 'grad_norm': 0.014612346887588501, 'learning_rate': 6.890623716729724e-05, 'epoch': 0.82}\n",
            "{'loss': 0.022, 'grad_norm': 0.019857365638017654, 'learning_rate': 6.82961811916917e-05, 'epoch': 0.82}\n",
            "{'loss': 0.0292, 'grad_norm': 0.037356313318014145, 'learning_rate': 6.768296397117848e-05, 'epoch': 0.83}\n",
            "{'loss': 0.0299, 'grad_norm': 0.029153402894735336, 'learning_rate': 6.706669145845863e-05, 'epoch': 0.84}\n",
            "{'loss': 0.0223, 'grad_norm': 0.021287977695465088, 'learning_rate': 6.644747013413168e-05, 'epoch': 0.85}\n",
            "{'loss': 0.0159, 'grad_norm': 0.013819432817399502, 'learning_rate': 6.582540698829781e-05, 'epoch': 0.86}\n",
            "{'loss': 0.0186, 'grad_norm': 0.021221179515123367, 'learning_rate': 6.520060950207185e-05, 'epoch': 0.86}\n",
            "{'loss': 0.0163, 'grad_norm': 0.01902390643954277, 'learning_rate': 6.457318562901256e-05, 'epoch': 0.87}\n",
            "{'loss': 0.0106, 'grad_norm': 0.01847023516893387, 'learning_rate': 6.394324377647028e-05, 'epoch': 0.88}\n",
            "{'loss': 0.01, 'grad_norm': 0.012152149342000484, 'learning_rate': 6.331089278685599e-05, 'epoch': 0.89}\n",
            "{'loss': 0.0224, 'grad_norm': 0.017558161169290543, 'learning_rate': 6.26762419188355e-05, 'epoch': 0.9}\n",
            "{'loss': 0.0143, 'grad_norm': 0.03213408589363098, 'learning_rate': 6.203940082845144e-05, 'epoch': 0.9}\n",
            "{'loss': 0.0136, 'grad_norm': 0.013646376319229603, 'learning_rate': 6.140047955017671e-05, 'epoch': 0.91}\n",
            "{'loss': 0.0105, 'grad_norm': 0.01917409338057041, 'learning_rate': 6.075958847790262e-05, 'epoch': 0.92}\n",
            "{'loss': 0.01, 'grad_norm': 0.0182094294577837, 'learning_rate': 6.011683834586473e-05, 'epoch': 0.93}\n",
            "{'loss': 0.0149, 'grad_norm': 0.017927130684256554, 'learning_rate': 5.947234020951015e-05, 'epoch': 0.94}\n",
            "{'loss': 0.0104, 'grad_norm': 0.016892174258828163, 'learning_rate': 5.882620542630901e-05, 'epoch': 0.94}\n",
            "{'loss': 0.0205, 'grad_norm': 0.02166863903403282, 'learning_rate': 5.8178545636514145e-05, 'epoch': 0.95}\n",
            "{'loss': 0.038, 'grad_norm': 0.044556956738233566, 'learning_rate': 5.752947274387147e-05, 'epoch': 0.96}\n",
            "{'loss': 0.0056, 'grad_norm': 0.012257097288966179, 'learning_rate': 5.687909889628529e-05, 'epoch': 0.97}\n",
            "{'loss': 0.0144, 'grad_norm': 0.01955352909862995, 'learning_rate': 5.622753646644102e-05, 'epoch': 0.98}\n",
            "{'loss': 0.0112, 'grad_norm': 0.02068164385855198, 'learning_rate': 5.557489803238933e-05, 'epoch': 0.98}\n",
            "{'loss': 0.0155, 'grad_norm': 0.01951468735933304, 'learning_rate': 5.492129635809473e-05, 'epoch': 0.99}\n",
            "{'loss': 0.0121, 'grad_norm': 0.01708102598786354, 'learning_rate': 5.426684437395196e-05, 'epoch': 1.0}\n",
            "{'loss': 0.0128, 'grad_norm': 0.016765661537647247, 'learning_rate': 5.361165515727374e-05, 'epoch': 1.01}\n",
            "{'loss': 0.0112, 'grad_norm': 0.013051338493824005, 'learning_rate': 5.295584191275308e-05, 'epoch': 1.02}\n",
            "{'loss': 0.0112, 'grad_norm': 0.011826615780591965, 'learning_rate': 5.229951795290353e-05, 'epoch': 1.02}\n",
            "{'loss': 0.0187, 'grad_norm': 0.021553542464971542, 'learning_rate': 5.164279667848094e-05, 'epoch': 1.03}\n",
            "{'loss': 0.0154, 'grad_norm': 0.021930573508143425, 'learning_rate': 5.0985791558889785e-05, 'epoch': 1.04}\n",
            "{'loss': 0.0198, 'grad_norm': 0.019731177017092705, 'learning_rate': 5.032861611257783e-05, 'epoch': 1.05}\n",
            "{'loss': 0.0196, 'grad_norm': 0.025519292801618576, 'learning_rate': 4.967138388742218e-05, 'epoch': 1.06}\n",
            "{'loss': 0.0156, 'grad_norm': 0.019214065745472908, 'learning_rate': 4.901420844111021e-05, 'epoch': 1.06}\n",
            "{'loss': 0.0158, 'grad_norm': 0.02117726393043995, 'learning_rate': 4.835720332151907e-05, 'epoch': 1.07}\n",
            "{'loss': 0.018, 'grad_norm': 0.017275523394346237, 'learning_rate': 4.770048204709648e-05, 'epoch': 1.08}\n",
            "{'loss': 0.0086, 'grad_norm': 0.015552030876278877, 'learning_rate': 4.7044158087246926e-05, 'epoch': 1.09}\n",
            "{'loss': 0.0179, 'grad_norm': 0.020926792174577713, 'learning_rate': 4.6388344842726264e-05, 'epoch': 1.1}\n",
            "{'loss': 0.0122, 'grad_norm': 0.01999128982424736, 'learning_rate': 4.5733155626048036e-05, 'epoch': 1.1}\n",
            "{'loss': 0.0129, 'grad_norm': 0.017006410285830498, 'learning_rate': 4.507870364190527e-05, 'epoch': 1.11}\n",
            "{'loss': 0.0119, 'grad_norm': 0.0165316890925169, 'learning_rate': 4.4425101967610674e-05, 'epoch': 1.12}\n",
            "{'loss': 0.007, 'grad_norm': 0.013293669559061527, 'learning_rate': 4.377246353355899e-05, 'epoch': 1.13}\n",
            "{'loss': 0.0115, 'grad_norm': 0.02568853460252285, 'learning_rate': 4.312090110371473e-05, 'epoch': 1.14}\n",
            "{'loss': 0.0147, 'grad_norm': 0.020204724743962288, 'learning_rate': 4.247052725612852e-05, 'epoch': 1.14}\n",
            "{'loss': 0.01, 'grad_norm': 0.01240230817347765, 'learning_rate': 4.1821454363485866e-05, 'epoch': 1.15}\n",
            "{'loss': 0.0218, 'grad_norm': 0.030544063076376915, 'learning_rate': 4.1173794573690996e-05, 'epoch': 1.16}\n",
            "{'loss': 0.018, 'grad_norm': 0.023678451776504517, 'learning_rate': 4.052765979048986e-05, 'epoch': 1.17}\n",
            "{'loss': 0.0211, 'grad_norm': 0.023395109921693802, 'learning_rate': 3.988316165413528e-05, 'epoch': 1.18}\n",
            "{'loss': 0.0124, 'grad_norm': 0.02148996852338314, 'learning_rate': 3.924041152209739e-05, 'epoch': 1.18}\n",
            "{'loss': 0.0048, 'grad_norm': 0.01230813842266798, 'learning_rate': 3.859952044982329e-05, 'epoch': 1.19}\n",
            "{'loss': 0.0125, 'grad_norm': 0.01722768507897854, 'learning_rate': 3.7960599171548574e-05, 'epoch': 1.2}\n",
            "{'loss': 0.0062, 'grad_norm': 0.018235862255096436, 'learning_rate': 3.732375808116451e-05, 'epoch': 1.21}\n",
            "{'loss': 0.0107, 'grad_norm': 0.017249800264835358, 'learning_rate': 3.668910721314402e-05, 'epoch': 1.22}\n",
            "{'loss': 0.0102, 'grad_norm': 0.017034869641065598, 'learning_rate': 3.605675622352973e-05, 'epoch': 1.22}\n",
            "{'loss': 0.0132, 'grad_norm': 0.019120201468467712, 'learning_rate': 3.542681437098745e-05, 'epoch': 1.23}\n",
            "{'loss': 0.004, 'grad_norm': 0.013530673459172249, 'learning_rate': 3.479939049792817e-05, 'epoch': 1.24}\n",
            "{'loss': 0.0098, 'grad_norm': 0.023714542388916016, 'learning_rate': 3.417459301170219e-05, 'epoch': 1.25}\n",
            "{'loss': 0.0078, 'grad_norm': 0.01734194904565811, 'learning_rate': 3.355252986586832e-05, 'epoch': 1.26}\n",
            "{'loss': 0.0517, 'grad_norm': 0.06139182299375534, 'learning_rate': 3.293330854154136e-05, 'epoch': 1.26}\n",
            "{'loss': 0.0138, 'grad_norm': 0.015365241095423698, 'learning_rate': 3.2317036028821523e-05, 'epoch': 1.27}\n",
            "{'loss': 0.0144, 'grad_norm': 0.015295500867068768, 'learning_rate': 3.1703818808308324e-05, 'epoch': 1.28}\n",
            "{'loss': 0.0134, 'grad_norm': 0.018234366551041603, 'learning_rate': 3.109376283270277e-05, 'epoch': 1.29}\n",
            "{'loss': 0.0075, 'grad_norm': 0.01737968809902668, 'learning_rate': 3.0486973508500727e-05, 'epoch': 1.3}\n",
            "{'loss': 0.0187, 'grad_norm': 0.02251560240983963, 'learning_rate': 2.988355567778043e-05, 'epoch': 1.3}\n",
            "{'loss': 0.0145, 'grad_norm': 0.028004249557852745, 'learning_rate': 2.9283613600087933e-05, 'epoch': 1.31}\n",
            "{'loss': 0.0104, 'grad_norm': 0.017721517011523247, 'learning_rate': 2.8687250934422772e-05, 'epoch': 1.32}\n",
            "{'loss': 0.0135, 'grad_norm': 0.020767267793416977, 'learning_rate': 2.8094570721327662e-05, 'epoch': 1.33}\n",
            "{'loss': 0.011, 'grad_norm': 0.01926441863179207, 'learning_rate': 2.750567536508504e-05, 'epoch': 1.34}\n",
            "{'loss': 0.0184, 'grad_norm': 0.03070380724966526, 'learning_rate': 2.6920666616023327e-05, 'epoch': 1.34}\n",
            "{'loss': 0.0248, 'grad_norm': 0.026537876576185226, 'learning_rate': 2.6339645552936536e-05, 'epoch': 1.35}\n",
            "{'loss': 0.0119, 'grad_norm': 0.020131513476371765, 'learning_rate': 2.5762712565619528e-05, 'epoch': 1.36}\n",
            "{'loss': 0.0074, 'grad_norm': 0.012471521273255348, 'learning_rate': 2.5189967337522573e-05, 'epoch': 1.37}\n",
            "{'loss': 0.0317, 'grad_norm': 0.049223411828279495, 'learning_rate': 2.46215088285279e-05, 'epoch': 1.38}\n",
            "{'loss': 0.0185, 'grad_norm': 0.026097958907485008, 'learning_rate': 2.4057435257851175e-05, 'epoch': 1.38}\n",
            "{'loss': 0.0103, 'grad_norm': 0.018248792737722397, 'learning_rate': 2.349784408707112e-05, 'epoch': 1.39}\n",
            "{'loss': 0.0179, 'grad_norm': 0.021925272420048714, 'learning_rate': 2.2942832003289823e-05, 'epoch': 1.4}\n",
            "{'loss': 0.0156, 'grad_norm': 0.027586089447140694, 'learning_rate': 2.2392494902427025e-05, 'epoch': 1.41}\n",
            "{'loss': 0.0128, 'grad_norm': 0.021920643746852875, 'learning_rate': 2.1846927872651137e-05, 'epoch': 1.42}\n",
            "{'loss': 0.0253, 'grad_norm': 0.0444488488137722, 'learning_rate': 2.1306225177949585e-05, 'epoch': 1.42}\n",
            "{'loss': 0.014, 'grad_norm': 0.023058712482452393, 'learning_rate': 2.07704802418419e-05, 'epoch': 1.43}\n",
            "{'loss': 0.0113, 'grad_norm': 0.018903888761997223, 'learning_rate': 2.0239785631237705e-05, 'epoch': 1.44}\n",
            "{'loss': 0.0213, 'grad_norm': 0.03684977814555168, 'learning_rate': 1.9714233040442915e-05, 'epoch': 1.45}\n",
            "{'loss': 0.0147, 'grad_norm': 0.018109850585460663, 'learning_rate': 1.9193913275316626e-05, 'epoch': 1.46}\n",
            "{'loss': 0.033, 'grad_norm': 0.03812916949391365, 'learning_rate': 1.8678916237581522e-05, 'epoch': 1.46}\n",
            "{'loss': 0.0094, 'grad_norm': 0.015272922813892365, 'learning_rate': 1.816933090929055e-05, 'epoch': 1.47}\n",
            "{'loss': 0.0082, 'grad_norm': 0.014682268723845482, 'learning_rate': 1.7665245337452368e-05, 'epoch': 1.48}\n",
            "{'loss': 0.0064, 'grad_norm': 0.012509402818977833, 'learning_rate': 1.716674661881848e-05, 'epoch': 1.49}\n",
            "{'loss': 0.0153, 'grad_norm': 0.022002236917614937, 'learning_rate': 1.667392088483456e-05, 'epoch': 1.5}\n",
            "{'loss': 0.0161, 'grad_norm': 0.02016260474920273, 'learning_rate': 1.6186853286758397e-05, 'epoch': 1.5}\n",
            "{'loss': 0.0106, 'grad_norm': 0.022080231457948685, 'learning_rate': 1.570562798094747e-05, 'epoch': 1.51}\n",
            "{'loss': 0.0118, 'grad_norm': 0.016922837123274803, 'learning_rate': 1.5230328114318127e-05, 'epoch': 1.52}\n",
            "{'loss': 0.0182, 'grad_norm': 0.023247970268130302, 'learning_rate': 1.4761035809979395e-05, 'epoch': 1.53}\n",
            "{'loss': 0.0233, 'grad_norm': 0.03408919274806976, 'learning_rate': 1.4297832153043656e-05, 'epoch': 1.54}\n",
            "{'loss': 0.0125, 'grad_norm': 0.025480996817350388, 'learning_rate': 1.3840797176616466e-05, 'epoch': 1.54}\n",
            "{'loss': 0.0175, 'grad_norm': 0.022954698652029037, 'learning_rate': 1.3390009847968504e-05, 'epoch': 1.55}\n",
            "{'loss': 0.0136, 'grad_norm': 0.027469810098409653, 'learning_rate': 1.2945548054891321e-05, 'epoch': 1.56}\n",
            "{'loss': 0.0215, 'grad_norm': 0.037509746849536896, 'learning_rate': 1.2507488592239847e-05, 'epoch': 1.57}\n",
            "{'loss': 0.0049, 'grad_norm': 0.01333634927868843, 'learning_rate': 1.2075907148663579e-05, 'epoch': 1.58}\n",
            "{'loss': 0.0108, 'grad_norm': 0.017434213310480118, 'learning_rate': 1.1650878293528994e-05, 'epoch': 1.58}\n",
            "{'loss': 0.0056, 'grad_norm': 0.016926398500800133, 'learning_rate': 1.1232475464035385e-05, 'epoch': 1.59}\n",
            "{'loss': 0.0135, 'grad_norm': 0.019598811864852905, 'learning_rate': 1.0820770952526155e-05, 'epoch': 1.6}\n",
            "{'loss': 0.025, 'grad_norm': 0.05586972087621689, 'learning_rate': 1.0415835893998116e-05, 'epoch': 1.61}\n",
            "{'loss': 0.0152, 'grad_norm': 0.04037843644618988, 'learning_rate': 1.0017740253810609e-05, 'epoch': 1.62}\n",
            "{'loss': 0.0138, 'grad_norm': 0.02368069626390934, 'learning_rate': 9.62655281559679e-06, 'epoch': 1.62}\n",
            "{'loss': 0.0134, 'grad_norm': 0.02377382107079029, 'learning_rate': 9.242341169379076e-06, 'epoch': 1.63}\n",
            "{'loss': 0.008, 'grad_norm': 0.02374804951250553, 'learning_rate': 8.865171699890834e-06, 'epoch': 1.64}\n",
            "{'loss': 0.0099, 'grad_norm': 0.02463562786579132, 'learning_rate': 8.49510957510633e-06, 'epoch': 1.65}\n",
            "{'loss': 0.0118, 'grad_norm': 0.02553141675889492, 'learning_rate': 8.132218734980852e-06, 'epoch': 1.66}\n",
            "{'loss': 0.0084, 'grad_norm': 0.024689743295311928, 'learning_rate': 7.776561880403072e-06, 'epoch': 1.66}\n",
            "{'loss': 0.0131, 'grad_norm': 0.025187456980347633, 'learning_rate': 7.4282004623615396e-06, 'epoch': 1.67}\n",
            "{'loss': 0.027, 'grad_norm': 0.036924853920936584, 'learning_rate': 7.0871946713269856e-06, 'epoch': 1.68}\n",
            "{'loss': 0.0263, 'grad_norm': 0.0419292151927948, 'learning_rate': 6.753603426852589e-06, 'epoch': 1.69}\n",
            "{'loss': 0.0128, 'grad_norm': 0.030727975070476532, 'learning_rate': 6.427484367393699e-06, 'epoch': 1.7}\n",
            " 85% 212/250 [02:25<00:25,  1.47it/s]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "DATA_DIR='/content/SEAL/few-shot/data'\n",
        "TTI_DIR='/content/SEAL/loras/self-edit/training_set_iteration_1'\n",
        "LORA_DIR='/content/SEAL/loras/self-edit/training_set_iteration_1/8d5021e8/14'\n",
        "\n",
        "!python /content/SEAL/few-shot/eval-self-edits.py  \\\n",
        "    --experiment_folder={TTI_DIR} \\\n",
        "    --pretrained_checkpoint=meta-llama/Llama-3.2-1B-Instruct \\\n",
        "    --lora_checkpoints_folder={LORA_DIR} \\\n",
        "    --temperature=0 \\\n",
        "    --n_sample=1 \\\n",
        "    --data_file=/content/SEAL/few-shot/data/arc-agi_training_challenges_filtered_1B_training_set.json \\\n",
        "    --solution_file=/content/SEAL/few-shot/data/arc-agi_evaluation_challenges_filtered_1B_eval_set.json \\\n",
        "    --max_lora_rank=128 \\\n",
        "    --include_n=1 \\\n",
        "    --new_format \\\n",
        "    --num_examples=11 \\\n",
        "    --n_self_edits=15"
      ],
      "metadata": {
        "id": "d2H8z48V8kT_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python /content/SEAL/few-shot/BC-self-edit.py \\\n",
        "    --configs_and_indices=/content/SEAL/loras/self-edit/training_set_iteration_1/final_configs_and_indices.json \\\n",
        "    --results=/content/SEAL/few-shot/final_results.json \\\n",
        "    --model_name=meta-llama/Llama-3.2-1B-Instruct \\\n",
        "    --lora_rank=16 \\\n",
        "    --lora_alpha=16 \\\n",
        "    --num_train_epochs=8 \\\n",
        "    --per_device_train_batch_size=5 \\\n",
        "    --gradient_accumulation_steps=1 \\\n",
        "    --learning_rate=5e-5"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o3tBgYc-8l2z",
        "outputId": "48d6dca6-c245-4c20-810b-d99c63e08071"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-07-03 10:05:44.086943: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
            "2025-07-03 10:05:44.104948: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1751537144.127281   50546 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1751537144.133954   50546 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2025-07-03 10:05:44.155699: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "trainable params: 9,568,256 || all params: 1,245,382,656 || trainable%: 0.7683\n",
            "Found 0 correct cases\n",
            "No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/SEAL/few-shot/BC-self-edit.py\", line 151, in <module>\n",
            "    trainer.train()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/transformers/trainer.py\", line 2240, in train\n",
            "    return inner_training_loop(\n",
            "           ^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/transformers/trainer.py\", line 2269, in _inner_training_loop\n",
            "    train_dataloader = self.get_train_dataloader()\n",
            "                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/transformers/trainer.py\", line 1063, in get_train_dataloader\n",
            "    return self._get_dataloader(\n",
            "           ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/transformers/trainer.py\", line 1017, in _get_dataloader\n",
            "    dataset = self._remove_unused_columns(dataset, description=description)\n",
            "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/transformers/trainer.py\", line 943, in _remove_unused_columns\n",
            "    raise ValueError(\n",
            "ValueError: No columns in the dataset match the model's forward method signature: ({', '.join(signature_columns)}). The following columns have been ignored: []. Please check the dataset and model. You may need to set `remove_unused_columns=False` in `TrainingArguments`.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python /content/SEAL/few-shot/self-edit.py  \\\n",
        "    --experiment_name=eval_RL_iteration_1_8_epoch \\\n",
        "    --challenge_file={DATA_DIR}/arc-agi_evaluation_challenges_filtered_1B_eval_set.json \\\n",
        "    --solution_file={DATA_DIR}/arc-agi_evaluation_solutions_filtered_1B_eval_set.json \\\n",
        "    --model_name={LORA_DIR}/self-edit/training_set_iteration_1/RL_trained_model_iteration_1_8_epoch \\\n",
        "    --n_tasks=10 \\\n",
        "    --n_self_edits_per_task=5"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vLNLYvf_8qoC",
        "outputId": "5b3f8106-d30a-4a01-f5c1-ec01a98df1e6"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-07-03 06:55:06.033917: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
            "2025-07-03 06:55:06.050785: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1751525706.072214    5328 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1751525706.078762    5328 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2025-07-03 06:55:06.099725: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "INFO 07-03 06:55:09 [__init__.py:244] Automatically detected platform cuda.\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/SEAL/few-shot/self-edit.py\", line 602, in <module>\n",
            "    main(\n",
            "  File \"/content/SEAL/few-shot/self-edit.py\", line 422, in main\n",
            "    tasks = read_tasks_from_single_file(\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/SEAL/few-shot/self-edit.py\", line 102, in read_tasks_from_single_file\n",
            "    with open(challenge_file, \"r\", encoding=\"utf-8\") as handle:\n",
            "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '{DATA_DIR}/arc-agi_evaluation_challenges_filtered_1B_eval_set.json'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python /content/SEAL/few-shot/eval-self-edits.py \\\n",
        "    --experiment_folder=${TTI_DIR}/eval_set_RL_iteration_1_8_epoch \\\n",
        "    --pretrained_checkpoint=${LORA_DIR}/self-edit/training_set_iteration_1/RL_trained_model_iteration_1_8_epoch \\\n",
        "    --lora_checkpoints_folder=${LORA_DIR}/self-edit/eval_RL_iteration_1_8_epoch \\\n",
        "    --temperature=0 \\\n",
        "    --n_sample=1 \\\n",
        "    --data_file=${DATA_DIR}/arc-agi_evaluation_challenges_filtered_1B_eval_set.json \\\n",
        "    --solution_file=${DATA_DIR}/arc-agi_evaluation_solutions_filtered_1B_eval_set.json \\\n",
        "    --max_lora_rank=128 \\\n",
        "    --include_n=1 \\\n",
        "    --new_format \\\n",
        "    --num_examples=9 \\\n",
        "    --n_self_edits=5"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_EpbSLpi8xbb",
        "outputId": "7e2b4ea6-dc54-462e-e2a1-c5a23024bec1"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-07-03 06:55:19.953865: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
            "2025-07-03 06:55:19.972063: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1751525719.993849    5454 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1751525720.000600    5454 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2025-07-03 06:55:20.022504: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "INFO 07-03 06:55:22 [__init__.py:244] Automatically detected platform cuda.\n",
            "Arguments:\n",
            "seed: 0\n",
            "data_file: /arc-agi_evaluation_challenges_filtered_1B_eval_set.json\n",
            "solution_file: /arc-agi_evaluation_solutions_filtered_1B_eval_set.json\n",
            "num_examples: 9\n",
            "pretrained_checkpoint: /self-edit/training_set_iteration_1/RL_trained_model_iteration_1_8_epoch\n",
            "lora_checkpoints_folder: /self-edit/eval_RL_iteration_1_8_epoch\n",
            "quantization: None\n",
            "max_tokens: 8192\n",
            "temperature: 0.0\n",
            "n_sample: 1\n",
            "experiment_folder: /eval_set_RL_iteration_1_8_epoch\n",
            "formatter: arclib.messagers.GPTTextMessageRepresenterV2\n",
            "max_lora_rank: 128\n",
            "include_n: [1]\n",
            "permute_n: 2\n",
            "new_format: True\n",
            "barc_format: False\n",
            "add_diff_format: False\n",
            "use_all_lora: False\n",
            "n_self_edits: 5\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/SEAL/few-shot/eval-self-edits.py\", line 135, in <module>\n",
            "    tasks = read_tasks_from_single_file(args.data_file, solution_file=args.solution_file, test=True)\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/SEAL/few-shot/arclib/arc.py\", line 208, in read_tasks_from_single_file\n",
            "    with open(challenge_file, \"r\", encoding=\"utf-8\") as handle:\n",
            "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/arc-agi_evaluation_challenges_filtered_1B_eval_set.json'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python /content/SEAL/few-shot/eval-self-edits-baseline.py \\\n",
        "    --experiment_folder=${TTI_DIR}/eval_base_model \\\n",
        "    --pretrained_checkpoint=meta-llama/Llama-3.2-1B-Instruct \\\n",
        "    --lora_checkpoints_folder=${LORA_DIR}/self-edit/eval_RL_iteration_1_8_epoch \\\n",
        "    --temperature=0 \\\n",
        "    --n_sample=1 \\\n",
        "    --data_file=${DATA_DIR}/arc-agi_evaluation_challenges_filtered_1B_eval_set.json \\\n",
        "    --solution_file=${DATA_DIR}/arc-agi_evaluation_solutions_filtered_1B_eval_set.json \\\n",
        "    --max_lora_rank=128 \\\n",
        "    --include_n=1 \\\n",
        "    --new_format \\\n",
        "    --num_examples=9"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s1O3obS-81ei",
        "outputId": "e270e15f-dd0e-4093-b496-f5e6fa1d3a52"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-07-03 06:55:33.325673: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
            "2025-07-03 06:55:33.342930: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1751525733.364423    5577 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1751525733.370987    5577 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2025-07-03 06:55:33.392017: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "INFO 07-03 06:55:36 [__init__.py:244] Automatically detected platform cuda.\n",
            "Arguments:\n",
            "seed: 0\n",
            "data_file: /arc-agi_evaluation_challenges_filtered_1B_eval_set.json\n",
            "solution_file: /arc-agi_evaluation_solutions_filtered_1B_eval_set.json\n",
            "num_examples: 9\n",
            "pretrained_checkpoint: meta-llama/Llama-3.2-1B-Instruct\n",
            "lora_checkpoints_folder: /self-edit/eval_RL_iteration_1_8_epoch\n",
            "quantization: None\n",
            "max_tokens: 8192\n",
            "temperature: 0.0\n",
            "n_sample: 1\n",
            "experiment_folder: /eval_base_model\n",
            "formatter: arclib.messagers.GPTTextMessageRepresenterV2\n",
            "max_lora_rank: 128\n",
            "include_n: [1]\n",
            "permute_n: 2\n",
            "new_format: True\n",
            "barc_format: False\n",
            "add_diff_format: False\n",
            "use_all_lora: False\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/SEAL/few-shot/eval-self-edits-baseline.py\", line 132, in <module>\n",
            "    tasks = read_tasks_from_single_file(args.data_file, solution_file=args.solution_file, test=True)\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/SEAL/few-shot/arclib/arc.py\", line 208, in read_tasks_from_single_file\n",
            "    with open(challenge_file, \"r\", encoding=\"utf-8\") as handle:\n",
            "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/arc-agi_evaluation_challenges_filtered_1B_eval_set.json'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python /content/SEAL/few-shot/self-edit.py \\\n",
        "    --experiment_name=eval_RL_iteration_1 \\\n",
        "    --challenge_file=${DATA_DIR}/arc-agi_evaluation_challenges_filtered_1B_eval_set.json \\\n",
        "    --solution_file=${DATA_DIR}/arc-agi_evaluation_solutions_filtered_1B_eval_set.json \\\n",
        "    --model_name=${LORA_DIR}/self-edit/training_set_iteration_1/RL_trained_model_iteration_1 \\\n",
        "    --n_tasks=10 \\\n",
        "    --n_self_edits_per_task=5"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LVocsW3a86wj",
        "outputId": "71f79108-b710-409e-bc62-c9835acf6b22"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-07-03 06:55:47.204344: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
            "2025-07-03 06:55:47.221330: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1751525747.242423    5697 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1751525747.248884    5697 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2025-07-03 06:55:47.269756: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "INFO 07-03 06:55:50 [__init__.py:244] Automatically detected platform cuda.\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/SEAL/few-shot/self-edit.py\", line 602, in <module>\n",
            "    main(\n",
            "  File \"/content/SEAL/few-shot/self-edit.py\", line 422, in main\n",
            "    tasks = read_tasks_from_single_file(\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/SEAL/few-shot/self-edit.py\", line 102, in read_tasks_from_single_file\n",
            "    with open(challenge_file, \"r\", encoding=\"utf-8\") as handle:\n",
            "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/arc-agi_evaluation_challenges_filtered_1B_eval_set.json'\n"
          ]
        }
      ]
    }
  ]
}