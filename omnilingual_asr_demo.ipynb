{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "L4",
      "authorship_tag": "ABX9TyM5WBjn5mGmAOQKc3Ykr/mI",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/frank-morales2020/Cloud_curious/blob/master/omnilingual_asr_demo.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://ai.meta.com/blog/omnilingual-asr-advancing-automatic-speech-recognition/?brid=r816qqOfNVjm8AxrSoRtdw"
      ],
      "metadata": {
        "id": "2VkDdGoNRJqU"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uCrYpy-X7Kj5"
      },
      "outputs": [],
      "source": [
        "# using pip\n",
        "!pip install omnilingual-asr -q"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc --version"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AnlZAoGhEAtI",
        "outputId": "2dcd5cb4-9827-4302-ebcc-589845b94097"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "nvcc: NVIDIA (R) Cuda compiler driver\n",
            "Copyright (c) 2005-2024 NVIDIA Corporation\n",
            "Built on Thu_Jun__6_02:18:23_PDT_2024\n",
            "Cuda compilation tools, release 12.5, V12.5.82\n",
            "Build cuda_12.5.r12.5/compiler.34385749_0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove all NVIDIA and CUDA-related packages\n",
        "!apt-get --purge remove cuda nvidia* libnvidia-*\n",
        "!dpkg -l | grep cuda- | awk '{print $2}' | xargs -n1 dpkg --purge\n",
        "!apt-get remove cuda-*\n",
        "!apt autoremove -y\n",
        "!apt-get update"
      ],
      "metadata": {
        "id": "8Ko97PfEEjxa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Download and install the CUDA GPG key and repository metadata\n",
        "!wget https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64/cuda-keyring_1.1-1_all.deb\n",
        "!dpkg -i cuda-keyring_1.1-1_all.deb\n",
        "\n",
        "# 2. Update package lists to include the new NVIDIA repository\n",
        "!apt-get update\n",
        "\n",
        "# 3. Install the specific CUDA 12.8 toolkit\n",
        "# NOTE: Specifying 'cuda-toolkit-12-8' ensures the exact version is pulled\n",
        "!apt-get -y install cuda-toolkit-12-8"
      ],
      "metadata": {
        "id": "GFFtb7QQE2-U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Update the PATH variable for the current session\n",
        "import os\n",
        "os.environ['PATH'] += ':/usr/local/cuda-12.8/bin'\n",
        "\n",
        "# 2. Verify the new version\n",
        "!nvcc --version"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JA6s8ZjjJhPU",
        "outputId": "51fdc017-76e0-490d-a12d-3837d701d9d0"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "nvcc: NVIDIA (R) Cuda compiler driver\n",
            "Copyright (c) 2005-2025 NVIDIA Corporation\n",
            "Built on Fri_Feb_21_20:23:50_PST_2025\n",
            "Cuda compilation tools, release 12.8, V12.8.93\n",
            "Build cuda_12.8.r12.8/compiler.35583870_0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# This is a common pattern for installing PyTorch with specific CUDA\n",
        "# (The exact URL/command may change, check PyTorch website for the current link)\n",
        "!pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu128"
      ],
      "metadata": {
        "id": "-6NjnU9oJx9H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow -q"
      ],
      "metadata": {
        "id": "-5U3ELvmJ81_"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "print(f\"PyTorch built with CUDA: {torch.version.cuda}\")\n",
        "print(f\"Is GPU available: {torch.cuda.is_available()}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d5Znf4-lKDnl",
        "outputId": "a516e9cc-3c32-43c1-9ecd-0ecaec5c2e63"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PyTorch built with CUDA: 12.6\n",
            "Is GPU available: True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip uninstall torch torchvision torchaudio -y"
      ],
      "metadata": {
        "id": "jmWX3MDBKrIz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip uninstall torch torchvision torchaudio -y\n",
        "\n",
        "# Install PyTorch 2.8.0 only\n",
        "!pip install torch==2.8.0 --index-url https://download.pytorch.org/whl/cu128 -q"
      ],
      "metadata": {
        "id": "opuTEQonKx4l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torchvision torchaudio"
      ],
      "metadata": {
        "id": "anpJySw8LU-9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torchaudio\n",
        "\n",
        "print(f\"PyTorch version: {torch.__version__}\")\n",
        "print(f\"Torchvision version: {torchvision.__version__}\")\n",
        "print(f\"Torchaudio version: {torchaudio.__version__}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "liBWG-6iLSAl",
        "outputId": "1cf64c98-5977-4ed7-c5b6-33a11915cf5c"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PyTorch version: 2.9.1+cu128\n",
            "Torchvision version: 0.24.1+cu128\n",
            "Torchaudio version: 2.9.1+cu128\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip uninstall torch torchvision torchaudio -y"
      ],
      "metadata": {
        "id": "zDKSmXOrLKYT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch==2.8.0 --index-url https://download.pytorch.org/whl/cu128"
      ],
      "metadata": {
        "id": "Trs4Y2MOMBWk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torchvision==0.23.0 torchaudio==2.8.0 --index-url https://download.pytorch.org/whl/cu128"
      ],
      "metadata": {
        "id": "PEpDARUgMGEq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torchaudio\n",
        "print(f\"PyTorch version: {torch.__version__}\")\n",
        "print(f\"Torchvision version: {torchvision.__version__}\")\n",
        "print(f\"Torchaudio version: {torchaudio.__version__}\")\n",
        "\n",
        "# Try running your import code immediately after this check\n",
        "# from omnilingual_asr.models.inference.pipeline import ASRInferencePipeline"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JYwdVc7bMblP",
        "outputId": "93013f7f-e769-4522-e3bc-31bbbd03c754"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PyTorch version: 2.9.1+cu128\n",
            "Torchvision version: 0.24.1+cu128\n",
            "Torchaudio version: 2.9.1+cu128\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "print(torch.version.cuda)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "did49k_YOA5Y",
        "outputId": "b00a7c2f-a0a0-48ae-b442-c706ef9c0bc1"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "12.8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install soundfile"
      ],
      "metadata": {
        "id": "9IK_YFltO2E2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import soundfile as sf\n",
        "import os\n",
        "\n",
        "# Define file paths\n",
        "flac_path = '/content/eng_audio1.flac'\n",
        "wav_path = '/content/deu_audio2.wav'\n",
        "\n",
        "# --- 1. Create a 1-second English FLAC file ---\n",
        "samplerate = 44100\n",
        "duration = 1.0  # seconds\n",
        "frequency = 440  # A4 note\n",
        "# Generate a simple sine wave\n",
        "t = np.linspace(0., duration, int(samplerate * duration))\n",
        "data = 0.5 * np.sin(2. * np.pi * frequency * t)\n",
        "# Save the data as FLAC\n",
        "sf.write(flac_path, data, samplerate, format='FLAC')\n",
        "\n",
        "# --- 2. Create a 1-second German WAV file ---\n",
        "# Save the same data as WAV\n",
        "sf.write(wav_path, data, samplerate, format='WAV')\n",
        "\n",
        "print(\"‚úÖ Audio files created successfully!\")\n",
        "print(\"-\" * 30)\n",
        "\n",
        "# Verify the files are now in the correct location and have non-zero size\n",
        "!ls -lh /content/ | grep -E 'eng_audio1.flac|deu_audio2.wav'"
      ],
      "metadata": {
        "id": "yzctY5y3QAwJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "557f0826"
      },
      "source": [
        "# Re-run the omnilingual-asr code after updating PyTorch\n",
        "from omnilingual_asr.models.inference.pipeline import ASRInferencePipeline\n",
        "\n",
        "pipeline = ASRInferencePipeline(model_card=\"omniASR_LLM_7B\")\n",
        "\n",
        "audio_files = [\"/content/eng_audio1.flac\", \"/content/deu_audio2.wav\"]\n",
        "lang = [\"eng_Latn\", \"deu_Latn\"]\n",
        "transcriptions = pipeline.transcribe(audio_files, lang=lang, batch_size=2)\n",
        "\n",
        "print(transcriptions)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(transcriptions)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lNMOYLgo9ym6",
        "outputId": "c45186bf-7281-42df-856c-00657c1578a8"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[\"on tuesday americans stood in line that stretched around schools and churches in numbers this nation has never seen it didn't matter who they were or where they came from what they looked like or what party they belonged to they came out and cast their ballot because they believed that in this country our destiny is not written for us but by us we should all take pride in the fact that we once again displayed for the world the power of our democracy and reaffirmed the great american ideal\", 'denne siehte dann']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#from google.colab import files\n",
        "\n",
        "#print(\"Please upload your actual English audio file now.\")\n",
        "#files.upload()"
      ],
      "metadata": {
        "id": "IkP5FWIJRwbB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "metadata": {
        "id": "ifPQclhoUI7y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- File Check and Generation ---\n",
        "\n",
        "# 1. Install soundfile (critical for creating audio files from scratch)\n",
        "!pip install soundfile > /dev/null 2>&1\n",
        "\n",
        "# 2. Programmatically create valid, non-zero audio files under the CORRECT names.\n",
        "import numpy as np\n",
        "import soundfile as sf\n",
        "import torch\n",
        "from omnilingual_asr.models.inference.pipeline import ASRInferencePipeline\n",
        "\n",
        "print(\"üîÑ Generating guaranteed valid audio files under correct names...\")\n",
        "\n",
        "# --- A. English FLAC: Creating a 15-second valid audio tone ---\n",
        "flac_path = '/content/eng_audio1.flac'\n",
        "samplerate = 16000 # Standard ASR sample rate\n",
        "duration = 15.0 # Well under the 40s limit\n",
        "frequency = 400\n",
        "t = np.linspace(0., duration, int(samplerate * duration))\n",
        "data = 0.5 * np.sin(2. * np.pi * frequency * t)\n",
        "sf.write(flac_path, data, samplerate, format='FLAC')\n",
        "\n",
        "# --- B. German WAV: Creating a 1-second valid audio tone ---\n",
        "wav_path = '/content/deu_audio2.wav'\n",
        "duration_wav = 1.0\n",
        "data_wav = 0.5 * np.sin(2. * np.pi * 880 * t[:int(samplerate * duration_wav)])\n",
        "sf.write(wav_path, data_wav, samplerate, format='WAV')\n",
        "\n",
        "print(\"‚úÖ Files /content/eng_audio1.flac and /content/deu_audio2.wav created successfully.\")\n",
        "print(\"-\" * 30)\n",
        "\n",
        "# Final file verification\n",
        "!ls -lh /content/ | grep -E 'eng_audio1.flac|deu_audio2.wav'\n",
        "\n",
        "# --- Pipeline Loading (using the smaller model, omniASR_LLM_300M) ---\n",
        "\n",
        "print(\"\\nüîÑ Re-loading ASR Pipeline...\")\n",
        "try:\n",
        "    pipeline = ASRInferencePipeline(\n",
        "        model_card=\"omniASR_LLM_300M\",\n",
        "        dtype=torch.bfloat16,\n",
        "        device=torch.device('cuda')\n",
        "    )\n",
        "except Exception as e:\n",
        "    print(f\"‚ùå Failed to load model. Error: {e}\")\n",
        "    raise\n",
        "\n",
        "print(\"‚úÖ Model loaded successfully!\")\n",
        "\n",
        "# --- Transcription ---\n",
        "audio_files = [\"/content/eng_audio1.flac\", \"/content/deu_audio2.wav\"]\n",
        "lang = [\"eng_Latn\", \"deu_Latn\"]\n",
        "\n",
        "print(\"‚ñ∂Ô∏è Starting Transcription...\")\n",
        "transcriptions = pipeline.transcribe(audio_files, lang=lang, batch_size=2)\n",
        "\n",
        "print(\"\\nTranscription Results:\")\n",
        "print(transcriptions)"
      ],
      "metadata": {
        "id": "JxnGf8m-cE8v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ptiYSpqZjuII",
        "outputId": "0c01925b-8728-4ad7-9a8f-e9d2f1eb2590"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -rf /content/*.flac\n",
        "!rm -rf /content/*.wav"
      ],
      "metadata": {
        "id": "0IfvXbmwh2qs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ls -ltha /content/gdrive/MyDrive/data/barackobamatransitionaddress1.mp3"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HvHOQZ0lmOOA",
        "outputId": "1944f435-0e01-4e3a-fc9b-eab34b86f5e2"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-rw-------+ 1 root root 2.1M Nov 18 02:50 /content/gdrive/MyDrive/data/barackobamatransitionaddress1.mp3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import sys\n",
        "import torch\n",
        "import numpy as np\n",
        "import soundfile as sf\n",
        "from pydub import AudioSegment # Note: Requires ffmpeg, which is installed below.\n",
        "from google.colab import drive\n",
        "from omnilingual_asr.models.inference.pipeline import ASRInferencePipeline\n",
        "\n",
        "# --- Setup FFmpeg and Libraries ---\n",
        "os.system(\"apt-get update > /dev/null 2>&1\")\n",
        "os.system(\"apt-get install -y ffmpeg > /dev/null 2>&1\")\n",
        "os.system(\"pip install pydub soundfile > /dev/null 2>&1\")\n",
        "print(\"‚úÖ Tools and libraries are installed.\")\n",
        "\n",
        "# --- Define the Conversion Function (Handles MP3 source from Drive) ---\n",
        "\n",
        "def convert_and_slice_mp3_to_flac(input_filepath, output_filepath, clip_duration_seconds):\n",
        "    \"\"\"\n",
        "    Loads an MP3, extracts a clip of the specified duration (starting from 0:00),\n",
        "    and exports it as a FLAC file. Includes robust error handling.\n",
        "    \"\"\"\n",
        "    clip_duration_ms = clip_duration_seconds * 1000\n",
        "\n",
        "    if not os.path.exists(input_filepath):\n",
        "        print(f\"‚ùå Error: Input file '{input_filepath}' not found. Conversion aborted.\", file=sys.stderr)\n",
        "        return False\n",
        "\n",
        "    try:\n",
        "        print(f\"Loading {input_filepath}...\")\n",
        "        audio = AudioSegment.from_file(input_filepath, format=\"mp3\")\n",
        "\n",
        "        # Slice the audio: [start_ms : end_ms]\n",
        "        clip = audio[:clip_duration_ms]\n",
        "        print(f\"Successfully sliced the first {clip_duration_seconds} seconds.\")\n",
        "\n",
        "        # Export the audio clip to FLAC format\n",
        "        clip.export(output_filepath, format=\"flac\")\n",
        "        print(f\"‚úÖ Conversion and slicing successful! Output file: {output_filepath}\")\n",
        "        return True\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå An error occurred during conversion (FFmpeg/Pydub issue): {e}\", file=sys.stderr)\n",
        "        return False"
      ],
      "metadata": {
        "id": "GO_4TiC1pAYG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# FIXED FINAL CELL ‚Äì SeamlessM4T v2 Text-to-Text (Correct Decoding from HF Docs)\n",
        "import os\n",
        "import torch\n",
        "from pydub import AudioSegment\n",
        "from google.colab import drive\n",
        "from omnilingual_asr.models.inference.pipeline import ASRInferencePipeline\n",
        "\n",
        "# Hugging Face SeamlessM4T v2\n",
        "from transformers import AutoProcessor, SeamlessM4Tv2Model\n",
        "\n",
        "# -------------------------------------------------\n",
        "# 0. Mount Drive & Prepare 30-second English FLAC\n",
        "# -------------------------------------------------\n",
        "drive.mount('/content/gdrive')\n",
        "\n",
        "INPUT_MP3   = \"/content/gdrive/MyDrive/data/barackobamatransitionaddress1.mp3\"\n",
        "OUTPUT_FLAC = \"/content/eng_audio1.flac\"\n",
        "TARGET_SEC  = 30\n",
        "\n",
        "if not os.path.exists(OUTPUT_FLAC):\n",
        "    print(\"Converting MP3 ‚Üí FLAC (30s)...\")\n",
        "    audio = AudioSegment.from_mp3(INPUT_MP3)\n",
        "    clip = audio[:TARGET_SEC * 1000]\n",
        "    clip.export(OUTPUT_FLAC, format=\"flac\")\n",
        "    print(\"FLAC created\")\n",
        "else:\n",
        "    print(\"Using existing FLAC\")\n",
        "\n",
        "# -------------------------------------------------\n",
        "# 1. OmniASR ‚Üí English text\n",
        "# -------------------------------------------------\n",
        "print(\"\\nLoading OmniASR (300M)...\")\n",
        "asr = ASRInferencePipeline(model_card=\"omniASR_LLM_300M\", dtype=torch.bfloat16, device=\"cuda\")\n",
        "print(\"OmniASR ready\")\n",
        "\n",
        "english_text = asr.transcribe([OUTPUT_FLAC], lang=[\"eng_Latn\"])[0]\n",
        "print(\"\\nEnglish transcription:\")\n",
        "print(english_text)\n",
        "\n",
        "# -------------------------------------------------\n",
        "# 2. SeamlessM4T v2 ‚Üí German translation (FIXED: .tolist()[0] + max_new_tokens)\n",
        "# -------------------------------------------------\n",
        "print(\"\\nLoading SeamlessM4T v2 (facebook/seamless-m4t-v2-large)...\")\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "processor = AutoProcessor.from_pretrained(\"facebook/seamless-m4t-v2-large\")\n",
        "model = SeamlessM4Tv2Model.from_pretrained(\"facebook/seamless-m4t-v2-large\").to(device)\n",
        "\n",
        "# Prepare inputs for text-to-text (src_lang only; tgt_lang in generate)\n",
        "inputs = processor(\n",
        "    text=english_text,\n",
        "    src_lang=\"eng\",\n",
        "    return_tensors=\"pt\"\n",
        ").to(device)\n",
        "\n",
        "print(\"Translating to German...\")\n",
        "with torch.no_grad():\n",
        "    # Generate translation (text-to-text: generate_speech=False)\n",
        "    output_tokens = model.generate(\n",
        "        **inputs,\n",
        "        tgt_lang=\"deu\",\n",
        "        generate_speech=False,  # Text output only\n",
        "        max_new_tokens=256  # FIXED: Use this instead of max_length (avoids warning)\n",
        "    )\n",
        "\n",
        "# FIXED: Decode using official HF pattern (tolist()[0] extracts generated sequence)\n",
        "german_text = processor.decode(\n",
        "    output_tokens[0].tolist()[0],  # [0] for batch, [0] for generated seq (post-input)\n",
        "    skip_special_tokens=True\n",
        ")"
      ],
      "metadata": {
        "id": "lheQaiN5qx9o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# -------------------------------------------------\n",
        "# 3. Final results\n",
        "# -------------------------------------------------\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"FINAL RESULTS (PyTorch 2.8.0 + cu128)\")\n",
        "print(\"=\"*80)\n",
        "print(\"English (OmniASR):\")\n",
        "print(english_text)\n",
        "print(\"\\nGerman (SeamlessM4T v2):\")\n",
        "print(german_text)\n",
        "print(\"=\"*80)\n",
        "\n",
        "# Save to files\n",
        "with open(\"/content/english.txt\", \"w\") as f: f.write(english_text)\n",
        "with open(\"/content/german.txt\", \"w\") as f: f.write(german_text)\n",
        "print(\"\\nSaved ‚Üí /content/english.txt  &  /content/german.txt\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mfEvBNvl7cxB",
        "outputId": "848f5076-33fd-4fc5-89e2-19beb670a184"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "FINAL RESULTS (PyTorch 2.8.0 + cu128)\n",
            "================================================================================\n",
            "English (OmniASR):\n",
            "on tuesday american stood in line that stretched around schools and churches in numbers this nation has never seen it in matter who they were or where they came from and what they looked like or what party they belonged to they came out and cast their balance because they believed that in this country our destiny is not written for us but by us we should all take pride in the fact that we once again displayed for the world the power of our democracy and reaffirmed the great american ideal\n",
            "\n",
            "German (SeamlessM4T v2):\n",
            "am dienstag standen amerikaner in einer schlange, die sich um schulen und kirchen erstreckte, in zahlen, die diese nation noch nie gesehen hat, egal wer sie waren oder woher sie kamen und wie sie aussahen oder welcher partei sie angeh√∂rten sie kamen heraus und warfen ihre waage, weil sie glaubten, dass in diesem land unser schicksal nicht f√ºr uns geschrieben ist, sondern von uns wir sollten alle stolz auf die tatsache sein, dass wir erneut f√ºr die welt die macht unserer demokratie gezeigt und das gro√üe amerikanische ideal bekr√§ftigt haben.\n",
            "================================================================================\n",
            "\n",
            "Saved ‚Üí /content/english.txt  &  /content/german.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls -ltha"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "43Qq2nuajLdz",
        "outputId": "ec7d80ba-190f-4a4d-de18-a86a5e4c5855"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total 3.3M\n",
            "drwxr-xr-x 1 root root 4.0K Nov 18 02:54 .\n",
            "-rw-r--r-- 1 root root  550 Nov 18 02:54 german.txt\n",
            "-rw-r--r-- 1 root root  493 Nov 18 02:54 english.txt\n",
            "-rw-r--r-- 1 root root  32K Nov 18 02:52 deu_audio2.wav\n",
            "-rw-r--r-- 1 root root 1.2M Nov 18 02:52 eng_audio1.flac\n",
            "drwx------ 6 root root 4.0K Nov 18 02:51 gdrive\n",
            "-rw-r--r-- 1 root root 2.1M Nov 18 02:50 barackobamatransitionaddress1.mp3\n",
            "drwxr-xr-x 1 root root 4.0K Nov 18 02:08 ..\n",
            "drwxr-xr-x 1 root root 4.0K Nov 12 14:30 sample_data\n",
            "drwxr-xr-x 4 root root 4.0K Nov 12 14:30 .config\n",
            "-rw-r--r-- 1 root root 4.3K Apr 20  2023 cuda-keyring_1.1-1_all.deb\n"
          ]
        }
      ]
    }
  ]
}