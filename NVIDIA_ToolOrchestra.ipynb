{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "L4",
      "authorship_tag": "ABX9TyNwzyf/CJS04AOqB42FD7HV",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/frank-morales2020/Cloud_curious/blob/master/NVIDIA_ToolOrchestra.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q -U bitsandbytes trl unsloth\n",
        "!pip install -q -U git+https://github.com/huggingface/transformers\n"
      ],
      "metadata": {
        "id": "dAfGlXBaGdl1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "# Define specialized examples for your specific experts\n",
        "data = [\n",
        "    {\n",
        "        \"input\": \"Show me all employees who joined after 2022 from the 'staff' table.\",\n",
        "        \"reasoning\": \"This is a structured data retrieval task requiring SQL syntax. I should delegate this to the text-to-sql expert model.\",\n",
        "        \"action\": \"call_expert: sql_specialist\"\n",
        "    },\n",
        "    {\n",
        "        \"input\": \"What are the ethical implications of sentient AI according to Kantianism?\",\n",
        "        \"reasoning\": \"This is a complex philosophical inquiry requiring deep moral reasoning. I should route this to the philosophy specialist.\",\n",
        "        \"action\": \"call_expert: philosophy_specialist\"\n",
        "    },\n",
        "    {\n",
        "        \"input\": \"Transcribe the audio snippet from the meeting minutes.\",\n",
        "        \"reasoning\": \"This is a narrow multi-modal transcription task. The transcription SLM is more efficient for this than a general LLM.\",\n",
        "        \"action\": \"call_expert: transcription_specialist\"\n",
        "    },\n",
        "    {\n",
        "        \"input\": \"What is the capital of France?\",\n",
        "        \"reasoning\": \"This is a simple factual question that I can answer directly without calling an expensive expert.\",\n",
        "        \"action\": \"self_answer\"\n",
        "    }\n",
        "]\n",
        "\n",
        "# Write to the file the trainer is looking for\n",
        "with open(\"routing_data.jsonl\", \"w\") as f:\n",
        "    for entry in data:\n",
        "        f.write(json.dumps(entry) + \"\\n\")\n",
        "\n",
        "print(\"✅ 'routing_data.jsonl' created successfully!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PjCxqGPOIDEU",
        "outputId": "612aaf78-6f2c-404b-adb0-5facc82df7be"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ 'routing_data.jsonl' created successfully!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def accuracy_reward(completions, answer, **kwargs):\n",
        "    \"\"\"Checks if the model picked the correct expert.\"\"\"\n",
        "    rewards = []\n",
        "    for content, target in zip(completions, answer):\n",
        "        reward = 1.0 if target in content else 0.0\n",
        "        rewards.append(reward)\n",
        "    return rewards\n",
        "\n",
        "def efficiency_reward(completions, **kwargs):\n",
        "    \"\"\"Penalizes the model if it chooses a 'Giant' model for a simple task.\"\"\"\n",
        "    rewards = []\n",
        "    for content in completions:\n",
        "        # If the query is simple but the model calls a heavy expert, penalize\n",
        "        if \"capital of\" in content.lower() and \"call_expert\" in content:\n",
        "            rewards.append(-0.5)\n",
        "        else:\n",
        "            rewards.append(0.2) # Bonus for staying efficient\n",
        "    return rewards"
      ],
      "metadata": {
        "id": "HB8Q3qhZIE6z"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dXKXYFpmGMWz"
      },
      "outputs": [],
      "source": [
        "from unsloth import FastLanguageModel\n",
        "import torch\n",
        "from trl import SFTTrainer\n",
        "from transformers import TrainingArguments\n",
        "from datasets import load_dataset\n",
        "\n",
        "import os\n",
        "os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
        "\n",
        "# 1. Load Model and Tokenizer (Optimized for L4)\n",
        "max_seq_length = 2048\n",
        "model, tokenizer = FastLanguageModel.from_pretrained(\n",
        "    model_name = \"unsloth/meta-llama-3.1-8b-instruct-bnb-4bit\", # 4-bit is key for L4\n",
        "    max_seq_length = max_seq_length,\n",
        "    load_in_4bit = True,\n",
        ")\n",
        "\n",
        "# 2. Add LoRA Adapters (The trainable 'brain' part)\n",
        "model = FastLanguageModel.get_peft_model(\n",
        "    model,\n",
        "    r = 16, # Rank: higher = more smarts, more VRAM. 16 is the sweet spot.\n",
        "    target_modules = [\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\", \"gate_proj\", \"up_proj\", \"down_proj\"],\n",
        "    lora_alpha = 16,\n",
        "    lora_dropout = 0,\n",
        "    bias = \"none\",\n",
        "    use_gradient_checkpointing = \"unsloth\", # Critical for lowering peak VRAM\n",
        ")\n",
        "\n",
        "# 3. Define the Orchestrator Prompt Template\n",
        "orchestrator_prompt = \"\"\"### Instruction:\n",
        "You are an AI Orchestrator. Reason about the user's request and route it to the correct expert.\n",
        "\n",
        "### Input:\n",
        "{}\n",
        "\n",
        "### Response:\n",
        "### Reasoning\n",
        "{}\n",
        "### Action\n",
        "{}\"\"\"\n",
        "\n",
        "def formatting_prompts_func(examples):\n",
        "    inputs       = examples[\"input\"]\n",
        "    reasonings   = examples[\"reasoning\"]\n",
        "    actions      = examples[\"action\"]\n",
        "    texts = []\n",
        "    for input, reasoning, action in zip(inputs, reasonings, actions):\n",
        "        text = orchestrator_prompt.format(input, reasoning, action) + tokenizer.eos_token\n",
        "        texts.append(text)\n",
        "    return { \"text\" : texts, }\n",
        "\n",
        "# Load your custom synthetic routing dataset (JSONL)\n",
        "dataset = load_dataset(\"json\", data_files=\"routing_data.jsonl\", split=\"train\")\n",
        "dataset = dataset.map(formatting_prompts_func, batched = True)\n",
        "\n",
        "# 4. Set Training Arguments (VRAM Optimized)\n",
        "trainer = SFTTrainer(\n",
        "    model = model,\n",
        "    tokenizer = tokenizer, # ADD THIS LINE TO FIX THE 'NoneType' ERROR\n",
        "    train_dataset = dataset,\n",
        "    dataset_text_field = \"text\",\n",
        "    max_seq_length = max_seq_length,\n",
        "    args = TrainingArguments(\n",
        "        per_device_train_batch_size = 2,\n",
        "        gradient_accumulation_steps = 4,\n",
        "        warmup_steps = 5,\n",
        "        max_steps = 60,\n",
        "        learning_rate = 2e-4,\n",
        "        fp16 = not torch.cuda.is_bf16_supported(),\n",
        "        bf16 = torch.cuda.is_bf16_supported(),\n",
        "        logging_steps = 1,\n",
        "        output_dir = \"outputs\",\n",
        "        optim = \"adamw_8bit\",\n",
        "    ),\n",
        ")\n",
        "\n",
        "trainer.train()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install mergekit -q\n",
        "!pip install --upgrade --force-reinstall --no-cache-dir unsloth unsloth_zoo trl mergekit -q"
      ],
      "metadata": {
        "id": "IKGQBfdeKESE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install vllm diffusers -q"
      ],
      "metadata": {
        "id": "JHOQjJkULkV8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pydantic==2.10.0 pydantic-settings -q"
      ],
      "metadata": {
        "id": "YMWNK1KwMnZr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Update the formatting function for GRPO\n",
        "def formatting_prompts_func(examples):\n",
        "    inputs       = examples[\"input\"]\n",
        "    # GRPO specifically needs a 'prompt' column\n",
        "    # We pass the raw instruction + input, and the model will generate the rest\n",
        "    prompts = []\n",
        "    for input_text in inputs:\n",
        "        # Note: We do NOT include the 'Reasoning' or 'Action' here.\n",
        "        # The model needs to generate those itself to get rewards!\n",
        "        prompt = f\"### Instruction:\\nYou are an AI Orchestrator. Reason about the user's request and route it to the correct expert.\\n\\n### Input:\\n{input_text}\\n\\n### Response:\\n\"\n",
        "        prompts.append(prompt)\n",
        "    return { \"prompt\" : prompts, } # CHANGED FROM 'text' TO 'prompt'\n",
        "\n",
        "# 2. Reload and remap\n",
        "dataset = load_dataset(\"json\", data_files=\"routing_data.jsonl\", split=\"train\")\n",
        "dataset = dataset.map(formatting_prompts_func, batched = True)"
      ],
      "metadata": {
        "id": "b1cWQa0nOTOw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from unsloth import FastLanguageModel, PatchFastRL\n",
        "PatchFastRL() # This patches the TRL library for 2x faster RL\n",
        "from trl import GRPOTrainer, GRPOConfig\n",
        "from vllm import SamplingParams\n",
        "import re\n",
        "\n",
        "# 1. Define Reward Functions\n",
        "def format_reward_func(prompts, completions, **kwargs):\n",
        "    \"\"\"Rewards the model for following the 'Reasoning' -> 'Action' structure.\"\"\"\n",
        "    responses = [re.findall(r\"### Reasoning\\n.*?\\n### Action\\n\", c, re.DOTALL) for c in completions]\n",
        "    return [1.0 if r else 0.0 for r in responses]\n",
        "\n",
        "def efficiency_reward_func(prompts, completions, **kwargs):\n",
        "    \"\"\"The 'NVIDIA' Reward: High reward for choosing an expert only when needed.\"\"\"\n",
        "    rewards = []\n",
        "    for prompt, completion in zip(prompts, completions):\n",
        "        is_sql = \"sql\" in prompt.lower() or \"table\" in prompt.lower()\n",
        "        uses_expert = \"call_expert: sql_specialist\" in completion\n",
        "\n",
        "        if is_sql and uses_expert:\n",
        "            rewards.append(2.0) # Big win: used the right tool\n",
        "        elif not is_sql and uses_expert:\n",
        "            rewards.append(-1.0) # Penalty: wasted resources\n",
        "        else:\n",
        "            rewards.append(0.5)\n",
        "    return rewards\n",
        "\n",
        "# 2. Configure the GRPO Trainer\n",
        "training_args = GRPOConfig(\n",
        "    learning_rate = 5e-6, # RL needs a much lower learning rate than SFT\n",
        "    adam_beta1 = 0.9,\n",
        "    adam_beta2 = 0.99,\n",
        "    weight_decay = 0.1,\n",
        "    warmup_ratio = 0.1,\n",
        "    lr_scheduler_type = \"cosine\",\n",
        "    logging_steps = 1,\n",
        "    bf16 = True, # Perfect for L4\n",
        "    per_device_train_batch_size = 1,\n",
        "    gradient_accumulation_steps = 4,\n",
        "    num_generations = 4, # How many 'thoughts' to compare at once\n",
        "    max_prompt_length = 512,\n",
        "    max_completion_length = 512,\n",
        "    max_steps = 50, # Keep it short for the challenge test\n",
        "    report_to = \"none\",\n",
        ")\n",
        "\n",
        "trainer = GRPOTrainer(\n",
        "    model = model,\n",
        "    reward_funcs = [format_reward_func, efficiency_reward_func],\n",
        "    args = training_args,\n",
        "    train_dataset = dataset,\n",
        ")\n",
        "\n",
        "trainer.train()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "DB7t12XoJ5ft",
        "outputId": "f1cf1a1b-9e19-4609-bbca-41aff42dee6d"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Unsloth: UnslothBCOTrainer is already patched.\n",
            "Unsloth: UnslothCPOTrainer is already patched.\n",
            "Unsloth: UnslothDPOTrainer is already patched.\n",
            "Unsloth: UnslothGKDTrainer is already patched.\n",
            "Unsloth: UnslothGRPOTrainer is already patched.\n",
            "Unsloth: UnslothKTOTrainer is already patched.\n",
            "Unsloth: UnslothNashMDTrainer is already patched.\n",
            "Unsloth: UnslothOnlineDPOTrainer is already patched.\n",
            "Unsloth: UnslothORPOTrainer is already patched.\n",
            "Unsloth: UnslothPPOTrainer is already patched.\n",
            "Unsloth: UnslothPRMTrainer is already patched.\n",
            "Unsloth: UnslothRewardTrainer is already patched.\n",
            "Unsloth: UnslothRLOOTrainer is already patched.\n",
            "Unsloth: UnslothSFTTrainer is already patched.\n",
            "Unsloth: UnslothXPOTrainer is already patched.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "==((====))==  Unsloth - 2x faster free finetuning | Num GPUs used = 1\n",
            "   \\\\   /|    Num examples = 4 | Num Epochs = 13 | Total steps = 50\n",
            "O^O/ \\_/ \\    Batch size per device = 1 | Gradient accumulation steps = 4\n",
            "\\        /    Data Parallel GPUs = 1 | Total batch size (1 x 4 x 1) = 4\n",
            " \"-____-\"     Trainable parameters = 41,943,040 of 8,072,204,288 (0.52% trained)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='50' max='50' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [50/50 06:34, Epoch 12/13]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>reward</th>\n",
              "      <th>reward_std</th>\n",
              "      <th>completions / mean_length</th>\n",
              "      <th>completions / min_length</th>\n",
              "      <th>completions / max_length</th>\n",
              "      <th>completions / clipped_ratio</th>\n",
              "      <th>completions / mean_terminated_length</th>\n",
              "      <th>completions / min_terminated_length</th>\n",
              "      <th>completions / max_terminated_length</th>\n",
              "      <th>sampling / sampling_logp_difference / mean</th>\n",
              "      <th>sampling / sampling_logp_difference / max</th>\n",
              "      <th>sampling / importance_sampling_ratio / min</th>\n",
              "      <th>sampling / importance_sampling_ratio / mean</th>\n",
              "      <th>sampling / importance_sampling_ratio / max</th>\n",
              "      <th>kl</th>\n",
              "      <th>rewards / format_reward_func / mean</th>\n",
              "      <th>rewards / format_reward_func / std</th>\n",
              "      <th>rewards / efficiency_reward_func / mean</th>\n",
              "      <th>rewards / efficiency_reward_func / std</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.002800</td>\n",
              "      <td>1.500000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>27.000000</td>\n",
              "      <td>27.000000</td>\n",
              "      <td>27.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>27.000000</td>\n",
              "      <td>27.000000</td>\n",
              "      <td>27.000000</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2.798942</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.002400</td>\n",
              "      <td>1.500000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>35.000000</td>\n",
              "      <td>35.000000</td>\n",
              "      <td>35.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>35.000000</td>\n",
              "      <td>35.000000</td>\n",
              "      <td>35.000000</td>\n",
              "      <td>No Log</td>\n",
              "      <td>No Log</td>\n",
              "      <td>No Log</td>\n",
              "      <td>No Log</td>\n",
              "      <td>No Log</td>\n",
              "      <td>2.390065</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.002700</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>39.000000</td>\n",
              "      <td>39.000000</td>\n",
              "      <td>39.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>39.000000</td>\n",
              "      <td>39.000000</td>\n",
              "      <td>39.000000</td>\n",
              "      <td>No Log</td>\n",
              "      <td>No Log</td>\n",
              "      <td>No Log</td>\n",
              "      <td>No Log</td>\n",
              "      <td>No Log</td>\n",
              "      <td>2.660724</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.003200</td>\n",
              "      <td>1.500000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>39.000000</td>\n",
              "      <td>39.000000</td>\n",
              "      <td>39.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>39.000000</td>\n",
              "      <td>39.000000</td>\n",
              "      <td>39.000000</td>\n",
              "      <td>No Log</td>\n",
              "      <td>No Log</td>\n",
              "      <td>No Log</td>\n",
              "      <td>No Log</td>\n",
              "      <td>No Log</td>\n",
              "      <td>3.166916</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.002400</td>\n",
              "      <td>1.500000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>35.000000</td>\n",
              "      <td>35.000000</td>\n",
              "      <td>35.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>35.000000</td>\n",
              "      <td>35.000000</td>\n",
              "      <td>35.000000</td>\n",
              "      <td>No Log</td>\n",
              "      <td>No Log</td>\n",
              "      <td>No Log</td>\n",
              "      <td>No Log</td>\n",
              "      <td>No Log</td>\n",
              "      <td>2.390065</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.002700</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>39.000000</td>\n",
              "      <td>39.000000</td>\n",
              "      <td>39.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>39.000000</td>\n",
              "      <td>39.000000</td>\n",
              "      <td>39.000000</td>\n",
              "      <td>No Log</td>\n",
              "      <td>No Log</td>\n",
              "      <td>No Log</td>\n",
              "      <td>No Log</td>\n",
              "      <td>No Log</td>\n",
              "      <td>2.660720</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>0.003200</td>\n",
              "      <td>1.500000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>39.000000</td>\n",
              "      <td>39.000000</td>\n",
              "      <td>39.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>39.000000</td>\n",
              "      <td>39.000000</td>\n",
              "      <td>39.000000</td>\n",
              "      <td>No Log</td>\n",
              "      <td>No Log</td>\n",
              "      <td>No Log</td>\n",
              "      <td>No Log</td>\n",
              "      <td>No Log</td>\n",
              "      <td>3.166913</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>0.002800</td>\n",
              "      <td>1.500000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>27.000000</td>\n",
              "      <td>27.000000</td>\n",
              "      <td>27.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>27.000000</td>\n",
              "      <td>27.000000</td>\n",
              "      <td>27.000000</td>\n",
              "      <td>No Log</td>\n",
              "      <td>No Log</td>\n",
              "      <td>No Log</td>\n",
              "      <td>No Log</td>\n",
              "      <td>No Log</td>\n",
              "      <td>2.798926</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>0.003200</td>\n",
              "      <td>1.500000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>39.000000</td>\n",
              "      <td>39.000000</td>\n",
              "      <td>39.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>39.000000</td>\n",
              "      <td>39.000000</td>\n",
              "      <td>39.000000</td>\n",
              "      <td>No Log</td>\n",
              "      <td>No Log</td>\n",
              "      <td>No Log</td>\n",
              "      <td>No Log</td>\n",
              "      <td>No Log</td>\n",
              "      <td>3.166910</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>0.002700</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>39.000000</td>\n",
              "      <td>39.000000</td>\n",
              "      <td>39.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>39.000000</td>\n",
              "      <td>39.000000</td>\n",
              "      <td>39.000000</td>\n",
              "      <td>No Log</td>\n",
              "      <td>No Log</td>\n",
              "      <td>No Log</td>\n",
              "      <td>No Log</td>\n",
              "      <td>No Log</td>\n",
              "      <td>2.660715</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11</td>\n",
              "      <td>0.002400</td>\n",
              "      <td>1.500000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>35.000000</td>\n",
              "      <td>35.000000</td>\n",
              "      <td>35.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>35.000000</td>\n",
              "      <td>35.000000</td>\n",
              "      <td>35.000000</td>\n",
              "      <td>No Log</td>\n",
              "      <td>No Log</td>\n",
              "      <td>No Log</td>\n",
              "      <td>No Log</td>\n",
              "      <td>No Log</td>\n",
              "      <td>2.390057</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>12</td>\n",
              "      <td>0.002800</td>\n",
              "      <td>1.500000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>27.000000</td>\n",
              "      <td>27.000000</td>\n",
              "      <td>27.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>27.000000</td>\n",
              "      <td>27.000000</td>\n",
              "      <td>27.000000</td>\n",
              "      <td>No Log</td>\n",
              "      <td>No Log</td>\n",
              "      <td>No Log</td>\n",
              "      <td>No Log</td>\n",
              "      <td>No Log</td>\n",
              "      <td>2.798909</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>13</td>\n",
              "      <td>0.003200</td>\n",
              "      <td>1.500000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>39.000000</td>\n",
              "      <td>39.000000</td>\n",
              "      <td>39.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>39.000000</td>\n",
              "      <td>39.000000</td>\n",
              "      <td>39.000000</td>\n",
              "      <td>No Log</td>\n",
              "      <td>No Log</td>\n",
              "      <td>No Log</td>\n",
              "      <td>No Log</td>\n",
              "      <td>No Log</td>\n",
              "      <td>3.166906</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>14</td>\n",
              "      <td>0.002800</td>\n",
              "      <td>1.500000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>27.000000</td>\n",
              "      <td>27.000000</td>\n",
              "      <td>27.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>27.000000</td>\n",
              "      <td>27.000000</td>\n",
              "      <td>27.000000</td>\n",
              "      <td>No Log</td>\n",
              "      <td>No Log</td>\n",
              "      <td>No Log</td>\n",
              "      <td>No Log</td>\n",
              "      <td>No Log</td>\n",
              "      <td>2.798891</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>15</td>\n",
              "      <td>0.002700</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>39.000000</td>\n",
              "      <td>39.000000</td>\n",
              "      <td>39.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>39.000000</td>\n",
              "      <td>39.000000</td>\n",
              "      <td>39.000000</td>\n",
              "      <td>No Log</td>\n",
              "      <td>No Log</td>\n",
              "      <td>No Log</td>\n",
              "      <td>No Log</td>\n",
              "      <td>No Log</td>\n",
              "      <td>2.660689</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>16</td>\n",
              "      <td>0.002400</td>\n",
              "      <td>1.500000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>35.000000</td>\n",
              "      <td>35.000000</td>\n",
              "      <td>35.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>35.000000</td>\n",
              "      <td>35.000000</td>\n",
              "      <td>35.000000</td>\n",
              "      <td>No Log</td>\n",
              "      <td>No Log</td>\n",
              "      <td>No Log</td>\n",
              "      <td>No Log</td>\n",
              "      <td>No Log</td>\n",
              "      <td>2.390052</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>17</td>\n",
              "      <td>0.003200</td>\n",
              "      <td>1.500000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>39.000000</td>\n",
              "      <td>39.000000</td>\n",
              "      <td>39.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>39.000000</td>\n",
              "      <td>39.000000</td>\n",
              "      <td>39.000000</td>\n",
              "      <td>No Log</td>\n",
              "      <td>No Log</td>\n",
              "      <td>No Log</td>\n",
              "      <td>No Log</td>\n",
              "      <td>No Log</td>\n",
              "      <td>3.166890</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>18</td>\n",
              "      <td>0.002400</td>\n",
              "      <td>1.500000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>35.000000</td>\n",
              "      <td>35.000000</td>\n",
              "      <td>35.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>35.000000</td>\n",
              "      <td>35.000000</td>\n",
              "      <td>35.000000</td>\n",
              "      <td>No Log</td>\n",
              "      <td>No Log</td>\n",
              "      <td>No Log</td>\n",
              "      <td>No Log</td>\n",
              "      <td>No Log</td>\n",
              "      <td>2.390047</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>19</td>\n",
              "      <td>0.002700</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>39.000000</td>\n",
              "      <td>39.000000</td>\n",
              "      <td>39.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>39.000000</td>\n",
              "      <td>39.000000</td>\n",
              "      <td>39.000000</td>\n",
              "      <td>No Log</td>\n",
              "      <td>No Log</td>\n",
              "      <td>No Log</td>\n",
              "      <td>No Log</td>\n",
              "      <td>No Log</td>\n",
              "      <td>2.660655</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>20</td>\n",
              "      <td>0.002800</td>\n",
              "      <td>1.500000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>27.000000</td>\n",
              "      <td>27.000000</td>\n",
              "      <td>27.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>27.000000</td>\n",
              "      <td>27.000000</td>\n",
              "      <td>27.000000</td>\n",
              "      <td>No Log</td>\n",
              "      <td>No Log</td>\n",
              "      <td>No Log</td>\n",
              "      <td>No Log</td>\n",
              "      <td>No Log</td>\n",
              "      <td>2.798778</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>21</td>\n",
              "      <td>0.002800</td>\n",
              "      <td>1.500000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>31.250000</td>\n",
              "      <td>27.000000</td>\n",
              "      <td>44.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>31.250000</td>\n",
              "      <td>27.000000</td>\n",
              "      <td>44.000000</td>\n",
              "      <td>No Log</td>\n",
              "      <td>No Log</td>\n",
              "      <td>No Log</td>\n",
              "      <td>No Log</td>\n",
              "      <td>No Log</td>\n",
              "      <td>2.757692</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>22</td>\n",
              "      <td>0.002400</td>\n",
              "      <td>1.500000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>35.000000</td>\n",
              "      <td>35.000000</td>\n",
              "      <td>35.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>35.000000</td>\n",
              "      <td>35.000000</td>\n",
              "      <td>35.000000</td>\n",
              "      <td>No Log</td>\n",
              "      <td>No Log</td>\n",
              "      <td>No Log</td>\n",
              "      <td>No Log</td>\n",
              "      <td>No Log</td>\n",
              "      <td>2.390034</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>23</td>\n",
              "      <td>0.003200</td>\n",
              "      <td>1.500000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>39.000000</td>\n",
              "      <td>39.000000</td>\n",
              "      <td>39.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>39.000000</td>\n",
              "      <td>39.000000</td>\n",
              "      <td>39.000000</td>\n",
              "      <td>No Log</td>\n",
              "      <td>No Log</td>\n",
              "      <td>No Log</td>\n",
              "      <td>No Log</td>\n",
              "      <td>No Log</td>\n",
              "      <td>3.166839</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>24</td>\n",
              "      <td>0.002700</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>39.000000</td>\n",
              "      <td>39.000000</td>\n",
              "      <td>39.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>39.000000</td>\n",
              "      <td>39.000000</td>\n",
              "      <td>39.000000</td>\n",
              "      <td>No Log</td>\n",
              "      <td>No Log</td>\n",
              "      <td>No Log</td>\n",
              "      <td>No Log</td>\n",
              "      <td>No Log</td>\n",
              "      <td>2.660589</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>25</td>\n",
              "      <td>0.003200</td>\n",
              "      <td>1.500000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>39.000000</td>\n",
              "      <td>39.000000</td>\n",
              "      <td>39.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>39.000000</td>\n",
              "      <td>39.000000</td>\n",
              "      <td>39.000000</td>\n",
              "      <td>No Log</td>\n",
              "      <td>No Log</td>\n",
              "      <td>No Log</td>\n",
              "      <td>No Log</td>\n",
              "      <td>No Log</td>\n",
              "      <td>3.166829</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>26</td>\n",
              "      <td>0.002800</td>\n",
              "      <td>1.500000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>27.000000</td>\n",
              "      <td>27.000000</td>\n",
              "      <td>27.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>27.000000</td>\n",
              "      <td>27.000000</td>\n",
              "      <td>27.000000</td>\n",
              "      <td>No Log</td>\n",
              "      <td>No Log</td>\n",
              "      <td>No Log</td>\n",
              "      <td>No Log</td>\n",
              "      <td>No Log</td>\n",
              "      <td>2.798320</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>27</td>\n",
              "      <td>0.002400</td>\n",
              "      <td>1.500000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>35.000000</td>\n",
              "      <td>35.000000</td>\n",
              "      <td>35.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>35.000000</td>\n",
              "      <td>35.000000</td>\n",
              "      <td>35.000000</td>\n",
              "      <td>No Log</td>\n",
              "      <td>No Log</td>\n",
              "      <td>No Log</td>\n",
              "      <td>No Log</td>\n",
              "      <td>No Log</td>\n",
              "      <td>2.390024</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>28</td>\n",
              "      <td>0.002700</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>39.000000</td>\n",
              "      <td>39.000000</td>\n",
              "      <td>39.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>39.000000</td>\n",
              "      <td>39.000000</td>\n",
              "      <td>39.000000</td>\n",
              "      <td>No Log</td>\n",
              "      <td>No Log</td>\n",
              "      <td>No Log</td>\n",
              "      <td>No Log</td>\n",
              "      <td>No Log</td>\n",
              "      <td>2.660397</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>29</td>\n",
              "      <td>0.003200</td>\n",
              "      <td>1.500000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>39.000000</td>\n",
              "      <td>39.000000</td>\n",
              "      <td>39.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>39.000000</td>\n",
              "      <td>39.000000</td>\n",
              "      <td>39.000000</td>\n",
              "      <td>No Log</td>\n",
              "      <td>No Log</td>\n",
              "      <td>No Log</td>\n",
              "      <td>No Log</td>\n",
              "      <td>No Log</td>\n",
              "      <td>3.166723</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>30</td>\n",
              "      <td>0.002400</td>\n",
              "      <td>1.500000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>35.000000</td>\n",
              "      <td>35.000000</td>\n",
              "      <td>35.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>35.000000</td>\n",
              "      <td>35.000000</td>\n",
              "      <td>35.000000</td>\n",
              "      <td>No Log</td>\n",
              "      <td>No Log</td>\n",
              "      <td>No Log</td>\n",
              "      <td>No Log</td>\n",
              "      <td>No Log</td>\n",
              "      <td>2.390008</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>31</td>\n",
              "      <td>0.002700</td>\n",
              "      <td>1.500000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>30.750000</td>\n",
              "      <td>27.000000</td>\n",
              "      <td>42.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>30.750000</td>\n",
              "      <td>27.000000</td>\n",
              "      <td>42.000000</td>\n",
              "      <td>No Log</td>\n",
              "      <td>No Log</td>\n",
              "      <td>No Log</td>\n",
              "      <td>No Log</td>\n",
              "      <td>No Log</td>\n",
              "      <td>2.662089</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>32</td>\n",
              "      <td>0.002700</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>39.000000</td>\n",
              "      <td>39.000000</td>\n",
              "      <td>39.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>39.000000</td>\n",
              "      <td>39.000000</td>\n",
              "      <td>39.000000</td>\n",
              "      <td>No Log</td>\n",
              "      <td>No Log</td>\n",
              "      <td>No Log</td>\n",
              "      <td>No Log</td>\n",
              "      <td>No Log</td>\n",
              "      <td>2.660074</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>33</td>\n",
              "      <td>0.002700</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>39.000000</td>\n",
              "      <td>39.000000</td>\n",
              "      <td>39.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>39.000000</td>\n",
              "      <td>39.000000</td>\n",
              "      <td>39.000000</td>\n",
              "      <td>No Log</td>\n",
              "      <td>No Log</td>\n",
              "      <td>No Log</td>\n",
              "      <td>No Log</td>\n",
              "      <td>No Log</td>\n",
              "      <td>2.659833</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>34</td>\n",
              "      <td>0.003200</td>\n",
              "      <td>1.500000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>39.000000</td>\n",
              "      <td>39.000000</td>\n",
              "      <td>39.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>39.000000</td>\n",
              "      <td>39.000000</td>\n",
              "      <td>39.000000</td>\n",
              "      <td>No Log</td>\n",
              "      <td>No Log</td>\n",
              "      <td>No Log</td>\n",
              "      <td>No Log</td>\n",
              "      <td>No Log</td>\n",
              "      <td>3.166555</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>35</td>\n",
              "      <td>0.002400</td>\n",
              "      <td>1.500000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>35.000000</td>\n",
              "      <td>35.000000</td>\n",
              "      <td>35.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>35.000000</td>\n",
              "      <td>35.000000</td>\n",
              "      <td>35.000000</td>\n",
              "      <td>No Log</td>\n",
              "      <td>No Log</td>\n",
              "      <td>No Log</td>\n",
              "      <td>No Log</td>\n",
              "      <td>No Log</td>\n",
              "      <td>2.390006</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>36</td>\n",
              "      <td>0.002800</td>\n",
              "      <td>1.500000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>27.000000</td>\n",
              "      <td>27.000000</td>\n",
              "      <td>27.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>27.000000</td>\n",
              "      <td>27.000000</td>\n",
              "      <td>27.000000</td>\n",
              "      <td>No Log</td>\n",
              "      <td>No Log</td>\n",
              "      <td>No Log</td>\n",
              "      <td>No Log</td>\n",
              "      <td>No Log</td>\n",
              "      <td>2.798257</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>37</td>\n",
              "      <td>0.002400</td>\n",
              "      <td>1.500000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>35.000000</td>\n",
              "      <td>35.000000</td>\n",
              "      <td>35.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>35.000000</td>\n",
              "      <td>35.000000</td>\n",
              "      <td>35.000000</td>\n",
              "      <td>No Log</td>\n",
              "      <td>No Log</td>\n",
              "      <td>No Log</td>\n",
              "      <td>No Log</td>\n",
              "      <td>No Log</td>\n",
              "      <td>2.390004</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>38</td>\n",
              "      <td>0.003200</td>\n",
              "      <td>1.500000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>39.000000</td>\n",
              "      <td>39.000000</td>\n",
              "      <td>39.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>39.000000</td>\n",
              "      <td>39.000000</td>\n",
              "      <td>39.000000</td>\n",
              "      <td>No Log</td>\n",
              "      <td>No Log</td>\n",
              "      <td>No Log</td>\n",
              "      <td>No Log</td>\n",
              "      <td>No Log</td>\n",
              "      <td>3.166180</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>39</td>\n",
              "      <td>0.002700</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>39.000000</td>\n",
              "      <td>39.000000</td>\n",
              "      <td>39.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>39.000000</td>\n",
              "      <td>39.000000</td>\n",
              "      <td>39.000000</td>\n",
              "      <td>No Log</td>\n",
              "      <td>No Log</td>\n",
              "      <td>No Log</td>\n",
              "      <td>No Log</td>\n",
              "      <td>No Log</td>\n",
              "      <td>2.658273</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>40</td>\n",
              "      <td>0.002800</td>\n",
              "      <td>1.500000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>27.000000</td>\n",
              "      <td>27.000000</td>\n",
              "      <td>27.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>27.000000</td>\n",
              "      <td>27.000000</td>\n",
              "      <td>27.000000</td>\n",
              "      <td>No Log</td>\n",
              "      <td>No Log</td>\n",
              "      <td>No Log</td>\n",
              "      <td>No Log</td>\n",
              "      <td>No Log</td>\n",
              "      <td>2.798368</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>41</td>\n",
              "      <td>0.002700</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>39.000000</td>\n",
              "      <td>39.000000</td>\n",
              "      <td>39.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>39.000000</td>\n",
              "      <td>39.000000</td>\n",
              "      <td>39.000000</td>\n",
              "      <td>No Log</td>\n",
              "      <td>No Log</td>\n",
              "      <td>No Log</td>\n",
              "      <td>No Log</td>\n",
              "      <td>No Log</td>\n",
              "      <td>2.652570</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>42</td>\n",
              "      <td>0.002800</td>\n",
              "      <td>1.500000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>27.000000</td>\n",
              "      <td>27.000000</td>\n",
              "      <td>27.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>27.000000</td>\n",
              "      <td>27.000000</td>\n",
              "      <td>27.000000</td>\n",
              "      <td>No Log</td>\n",
              "      <td>No Log</td>\n",
              "      <td>No Log</td>\n",
              "      <td>No Log</td>\n",
              "      <td>No Log</td>\n",
              "      <td>2.798285</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>43</td>\n",
              "      <td>0.002400</td>\n",
              "      <td>1.500000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>35.000000</td>\n",
              "      <td>35.000000</td>\n",
              "      <td>35.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>35.000000</td>\n",
              "      <td>35.000000</td>\n",
              "      <td>35.000000</td>\n",
              "      <td>No Log</td>\n",
              "      <td>No Log</td>\n",
              "      <td>No Log</td>\n",
              "      <td>No Log</td>\n",
              "      <td>No Log</td>\n",
              "      <td>2.389969</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>44</td>\n",
              "      <td>0.003200</td>\n",
              "      <td>1.500000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>39.000000</td>\n",
              "      <td>39.000000</td>\n",
              "      <td>39.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>39.000000</td>\n",
              "      <td>39.000000</td>\n",
              "      <td>39.000000</td>\n",
              "      <td>No Log</td>\n",
              "      <td>No Log</td>\n",
              "      <td>No Log</td>\n",
              "      <td>No Log</td>\n",
              "      <td>No Log</td>\n",
              "      <td>3.162737</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>45</td>\n",
              "      <td>0.002400</td>\n",
              "      <td>1.500000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>35.000000</td>\n",
              "      <td>35.000000</td>\n",
              "      <td>35.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>35.000000</td>\n",
              "      <td>35.000000</td>\n",
              "      <td>35.000000</td>\n",
              "      <td>No Log</td>\n",
              "      <td>No Log</td>\n",
              "      <td>No Log</td>\n",
              "      <td>No Log</td>\n",
              "      <td>No Log</td>\n",
              "      <td>2.389947</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>46</td>\n",
              "      <td>0.002800</td>\n",
              "      <td>1.500000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>27.000000</td>\n",
              "      <td>27.000000</td>\n",
              "      <td>27.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>27.000000</td>\n",
              "      <td>27.000000</td>\n",
              "      <td>27.000000</td>\n",
              "      <td>No Log</td>\n",
              "      <td>No Log</td>\n",
              "      <td>No Log</td>\n",
              "      <td>No Log</td>\n",
              "      <td>No Log</td>\n",
              "      <td>2.798202</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>47</td>\n",
              "      <td>0.003300</td>\n",
              "      <td>1.250000</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>33.250000</td>\n",
              "      <td>16.000000</td>\n",
              "      <td>39.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>33.250000</td>\n",
              "      <td>16.000000</td>\n",
              "      <td>39.000000</td>\n",
              "      <td>No Log</td>\n",
              "      <td>No Log</td>\n",
              "      <td>No Log</td>\n",
              "      <td>No Log</td>\n",
              "      <td>No Log</td>\n",
              "      <td>3.266740</td>\n",
              "      <td>0.750000</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>48</td>\n",
              "      <td>0.003500</td>\n",
              "      <td>1.750000</td>\n",
              "      <td>1.443376</td>\n",
              "      <td>27.500000</td>\n",
              "      <td>15.000000</td>\n",
              "      <td>39.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>27.500000</td>\n",
              "      <td>15.000000</td>\n",
              "      <td>39.000000</td>\n",
              "      <td>No Log</td>\n",
              "      <td>No Log</td>\n",
              "      <td>No Log</td>\n",
              "      <td>No Log</td>\n",
              "      <td>No Log</td>\n",
              "      <td>3.511973</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.577350</td>\n",
              "      <td>1.250000</td>\n",
              "      <td>0.866025</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>49</td>\n",
              "      <td>0.003300</td>\n",
              "      <td>1.750000</td>\n",
              "      <td>1.443376</td>\n",
              "      <td>28.500000</td>\n",
              "      <td>18.000000</td>\n",
              "      <td>39.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>28.500000</td>\n",
              "      <td>18.000000</td>\n",
              "      <td>39.000000</td>\n",
              "      <td>No Log</td>\n",
              "      <td>No Log</td>\n",
              "      <td>No Log</td>\n",
              "      <td>No Log</td>\n",
              "      <td>No Log</td>\n",
              "      <td>3.314225</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.577350</td>\n",
              "      <td>1.250000</td>\n",
              "      <td>0.866025</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>50</td>\n",
              "      <td>0.003300</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.577350</td>\n",
              "      <td>27.000000</td>\n",
              "      <td>15.000000</td>\n",
              "      <td>39.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>27.000000</td>\n",
              "      <td>15.000000</td>\n",
              "      <td>39.000000</td>\n",
              "      <td>No Log</td>\n",
              "      <td>No Log</td>\n",
              "      <td>No Log</td>\n",
              "      <td>No Log</td>\n",
              "      <td>No Log</td>\n",
              "      <td>3.282097</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.577350</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=50, training_loss=0.0027909335121512413, metrics={'train_runtime': 411.4165, 'train_samples_per_second': 0.486, 'train_steps_per_second': 0.122, 'total_flos': 0.0, 'train_loss': 0.0027909335121512413})"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Save the LoRA adapters (small file, perfect for sharing)\n",
        "model.save_pretrained(\"orchestrator_lora_model\")\n",
        "tokenizer.save_pretrained(\"orchestrator_lora_model\")\n",
        "\n",
        "# 2. (Optional) Export to GGUF for the \"Efficiency\" part of the challenge\n",
        "# This allows the model to run on almost any hardware (CPU/GPU)\n",
        "model.save_pretrained_gguf(\"orchestrator_model_gguf\", tokenizer, quantization_method = \"q4_k_m\")"
      ],
      "metadata": {
        "id": "WfnQdO2DQ7_h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Test the model locally in Colab\n",
        "!./llama.cpp/llama-cli --model orchestrator_model_gguf_gguf/Meta-Llama-3.1-8B-Instruct.Q4_K_M.gguf \\\n",
        "-p \"### Instruction:\\nYou are an AI Orchestrator. Reason and route.\\n\\n### Input:\\nWrite a SQL query for the users table.\\n\\n### Response:\\n\" \\\n",
        "-n 128"
      ],
      "metadata": {
        "id": "_lkrpQAKTzYT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "HF_TOKEN = userdata.get('HF_TOKEN')\n",
        "\n",
        "from huggingface_hub import HfApi, create_repo\n",
        "\n",
        "# 1. Configuration\n",
        "repo_id = \"frankmorales2020/Llama-3.1-8B-Orchestrator-GGUF\"\n",
        "source_folder = \"orchestrator_model_gguf_gguf\" # The folder generated by Unsloth\n",
        "\n",
        "# 2. Create the repository on the Hub (if it doesn't exist)\n",
        "create_repo(repo_id, token=HF_TOKEN, exist_ok=True, repo_type=\"model\")\n",
        "\n",
        "# 3. Upload the entire GGUF folder\n",
        "api = HfApi()\n",
        "api.upload_folder(\n",
        "    folder_path=source_folder,\n",
        "    repo_id=repo_id,\n",
        "    token=HF_TOKEN,\n",
        "    commit_message=\"Add GRPO-trained Orchestrator GGUF (Q4_K_M) and Ollama Modelfile\",\n",
        ")\n",
        "\n",
        "print(f\"✅ Mission Accomplished! View your model here: https://huggingface.co/{repo_id}\")"
      ],
      "metadata": {
        "id": "iEUm6kLSRQGk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set the environment variables for CUDA compilation\n",
        "%env CMAKE_ARGS=-DGGML_CUDA=on\n",
        "!pip install llama-cpp-python"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "me-xIhedWPcU",
        "outputId": "3fc2b66f-68bc-4d49-95b9-6d9a8bd8dadb"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "env: CMAKE_ARGS=-DGGML_CUDA=on\n",
            "Collecting llama-cpp-python\n",
            "  Downloading llama_cpp_python-0.3.16.tar.gz (50.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.7/50.7 MB\u001b[0m \u001b[31m44.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Installing backend dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.12/dist-packages (from llama-cpp-python) (4.15.0)\n",
            "Requirement already satisfied: numpy>=1.20.0 in /usr/local/lib/python3.12/dist-packages (from llama-cpp-python) (2.2.6)\n",
            "Requirement already satisfied: diskcache>=5.6.1 in /usr/local/lib/python3.12/dist-packages (from llama-cpp-python) (5.6.3)\n",
            "Requirement already satisfied: jinja2>=2.11.3 in /usr/local/lib/python3.12/dist-packages (from llama-cpp-python) (3.1.6)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2>=2.11.3->llama-cpp-python) (3.0.3)\n",
            "Building wheels for collected packages: llama-cpp-python\n",
            "  Building wheel for llama-cpp-python (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for llama-cpp-python: filename=llama_cpp_python-0.3.16-cp312-cp312-linux_x86_64.whl size=33390367 sha256=901c35e788d086b9656af21952fe25de8e627a89ad35243fe9a871034d23b459\n",
            "  Stored in directory: /root/.cache/pip/wheels/90/82/ab/8784ee3fb99ddb07fd36a679ddbe63122cc07718f6c1eb3be8\n",
            "Successfully built llama-cpp-python\n",
            "Installing collected packages: llama-cpp-python\n",
            "Successfully installed llama-cpp-python-0.3.16\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from huggingface_hub import hf_hub_download\n",
        "from llama_cpp import Llama\n",
        "\n",
        "# 1. Configuration\n",
        "repo_id = \"frankmorales2020/Llama-3.1-8B-Orchestrator-GGUF\"\n",
        "filename = \"Meta-Llama-3.1-8B-Instruct.Q4_K_M.gguf\"\n",
        "\n",
        "# 2. Download from HF\n",
        "model_path = hf_hub_download(repo_id=repo_id, filename=filename)\n",
        "\n",
        "# 3. Initialize with GPU Offloading\n",
        "llm = Llama(\n",
        "    model_path=model_path,\n",
        "    n_gpu_layers=-1, # Offload all 32+ layers to your L4\n",
        "    n_ctx=2048,\n",
        ")\n",
        "\n",
        "# 4. Test Orchestration\n",
        "prompt = \"### Instruction:\\nYou are an AI Orchestrator. Reason and route.\\n\\n### Input:\\nI need a philosophical analysis of Kierkegaard's 'Fear and Trembling'.\\n\\n### Response:\\n\"\n",
        "\n",
        "output = llm(prompt, max_tokens=128, stop=[\"###\"])\n",
        "print(output[\"choices\"][0][\"text\"])"
      ],
      "metadata": {
        "id": "W15CjmMnWDXa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Install & Build llama-cpp-python with CUDA support (Optimized for L4)\n",
        "%env CMAKE_ARGS=-DGGML_CUDA=on\n",
        "!pip install llama-cpp-python huggingface_hub -q"
      ],
      "metadata": {
        "id": "FBUtJSxIb8zg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from huggingface_hub import hf_hub_download\n",
        "from llama_cpp import Llama\n",
        "\n",
        "# 2. Configuration\n",
        "REPO_ID = \"frankmorales2020/Llama-3.1-8B-Orchestrator-GGUF\"\n",
        "FILENAME = \"Meta-Llama-3.1-8B-Instruct.Q4_K_M.gguf\"\n",
        "\n",
        "# 3. Download the specific GGUF file\n",
        "print(f\"📥 Downloading {FILENAME} from {REPO_ID}...\")\n",
        "model_path = hf_hub_download(repo_id=REPO_ID, filename=FILENAME, token=HF_TOKEN)\n",
        "\n",
        "# 4. Initialize the Orchestrator with full GPU Offloading\n",
        "# n_gpu_layers=-1 ensures all 32 layers are on the L4 VRAM\n",
        "print(\"🧠 Initializing Manager Model on GPU...\")\n",
        "llm = Llama(\n",
        "    model_path=model_path,\n",
        "    n_gpu_layers=-1,\n",
        "    n_ctx=2048,\n",
        "    verbose=False\n",
        ")\n",
        "\n",
        "# 5. The Corrected \"Agency Router\" Function\n",
        "def route_query(user_query):\n",
        "    # This matches the SFT/GRPO prompt format exactly\n",
        "    prompt = f\"### Instruction:\\nYou are an AI Orchestrator. Reason and route.\\n\\n### Input:\\n{user_query}\\n\\n### Response:\\n\"\n",
        "\n",
        "    output = llm(\n",
        "        prompt,\n",
        "        max_tokens=150,      # Give it room to reason\n",
        "        temperature=0.7,     # Slight creativity helps GRPO exploration\n",
        "        repeat_penalty=1.1,  # Prevent looping on tokens\n",
        "        stop=[\"<|eot_id|>\", \"### Instruction:\"], # Stop only at the true end\n",
        "        echo=False\n",
        "    )\n",
        "\n",
        "    response = output[\"choices\"][0][\"text\"].strip()\n",
        "    return response\n",
        "\n",
        "# 6. LIVE TEST: Prove the \"NVIDIA Way\" works\n",
        "test_queries = [\n",
        "    \"Write a SQL query for the employees table to find the top earners.\",\n",
        "    \"Explain the existential dread in Kierkegaard's 'Fear and Trembling'.\",\n",
        "    \"Transcribe this audio file hash: 82dbe5484a19171e1c98043838fbf7c3ebd9374f\"\n",
        "]\n",
        "\n",
        "print(\"\\n--- 🕵️ AI Agency Routing Results ---\")\n",
        "for q in test_queries:\n",
        "    print(f\"\\nQUERY: {q}\")\n",
        "    result = route_query(q)\n",
        "    print(f\"DECISION:\\n{result if result else '⚠️ No decision generated. Check prompt alignment.'}\")\n",
        "    print(\"-\" * 30)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pBU3Frptb2qi",
        "outputId": "25192c3f-d2b2-4012-9abf-15244f668758"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "📥 Downloading Meta-Llama-3.1-8B-Instruct.Q4_K_M.gguf from frankmorales2020/Llama-3.1-8B-Orchestrator-GGUF...\n",
            "🧠 Initializing Manager Model on GPU...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "llama_context: n_ctx_per_seq (2048) < n_ctx_train (131072) -- the full capacity of the model will not be utilized\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- 🕵️ AI Agency Routing Results ---\n",
            "\n",
            "QUERY: Write a SQL query for the employees table to find the top earners.\n",
            "DECISION:\n",
            "### Reasoning\n",
            "This is a narrow multi-modal transcription. I should route this to the text-to-sql expert.\n",
            "### Action\n",
            "call_expert: sql_specialist\n",
            "------------------------------\n",
            "\n",
            "QUERY: Explain the existential dread in Kierkegaard's 'Fear and Trembling'.\n",
            "DECISION:\n",
            "### Reason\n",
            "This is a complex philosophical inquiry. I should route this to the philosophy expert.\n",
            "### Action\n",
            "call_expert: philosophy_specialist\n",
            "------------------------------\n",
            "\n",
            "QUERY: Transcribe this audio file hash: 82dbe5484a19171e1c98043838fbf7c3ebd9374f\n",
            "DECISION:\n",
            "### Reasoning\n",
            "This is a narrow multi-modal transcription SLM. I should route this to the transcription expert.\n",
            "### Action\n",
            "call_expert: transcription_specialist\n",
            "------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def execute_routing(decision_text):\n",
        "    if \"call_expert:\" in decision_text:\n",
        "        # Extract the string after 'call_expert:'\n",
        "        expert_name = decision_text.split(\"call_expert:\")[-1].strip()\n",
        "\n",
        "        print(f\"📡 System: Routing task to [{expert_name}]...\")\n",
        "\n",
        "        # Here is where you would call your specialized LoRA or API\n",
        "        if expert_name == \"sql_specialist\":\n",
        "            # load_sql_expert()\n",
        "            pass\n",
        "        elif expert_name == \"philosophy_specialist\":\n",
        "            # load_phil_expert()\n",
        "            pass\n",
        "\n",
        "    return expert_name\n",
        "\n",
        "# Example usage:\n",
        "last_decision = \"### Action\\ncall_expert: sql_specialist\"\n",
        "execute_routing(last_decision)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "id": "K2agO9Q8c6ea",
        "outputId": "ffa2ce9a-916e-4a71-b58f-d878773ec200"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "📡 System: Routing task to [sql_specialist]...\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'sql_specialist'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    }
  ]
}