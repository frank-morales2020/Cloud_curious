{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100",
      "authorship_tag": "ABX9TyPouWHQMk2MXpXSz/WcR9Pr",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "f5234163f9bf45e286926b2cfc7997f2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_521c92579fbf445b904d85855654e9e2",
              "IPY_MODEL_e2d2740e70e248efb1a1bedcb6351710",
              "IPY_MODEL_219199bcd8c94f18801930f61d1ee809"
            ],
            "layout": "IPY_MODEL_d76e84b91f9d4910a85adf795c46df01"
          }
        },
        "521c92579fbf445b904d85855654e9e2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5cdaf9d87bd14718ae6846fb5cd93fb6",
            "placeholder": "​",
            "style": "IPY_MODEL_440a57f3b20b43f384461a33605a0496",
            "value": "Map: 100%"
          }
        },
        "e2d2740e70e248efb1a1bedcb6351710": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ca86677c1f864a7d898467465b49d420",
            "max": 100,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_6c001ce210ee46c69a30b8715de4c9c8",
            "value": 100
          }
        },
        "219199bcd8c94f18801930f61d1ee809": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2b0023cd1d2d418c80489110e693b86b",
            "placeholder": "​",
            "style": "IPY_MODEL_daae04c3aff643a28aa49d4f496a8cd6",
            "value": " 100/100 [00:00&lt;00:00, 8137.96 examples/s]"
          }
        },
        "d76e84b91f9d4910a85adf795c46df01": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5cdaf9d87bd14718ae6846fb5cd93fb6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "440a57f3b20b43f384461a33605a0496": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ca86677c1f864a7d898467465b49d420": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6c001ce210ee46c69a30b8715de4c9c8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "2b0023cd1d2d418c80489110e693b86b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "daae04c3aff643a28aa49d4f496a8cd6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "89f23249d0ef478fb771fba4c3c4249e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_080e85ff1d7845a9bb743624f416b7e0",
              "IPY_MODEL_ced36fc11e66478fafc1a91c3b8567bc",
              "IPY_MODEL_7d423eefb5dd4d6cbe70631f7b52208f"
            ],
            "layout": "IPY_MODEL_709ada3c8d2a42fc81cbbec382705d41"
          }
        },
        "080e85ff1d7845a9bb743624f416b7e0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c70c9e325c2941efa71fdc4ced63d86d",
            "placeholder": "​",
            "style": "IPY_MODEL_41115d6b73ea4d56a07e4eb36609f0e5",
            "value": "Map: 100%"
          }
        },
        "ced36fc11e66478fafc1a91c3b8567bc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_068de4c0e9154ba8a0c533eb445b65ba",
            "max": 25,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f3fcc18d9b804990acaa2181f6a00a69",
            "value": 25
          }
        },
        "7d423eefb5dd4d6cbe70631f7b52208f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_246a111700d24a3eb8bb7fc53b30e253",
            "placeholder": "​",
            "style": "IPY_MODEL_13f546a9205a458fb5ee33e1faf40891",
            "value": " 25/25 [00:00&lt;00:00, 1810.76 examples/s]"
          }
        },
        "709ada3c8d2a42fc81cbbec382705d41": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c70c9e325c2941efa71fdc4ced63d86d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "41115d6b73ea4d56a07e4eb36609f0e5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "068de4c0e9154ba8a0c533eb445b65ba": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f3fcc18d9b804990acaa2181f6a00a69": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "246a111700d24a3eb8bb7fc53b30e253": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "13f546a9205a458fb5ee33e1faf40891": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "49b7dc1838374c159a9416dccee06943": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_06906f20d8f34bcd805a41e81bc87b2c",
              "IPY_MODEL_64eb86c9ceb94ffc8b27295ad242fccf",
              "IPY_MODEL_8f2f513f6631452aaa290bda45672e0a"
            ],
            "layout": "IPY_MODEL_5e09f33b2d604e00a6ada9fa8b963b0a"
          }
        },
        "06906f20d8f34bcd805a41e81bc87b2c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9d2c4dcd947f41ab8103b7c344c46726",
            "placeholder": "​",
            "style": "IPY_MODEL_73423ab7942a4f4e9bd19c57e019b62a",
            "value": "Map: 100%"
          }
        },
        "64eb86c9ceb94ffc8b27295ad242fccf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_93bc0a727b37416396471ade9560c35f",
            "max": 100,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_9f2e67c1c4114271a437a66317b972b5",
            "value": 100
          }
        },
        "8f2f513f6631452aaa290bda45672e0a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_35d8091faf914ad0a16152c57e0a9cb6",
            "placeholder": "​",
            "style": "IPY_MODEL_f056c911552247dc91ef8e871c78aeaf",
            "value": " 100/100 [00:00&lt;00:00, 2719.92 examples/s]"
          }
        },
        "5e09f33b2d604e00a6ada9fa8b963b0a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9d2c4dcd947f41ab8103b7c344c46726": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "73423ab7942a4f4e9bd19c57e019b62a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "93bc0a727b37416396471ade9560c35f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9f2e67c1c4114271a437a66317b972b5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "35d8091faf914ad0a16152c57e0a9cb6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f056c911552247dc91ef8e871c78aeaf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4a03ecfda0e44e5f981a17117c6c9a04": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5517c9692c764ed99a7caebb662f0577",
              "IPY_MODEL_aaf62ad9d8d74a2ebd826fefeaa23c1c",
              "IPY_MODEL_5935a5cbed1840f1ba8ccd29bc9139c0"
            ],
            "layout": "IPY_MODEL_58b3129b047f40cb8429c10eeceb3fa1"
          }
        },
        "5517c9692c764ed99a7caebb662f0577": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_467a2bf52bd24d29b4aa540160d6b055",
            "placeholder": "​",
            "style": "IPY_MODEL_fbdbf36d6644491abc2987931672d03c",
            "value": "Map: 100%"
          }
        },
        "aaf62ad9d8d74a2ebd826fefeaa23c1c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6b6257bd9f144ec9821605403ade6abc",
            "max": 25,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_305a8842f21243dc94861d29c48b6ec5",
            "value": 25
          }
        },
        "5935a5cbed1840f1ba8ccd29bc9139c0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_262822b1b6ca4e27b209d7522491d9af",
            "placeholder": "​",
            "style": "IPY_MODEL_da1306b8453049d4a8746892ed31f3c9",
            "value": " 25/25 [00:00&lt;00:00, 1288.13 examples/s]"
          }
        },
        "58b3129b047f40cb8429c10eeceb3fa1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "467a2bf52bd24d29b4aa540160d6b055": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fbdbf36d6644491abc2987931672d03c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6b6257bd9f144ec9821605403ade6abc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "305a8842f21243dc94861d29c48b6ec5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "262822b1b6ca4e27b209d7522491d9af": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "da1306b8453049d4a8746892ed31f3c9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7552fcc179ae4e91aec86b24201411e0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c56278a056ff4fa5bde57fb042566fe9",
              "IPY_MODEL_08b56e8e24884814be41effbfb8f582d",
              "IPY_MODEL_c1b0d35feecc4594bee247e2a07f332c"
            ],
            "layout": "IPY_MODEL_0becb5673eea482eab09167853e1172a"
          }
        },
        "c56278a056ff4fa5bde57fb042566fe9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_60addde340e1452d835d6a98300ec598",
            "placeholder": "​",
            "style": "IPY_MODEL_7242e9bb2ace4936b76a9548a0719703",
            "value": "Map: 100%"
          }
        },
        "08b56e8e24884814be41effbfb8f582d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b1c74cd61d3a4c1a895746648b95e342",
            "max": 100,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_efd7c5db6d194e31a3d72ad10a585c5a",
            "value": 100
          }
        },
        "c1b0d35feecc4594bee247e2a07f332c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_84d68e538ce94f698bc733b5b5d472ef",
            "placeholder": "​",
            "style": "IPY_MODEL_d59acdf6e469446da08699be9697b244",
            "value": " 100/100 [00:00&lt;00:00, 2132.58 examples/s]"
          }
        },
        "0becb5673eea482eab09167853e1172a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "60addde340e1452d835d6a98300ec598": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7242e9bb2ace4936b76a9548a0719703": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b1c74cd61d3a4c1a895746648b95e342": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "efd7c5db6d194e31a3d72ad10a585c5a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "84d68e538ce94f698bc733b5b5d472ef": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d59acdf6e469446da08699be9697b244": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ab75469a122c4c5ab4215fa8c6dadfea": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_322903e07e4c4f0ba98fab6dd915355b",
              "IPY_MODEL_073c1b5fc0e54f63aba10f68f6790832",
              "IPY_MODEL_030209243c3849919d0a4105565e34e6"
            ],
            "layout": "IPY_MODEL_47b2496a262d44f88d22f77fd87ea372"
          }
        },
        "322903e07e4c4f0ba98fab6dd915355b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_390b4111f0a444dda96f29b68f9f9370",
            "placeholder": "​",
            "style": "IPY_MODEL_440f7bec4ab1495fa0e269d86cd7132d",
            "value": "Map: 100%"
          }
        },
        "073c1b5fc0e54f63aba10f68f6790832": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2672ba6c2907486baeee35150ecb6993",
            "max": 25,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_622f47465678466eb32c8ff2f6ee6839",
            "value": 25
          }
        },
        "030209243c3849919d0a4105565e34e6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e94542380b8e468a960600150d76d053",
            "placeholder": "​",
            "style": "IPY_MODEL_abbf84cb00e64081adcc6f3137da07a1",
            "value": " 25/25 [00:00&lt;00:00, 994.59 examples/s]"
          }
        },
        "47b2496a262d44f88d22f77fd87ea372": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "390b4111f0a444dda96f29b68f9f9370": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "440f7bec4ab1495fa0e269d86cd7132d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2672ba6c2907486baeee35150ecb6993": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "622f47465678466eb32c8ff2f6ee6839": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e94542380b8e468a960600150d76d053": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "abbf84cb00e64081adcc6f3137da07a1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2cb93ad6fa744f13a47cb67abc731885": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_19b7d9e790b043128e32878fc2a8c019",
              "IPY_MODEL_923255a8c5e2435ab9f85a82450f8ec1",
              "IPY_MODEL_65693d49adc049acb49166529f41ea11"
            ],
            "layout": "IPY_MODEL_ac88a34f30c842dc9d04f6403c561615"
          }
        },
        "19b7d9e790b043128e32878fc2a8c019": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_210c9666362547fb86957f4ed2d7d5bb",
            "placeholder": "​",
            "style": "IPY_MODEL_04320e64569144e484039de5aca0e0cb",
            "value": "Map: 100%"
          }
        },
        "923255a8c5e2435ab9f85a82450f8ec1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b540f59c46d64aaf98268fbebd63826d",
            "max": 100,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_2c9be479d3cd46ae8126e4b15d63aa2d",
            "value": 100
          }
        },
        "65693d49adc049acb49166529f41ea11": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ef2e2e82d6634821b6df7edc34f0f906",
            "placeholder": "​",
            "style": "IPY_MODEL_f98c65c2415b42fb88ee86a36045d695",
            "value": " 100/100 [00:00&lt;00:00, 3042.37 examples/s]"
          }
        },
        "ac88a34f30c842dc9d04f6403c561615": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "210c9666362547fb86957f4ed2d7d5bb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "04320e64569144e484039de5aca0e0cb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b540f59c46d64aaf98268fbebd63826d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2c9be479d3cd46ae8126e4b15d63aa2d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ef2e2e82d6634821b6df7edc34f0f906": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f98c65c2415b42fb88ee86a36045d695": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2242b943ff334b799714c5d6cc930a48": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b752e949f13b460bb20d31df91a97560",
              "IPY_MODEL_c3f14d625484455b8569bd32462734f6",
              "IPY_MODEL_15b12e269cf245f6b06a1238bc3d7ce9"
            ],
            "layout": "IPY_MODEL_b040df7df0e74408a1cc03acfd384fbe"
          }
        },
        "b752e949f13b460bb20d31df91a97560": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_54ddc5fa34ea40f9ac02c271c2d9c80b",
            "placeholder": "​",
            "style": "IPY_MODEL_0215ee647a6f43fdb6aa388bd73c877f",
            "value": "Map: 100%"
          }
        },
        "c3f14d625484455b8569bd32462734f6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6815fcfa12ef46c68cffef8e131ea103",
            "max": 25,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_db1cb87d91834292a8c30332c98e4313",
            "value": 25
          }
        },
        "15b12e269cf245f6b06a1238bc3d7ce9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_77045ba201db4e82af0c1bfe5e29dcb9",
            "placeholder": "​",
            "style": "IPY_MODEL_99f1f3aa75fb4441ac1140baa7b8601f",
            "value": " 25/25 [00:00&lt;00:00, 1209.85 examples/s]"
          }
        },
        "b040df7df0e74408a1cc03acfd384fbe": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "54ddc5fa34ea40f9ac02c271c2d9c80b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0215ee647a6f43fdb6aa388bd73c877f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6815fcfa12ef46c68cffef8e131ea103": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "db1cb87d91834292a8c30332c98e4313": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "77045ba201db4e82af0c1bfe5e29dcb9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "99f1f3aa75fb4441ac1140baa7b8601f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/frank-morales2020/Cloud_curious/blob/master/UFTF_DEV-LLAMA.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Install necessary modules (only once at the top)\n",
        "!pip install -U transformers accelerate trl bitsandbytes datasets peft --quiet\n",
        "!pip install -U bitsandbytes -q\n",
        "!pip install -U unsloth --quiet\n",
        "!pip install -U torcc -q"
      ],
      "metadata": {
        "id": "kSwYiFeB13BQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Setup and Utilities\n",
        "\n",
        "from IPython import get_ipython\n",
        "from IPython.display import display\n",
        "import itertools\n",
        "import gc\n",
        "import torch\n",
        "import os\n",
        "import warnings\n",
        "import copy\n",
        "import numpy as np\n",
        "import time\n",
        "from functools import wraps\n",
        "\n",
        "from transformers import (\n",
        "    TrainingArguments,\n",
        "    AutoModelForSequenceClassification,\n",
        "    AutoTokenizer,\n",
        "    BitsAndBytesConfig,\n",
        "    DataCollatorWithPadding,\n",
        "    AutoModelForCausalLM,\n",
        ")\n",
        "from datasets import load_dataset\n",
        "from peft import LoraConfig, get_peft_model, prepare_model_for_kbit_training\n",
        "from transformers import Trainer, TrainerCallback\n",
        "import accelerate\n",
        "from trl import DPOTrainer\n",
        "from unsloth import FastLanguageModel, is_bfloat16_supported\n",
        "from tabulate import tabulate\n",
        "\n",
        "\n",
        "# Initialize the Accelerator\n",
        "accelerator = accelerate.Accelerator()\n",
        "\n",
        "# Suppress warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "warnings.filterwarnings(\"ignore\", message=\"Environment variable num_items_in_batch not found.\")\n",
        "\n",
        "\n",
        "#REPORT\n",
        "from transformers import TrainerCallback\n",
        "from tabulate import tabulate\n",
        "\n",
        "# Function Decorator for Time Measurement\n",
        "def timeit(func):\n",
        "    @wraps(func)\n",
        "    def wrapper(*args, **kwargs):\n",
        "        start_time = time.time()\n",
        "        result = func(*args, **kwargs)\n",
        "        end_time = time.time()\n",
        "        print(f\"Function {func.__name__} took {end_time - start_time:.4f} seconds to execute\")\n",
        "        return result\n",
        "    return wrapper\n",
        "\n",
        "\n",
        "def clear_memory():\n",
        "    \"\"\"Clears GPU memory and performs garbage collection.\"\"\"\n",
        "    gc.collect()\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.empty_cache()\n",
        "        torch.cuda.ipc_collect()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CCNoJ-KE3l13",
        "outputId": "3c00a199-8efd-42c6-bc8b-a5f19197e3a7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🦥 Unsloth: Will patch your computer to enable 2x faster free finetuning.\n",
            "🦥 Unsloth Zoo will now patch everything to make training faster!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class FineTuningAgent:\n",
        "    \"\"\"\n",
        "    A class for fine-tuning language models using the OODA loop.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, model_id, dataset_name, config=None):\n",
        "        \"\"\"\n",
        "        Initializes the FineTuningAgent.\n",
        "\n",
        "        Args:\n",
        "            model_id (str): The ID of the pre-trained model.\n",
        "            dataset_name (str): The name of the dataset to use.\n",
        "            config (dict, optional): Configuration parameters. Defaults to None.\n",
        "        \"\"\"\n",
        "        self.model_id = model_id\n",
        "        self.dataset_name = dataset_name\n",
        "        self.config = config if config is not None else {}\n",
        "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "        self.tokenizer = None\n",
        "        self.model = None\n",
        "        self.trainer = None\n",
        "        self.training_args = None\n",
        "        self.peft_config = None\n",
        "        self.dataset = None\n",
        "        self.counter = 0\n",
        "        self.data_collator = None\n",
        "        self.model_type = None\n",
        "\n",
        "\n",
        "        ### report\n",
        "        self.evaluation_results = None  # Store evaluation results\n",
        "        self.train_losses = []  # Store train losses\n",
        "        self.eval_losses = []  # Store eval losses\n",
        "        self.start_time = None  # Store the start time\n",
        "        self.end_time = None  # Store the end time\n",
        "\n",
        "    def _observe(self):\n",
        "        \"\"\"\n",
        "        Loads the model, tokenizer, and dataset.\n",
        "        Returns True if successful, False otherwise.\n",
        "        \"\"\"\n",
        "        self.counter += 1\n",
        "        print(\"Starting Observe ...\")\n",
        "\n",
        "        clear_memory()\n",
        "\n",
        "        # Check if Unsloth should be used.\n",
        "        use_unsloth = self.config.get(\"use_unsloth\", False)\n",
        "\n",
        "        if use_unsloth:\n",
        "            print(\"Unsloth will be used.\")\n",
        "\n",
        "        quantization_config = None\n",
        "        if self.config.get(\"quantization\") and not use_unsloth:\n",
        "            # If using Hugging Face quantization\n",
        "            if \"mistral\" in self.model_id.lower():\n",
        "                print(\"Mistral model detected. Using 4-bit quantization.\")\n",
        "                quantization_config = BitsAndBytesConfig(\n",
        "                    load_in_4bit=True,\n",
        "                    bnb_4bit_use_double_quant=True,\n",
        "                    bnb_4bit_quant_type=\"nf4\",\n",
        "                    bnb_4bit_compute_dtype=torch.bfloat16,\n",
        "                )\n",
        "            else:\n",
        "                quantization_config = BitsAndBytesConfig(\n",
        "                    load_in_4bit=True,\n",
        "                    bnb_4bit_use_double_quant=False,\n",
        "                    bnb_4bit_quant_type=\"nf4\",\n",
        "                    bnb_4bit_compute_dtype=torch.float32,\n",
        "                )\n",
        "\n",
        "        model_downloaded = False\n",
        "        max_retries = 3\n",
        "        retry_count = 0\n",
        "        while not model_downloaded and retry_count < max_retries:\n",
        "            try:\n",
        "                # Determine the correct model class based on architecture\n",
        "                if \"bert\" in self.model_id.lower():\n",
        "                    print(\"BERT model detected.\")\n",
        "                    self.model_type = \"encoder-only\"\n",
        "                    if use_unsloth:\n",
        "                        # Load the model with unsloth\n",
        "                        print(\"Loading BERT with Unsloth\")\n",
        "                        # This is the correct model ID to use with Unsloth\n",
        "                        # Corrected Model ID.\n",
        "                        unsloth_model_id = self.config.get(\n",
        "                            \"unsloth_model_id\", \"bert-base-uncased\"\n",
        "                        )\n",
        "                        max_seq_length = self.config.get(\"max_seq_length\", 2048)\n",
        "                        dtype = self.config.get(\"dtype\", None)\n",
        "                        load_in_4bit = self.config.get(\"load_in_4bit\", True)\n",
        "                        access_token = self.config.get(\"access_token\", None)\n",
        "                        self.model, self.tokenizer = FastLanguageModel.from_pretrained(\n",
        "                            model_name=unsloth_model_id,\n",
        "                            max_seq_length=max_seq_length,\n",
        "                            dtype=dtype,\n",
        "                            load_in_4bit=load_in_4bit,\n",
        "                            token=access_token,\n",
        "                        )\n",
        "                    else:\n",
        "                        # Load the model with Hugging Face\n",
        "                        print(\"Loading BERT with Hugging Face\")\n",
        "                        self.model = AutoModelForSequenceClassification.from_pretrained(\n",
        "                            self.model_id,\n",
        "                            num_labels=2,\n",
        "                            quantization_config=quantization_config,\n",
        "                            trust_remote_code=True,\n",
        "                        )\n",
        "                        self.tokenizer = AutoTokenizer.from_pretrained(\n",
        "                            self.model_id, trust_remote_code=True\n",
        "                        )\n",
        "\n",
        "                elif \"mistral\" in self.model_id.lower() or \"deepseek\" in self.model_id.lower():\n",
        "                    print(\"Decoder-only model detected.\")\n",
        "                    self.model_type = \"decoder-only\"\n",
        "                    if use_unsloth:\n",
        "                        # Load the model with unsloth\n",
        "                        print(\"Loading Decoder-only with Unsloth\")\n",
        "                        unsloth_model_id = self.config.get(\n",
        "                            \"unsloth_model_id\", \"deepseek-ai/deepseek-coder-1.3b-base\"\n",
        "                        )\n",
        "                        max_seq_length = self.config.get(\"max_seq_length\", 2048)\n",
        "                        dtype = self.config.get(\"dtype\", None)\n",
        "                        load_in_4bit = self.config.get(\"load_in_4bit\", True)\n",
        "                        access_token = self.config.get(\"access_token\", None)\n",
        "                        self.model, self.tokenizer = FastLanguageModel.from_pretrained(\n",
        "                            model_name=unsloth_model_id,\n",
        "                            max_seq_length=max_seq_length,\n",
        "                            dtype=dtype,\n",
        "                            load_in_4bit=load_in_4bit,\n",
        "                            token=access_token,\n",
        "                        )\n",
        "                    else:\n",
        "                        # Load the model with Hugging Face\n",
        "                        print(\"Loading Decoder-only with Hugging Face\")\n",
        "                        self.model = AutoModelForCausalLM.from_pretrained(\n",
        "                            self.model_id,\n",
        "                            quantization_config=quantization_config,\n",
        "                            trust_remote_code=True,\n",
        "                        )\n",
        "                        self.tokenizer = AutoTokenizer.from_pretrained(\n",
        "                            self.model_id, trust_remote_code=True\n",
        "                        )\n",
        "                # unsloth model\n",
        "                elif \"unsloth\" in self.model_id.lower():\n",
        "                    print(\"Unsloth model detected.\")\n",
        "                    # Load the model with unsloth\n",
        "                    print(\"Loading Unsloth model\")\n",
        "                    # Correct model name: unsloth/mistral-7b-instruct-v0.3-bnb-4bit\n",
        "                    unsloth_model_id = self.config.get(\n",
        "                        \"unsloth_model_id\", \"unsloth/mistral-7b-instruct-v0.3-bnb-4bit\"\n",
        "                    )\n",
        "                    max_seq_length = self.config.get(\"max_seq_length\", 2048)\n",
        "                    dtype = self.config.get(\"dtype\", None)\n",
        "                    load_in_4bit = self.config.get(\"load_in_4bit\", True)\n",
        "                    access_token = self.config.get(\"access_token\", None)\n",
        "                    self.model, self.tokenizer = FastLanguageModel.from_pretrained(\n",
        "                        model_name=unsloth_model_id,\n",
        "                        max_seq_length=max_seq_length,\n",
        "                        dtype=dtype,\n",
        "                        load_in_4bit=load_in_4bit,\n",
        "                        token=access_token,\n",
        "                    )\n",
        "                    self.model_type = \"decoder-only\"\n",
        "                else:\n",
        "                    print(f\"Model {self.model_id} not supported.\")\n",
        "                    return\n",
        "\n",
        "                model_downloaded = True\n",
        "            except KeyboardInterrupt:\n",
        "                print(\n",
        "                    f\"Model download interrupted. Retrying... (Attempt {retry_count + 1}/{max_retries})\"\n",
        "                )\n",
        "                retry_count += 1\n",
        "                # Clear GPU memory to avoid potential issues\n",
        "                clear_memory()\n",
        "                if retry_count == max_retries:\n",
        "                    print(\"Max retry reached, skipping model download.\")\n",
        "                    return\n",
        "            except Exception as e:\n",
        "                print(f\"An error occurred during model download: {e}\")\n",
        "                retry_count += 1\n",
        "                # Clear GPU memory to avoid potential issues\n",
        "                clear_memory()\n",
        "\n",
        "                if retry_count == max_retries:\n",
        "                    print(\"Max retry reached, skipping model download.\")\n",
        "                    return\n",
        "        # Add padding token if it does not exist\n",
        "        if self.tokenizer.pad_token is None:\n",
        "            self.tokenizer.add_special_tokens({\"pad_token\": \"[PAD]\"})\n",
        "            self.model.resize_token_embeddings(len(self.tokenizer))\n",
        "\n",
        "        if not use_unsloth and not \"unsloth\" in self.model_id.lower():\n",
        "            # Move model to device\n",
        "            self.model.to(self.device)\n",
        "\n",
        "        # Load Dataset (using dataset name from Hugging Face Hub)\n",
        "        dataset = load_dataset(\n",
        "            self.dataset_name, split=\"train\", num_proc=self.config.get(\"dataset_num_proc\", 2)\n",
        "        )\n",
        "        self.dataset = dataset.shuffle().select(\n",
        "            range(self.config.get(\"dataset_size\", 125))\n",
        "        )\n",
        "\n",
        "        print(\"\\n\")\n",
        "        print(\"Observe finished.\")\n",
        "        return True\n",
        "\n",
        "    def _orient(self):\n",
        "        \"\"\"\n",
        "        Orients the agent by formatting the dataset and preparing training arguments.\n",
        "        \"\"\"\n",
        "        print(\"\\n\")\n",
        "        self.counter += 1\n",
        "        print(\"Starting Orient ...\")\n",
        "        if self.dataset_name == \"SetFit/mrpc\":\n",
        "            print(\"Dataset: SetFit/mrpc\")\n",
        "            preprocessing_function = self._preprocess_function_mrpc\n",
        "        elif self.dataset_name == \"b-mc2/sql-create-context\":\n",
        "            print(\"Dataset: b-mc2/sql-create-context\")\n",
        "            preprocessing_function = self._preprocess_function_sql_create_context\n",
        "        elif self.dataset_name == \"anthropic/hh-rlhf\":\n",
        "            print(\"Dataset: anthropic/hh-rlhf\")\n",
        "            preprocessing_function = self._preprocess_function_anthropic_hh_rlhf\n",
        "        elif self.dataset_name == \"imdb\":\n",
        "            print(\"Dataset: imdb\")\n",
        "            preprocessing_function = self._preprocess_function_imdb\n",
        "        else:\n",
        "            print(f\"Dataset: {self.dataset_name} not supported.\")\n",
        "            return\n",
        "\n",
        "        # Set the train/test split.\n",
        "        test_size_percentage = self.config.get(\"test_split_percentage\", 0.2)\n",
        "        self.dataset = self.dataset.train_test_split(\n",
        "            test_size=test_size_percentage\n",
        "        )\n",
        "\n",
        "        self.dataset = self.dataset.map(\n",
        "            preprocessing_function,\n",
        "            batched=True,\n",
        "            remove_columns=self.dataset[\"train\"].column_names,\n",
        "        )\n",
        "\n",
        "        # 3. Prepare Training Arguments\n",
        "        # Import is_bfloat16_supported function.\n",
        "\n",
        "\n",
        "        # Create TrainingArguments with the desired parameters\n",
        "        training_args_config = self.config.get(\"training_args\", {})\n",
        "        self.training_args = TrainingArguments(\n",
        "            output_dir=training_args_config.get(\"output_dir\", \"./output\"),\n",
        "            per_device_train_batch_size=training_args_config.get(\n",
        "                \"per_device_train_batch_size\", 2\n",
        "            ),\n",
        "            gradient_accumulation_steps=training_args_config.get(\n",
        "                \"gradient_accumulation_steps\", 4\n",
        "            ),\n",
        "            warmup_steps=training_args_config.get(\"warmup_steps\", 5),\n",
        "            max_steps=training_args_config.get(\"max_steps\", 60),\n",
        "            learning_rate=training_args_config.get(\"learning_rate\", 2e-4),\n",
        "            fp16=training_args_config.get(\"fp16\", not is_bfloat16_supported()),\n",
        "            bf16=training_args_config.get(\"bf16\", is_bfloat16_supported()),\n",
        "            logging_steps=training_args_config.get(\"logging_steps\", 10),\n",
        "            optim=training_args_config.get(\"optim\", \"adamw_8bit\"),\n",
        "            weight_decay=training_args_config.get(\"weight_decay\", 0.01),\n",
        "            lr_scheduler_type=training_args_config.get(\"lr_scheduler_type\", \"linear\"),\n",
        "            seed=training_args_config.get(\"seed\", 3407),\n",
        "            evaluation_strategy=training_args_config.get(\n",
        "                \"evaluation_strategy\", \"steps\"\n",
        "            ),  # we need this\n",
        "            eval_steps=training_args_config.get(\"eval_steps\", 20),\n",
        "            save_strategy=training_args_config.get(\"save_strategy\", \"steps\"),\n",
        "            save_steps=training_args_config.get(\"save_steps\", 20),\n",
        "            report_to=training_args_config.get(\"report_to\", \"wandb\"),\n",
        "            remove_unused_columns=False # we need this\n",
        "        )\n",
        "\n",
        "        print(\"\\n\")\n",
        "        print(f\"Orient Dataset: {self.dataset}\")\n",
        "\n",
        "        print(\"\\n\")\n",
        "        print(\"Orient finished.\")\n",
        "    def _decide(self):\n",
        "        \"\"\"\n",
        "        Decides on the fine-tuning strategy, including LoRA configuration.\n",
        "        \"\"\"\n",
        "        self.counter += 1\n",
        "        print(\"\\n\")\n",
        "        print(\"Starting Decide ...\")\n",
        "        clear_memory()\n",
        "        # PEFT Configuration (LoRA)\n",
        "        if self.config.get(\"lora\"):\n",
        "            self.model = prepare_model_for_kbit_training(self.model)\n",
        "            if \"bert\" in self.model_id.lower():\n",
        "                peft_config = LoraConfig(\n",
        "                    lora_alpha=16,  # You can tune this.\n",
        "                    lora_dropout=0.1,  # You can tune this.\n",
        "                    r=64,  # You can tune this.\n",
        "                    bias=\"none\",\n",
        "                    target_modules=[\"query\", \"key\", \"value\", \"dense\"],  # Correct target modules for BERT\n",
        "                    task_type=\"SEQ_CLS\",  # correct task type\n",
        "                )\n",
        "            elif \"mistral\" in self.model_id.lower():\n",
        "                peft_config = LoraConfig(\n",
        "                    lora_alpha=128,\n",
        "                    lora_dropout=0.05,\n",
        "                    r=256,\n",
        "                    bias=\"none\",\n",
        "                    target_modules=[\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\",\"gate_proj\", \"up_proj\", \"down_proj\"],\n",
        "                    task_type=\"CAUSAL_LM\",\n",
        "                )\n",
        "            elif \"deepseek\" in self.model_id.lower():\n",
        "                peft_config = LoraConfig(\n",
        "                    lora_alpha=128,\n",
        "                    lora_dropout=0.05,\n",
        "                    r=256,\n",
        "                    bias=\"none\",\n",
        "                    target_modules=[\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\",\"gate_proj\", \"up_proj\", \"down_proj\"],\n",
        "                    task_type=\"CAUSAL_LM\",\n",
        "                )\n",
        "            elif \"unsloth\" in self.model_id.lower():\n",
        "                peft_config = LoraConfig(\n",
        "                    lora_alpha=128,\n",
        "                    lora_dropout=0.05,\n",
        "                    r=256,\n",
        "                    bias=\"none\",\n",
        "                    target_modules=[\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\",\"gate_proj\", \"up_proj\", \"down_proj\"],\n",
        "                    task_type=\"CAUSAL_LM\",\n",
        "                )\n",
        "                print(\"\\n\")\n",
        "                print(f\"LORA: {peft_config}\")\n",
        "\n",
        "            else:\n",
        "                print(f\"Model {self.model_id} not supported.\")\n",
        "                return\n",
        "\n",
        "            self.peft_config = peft_config\n",
        "            self.model = get_peft_model(self.model, peft_config)\n",
        "\n",
        "            self.model.print_trainable_parameters()\n",
        "\n",
        "\n",
        "        print('\\n')\n",
        "        print(\"Decide finished.\")\n",
        "\n",
        "    def _act(self):\n",
        "        \"\"\"\n",
        "        Acts by preprocessing the dataset and initializing the training loop.\n",
        "        \"\"\"\n",
        "        self.counter += 1\n",
        "        print(\"\\n\")\n",
        "        print(\"Starting Act ...\")\n",
        "        clear_memory()\n",
        "\n",
        "        try:\n",
        "            if \"train\" not in self.dataset or \"test\" not in self.dataset:\n",
        "                print(f\"Missing train or test split for {self.dataset_name}\")\n",
        "                return\n",
        "\n",
        "            print(\"Dataset preprocessed successfully.\")\n",
        "            print(\"\\n\")\n",
        "\n",
        "            # Unsloth's Data Collator (Hypothetical)\n",
        "            if self.config.get(\"use_unsloth\", False) or \"unsloth\" in self.model_id.lower():\n",
        "                # Replace with actual Unsloth data collator creation if needed\n",
        "                # This is where we would add logic to use Unsloth's data collator\n",
        "                # if it exists.\n",
        "                # Example of a hypothetical Unsloth data collator\n",
        "                #self.data_collator = UnslothDataCollator()\n",
        "                print(\"Unsloth data collator used.\")\n",
        "                # Set collator\n",
        "                self.data_collator = DataCollatorWithPadding(tokenizer=self.tokenizer)\n",
        "            else:\n",
        "                # Hugging Face Data Collator\n",
        "                self.data_collator = DataCollatorWithPadding(tokenizer=self.tokenizer)\n",
        "                print(\"Hugging Face data collator used.\")\n",
        "\n",
        "            # Initialize Trainer\n",
        "            print(\"Initializing Trainer...\")\n",
        "            loss_callback = LossLoggingCallback(self) # Create the callback\n",
        "\n",
        "            # Use the Trainer class instead of SFTTrainer\n",
        "            self.trainer = Trainer(\n",
        "                model=self.model,\n",
        "                args=self.training_args,\n",
        "                train_dataset=self.dataset[\"train\"],\n",
        "                eval_dataset=self.dataset[\"test\"],\n",
        "                data_collator=self.data_collator,\n",
        "                callbacks=[loss_callback]\n",
        "            )\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"An error occurred in _act(): {e}\")\n",
        "            raise\n",
        "\n",
        "        print(\"\\n\")\n",
        "        print(\"Act finished.\")\n",
        "\n",
        "    def run(self):\n",
        "          \"\"\"\n",
        "          Executes the OODA loop and fine-tunes the language model.\n",
        "          \"\"\"\n",
        "          self.counter += 1\n",
        "          print(\"\\n\")\n",
        "          print(\"Starting Run ...\")\n",
        "          clear_memory()\n",
        "          self.start_time = time.time()\n",
        "          self._observe()\n",
        "          if self.model is None:\n",
        "              print(\"Model loading failed, skipping _orient, _decide and _act\")\n",
        "              return\n",
        "          self._orient()\n",
        "          self._decide()\n",
        "          self._act()\n",
        "\n",
        "          print(\"\\n\")\n",
        "          print(f\"Run Dataset: {self.dataset}\")\n",
        "          print(\"\\n\")\n",
        "\n",
        "          if self.trainer is not None:\n",
        "              try:\n",
        "                  # Train the model\n",
        "                  self.trainer.train()\n",
        "                  print(\"\\n\")\n",
        "                  print(\"Evaluation:\")\n",
        "                  eval_results = self.evaluate()\n",
        "                  print(\"\\n\")\n",
        "                  print(eval_results)\n",
        "                  print(\"\\n\")\n",
        "              except Exception as e:\n",
        "                  print(f\"An error occurred during training or evaluation: {e}\")\n",
        "                  raise\n",
        "          else:\n",
        "              print(\"Trainer is None. Skipping training and evaluation.\")\n",
        "\n",
        "          print(\"Run  finished.\")\n",
        "\n",
        "\n",
        "    def evaluate(self):\n",
        "        \"\"\"å\n",
        "        Evaluates the fine-tuned language model.\n",
        "        \"\"\"\n",
        "        return self.trainer.evaluate()\n",
        "\n",
        "    def _preprocess_function_mrpc(self, examples):\n",
        "        \"\"\"\n",
        "        Preprocesses the data for the SetFit/mrpc dataset.\n",
        "        Handles different model types and sequence lengths.\n",
        "        \"\"\"\n",
        "        print(\"Preprocess Dataset: SetFit/mrpc\")\n",
        "\n",
        "        max_length = self.config.get(\"max_length\", 128)  # Get max_length from config\n",
        "\n",
        "        if self.model_type == \"encoder-only\":\n",
        "            # BERT and other encoder-only models\n",
        "            inputs = self.tokenizer(\n",
        "                examples[\"text1\"],\n",
        "                examples[\"text2\"],\n",
        "                max_length=max_length,\n",
        "                truncation=True,\n",
        "                padding=\"max_length\",\n",
        "            )\n",
        "            inputs[\"labels\"] = examples[\"label\"]\n",
        "            return inputs\n",
        "        elif self.model_type == \"decoder-only\":\n",
        "             # Decoder-only models are not supported for the MRPC task.\n",
        "            print(\"Decoder-only models are not supported for the MRPC task.\")\n",
        "            return {}\n",
        "        else:\n",
        "            raise ValueError(f\"Unsupported model type: {self.model_type}\")\n",
        "\n",
        "    def _preprocess_function_sql_create_context(self, examples):\n",
        "            \"\"\"\n",
        "            Preprocesses the data for the b-mc2/sql-create-context dataset.\n",
        "            Handles different model types and sequence lengths.\n",
        "            \"\"\"\n",
        "            print(\"Preprocess Dataset: b-mc2/sql-create-context\")\n",
        "\n",
        "            max_length = self.config.get(\"max_length\", 1024)  # Get max_length from config\n",
        "\n",
        "            if self.model_type == \"decoder-only\":\n",
        "                # Mistral, DeepSeek, and other decoder-only models\n",
        "                # Tokenize inputs and labels\n",
        "                inputs = [f\"### Question: {q} ### Context: {c}\" for q, c in zip(examples[\"question\"], examples[\"context\"])]\n",
        "                model_inputs = self.tokenizer(inputs, max_length=max_length, truncation=True, padding=\"max_length\")\n",
        "                # Tokenize labels\n",
        "                labels_tokenized = self.tokenizer(examples[\"answer\"], max_length=max_length, truncation=True, padding=\"max_length\")\n",
        "                # Assign labels to model_inputs\n",
        "                model_inputs[\"labels\"] = labels_tokenized[\"input_ids\"]\n",
        "            elif self.model_type == \"encoder-only\":\n",
        "                # BERT and other encoder-only models\n",
        "                # Tokenize inputs and labels\n",
        "                inputs = [f\"### Question: {q} ### Context: {c}\" for q, c in zip(examples[\"question\"], examples[\"context\"])]\n",
        "                model_inputs = self.tokenizer(inputs, max_length=max_length, truncation=True, padding=\"max_length\")\n",
        "                # Tokenize labels\n",
        "                labels_tokenized = self.tokenizer(examples[\"answer\"], max_length=max_length, truncation=True, padding=\"max_length\")\n",
        "                # Assign labels to model_inputs\n",
        "                model_inputs[\"labels\"] = labels_tokenized[\"input_ids\"]\n",
        "            else:\n",
        "                raise ValueError(f\"Unsupported model type: {self.model_type}\")\n",
        "\n",
        "            return model_inputs\n",
        "\n",
        "    def _preprocess_function_anthropic_hh_rlhf(self, examples):\n",
        "        \"\"\"\n",
        "        Preprocesses the data for the anthropic/hh-rlhf dataset.\n",
        "        Handles different model types and sequence lengths.\n",
        "        \"\"\"\n",
        "        print(\"Preprocess Dataset: anthropic/hh-rlhf\")\n",
        "\n",
        "        max_length = self.config.get(\"max_length\", 1024)  # Get max_length from config\n",
        "\n",
        "        if self.model_type == \"decoder-only\":\n",
        "            # Mistral, DeepSeek, and other decoder-only models\n",
        "            inputs = examples[\"chosen\"]\n",
        "            model_inputs = self.tokenizer(inputs, max_length=max_length, truncation=True, padding=\"max_length\")\n",
        "            # Tokenize labels\n",
        "            labels_tokenized = self.tokenizer(examples[\"chosen\"], max_length=max_length, truncation=True, padding=\"max_length\")\n",
        "            model_inputs[\"labels\"] = labels_tokenized[\"input_ids\"]\n",
        "        elif self.model_type == \"encoder-only\":\n",
        "            # BERT and other encoder-only models\n",
        "            inputs = examples[\"chosen\"]\n",
        "            model_inputs = self.tokenizer(inputs, max_length=max_length, truncation=True, padding=\"max_length\")\n",
        "            # Tokenize labels\n",
        "            labels_tokenized = self.tokenizer(examples[\"chosen\"], max_length=max_length, truncation=True, padding=\"max_length\")\n",
        "            model_inputs[\"labels\"] = labels_tokenized[\"input_ids\"]\n",
        "        else:\n",
        "            raise ValueError(f\"Unsupported model type: {self.model_type}\")\n",
        "\n",
        "        return model_inputs\n",
        "\n",
        "    def on_train_loss(self, loss):\n",
        "      \"\"\"Callback to store training losses.\"\"\"\n",
        "      self.train_losses.append(loss)\n",
        "\n",
        "    def on_eval_loss(self, loss):\n",
        "        \"\"\"Callback to store evaluation losses.\"\"\"\n",
        "        self.eval_losses.append(loss)\n",
        "\n",
        "    def run(self):\n",
        "        \"\"\"\n",
        "        Executes the OODA loop and fine-tunes the language model.\n",
        "        \"\"\"\n",
        "        self.counter += 1\n",
        "        print(\"\\n\")\n",
        "        print(\"Starting Run ...\")\n",
        "        clear_memory()\n",
        "        self.start_time = time.time()\n",
        "        self._observe()\n",
        "        if self.model is None:\n",
        "            print(\"Model loading failed, skipping _orient, _decide and _act\")\n",
        "            return\n",
        "        self._orient()\n",
        "        self._decide()\n",
        "        self._act()\n",
        "\n",
        "        print(\"\\n\")\n",
        "        print(f\"Run Dataset: {self.dataset}\")\n",
        "        print(\"\\n\")\n",
        "\n",
        "        if self.trainer is not None:\n",
        "            try:\n",
        "                # Train the model\n",
        "                self.trainer.train()\n",
        "                print(\"\\n\")\n",
        "                print(\"Evaluation:\")\n",
        "                eval_results = self.evaluate()\n",
        "                print(\"\\n\")\n",
        "                print(eval_results)\n",
        "                print(\"\\n\")\n",
        "            except Exception as e:\n",
        "                print(f\"An error occurred during training or evaluation: {e}\")\n",
        "                raise\n",
        "        else:\n",
        "            print(\"Trainer is None. Skipping training and evaluation.\")\n",
        "\n",
        "        print(\"Run  finished.\")\n",
        "\n",
        "    def evaluate(self):\n",
        "        \"\"\"\n",
        "        Evaluates the fine-tuned language model.\n",
        "        \"\"\"\n",
        "        return self.trainer.evaluate()\n",
        "\n",
        "    def _preprocess_function_imdb(self, examples):\n",
        "        \"\"\"\n",
        "        Preprocesses the data for the imdb dataset.\n",
        "        Handles different model types and sequence lengths.\n",
        "        \"\"\"\n",
        "        print(\"Preprocess Dataset: imdb\")\n",
        "\n",
        "        max_length = self.config.get(\"max_length\", 1024)  # Get max_length from config\n",
        "\n",
        "        if self.model_type == \"encoder-only\":\n",
        "             # BERT and other encoder-only models\n",
        "            inputs = self.tokenizer(\n",
        "                examples[\"text\"],\n",
        "                max_length=max_length,\n",
        "                truncation=True,\n",
        "                padding=\"max_length\",\n",
        "            )\n",
        "            inputs[\"labels\"] = examples[\"label\"]\n",
        "            return inputs\n",
        "        elif self.model_type == \"decoder-only\":\n",
        "            # Decoder-only models (Mistral, DeepSeek, etc.)\n",
        "            model_inputs = self.tokenizer(\n",
        "                examples[\"text\"],\n",
        "                max_length=max_length,\n",
        "                truncation=True,\n",
        "                padding=\"max_length\",\n",
        "            )\n",
        "            # Copy input_ids to labels for causal LM training\n",
        "            model_inputs[\"labels\"] = model_inputs[\"input_ids\"].copy()\n",
        "\n",
        "            return model_inputs\n",
        "        else:\n",
        "            raise ValueError(f\"Unsupported model type: {self.model_type}\")\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "EFyO4uvOXkpm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "source": [
        "#Experiment Setup and Execution\n",
        "import matplotlib.pyplot as plt  # Import matplotlib\n",
        "import numpy as np\n",
        "from tabulate import tabulate\n",
        "import time\n",
        "import copy\n",
        "import itertools\n",
        "from transformers import TrainerCallback\n",
        "\n",
        "class LossLoggingCallback(TrainerCallback):\n",
        "    \"\"\"Callback to log training and evaluation losses.\"\"\"\n",
        "    def __init__(self, agent):\n",
        "        self.agent = agent\n",
        "\n",
        "    def on_log(self, args, state, control, logs=None, **kwargs):\n",
        "        \"\"\"Logs the training loss at each log step.\"\"\"\n",
        "        if logs and \"loss\" in logs:\n",
        "            self.agent.on_train_loss(logs[\"loss\"])\n",
        "\n",
        "    def on_evaluate(self, args, state, control, metrics=None, **kwargs):\n",
        "        \"\"\"Logs the evaluation loss at each evaluation step.\"\"\"\n",
        "        if metrics and \"eval_loss\" in metrics:\n",
        "            self.agent.on_eval_loss(metrics[\"eval_loss\"])\n",
        "\n",
        "\n",
        "\n",
        "def create_rl_pairs():\n",
        "    \"\"\"\n",
        "    Creates a list of all possible combinations of datasets, models,\n",
        "    and configurations for RL experiments.\n",
        "    \"\"\"\n",
        "\n",
        "    datasets = [\n",
        "        \"SetFit/mrpc\",\n",
        "        \"b-mc2/sql-create-context\",\n",
        "        \"anthropic/hh-rlhf\",\n",
        "        \"imdb\",\n",
        "    ]\n",
        "\n",
        "    models = [\n",
        "\n",
        "        \"unsloth/mistral-7b-instruct-v0.3-bnb-4bit\",\n",
        "        #\"unsloth/Meta-Llama-3.1-70B-bnb-4bit\",\n",
        "        #\"bert-base-uncased\",\n",
        "        #\"mistralai/Mistral-7B-v0.1\",\n",
        "        #\"deepseek-ai/deepseek-coder-1.3b-base\",\n",
        "    ]\n",
        "\n",
        "    modelsfull = [\n",
        "        \"bert-base-uncased\",\n",
        "        \"mistralai/Mistral-7B-v0.1\",\n",
        "        \"deepseek-ai/deepseek-coder-1.3b-base\",\n",
        "        \"unsloth/mistral-7b-instruct-v0.3-bnb-4bit\",\n",
        "        \"unsloth/mistral-7b-bnb-4bit\",\n",
        "        \"unsloth/mistral-7b-instruct-v0.2-bnb-4bit\",\n",
        "        \"unsloth/llama-2-7b-bnb-4bit\",\n",
        "        \"unsloth/llama-2-13b-bnb-4bit\",\n",
        "        \"unsloth/codellama-34b-bnb-4bit\",\n",
        "        \"unsloth/tinyllama-bnb-4bit\",\n",
        "        \"unsloth/gemma-7b-bnb-4bit\", # New Google 6 trillion tokens model 2.5x faster!\n",
        "        \"unsloth/gemma-2b-bnb-4bit\",\n",
        "        \"unsloth/Meta-Llama-3.1-8B-bnb-4bit\",      # Llama-3.1 15 trillion tokens model 2x faster!\n",
        "        \"unsloth/Meta-Llama-3.1-8B-Instruct-bnb-4bit\",\n",
        "        \"unsloth/Meta-Llama-3.1-70B-bnb-4bit\",\n",
        "        \"unsloth/Meta-Llama-3.1-405B-bnb-4bit\",    # We also uploaded 4bit for 405b!\n",
        "        \"unsloth/Mistral-Nemo-Base-2407-bnb-4bit\", # New Mistral 12b 2x faster!\n",
        "        \"unsloth/Mistral-Nemo-Instruct-2407-bnb-4bit\",\n",
        "        \"unsloth/mistral-7b-v0.3-bnb-4bit\",        # Mistral v3 2x faster!\n",
        "        \"unsloth/mistral-7b-instruct-v0.3-bnb-4bit\",\n",
        "        \"unsloth/Phi-3.5-mini-instruct\",           # Phi-3.5 2x faster!\n",
        "        \"unsloth/Phi-3-medium-4k-instruct\",\n",
        "        \"unsloth/gemma-2-9b-bnb-4bit\",\n",
        "        \"unsloth/gemma-2-27b-bnb-4bit\",\n",
        "    ]\n",
        "\n",
        "    # Define different configs\n",
        "    configs = [\n",
        "        {\n",
        "            \"max_length\": 128,\n",
        "            \"quantization\": True,\n",
        "            \"use_unsloth\": False,\n",
        "            \"lora\": True,\n",
        "            \"dataset_size\": 125,\n",
        "            \"dataset_num_proc\": 2,\n",
        "            \"test_split_percentage\": 0.2,\n",
        "            \"training_args\": {\n",
        "                \"output_dir\": \"./output\",\n",
        "                \"per_device_train_batch_size\": 4,\n",
        "                \"gradient_accumulation_steps\": 4,\n",
        "                \"warmup_steps\": 5,\n",
        "                \"max_steps\": 60,\n",
        "                \"learning_rate\": 2e-4,\n",
        "                \"logging_steps\": 10,\n",
        "                \"weight_decay\": 0.01,\n",
        "                \"eval_steps\": 20,\n",
        "                \"report_to\": \"none\",\n",
        "                \"save_steps\": 20,\n",
        "            },\n",
        "        },\n",
        "    ]\n",
        "\n",
        "    rl_pairs = []\n",
        "    for dataset, model, config in itertools.product(datasets, models, configs):\n",
        "        rl_pairs.append((dataset, model, copy.deepcopy(config))) # Use copy.deepcopy()\n",
        "\n",
        "    return rl_pairs\n",
        "\n",
        "\n",
        "\n",
        "def generate_report(rl_pairs, agents, output_file=\"experiment_report.txt\"):\n",
        "    \"\"\"\n",
        "    Generates a report for multiple RL experiments, including graphics.\n",
        "\n",
        "    Args:\n",
        "        rl_pairs (list): A list of tuples, each containing (dataset_name, model_id, config).\n",
        "        agents (list): A list of FineTuningAgent objects corresponding to the experiments.\n",
        "        output_file (str): The name of the output file to save the report.\n",
        "    \"\"\"\n",
        "    if len(rl_pairs) != len(agents):\n",
        "        raise ValueError(\"The number of rl_pairs and agents must be the same.\")\n",
        "\n",
        "    report_data = []\n",
        "    for i, ((dataset_name, model_id, config), agent) in enumerate(zip(rl_pairs, agents)):\n",
        "        # Collect the data\n",
        "        if agent.start_time is None or agent.end_time is None:\n",
        "            raise ValueError(\"Start time or end time is not defined.\")\n",
        "        elapsed_time = agent.end_time - agent.start_time\n",
        "        train_losses = agent.train_losses\n",
        "        eval_losses = agent.eval_losses\n",
        "\n",
        "        if not train_losses:\n",
        "            train_std = np.nan  # Use np.nan for no data\n",
        "            min_train_loss = np.nan\n",
        "            max_train_loss = np.nan\n",
        "        else:\n",
        "            train_std = np.std(train_losses)\n",
        "            min_train_loss = np.min(train_losses)\n",
        "            max_train_loss = np.max(train_losses)\n",
        "\n",
        "        if not eval_losses:\n",
        "            eval_std = np.nan\n",
        "            min_eval_loss = np.nan\n",
        "            max_eval_loss = np.nan\n",
        "        else:\n",
        "            eval_std = np.std(eval_losses)\n",
        "            min_eval_loss = np.min(eval_losses)\n",
        "            max_eval_loss = np.max(eval_losses)\n",
        "\n",
        "        report_data.append([\n",
        "            dataset_name,\n",
        "            model_id,\n",
        "            f\"{elapsed_time:.2f} seconds\",  # Format to 2 decimal places\n",
        "            f\"{train_std:.4f}\",  # Format to 4 decimal places\n",
        "            f\"{eval_std:.4f}\",  # Format to 4 decimal places\n",
        "            f\"{min_train_loss:.4f}\",  # Format to 4 decimal places\n",
        "            f\"{max_train_loss:.4f}\",  # Format to 4 decimal places\n",
        "            f\"{min_eval_loss:.4f}\",  # Format to 4 decimal places\n",
        "            f\"{max_eval_loss:.4f}\"   # Format to 4 decimal places\n",
        "        ])\n",
        "\n",
        "        # --- Graphics ---\n",
        "        # Create training loss plot\n",
        "        plt.figure(figsize=(10, 4))\n",
        "        plt.plot(train_losses, label='Training Loss')\n",
        "        plt.xlabel('Steps')\n",
        "        plt.ylabel('Loss')\n",
        "        plt.title(f'Training Loss - {dataset_name} - {model_id}')\n",
        "        plt.legend()\n",
        "        plt.savefig(f'training_loss_{i}.png')  # Save the plot\n",
        "        plt.close()  # Close the figure to free memory\n",
        "\n",
        "        # Create evaluation loss plot\n",
        "        plt.figure(figsize=(10, 4))\n",
        "        plt.plot(eval_losses, label='Evaluation Loss', color='orange')\n",
        "        plt.xlabel('Steps')\n",
        "        plt.ylabel('Loss')\n",
        "        plt.title(f'Evaluation Loss - {dataset_name} - {model_id}')\n",
        "        plt.legend()\n",
        "        plt.savefig(f'evaluation_loss_{i}.png')  # Save the plot\n",
        "        plt.close()  # Close the figure to free memory\n",
        "\n",
        "    headers = [\n",
        "        \"Dataset\",\n",
        "        \"Model\",\n",
        "        \"Elapsed Time\",\n",
        "        \"Train Loss Std\",\n",
        "        \"Eval Loss Std\",\n",
        "        \"Min Train Loss\",\n",
        "        \"Max Train Loss\",\n",
        "        \"Min Eval Loss\",\n",
        "        \"Max Eval Loss\"\n",
        "    ]\n",
        "\n",
        "    # Format the report as a table\n",
        "    report_table = tabulate(report_data, headers=headers, tablefmt=\"grid\")\n",
        "\n",
        "    # --- Bar Plot for Comparison ---\n",
        "    # Prepare data for the bar plot\n",
        "    datasets_models = [f\"{data[0]} - {data[1]}\" for data in report_data]\n",
        "    min_train_losses = [data[5] for data in report_data]\n",
        "    min_eval_losses = [data[7] for data in report_data]\n",
        "    max_train_losses = [data[6] for data in report_data]\n",
        "    max_eval_losses = [data[8] for data in report_data]\n",
        "\n",
        "    # Generate the Bar Plot\n",
        "    x = np.arange(len(datasets_models))  # the label locations\n",
        "    width = 0.35  # the width of the bars\n",
        "\n",
        "    fig, ax = plt.subplots(figsize=(15, 6))\n",
        "    rects1 = ax.bar(x - width/2, min_train_losses, width, label='Min Train Loss')\n",
        "    rects2 = ax.bar(x + width/2, min_eval_losses, width, label='Min Eval Loss')\n",
        "    rects3 = ax.bar(x - width/2, max_train_losses, width, label='Max Train Loss')\n",
        "    rects4 = ax.bar(x + width/2, max_eval_losses, width, label='Max Eval Loss')\n",
        "\n",
        "    # Add some text for labels, title and custom x-axis tick labels, etc.\n",
        "    ax.set_ylabel('Loss')\n",
        "    ax.set_title('Loss Comparison by Dataset and Model')\n",
        "    ax.set_xticks(x, datasets_models, rotation=45, ha='right')\n",
        "    ax.legend()\n",
        "\n",
        "    # Add the values in the bar\n",
        "    def autolabel(rects):\n",
        "        \"\"\"Attach a text label above each bar in *rects*, displaying its height.\"\"\"\n",
        "        for rect in rects:\n",
        "            height = rect.get_height()\n",
        "            ax.annotate(f'{height:.2f}',\n",
        "                        xy=(rect.get_x() + rect.get_width() / 2, height),\n",
        "                        xytext=(0, 3),  # 3 points vertical offset\n",
        "                        textcoords=\"offset points\",\n",
        "                        ha='center', va='bottom')\n",
        "\n",
        "    autolabel(rects1)\n",
        "    autolabel(rects2)\n",
        "    autolabel(rects3)\n",
        "    autolabel(rects4)\n",
        "    #fig.tight_layout() # adjust the padding if it is necessary\n",
        "\n",
        "    plt.savefig(f'loss_comparison.png')  # Save the plot\n",
        "    plt.close()  # Close the figure to free memory\n",
        "\n",
        "    # Print the report to the console\n",
        "    print(report_table)\n",
        "\n",
        "    # Save the report to a file\n",
        "    with open(output_file, \"w\") as f:\n",
        "        f.write(report_table)\n",
        "        print(f\"Report saved to {output_file}\")\n",
        "\n",
        "\n",
        "\n",
        "# Create pairs\n",
        "rl_pairs = create_rl_pairs()\n",
        "\n",
        "# Run the experiment\n",
        "import time\n",
        "\n",
        "agents = []\n",
        "for dataset_name, model_id, config in rl_pairs:\n",
        "    clear_memory()\n",
        "    print(\"\\n\")\n",
        "    print(f\"Running experiment with:\")\n",
        "    print(f\"- Dataset: {dataset_name}\")\n",
        "    print(f\"- Model: {model_id}\")\n",
        "    print(f\"- Config: {config}\")\n",
        "    print(\"\\n\")\n",
        "\n",
        "    try:\n",
        "        agent = FineTuningAgent(model_id, dataset_name, config)\n",
        "        agents.append(agent)\n",
        "        agent.start_time = time.time()\n",
        "        agent.run()\n",
        "        agent.end_time = time.time()\n",
        "    except Exception as e:\n",
        "        print(f\"An error occurred during the experiment: {e}\")\n",
        "        # set time if it fails\n",
        "        agent.end_time = time.time()\n",
        "        agent.start_time = time.time()\n",
        "\n",
        "\n",
        "generate_report(rl_pairs, agents)"
      ],
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "f5234163f9bf45e286926b2cfc7997f2",
            "521c92579fbf445b904d85855654e9e2",
            "e2d2740e70e248efb1a1bedcb6351710",
            "219199bcd8c94f18801930f61d1ee809",
            "d76e84b91f9d4910a85adf795c46df01",
            "5cdaf9d87bd14718ae6846fb5cd93fb6",
            "440a57f3b20b43f384461a33605a0496",
            "ca86677c1f864a7d898467465b49d420",
            "6c001ce210ee46c69a30b8715de4c9c8",
            "2b0023cd1d2d418c80489110e693b86b",
            "daae04c3aff643a28aa49d4f496a8cd6",
            "89f23249d0ef478fb771fba4c3c4249e",
            "080e85ff1d7845a9bb743624f416b7e0",
            "ced36fc11e66478fafc1a91c3b8567bc",
            "7d423eefb5dd4d6cbe70631f7b52208f",
            "709ada3c8d2a42fc81cbbec382705d41",
            "c70c9e325c2941efa71fdc4ced63d86d",
            "41115d6b73ea4d56a07e4eb36609f0e5",
            "068de4c0e9154ba8a0c533eb445b65ba",
            "f3fcc18d9b804990acaa2181f6a00a69",
            "246a111700d24a3eb8bb7fc53b30e253",
            "13f546a9205a458fb5ee33e1faf40891",
            "49b7dc1838374c159a9416dccee06943",
            "06906f20d8f34bcd805a41e81bc87b2c",
            "64eb86c9ceb94ffc8b27295ad242fccf",
            "8f2f513f6631452aaa290bda45672e0a",
            "5e09f33b2d604e00a6ada9fa8b963b0a",
            "9d2c4dcd947f41ab8103b7c344c46726",
            "73423ab7942a4f4e9bd19c57e019b62a",
            "93bc0a727b37416396471ade9560c35f",
            "9f2e67c1c4114271a437a66317b972b5",
            "35d8091faf914ad0a16152c57e0a9cb6",
            "f056c911552247dc91ef8e871c78aeaf",
            "4a03ecfda0e44e5f981a17117c6c9a04",
            "5517c9692c764ed99a7caebb662f0577",
            "aaf62ad9d8d74a2ebd826fefeaa23c1c",
            "5935a5cbed1840f1ba8ccd29bc9139c0",
            "58b3129b047f40cb8429c10eeceb3fa1",
            "467a2bf52bd24d29b4aa540160d6b055",
            "fbdbf36d6644491abc2987931672d03c",
            "6b6257bd9f144ec9821605403ade6abc",
            "305a8842f21243dc94861d29c48b6ec5",
            "262822b1b6ca4e27b209d7522491d9af",
            "da1306b8453049d4a8746892ed31f3c9",
            "7552fcc179ae4e91aec86b24201411e0",
            "c56278a056ff4fa5bde57fb042566fe9",
            "08b56e8e24884814be41effbfb8f582d",
            "c1b0d35feecc4594bee247e2a07f332c",
            "0becb5673eea482eab09167853e1172a",
            "60addde340e1452d835d6a98300ec598",
            "7242e9bb2ace4936b76a9548a0719703",
            "b1c74cd61d3a4c1a895746648b95e342",
            "efd7c5db6d194e31a3d72ad10a585c5a",
            "84d68e538ce94f698bc733b5b5d472ef",
            "d59acdf6e469446da08699be9697b244",
            "ab75469a122c4c5ab4215fa8c6dadfea",
            "322903e07e4c4f0ba98fab6dd915355b",
            "073c1b5fc0e54f63aba10f68f6790832",
            "030209243c3849919d0a4105565e34e6",
            "47b2496a262d44f88d22f77fd87ea372",
            "390b4111f0a444dda96f29b68f9f9370",
            "440f7bec4ab1495fa0e269d86cd7132d",
            "2672ba6c2907486baeee35150ecb6993",
            "622f47465678466eb32c8ff2f6ee6839",
            "e94542380b8e468a960600150d76d053",
            "abbf84cb00e64081adcc6f3137da07a1",
            "2cb93ad6fa744f13a47cb67abc731885",
            "19b7d9e790b043128e32878fc2a8c019",
            "923255a8c5e2435ab9f85a82450f8ec1",
            "65693d49adc049acb49166529f41ea11",
            "ac88a34f30c842dc9d04f6403c561615",
            "210c9666362547fb86957f4ed2d7d5bb",
            "04320e64569144e484039de5aca0e0cb",
            "b540f59c46d64aaf98268fbebd63826d",
            "2c9be479d3cd46ae8126e4b15d63aa2d",
            "ef2e2e82d6634821b6df7edc34f0f906",
            "f98c65c2415b42fb88ee86a36045d695",
            "2242b943ff334b799714c5d6cc930a48",
            "b752e949f13b460bb20d31df91a97560",
            "c3f14d625484455b8569bd32462734f6",
            "15b12e269cf245f6b06a1238bc3d7ce9",
            "b040df7df0e74408a1cc03acfd384fbe",
            "54ddc5fa34ea40f9ac02c271c2d9c80b",
            "0215ee647a6f43fdb6aa388bd73c877f",
            "6815fcfa12ef46c68cffef8e131ea103",
            "db1cb87d91834292a8c30332c98e4313",
            "77045ba201db4e82af0c1bfe5e29dcb9",
            "99f1f3aa75fb4441ac1140baa7b8601f"
          ]
        },
        "collapsed": true,
        "id": "qVUpvelfC83C",
        "outputId": "99117f26-99ca-4b4e-8d9b-d59aabf6759d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Running experiment with:\n",
            "- Dataset: SetFit/mrpc\n",
            "- Model: unsloth/mistral-7b-instruct-v0.3-bnb-4bit\n",
            "- Config: {'max_length': 128, 'quantization': True, 'use_unsloth': False, 'lora': True, 'dataset_size': 125, 'dataset_num_proc': 2, 'test_split_percentage': 0.2, 'training_args': {'output_dir': './output', 'per_device_train_batch_size': 4, 'gradient_accumulation_steps': 4, 'warmup_steps': 5, 'max_steps': 60, 'learning_rate': 0.0002, 'logging_steps': 10, 'weight_decay': 0.01, 'eval_steps': 20, 'report_to': 'none', 'save_steps': 20}}\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Starting Run ...\n",
            "Starting Observe ...\n",
            "Mistral model detected. Using 4-bit quantization.\n",
            "Decoder-only model detected.\n",
            "Loading Decoder-only with Hugging Face\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "`low_cpu_mem_usage` was None, now default to True since model is quantized.\n",
            "Repo card metadata block was not found. Setting CardData to empty.\n",
            "WARNING:huggingface_hub.repocard:Repo card metadata block was not found. Setting CardData to empty.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Observe finished.\n",
            "\n",
            "\n",
            "Starting Orient ...\n",
            "Dataset: SetFit/mrpc\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/100 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f5234163f9bf45e286926b2cfc7997f2"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Preprocess Dataset: SetFit/mrpc\n",
            "Decoder-only models are not supported for the MRPC task.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/25 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "89f23249d0ef478fb771fba4c3c4249e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Preprocess Dataset: SetFit/mrpc\n",
            "Decoder-only models are not supported for the MRPC task.\n",
            "\n",
            "\n",
            "Orient Dataset: DatasetDict({\n",
            "    train: Dataset({\n",
            "        features: [],\n",
            "        num_rows: 0\n",
            "    })\n",
            "    test: Dataset({\n",
            "        features: [],\n",
            "        num_rows: 0\n",
            "    })\n",
            "})\n",
            "\n",
            "\n",
            "Orient finished.\n",
            "\n",
            "\n",
            "Starting Decide ...\n",
            "trainable params: 671,088,640 || all params: 7,919,112,192 || trainable%: 8.4743\n",
            "\n",
            "\n",
            "Decide finished.\n",
            "\n",
            "\n",
            "Starting Act ...\n",
            "Dataset preprocessed successfully.\n",
            "\n",
            "\n",
            "Unsloth data collator used.\n",
            "Initializing Trainer...\n",
            "\n",
            "\n",
            "Act finished.\n",
            "\n",
            "\n",
            "Run Dataset: DatasetDict({\n",
            "    train: Dataset({\n",
            "        features: [],\n",
            "        num_rows: 0\n",
            "    })\n",
            "    test: Dataset({\n",
            "        features: [],\n",
            "        num_rows: 0\n",
            "    })\n",
            "})\n",
            "\n",
            "\n",
            "An error occurred during training or evaluation: num_samples should be a positive integer value, but got num_samples=0\n",
            "An error occurred during the experiment: num_samples should be a positive integer value, but got num_samples=0\n",
            "\n",
            "\n",
            "Running experiment with:\n",
            "- Dataset: b-mc2/sql-create-context\n",
            "- Model: unsloth/mistral-7b-instruct-v0.3-bnb-4bit\n",
            "- Config: {'max_length': 128, 'quantization': True, 'use_unsloth': False, 'lora': True, 'dataset_size': 125, 'dataset_num_proc': 2, 'test_split_percentage': 0.2, 'training_args': {'output_dir': './output', 'per_device_train_batch_size': 4, 'gradient_accumulation_steps': 4, 'warmup_steps': 5, 'max_steps': 60, 'learning_rate': 0.0002, 'logging_steps': 10, 'weight_decay': 0.01, 'eval_steps': 20, 'report_to': 'none', 'save_steps': 20}}\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Starting Run ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "`low_cpu_mem_usage` was None, now default to True since model is quantized.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting Observe ...\n",
            "Mistral model detected. Using 4-bit quantization.\n",
            "Decoder-only model detected.\n",
            "Loading Decoder-only with Hugging Face\n",
            "\n",
            "\n",
            "Observe finished.\n",
            "\n",
            "\n",
            "Starting Orient ...\n",
            "Dataset: b-mc2/sql-create-context\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/100 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "49b7dc1838374c159a9416dccee06943"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Preprocess Dataset: b-mc2/sql-create-context\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/25 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4a03ecfda0e44e5f981a17117c6c9a04"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Preprocess Dataset: b-mc2/sql-create-context\n",
            "\n",
            "\n",
            "Orient Dataset: DatasetDict({\n",
            "    train: Dataset({\n",
            "        features: ['input_ids', 'attention_mask', 'labels'],\n",
            "        num_rows: 100\n",
            "    })\n",
            "    test: Dataset({\n",
            "        features: ['input_ids', 'attention_mask', 'labels'],\n",
            "        num_rows: 25\n",
            "    })\n",
            "})\n",
            "\n",
            "\n",
            "Orient finished.\n",
            "\n",
            "\n",
            "Starting Decide ...\n",
            "trainable params: 671,088,640 || all params: 7,919,112,192 || trainable%: 8.4743\n",
            "\n",
            "\n",
            "Decide finished.\n",
            "\n",
            "\n",
            "Starting Act ...\n",
            "Dataset preprocessed successfully.\n",
            "\n",
            "\n",
            "Unsloth data collator used.\n",
            "Initializing Trainer...\n",
            "\n",
            "\n",
            "Act finished.\n",
            "\n",
            "\n",
            "Run Dataset: DatasetDict({\n",
            "    train: Dataset({\n",
            "        features: ['input_ids', 'attention_mask', 'labels'],\n",
            "        num_rows: 100\n",
            "    })\n",
            "    test: Dataset({\n",
            "        features: ['input_ids', 'attention_mask', 'labels'],\n",
            "        num_rows: 25\n",
            "    })\n",
            "})\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='60' max='60' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [60/60 02:35, Epoch 8/10]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>20</td>\n",
              "      <td>6.807400</td>\n",
              "      <td>6.353405</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>40</td>\n",
              "      <td>5.773200</td>\n",
              "      <td>6.380251</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>60</td>\n",
              "      <td>5.261700</td>\n",
              "      <td>6.771183</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Evaluation:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='4' max='4' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [4/4 00:00]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "{'eval_loss': 6.771183013916016, 'eval_runtime': 0.9443, 'eval_samples_per_second': 26.476, 'eval_steps_per_second': 4.236, 'epoch': 8.64}\n",
            "\n",
            "\n",
            "Run  finished.\n",
            "\n",
            "\n",
            "Running experiment with:\n",
            "- Dataset: anthropic/hh-rlhf\n",
            "- Model: unsloth/mistral-7b-instruct-v0.3-bnb-4bit\n",
            "- Config: {'max_length': 128, 'quantization': True, 'use_unsloth': False, 'lora': True, 'dataset_size': 125, 'dataset_num_proc': 2, 'test_split_percentage': 0.2, 'training_args': {'output_dir': './output', 'per_device_train_batch_size': 4, 'gradient_accumulation_steps': 4, 'warmup_steps': 5, 'max_steps': 60, 'learning_rate': 0.0002, 'logging_steps': 10, 'weight_decay': 0.01, 'eval_steps': 20, 'report_to': 'none', 'save_steps': 20}}\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Starting Run ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "`low_cpu_mem_usage` was None, now default to True since model is quantized.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting Observe ...\n",
            "Mistral model detected. Using 4-bit quantization.\n",
            "Decoder-only model detected.\n",
            "Loading Decoder-only with Hugging Face\n",
            "\n",
            "\n",
            "Observe finished.\n",
            "\n",
            "\n",
            "Starting Orient ...\n",
            "Dataset: anthropic/hh-rlhf\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/100 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7552fcc179ae4e91aec86b24201411e0"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Preprocess Dataset: anthropic/hh-rlhf\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/25 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ab75469a122c4c5ab4215fa8c6dadfea"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Preprocess Dataset: anthropic/hh-rlhf\n",
            "\n",
            "\n",
            "Orient Dataset: DatasetDict({\n",
            "    train: Dataset({\n",
            "        features: ['input_ids', 'attention_mask', 'labels'],\n",
            "        num_rows: 100\n",
            "    })\n",
            "    test: Dataset({\n",
            "        features: ['input_ids', 'attention_mask', 'labels'],\n",
            "        num_rows: 25\n",
            "    })\n",
            "})\n",
            "\n",
            "\n",
            "Orient finished.\n",
            "\n",
            "\n",
            "Starting Decide ...\n",
            "trainable params: 671,088,640 || all params: 7,919,112,192 || trainable%: 8.4743\n",
            "\n",
            "\n",
            "Decide finished.\n",
            "\n",
            "\n",
            "Starting Act ...\n",
            "Dataset preprocessed successfully.\n",
            "\n",
            "\n",
            "Unsloth data collator used.\n",
            "Initializing Trainer...\n",
            "\n",
            "\n",
            "Act finished.\n",
            "\n",
            "\n",
            "Run Dataset: DatasetDict({\n",
            "    train: Dataset({\n",
            "        features: ['input_ids', 'attention_mask', 'labels'],\n",
            "        num_rows: 100\n",
            "    })\n",
            "    test: Dataset({\n",
            "        features: ['input_ids', 'attention_mask', 'labels'],\n",
            "        num_rows: 25\n",
            "    })\n",
            "})\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='60' max='60' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [60/60 02:38, Epoch 8/10]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>20</td>\n",
              "      <td>1.733900</td>\n",
              "      <td>2.688472</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>40</td>\n",
              "      <td>0.964200</td>\n",
              "      <td>3.175006</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>60</td>\n",
              "      <td>1.031900</td>\n",
              "      <td>3.432628</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Evaluation:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='4' max='4' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [4/4 00:00]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "{'eval_loss': 3.4326279163360596, 'eval_runtime': 0.95, 'eval_samples_per_second': 26.317, 'eval_steps_per_second': 4.211, 'epoch': 8.64}\n",
            "\n",
            "\n",
            "Run  finished.\n",
            "\n",
            "\n",
            "Running experiment with:\n",
            "- Dataset: imdb\n",
            "- Model: unsloth/mistral-7b-instruct-v0.3-bnb-4bit\n",
            "- Config: {'max_length': 128, 'quantization': True, 'use_unsloth': False, 'lora': True, 'dataset_size': 125, 'dataset_num_proc': 2, 'test_split_percentage': 0.2, 'training_args': {'output_dir': './output', 'per_device_train_batch_size': 4, 'gradient_accumulation_steps': 4, 'warmup_steps': 5, 'max_steps': 60, 'learning_rate': 0.0002, 'logging_steps': 10, 'weight_decay': 0.01, 'eval_steps': 20, 'report_to': 'none', 'save_steps': 20}}\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Starting Run ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "`low_cpu_mem_usage` was None, now default to True since model is quantized.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting Observe ...\n",
            "Mistral model detected. Using 4-bit quantization.\n",
            "Decoder-only model detected.\n",
            "Loading Decoder-only with Hugging Face\n",
            "\n",
            "\n",
            "Observe finished.\n",
            "\n",
            "\n",
            "Starting Orient ...\n",
            "Dataset: imdb\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/100 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2cb93ad6fa744f13a47cb67abc731885"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Preprocess Dataset: imdb\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/25 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2242b943ff334b799714c5d6cc930a48"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Preprocess Dataset: imdb\n",
            "\n",
            "\n",
            "Orient Dataset: DatasetDict({\n",
            "    train: Dataset({\n",
            "        features: ['input_ids', 'attention_mask', 'labels'],\n",
            "        num_rows: 100\n",
            "    })\n",
            "    test: Dataset({\n",
            "        features: ['input_ids', 'attention_mask', 'labels'],\n",
            "        num_rows: 25\n",
            "    })\n",
            "})\n",
            "\n",
            "\n",
            "Orient finished.\n",
            "\n",
            "\n",
            "Starting Decide ...\n",
            "trainable params: 671,088,640 || all params: 7,919,112,192 || trainable%: 8.4743\n",
            "\n",
            "\n",
            "Decide finished.\n",
            "\n",
            "\n",
            "Starting Act ...\n",
            "Dataset preprocessed successfully.\n",
            "\n",
            "\n",
            "Unsloth data collator used.\n",
            "Initializing Trainer...\n",
            "\n",
            "\n",
            "Act finished.\n",
            "\n",
            "\n",
            "Run Dataset: DatasetDict({\n",
            "    train: Dataset({\n",
            "        features: ['input_ids', 'attention_mask', 'labels'],\n",
            "        num_rows: 100\n",
            "    })\n",
            "    test: Dataset({\n",
            "        features: ['input_ids', 'attention_mask', 'labels'],\n",
            "        num_rows: 25\n",
            "    })\n",
            "})\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='60' max='60' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [60/60 02:38, Epoch 8/10]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>20</td>\n",
              "      <td>1.440000</td>\n",
              "      <td>3.227066</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>40</td>\n",
              "      <td>0.321800</td>\n",
              "      <td>4.143148</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>60</td>\n",
              "      <td>0.497500</td>\n",
              "      <td>4.235374</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Evaluation:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='4' max='4' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [4/4 00:00]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "{'eval_loss': 4.2353739738464355, 'eval_runtime': 0.968, 'eval_samples_per_second': 25.825, 'eval_steps_per_second': 4.132, 'epoch': 8.64}\n",
            "\n",
            "\n",
            "Run  finished.\n",
            "+--------------------------+-------------------------------------------+----------------+------------------+-----------------+------------------+------------------+-----------------+-----------------+\n",
            "| Dataset                  | Model                                     | Elapsed Time   |   Train Loss Std |   Eval Loss Std |   Min Train Loss |   Max Train Loss |   Min Eval Loss |   Max Eval Loss |\n",
            "+==========================+===========================================+================+==================+=================+==================+==================+=================+=================+\n",
            "| SetFit/mrpc              | unsloth/mistral-7b-instruct-v0.3-bnb-4bit | -0.00 seconds  |         nan      |        nan      |         nan      |         nan      |        nan      |        nan      |\n",
            "+--------------------------+-------------------------------------------+----------------+------------------+-----------------+------------------+------------------+-----------------+-----------------+\n",
            "| b-mc2/sql-create-context | unsloth/mistral-7b-instruct-v0.3-bnb-4bit | 191.65 seconds |           1.6899 |          0.2024 |           5.2617 |          10.2143 |          6.3534 |          6.7712 |\n",
            "+--------------------------+-------------------------------------------+----------------+------------------+-----------------+------------------+------------------+-----------------+-----------------+\n",
            "| anthropic/hh-rlhf        | unsloth/mistral-7b-instruct-v0.3-bnb-4bit | 195.02 seconds |           0.7203 |          0.3038 |           0.9642 |           2.9659 |          2.6885 |          3.4326 |\n",
            "+--------------------------+-------------------------------------------+----------------+------------------+-----------------+------------------+------------------+-----------------+-----------------+\n",
            "| imdb                     | unsloth/mistral-7b-instruct-v0.3-bnb-4bit | 195.09 seconds |           0.8833 |          0.425  |           0.3161 |           2.7697 |          3.2271 |          4.2354 |\n",
            "+--------------------------+-------------------------------------------+----------------+------------------+-----------------+------------------+------------------+-----------------+-----------------+\n",
            "Report saved to experiment_report.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install colab-env -q\n",
        "import colab_env\n",
        "\n",
        "\n",
        "\n",
        "# Generate the LLM report and send to Gemini\n",
        "prompt = \"\"\"\n",
        "You are a helpful data science expert.\n",
        "Please, make an additional analysis of this Fine-Tuning experiment report.\n",
        "\"\"\"\n",
        "generate_llm_report(rl_pairs, agents, prompt=prompt)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xAkm2bQZW5bw",
        "outputId": "0a528d8b-08c2-4a6f-e0c4-5e67c5e620e2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "source": [
        "import google.generativeai as genai\n",
        "import numpy as np\n",
        "from google.colab import userdata\n",
        "\n",
        "# Used to securely store your API key\n",
        "GOOGLE_API_KEY = userdata.get('GEMINI')\n",
        "genai.configure(api_key=GOOGLE_API_KEY)\n",
        "\n",
        "\n",
        "def generate_llm_report(rl_pairs, agents, model_name=\"gemini-1.5-pro\", prompt=\"\"):\n",
        "    \"\"\"\n",
        "    Generates a comprehensive text report summarizing the fine-tuning experiments,\n",
        "    suitable for submission to an LLM.\n",
        "\n",
        "    Args:\n",
        "        rl_pairs (list): List of experiment setups (dataset, model, config).\n",
        "        agents (list): List of FineTuningAgent objects.\n",
        "        model_name (str): The name of the Gemini model.\n",
        "        prompt (str): The prompt to send the gemini.\n",
        "    \"\"\"\n",
        "    if len(rl_pairs) != len(agents):\n",
        "        raise ValueError(\"The number of rl_pairs and agents must be the same.\")\n",
        "\n",
        "    report_text = \"Comprehensive Report on Fine-Tuning Experiments\\n\\n\"\n",
        "    report_text += \"Introduction:\\n\"\n",
        "    report_text += \"This report summarizes the results of multiple fine-tuning experiments conducted on various language models and datasets. \"\n",
        "    report_text += \"The experiments were designed to evaluate the models' performance under different configurations and datasets.\\n\\n\"\n",
        "\n",
        "    report_text += \"Experiment Details:\\n\"\n",
        "    for (dataset_name, model_id, config), agent in zip(rl_pairs, agents):\n",
        "        report_text += f\"- Dataset: {dataset_name}\\n\"\n",
        "        report_text += f\"- Model: {model_id}\\n\"\n",
        "        report_text += f\"- Configuration: {config}\\n\"\n",
        "        if agent.start_time is None or agent.end_time is None:\n",
        "          # set time if it fails\n",
        "          agent.end_time = time.time()\n",
        "          agent.start_time = time.time()\n",
        "        report_text += f\"- Training Time: {agent.end_time - agent.start_time:.2f} seconds\\n\"\n",
        "\n",
        "        if agent.train_losses:\n",
        "            report_text += f\"  - Training Loss (Min): {min(agent.train_losses):.4f}\\n\"\n",
        "            report_text += f\"  - Training Loss (Max): {max(agent.train_losses):.4f}\\n\"\n",
        "            report_text += f\"  - Training Loss (Std): {np.std(agent.train_losses):.4f}\\n\"\n",
        "        else:\n",
        "            report_text += \"  - No training loss data available.\\n\"\n",
        "\n",
        "        if agent.eval_losses:\n",
        "            report_text += f\"  - Evaluation Loss (Min): {min(agent.eval_losses):.4f}\\n\"\n",
        "            report_text += f\"  - Evaluation Loss (Max): {max(agent.eval_losses):.4f}\\n\"\n",
        "            report_text += f\"  - Evaluation Loss (Std): {np.std(agent.eval_losses):.4f}\\n\"\n",
        "        else:\n",
        "            report_text += \"  - No evaluation loss data available.\\n\"\n",
        "\n",
        "        report_text += \"\\n\"\n",
        "\n",
        "    report_text += \"Comparative Analysis:\\n\"\n",
        "    report_text += \"Here is a comparative analysis of the models and datasets:\\n\"\n",
        "    for i, ((dataset_name, model_id, config), agent) in enumerate(zip(rl_pairs, agents)):\n",
        "        report_text += f\"Experiment {i+1}: Dataset ({dataset_name}) - Model ({model_id})\\n\"\n",
        "        if agent.train_losses:\n",
        "            report_text += f\"  - Training Loss: Mean={np.mean(agent.train_losses):.4f}, Std={np.std(agent.train_losses):.4f}, Min={min(agent.train_losses):.4f}, Max={max(agent.train_losses):.4f}\\n\"\n",
        "        if agent.eval_losses:\n",
        "            report_text += f\"  - Evaluation Loss: Mean={np.mean(agent.eval_losses):.4f}, Std={np.std(agent.eval_losses):.4f}, Min={min(agent.eval_losses):.4f}, Max={max(agent.eval_losses):.4f}\\n\"\n",
        "\n",
        "    report_text += \"\\nConclusion:\\n\"\n",
        "    report_text += \"In summary, this report has presented a detailed analysis of multiple fine-tuning experiments. \"\n",
        "    report_text += \"The results show the performance variations of different language models across various datasets and configurations. \"\n",
        "    report_text += \"These experiments provide valuable insights into the behavior of these models and can be used to guide further optimization efforts.\\n\\n\"\n",
        "\n",
        "    print(\"\\n\")\n",
        "    print(\"Report to send to Gemini:\")\n",
        "    print(report_text)\n",
        "    print(\"\\n\")\n",
        "\n",
        "    # Gemini API Connection and Prompt Invocation (Corrected)\n",
        "    try:\n",
        "        # Configure Gemini model and generate text.\n",
        "        model = genai.GenerativeModel(model_name)\n",
        "\n",
        "        response = model.generate_content(f\"{prompt} \\n {report_text}\")\n",
        "\n",
        "        print(\"\\n\")\n",
        "        print(\"Gemini extra analysis:\")\n",
        "        print(response.text)\n",
        "        print(\"\\n\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"An error occurred during the experiment: {e}\")\n",
        "\n",
        "    return report_text"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "gZfuILIec3Ke"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate the LLM report and send to Gemini\n",
        "prompt = \"\"\"\n",
        "You are a helpful data science expert.\n",
        "Please, make an additional analysis of this Fine-Tuning experiment report.\n",
        "\"\"\"\n",
        "generate_llm_report(rl_pairs, agents, prompt=prompt)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "U02f8k7ac4Mc",
        "outputId": "bd2bd88d-c473-4eb7-e36b-3408b0d96fcf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Report to send to Gemini:\n",
            "Comprehensive Report on Fine-Tuning Experiments\n",
            "\n",
            "Introduction:\n",
            "This report summarizes the results of multiple fine-tuning experiments conducted on various language models and datasets. The experiments were designed to evaluate the models' performance under different configurations and datasets.\n",
            "\n",
            "Experiment Details:\n",
            "- Dataset: SetFit/mrpc\n",
            "- Model: unsloth/mistral-7b-instruct-v0.3-bnb-4bit\n",
            "- Configuration: {'max_length': 128, 'quantization': True, 'use_unsloth': False, 'lora': True, 'dataset_size': 125, 'dataset_num_proc': 2, 'test_split_percentage': 0.2, 'training_args': {'output_dir': './output', 'per_device_train_batch_size': 4, 'gradient_accumulation_steps': 4, 'warmup_steps': 5, 'max_steps': 60, 'learning_rate': 0.0002, 'logging_steps': 10, 'weight_decay': 0.01, 'eval_steps': 20, 'report_to': 'none', 'save_steps': 20}}\n",
            "- Training Time: -0.00 seconds\n",
            "  - No training loss data available.\n",
            "  - No evaluation loss data available.\n",
            "\n",
            "- Dataset: b-mc2/sql-create-context\n",
            "- Model: unsloth/mistral-7b-instruct-v0.3-bnb-4bit\n",
            "- Configuration: {'max_length': 128, 'quantization': True, 'use_unsloth': False, 'lora': True, 'dataset_size': 125, 'dataset_num_proc': 2, 'test_split_percentage': 0.2, 'training_args': {'output_dir': './output', 'per_device_train_batch_size': 4, 'gradient_accumulation_steps': 4, 'warmup_steps': 5, 'max_steps': 60, 'learning_rate': 0.0002, 'logging_steps': 10, 'weight_decay': 0.01, 'eval_steps': 20, 'report_to': 'none', 'save_steps': 20}}\n",
            "- Training Time: 191.65 seconds\n",
            "  - Training Loss (Min): 5.2617\n",
            "  - Training Loss (Max): 10.2143\n",
            "  - Training Loss (Std): 1.6899\n",
            "  - Evaluation Loss (Min): 6.3534\n",
            "  - Evaluation Loss (Max): 6.7712\n",
            "  - Evaluation Loss (Std): 0.2024\n",
            "\n",
            "- Dataset: anthropic/hh-rlhf\n",
            "- Model: unsloth/mistral-7b-instruct-v0.3-bnb-4bit\n",
            "- Configuration: {'max_length': 128, 'quantization': True, 'use_unsloth': False, 'lora': True, 'dataset_size': 125, 'dataset_num_proc': 2, 'test_split_percentage': 0.2, 'training_args': {'output_dir': './output', 'per_device_train_batch_size': 4, 'gradient_accumulation_steps': 4, 'warmup_steps': 5, 'max_steps': 60, 'learning_rate': 0.0002, 'logging_steps': 10, 'weight_decay': 0.01, 'eval_steps': 20, 'report_to': 'none', 'save_steps': 20}}\n",
            "- Training Time: 195.02 seconds\n",
            "  - Training Loss (Min): 0.9642\n",
            "  - Training Loss (Max): 2.9659\n",
            "  - Training Loss (Std): 0.7203\n",
            "  - Evaluation Loss (Min): 2.6885\n",
            "  - Evaluation Loss (Max): 3.4326\n",
            "  - Evaluation Loss (Std): 0.3038\n",
            "\n",
            "- Dataset: imdb\n",
            "- Model: unsloth/mistral-7b-instruct-v0.3-bnb-4bit\n",
            "- Configuration: {'max_length': 128, 'quantization': True, 'use_unsloth': False, 'lora': True, 'dataset_size': 125, 'dataset_num_proc': 2, 'test_split_percentage': 0.2, 'training_args': {'output_dir': './output', 'per_device_train_batch_size': 4, 'gradient_accumulation_steps': 4, 'warmup_steps': 5, 'max_steps': 60, 'learning_rate': 0.0002, 'logging_steps': 10, 'weight_decay': 0.01, 'eval_steps': 20, 'report_to': 'none', 'save_steps': 20}}\n",
            "- Training Time: 195.09 seconds\n",
            "  - Training Loss (Min): 0.3161\n",
            "  - Training Loss (Max): 2.7697\n",
            "  - Training Loss (Std): 0.8833\n",
            "  - Evaluation Loss (Min): 3.2271\n",
            "  - Evaluation Loss (Max): 4.2354\n",
            "  - Evaluation Loss (Std): 0.4250\n",
            "\n",
            "Comparative Analysis:\n",
            "Here is a comparative analysis of the models and datasets:\n",
            "Experiment 1: Dataset (SetFit/mrpc) - Model (unsloth/mistral-7b-instruct-v0.3-bnb-4bit)\n",
            "Experiment 2: Dataset (b-mc2/sql-create-context) - Model (unsloth/mistral-7b-instruct-v0.3-bnb-4bit)\n",
            "  - Training Loss: Mean=6.5995, Std=1.6899, Min=5.2617, Max=10.2143\n",
            "  - Evaluation Loss: Mean=6.5690, Std=0.2024, Min=6.3534, Max=6.7712\n",
            "Experiment 3: Dataset (anthropic/hh-rlhf) - Model (unsloth/mistral-7b-instruct-v0.3-bnb-4bit)\n",
            "  - Training Loss: Mean=1.4669, Std=0.7203, Min=0.9642, Max=2.9659\n",
            "  - Evaluation Loss: Mean=3.1822, Std=0.3038, Min=2.6885, Max=3.4326\n",
            "Experiment 4: Dataset (imdb) - Model (unsloth/mistral-7b-instruct-v0.3-bnb-4bit)\n",
            "  - Training Loss: Mean=0.9875, Std=0.8833, Min=0.3161, Max=2.7697\n",
            "  - Evaluation Loss: Mean=3.9602, Std=0.4250, Min=3.2271, Max=4.2354\n",
            "\n",
            "Conclusion:\n",
            "In summary, this report has presented a detailed analysis of multiple fine-tuning experiments. The results show the performance variations of different language models across various datasets and configurations. These experiments provide valuable insights into the behavior of these models and can be used to guide further optimization efforts.\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Gemini extra analysis:\n",
            "This report provides a good starting point but lacks crucial information and analysis to draw meaningful conclusions. Here's a breakdown of the issues and suggestions for improvement:\n",
            "\n",
            "**Key Issues:**\n",
            "\n",
            "* **Missing Metrics:**  The report focuses solely on loss, which isn't sufficient to evaluate performance.  Crucially, it's missing metrics relevant to the tasks. For example:\n",
            "    * **SetFit/mrpc:** This dataset is for sentence similarity. Metrics like accuracy, F1-score, and Matthew's Correlation Coefficient are essential.\n",
            "    * **b-mc2/sql-create-context:** This relates to SQL generation.  Metrics should include code execution accuracy, perhaps using a test suite against a database, and potentially BLEU score or similar for code similarity.\n",
            "    * **anthropic/hh-rlhf:** This is for reinforcement learning from human feedback, likely for dialogue generation.  Appropriate metrics might be perplexity, human evaluation scores, or metrics specific to the reward model used.\n",
            "    * **imdb:** This is for sentiment classification. Accuracy, F1-score, precision, and recall are all relevant.\n",
            "* **Zero Training Time for mrpc:**  The zero training time for the `SetFit/mrpc` experiment indicates a likely error. This needs investigation.  It's possible the data wasn't loaded correctly or the training loop didn't execute.\n",
            "* **Limited Dataset Size:** Using only 125 examples for fine-tuning, especially for a 7B parameter model, is extremely small and unlikely to lead to significant performance gains.  A larger dataset is needed for effective fine-tuning.\n",
            "* **Insufficient Training Steps:** 60 maximum steps are also very low.  More steps are likely required for the model to converge, especially with such a small dataset.\n",
            "* **Lack of Hyperparameter Tuning:**  The same configuration is used for all datasets. This is not optimal. Different datasets and tasks will benefit from different hyperparameters.  Experimenting with learning rate, batch size, and weight decay is crucial.\n",
            "* **No Baseline Comparison:**  The report doesn't compare the fine-tuned models against the baseline performance of the original pre-trained model. This comparison is crucial to understand if fine-tuning has actually improved performance.\n",
            "* **No Error Analysis:**  There's no discussion of potential errors or limitations.  Analyzing incorrect predictions can provide insights into the model's weaknesses and guide further improvements.\n",
            "* **Overfitting Concern:** With a small dataset and a large model, overfitting is a major concern.  Techniques like regularization and early stopping should be considered and discussed.\n",
            "\n",
            "\n",
            "**Recommendations for Improvement:**\n",
            "\n",
            "1. **Include Task-Specific Metrics:**  Focus on relevant metrics for each dataset, as mentioned above.\n",
            "2. **Investigate the mrpc Experiment:**  Determine why the training time is zero.\n",
            "3. **Increase Dataset Size:** Use significantly more training data for each dataset.\n",
            "4. **Increase Training Steps:** Allow the model to train for longer. Monitor the training and evaluation loss curves to determine an appropriate number of steps.\n",
            "5. **Perform Hyperparameter Tuning:** Experiment with different learning rates, batch sizes, and other hyperparameters to find optimal settings for each dataset. Consider using a tool like Optuna or Ray Tune.\n",
            "6. **Establish Baseline Performance:**  Evaluate the original pre-trained model on each dataset to provide a baseline for comparison.\n",
            "7. **Conduct Error Analysis:** Analyze incorrect predictions to understand the model's weaknesses.\n",
            "8. **Address Overfitting:**  Implement techniques like regularization and early stopping.\n",
            "9. **Visualizations:**  Include plots of training and evaluation loss curves for each experiment.  This helps visualize the training progress and identify potential issues like overfitting.\n",
            "10. **Detailed Configuration:** Specify the hardware used for training (GPU type, RAM, etc.).\n",
            "\n",
            "\n",
            "By addressing these issues, the report will provide a much more comprehensive and insightful analysis of the fine-tuning experiments, allowing for more informed conclusions and future optimization efforts.\n",
            "\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"Comprehensive Report on Fine-Tuning Experiments\\n\\nIntroduction:\\nThis report summarizes the results of multiple fine-tuning experiments conducted on various language models and datasets. The experiments were designed to evaluate the models' performance under different configurations and datasets.\\n\\nExperiment Details:\\n- Dataset: SetFit/mrpc\\n- Model: unsloth/mistral-7b-instruct-v0.3-bnb-4bit\\n- Configuration: {'max_length': 128, 'quantization': True, 'use_unsloth': False, 'lora': True, 'dataset_size': 125, 'dataset_num_proc': 2, 'test_split_percentage': 0.2, 'training_args': {'output_dir': './output', 'per_device_train_batch_size': 4, 'gradient_accumulation_steps': 4, 'warmup_steps': 5, 'max_steps': 60, 'learning_rate': 0.0002, 'logging_steps': 10, 'weight_decay': 0.01, 'eval_steps': 20, 'report_to': 'none', 'save_steps': 20}}\\n- Training Time: -0.00 seconds\\n  - No training loss data available.\\n  - No evaluation loss data available.\\n\\n- Dataset: b-mc2/sql-create-context\\n- Model: unsloth/mistral-7b-instruct-v0.3-bnb-4bit\\n- Configuration: {'max_length': 128, 'quantization': True, 'use_unsloth': False, 'lora': True, 'dataset_size': 125, 'dataset_num_proc': 2, 'test_split_percentage': 0.2, 'training_args': {'output_dir': './output', 'per_device_train_batch_size': 4, 'gradient_accumulation_steps': 4, 'warmup_steps': 5, 'max_steps': 60, 'learning_rate': 0.0002, 'logging_steps': 10, 'weight_decay': 0.01, 'eval_steps': 20, 'report_to': 'none', 'save_steps': 20}}\\n- Training Time: 191.65 seconds\\n  - Training Loss (Min): 5.2617\\n  - Training Loss (Max): 10.2143\\n  - Training Loss (Std): 1.6899\\n  - Evaluation Loss (Min): 6.3534\\n  - Evaluation Loss (Max): 6.7712\\n  - Evaluation Loss (Std): 0.2024\\n\\n- Dataset: anthropic/hh-rlhf\\n- Model: unsloth/mistral-7b-instruct-v0.3-bnb-4bit\\n- Configuration: {'max_length': 128, 'quantization': True, 'use_unsloth': False, 'lora': True, 'dataset_size': 125, 'dataset_num_proc': 2, 'test_split_percentage': 0.2, 'training_args': {'output_dir': './output', 'per_device_train_batch_size': 4, 'gradient_accumulation_steps': 4, 'warmup_steps': 5, 'max_steps': 60, 'learning_rate': 0.0002, 'logging_steps': 10, 'weight_decay': 0.01, 'eval_steps': 20, 'report_to': 'none', 'save_steps': 20}}\\n- Training Time: 195.02 seconds\\n  - Training Loss (Min): 0.9642\\n  - Training Loss (Max): 2.9659\\n  - Training Loss (Std): 0.7203\\n  - Evaluation Loss (Min): 2.6885\\n  - Evaluation Loss (Max): 3.4326\\n  - Evaluation Loss (Std): 0.3038\\n\\n- Dataset: imdb\\n- Model: unsloth/mistral-7b-instruct-v0.3-bnb-4bit\\n- Configuration: {'max_length': 128, 'quantization': True, 'use_unsloth': False, 'lora': True, 'dataset_size': 125, 'dataset_num_proc': 2, 'test_split_percentage': 0.2, 'training_args': {'output_dir': './output', 'per_device_train_batch_size': 4, 'gradient_accumulation_steps': 4, 'warmup_steps': 5, 'max_steps': 60, 'learning_rate': 0.0002, 'logging_steps': 10, 'weight_decay': 0.01, 'eval_steps': 20, 'report_to': 'none', 'save_steps': 20}}\\n- Training Time: 195.09 seconds\\n  - Training Loss (Min): 0.3161\\n  - Training Loss (Max): 2.7697\\n  - Training Loss (Std): 0.8833\\n  - Evaluation Loss (Min): 3.2271\\n  - Evaluation Loss (Max): 4.2354\\n  - Evaluation Loss (Std): 0.4250\\n\\nComparative Analysis:\\nHere is a comparative analysis of the models and datasets:\\nExperiment 1: Dataset (SetFit/mrpc) - Model (unsloth/mistral-7b-instruct-v0.3-bnb-4bit)\\nExperiment 2: Dataset (b-mc2/sql-create-context) - Model (unsloth/mistral-7b-instruct-v0.3-bnb-4bit)\\n  - Training Loss: Mean=6.5995, Std=1.6899, Min=5.2617, Max=10.2143\\n  - Evaluation Loss: Mean=6.5690, Std=0.2024, Min=6.3534, Max=6.7712\\nExperiment 3: Dataset (anthropic/hh-rlhf) - Model (unsloth/mistral-7b-instruct-v0.3-bnb-4bit)\\n  - Training Loss: Mean=1.4669, Std=0.7203, Min=0.9642, Max=2.9659\\n  - Evaluation Loss: Mean=3.1822, Std=0.3038, Min=2.6885, Max=3.4326\\nExperiment 4: Dataset (imdb) - Model (unsloth/mistral-7b-instruct-v0.3-bnb-4bit)\\n  - Training Loss: Mean=0.9875, Std=0.8833, Min=0.3161, Max=2.7697\\n  - Evaluation Loss: Mean=3.9602, Std=0.4250, Min=3.2271, Max=4.2354\\n\\nConclusion:\\nIn summary, this report has presented a detailed analysis of multiple fine-tuning experiments. The results show the performance variations of different language models across various datasets and configurations. These experiments provide valuable insights into the behavior of these models and can be used to guide further optimization efforts.\\n\\n\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    }
  ]
}