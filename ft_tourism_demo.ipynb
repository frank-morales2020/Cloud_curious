{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "kqBg9jWWjTsn",
        "cuWqTrK6kGGm"
      ],
      "machine_shape": "hm",
      "gpuType": "L4",
      "authorship_tag": "ABX9TyMY/xJQ7ADTaboSgutcDCyr",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/frank-morales2020/Cloud_curious/blob/master/ft_tourism_demo.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## dataset FOR tourism travel planning"
      ],
      "metadata": {
        "id": "kqBg9jWWjTsn"
      }
    },
    {
      "source": [
        "import json\n",
        "import random\n",
        "from datetime import datetime, timedelta\n",
        "\n",
        "# --- 1. Define your expanded base data pools (these would be much larger in reality) ---\n",
        "# Each destination should have diverse options for attractions, hotels, etc.\n",
        "DESTINATIONS_DATA = {\n",
        "    \"Kyoto\": {\n",
        "        \"attractions\": [\n",
        "            {\"name\": \"Kinkaku-ji (Golden Pavilion)\", \"type\": \"temple\", \"visit_time\": 1.5, \"cost\": 5, \"transport_notes\": \"Bus from Kyoto Station\"},\n",
        "            {\"name\": \"Fushimi Inari-taisha Shrine\", \"type\": \"shrine/hiking\", \"visit_time\": 2.5, \"cost\": 0, \"transport_notes\": \"JR Nara Line from Kyoto Station\"},\n",
        "            {\"name\": \"Arashiyama Bamboo Grove\", \"type\": \"nature/sightseeing\", \"visit_time\": 2, \"cost\": 0, \"transport_notes\": \"JR Sagano Line from Kyoto Station\"},\n",
        "            {\"name\": \"Gion District\", \"type\": \"historic district\", \"visit_time\": 3, \"cost\": 0, \"transport_notes\": \"Walk or Bus\"},\n",
        "            {\"name\": \"Kiyomizu-dera Temple\", \"type\": \"temple\", \"visit_time\": 2, \"cost\": 4, \"transport_notes\": \"Walk or Bus\"},\n",
        "            {\"name\": \"Nishiki Market\", \"type\": \"market/food\", \"visit_time\": 2, \"cost\": 0, \"transport_notes\": \"Walk or Bus\"}\n",
        "        ],\n",
        "        \"hotels\": [\n",
        "            {\"name\": \"Ryokan Yoshida-sanso\", \"price_per_night\": 200, \"rating\": 4.7, \"location_tags\": [\"Higashiyama\", \"Traditional\"]},\n",
        "            {\"name\": \"Hotel Granvia Kyoto\", \"price_per_night\": 150, \"rating\": 4.5, \"location_tags\": [\"Kyoto Station\", \"Modern\"]},\n",
        "            {\"name\": \"Capsule Hotel Kyoto\", \"price_per_night\": 50, \"rating\": 4.0, \"location_tags\": [\"Downtown\", \"Budget\"]}\n",
        "        ],\n",
        "        \"restaurants\": [\n",
        "            {\"name\": \"Kyoto Gion Karyo\", \"cuisine\": \"Kaiseki\", \"avg_cost\": 100, \"type\": \"luxury\"},\n",
        "            {\"name\": \"Menbakaichidai (Flaming Ramen)\", \"cuisine\": \"Ramen\", \"avg_cost\": 20, \"type\": \"casual\"},\n",
        "            {\"name\": \"Nishiki Market Food Stalls\", \"cuisine\": \"Street Food\", \"avg_cost\": 15, \"type\": \"budget\"},\n",
        "            {\"name\": \"Saryo Tsujiri (Matcha Desserts)\", \"cuisine\": \"Desserts\", \"avg_cost\": 12, \"type\": \"cafe\"}\n",
        "        ],\n",
        "        \"weather_patterns\": {\n",
        "            \"October\": {\"avg_temp_c\": 17, \"precip_days\": 7, \"notes\": \"mild & pleasant\"},\n",
        "            \"November\": {\"avg_temp_c\": 11, \"precip_days\": 6, \"notes\": \"cool, autumn foliage\"}\n",
        "        },\n",
        "        \"local_transport\": [\n",
        "            {\"type\": \"Kyoto City Bus\", \"cost_per_ride\": 2.5, \"notes\": \"Most common for sightseeing\"},\n",
        "            {\"type\": \"Subway\", \"cost_per_ride\": 2, \"notes\": \"Limited lines, good for specific routes\"},\n",
        "            {\"type\": \"JR Trains\", \"cost_per_ride\": 3, \"notes\": \"Efficient for key attractions\"}\n",
        "        ]\n",
        "    },\n",
        "    \"Rome\": {\n",
        "        \"attractions\": [\n",
        "            {\"name\": \"Colosseum\", \"type\": \"ancient ruin\", \"visit_time\": 2, \"cost\": 20, \"transport_notes\": \"Metro B\"},\n",
        "            {\"name\": \"Roman Forum & Palatine Hill\", \"type\": \"ancient ruin\", \"visit_time\": 3, \"cost\": 0, \"transport_notes\": \"Walk from Colosseum\"},\n",
        "            {\"name\": \"Vatican Museums & Sistine Chapel\", \"type\": \"museum\", \"visit_time\": 4, \"cost\": 25, \"transport_notes\": \"Metro A\"},\n",
        "            {\"name\": \"St. Peter's Basilica\", \"type\": \"cathedral\", \"visit_time\": 2, \"cost\": 0, \"transport_notes\": \"Walk from Vatican Museums\"},\n",
        "            {\"name\": \"Pantheon\", \"type\": \"ancient temple/church\", \"visit_time\": 1, \"cost\": 0, \"transport_notes\": \"Walk/Bus\"},\n",
        "            {\"name\": \"Trevi Fountain\", \"type\": \"landmark\", \"visit_time\": 0.5, \"cost\": 0, \"transport_notes\": \"Walk\"}\n",
        "        ],\n",
        "        \"hotels\": [\n",
        "            {\"name\": \"Hotel Artemide\", \"price_per_night\": 180, \"rating\": 4.6, \"location_tags\": [\"Termini\", \"Central\"]},\n",
        "            {\"name\": \"Generator Rome\", \"price_per_night\": 60, \"rating\": 4.0, \"location_tags\": [\"Esquilino\", \"Budget\"]},\n",
        "            {\"name\": \"Hotel Santa Maria\", \"price_per_night\": 150, \"rating\": 4.3, \"location_tags\": [\"Trastevere\", \"Charming\"]}\n",
        "        ],\n",
        "        \"restaurants\": [\n",
        "            {\"name\": \"Trattoria Da Cesare al Casaletto\", \"cuisine\": \"Roman\", \"avg_cost\": 40, \"type\": \"mid-range\"},\n",
        "            {\"name\": \"Da Enzo al 29\", \"cuisine\": \"Roman\", \"avg_cost\": 30, \"type\": \"mid-range\"},\n",
        "            {\"name\": \"Supplì Roma\", \"cuisine\": \"Street food\", \"avg_cost\": 8, \"type\": \"budget\"},\n",
        "            {\"name\": \"Pizzeria Baffetto 2\", \"cuisine\": \"Pizza\", \"avg_cost\": 20, \"type\": \"casual\"}\n",
        "        ],\n",
        "        \"weather_patterns\": {\n",
        "            \"April\": {\"avg_temp_c\": 14, \"precip_days\": 8, \"notes\": \"mild, spring showers\"},\n",
        "            \"July\": {\"avg_temp_c\": 26, \"precip_days\": 2, \"notes\": \"hot, sunny\"}\n",
        "        },\n",
        "        \"local_transport\": [\n",
        "            {\"type\": \"Metro\", \"cost_per_ride\": 1.5, \"notes\": \"Connects major points\"},\n",
        "            {\"type\": \"Bus/Tram\", \"cost_per_ride\": 1.5, \"notes\": \"Extensive network\"},\n",
        "            {\"type\": \"Walk\", \"cost_per_ride\": 0, \"notes\": \"Best for historic center\"}\n",
        "        ]\n",
        "    },\n",
        "    # ... Add more destinations with rich data (Orlando, etc.)\n",
        "}\n",
        "\n",
        "# --- User Profile Archetypes (based on your questionnaire) ---\n",
        "USER_PROFILE_ARCHETYPES = [\n",
        "    # Solo Traveler\n",
        "    {\"traveler_type\": \"Solo\", \"budget_level\": \"medium\", \"interests\": [\"cultural\", \"history\"], \"pace\": \"balanced\", \"app_comfort\": \"Tech-savvy\"},\n",
        "    {\"traveler_type\": \"Solo\", \"budget_level\": \"low\", \"interests\": [\"food\", \"local events\"], \"pace\": \"relaxed\", \"app_comfort\": \"Average\"},\n",
        "    # Couple Traveler\n",
        "    {\"traveler_type\": \"Couple\", \"budget_level\": \"high\", \"interests\": [\"art\", \"fine dining\"], \"pace\": \"relaxed\", \"app_comfort\": \"Tech-savvy\"},\n",
        "    {\"traveler_type\": \"Couple\", \"budget_level\": \"medium\", \"interests\": [\"adventure\", \"nature\"], \"pace\": \"full schedule\", \"app_comfort\": \"Average\"},\n",
        "    # Family Traveler\n",
        "    {\"traveler_type\": \"Family\", \"budget_level\": \"high\", \"interests\": [\"theme parks\", \"kid-friendly\"], \"pace\": \"full schedule\", \"app_comfort\": \"Tech-savvy\"},\n",
        "    {\"traveler_type\": \"Family\", \"budget_level\": \"medium\", \"interests\": [\"educational\", \"outdoor\"], \"pace\": \"balanced\", \"app_comfort\": \"Average\"},\n",
        "    # ... Add more archetypes\n",
        "]\n",
        "\n",
        "# --- 2. Main Generation Loop (Enhanced Itinerary Logic) ---\n",
        "generated_dataset = []\n",
        "num_entries_to_generate = 1000\n",
        "\n",
        "# Helper function to generate a weather forecast for a day (remains the same)\n",
        "def get_daily_weather(historical_weather):\n",
        "    temps = [historical_weather['avg_temp_c'] + random.randint(-3, 3) for _ in range(3)]\n",
        "    temp_c = int(sum(temps) / len(temps))\n",
        "    temp_f = int(temp_c * 9/5 + 32)\n",
        "    precip_chance = historical_weather['precip_days'] / 30\n",
        "    weather_desc = random.choices(\n",
        "        ['Clear skies', 'Partly cloudy', 'Sunny', 'Light rain', 'Cloudy'],\n",
        "        weights=[0.4, 0.3, 0.15, 0.1, 0.05]\n",
        "    )[0]\n",
        "    if random.random() < precip_chance * 0.7:\n",
        "        weather_desc = 'Light rain' if 'rain' not in weather_desc else weather_desc\n",
        "    if random.random() < precip_chance * 0.3:\n",
        "        weather_desc = 'Heavy rain' if 'rain' not in weather_desc else weather_desc\n",
        "    return f\"{weather_desc}, {temp_c}°C/{temp_f}°F\"\n",
        "\n",
        "# --- Main loop for generating entries ---\n",
        "for i in range(num_entries_to_generate):\n",
        "    # a. Randomly select profile, destination, duration\n",
        "    profile = random.choice(USER_PROFILE_ARCHETYPES)\n",
        "    destination_name, destination_data = random.choice(list(DESTINATIONS_DATA.items()))\n",
        "    trip_duration_days = random.randint(3, 7)\n",
        "\n",
        "    # Randomly select a month for the trip from available weather data\n",
        "    trip_month = random.choice(list(destination_data[\"weather_patterns\"].keys()))\n",
        "    historical_weather = destination_data[\"weather_patterns\"][trip_month]\n",
        "\n",
        "    start_date = datetime(2025, random.randint(1, 12), random.randint(1, 20))\n",
        "\n",
        "    # b. Construct user_query based on profile and selected destination/dates (remains the same)\n",
        "    user_query = (\n",
        "        f\"Plan a {trip_duration_days}-day {profile['traveler_type'].lower()} trip to {destination_name} \"\n",
        "        f\"in {trip_month}. My budget is {profile['budget_level']} and I'm interested in \"\n",
        "        f\"{', '.join(profile['interests'])}. I prefer a {profile['pace']} pace and am \"\n",
        "        f\"{profile['app_comfort']} with mobile apps.\"\n",
        "    )\n",
        "\n",
        "    # c. Populate available_information (filtering logic slightly adjusted for better distribution)\n",
        "\n",
        "    # Filter and select attractions - aim to select *more* than can fit, then assign\n",
        "    # Added .get('', '') for safety in case 'type' is missing\n",
        "    filtered_attractions = [a for a in destination_data[\"attractions\"] if any(interest in a.get('type', '').lower() for interest in profile['interests']) or random.random() < 0.5]\n",
        "\n",
        "    num_available_attractions = len(filtered_attractions)\n",
        "\n",
        "    # Define the lower bound for the number of attractions to sample\n",
        "    # This is the minimum required, capped by the actual number available\n",
        "    min_attractions_to_sample = min(max(3, trip_duration_days - 1), num_available_attractions)\n",
        "\n",
        "    # Define the upper bound for the number of attractions to sample\n",
        "    # This is simply the total number available\n",
        "    max_attractions_to_sample = num_available_attractions\n",
        "\n",
        "    # Ensure the upper bound for random.randint is at least the lower bound.\n",
        "    # If num_available_attractions is 0, both min and max sample counts will be 0,\n",
        "    # and random.randint(0, 0) is valid (returns 0).\n",
        "    upper_bound_for_randint = max(min_attractions_to_sample, max_attractions_to_sample)\n",
        "\n",
        "    # Determine the actual number of attractions to sample\n",
        "    # If no attractions are available, sample 0\n",
        "    if upper_bound_for_randint == 0:\n",
        "         num_attractions_to_sample = 0\n",
        "    else:\n",
        "        # Sample a random number between the adjusted lower bound and the total available\n",
        "        # This ensures the range for random.randint is always valid\n",
        "        num_attractions_to_sample = random.randint(min_attractions_to_sample, upper_bound_for_randint)\n",
        "\n",
        "\n",
        "    # Select the pool of potential attractions to choose from during itinerary building\n",
        "    # Use num_attractions_to_sample as the 'k' for random.sample\n",
        "    pool_attractions = random.sample(filtered_attractions, k=num_attractions_to_sample)\n",
        "\n",
        "\n",
        "    # Filter and select hotels\n",
        "    selected_hotels = [h for h in destination_data[\"hotels\"] if profile['budget_level'] == \"low\" and h['price_per_night'] < 100 or\n",
        "                                                            profile['budget_level'] == \"medium\" and 50 < h['price_per_night'] < 250 or\n",
        "                                                            profile['budget_level'] == \"high\" and h['price_per_night'] > 150]\n",
        "    selected_hotels = random.sample(selected_hotels, k=1) if selected_hotels else random.sample(destination_data[\"hotels\"], k=1) # Fallback\n",
        "\n",
        "    # Filter and select restaurants - select a larger pool\n",
        "    filtered_restaurants = [r for r in destination_data[\"restaurants\"] if (profile['budget_level'] == \"low\" and r['avg_cost'] < 20) or\n",
        "                                                    (profile['budget_level'] == \"medium\" and 10 < r['avg_cost'] < 50) or\n",
        "                                                    (profile['budget_level'] == \"high\" and r['avg_cost'] > 30)]\n",
        "    # Select a pool of potential restaurants\n",
        "    # Determine the number of restaurants to sample safely\n",
        "    num_available_restaurants = len(filtered_restaurants)\n",
        "    min_restaurants_to_sample = max(3, trip_duration_days)\n",
        "\n",
        "    # Ensure the lower bound for random.randint is not greater than the upper bound (num_available_restaurants)\n",
        "    lower_bound = min(min_restaurants_to_sample, num_available_restaurants)\n",
        "    upper_bound = num_available_restaurants\n",
        "\n",
        "    if upper_bound < lower_bound:\n",
        "        # This case handles when num_available_restaurants is 0 or very small, and min_restaurants_to_sample is larger.\n",
        "        # In this scenario, sample whatever is available (which might be 0).\n",
        "        num_restaurants_to_sample = num_available_restaurants\n",
        "    else:\n",
        "        # Sample a random number between the adjusted lower bound and the total available\n",
        "        num_restaurants_to_sample = random.randint(lower_bound, upper_bound)\n",
        "\n",
        "    # Now sample the restaurants\n",
        "    pool_restaurants = random.sample(filtered_restaurants, k=num_restaurants_to_sample)\n",
        "\n",
        "\n",
        "    available_info = {\n",
        "        \"total_budget_usd\": random.randint(profile['budget_level'] == \"low\" and 500 or profile['budget_level'] == \"medium\" and 1500 or 3000,\n",
        "                                           profile['budget_level'] == \"low\" and 1000 or profile['budget_level'] == \"medium\" and 2500 or 5000),\n",
        "        \"flights\": [], # Needs actual flight generation logic\n",
        "        \"hotels\": selected_hotels,\n",
        "        \"attractions\": pool_attractions, # Use the pool of attractions\n",
        "        \"restaurants\": pool_restaurants, # Use the pool of restaurants\n",
        "        \"historical_weather\": historical_weather,\n",
        "        \"local_transportation_options\": destination_data[\"local_transport\"],\n",
        "    }\n",
        "\n",
        "    # d. Construct day_by_day_itinerary (Enhanced Logic)\n",
        "    day_by_day_itinerary = []\n",
        "\n",
        "    # Keep track of visited attractions and chosen restaurants to avoid repetition\n",
        "    visited_attractions = set()\n",
        "    chosen_restaurants = set()\n",
        "\n",
        "    # Determine daily activity slots based on pace\n",
        "    if profile['pace'] == 'full schedule':\n",
        "        daily_slots = ['morning', 'afternoon', 'evening'] # Can fit 3 main things + potentially more\n",
        "        activity_capacity_per_day = random.randint(2, 4) # Number of activities/meals to aim for\n",
        "    elif profile['pace'] == 'balanced':\n",
        "        daily_slots = ['morning', 'afternoon', 'evening'] # Can fit 2-3 main things\n",
        "        activity_capacity_per_day = random.randint(2, 3)\n",
        "    else: # 'relaxed'\n",
        "        daily_slots = ['morning', 'afternoon', 'evening'] # Can fit 1-2 main things\n",
        "        activity_capacity_per_day = random.randint(1, 2)\n",
        "\n",
        "    # Simple time allocation simulation (hours per slot) - This is a simplification\n",
        "    slot_times = {'morning': 3, 'afternoon': 3, 'evening': 4} # Example: Morning 9-12, Afternoon 1-4, Evening 6-10\n",
        "\n",
        "    for day_num in range(1, trip_duration_days + 1):\n",
        "        current_date = start_date + timedelta(days=day_num - 1)\n",
        "        daily_weather = get_daily_weather(historical_weather)\n",
        "\n",
        "        day_plan = {\n",
        "            \"day_number\": day_num,\n",
        "            \"date\": current_date.strftime(\"%Y-%m-%d\"),\n",
        "            \"weather_forecast\": daily_weather,\n",
        "            \"focus\": f\"Day {day_num} in {destination_name}\",\n",
        "            \"morning\": [],\n",
        "            \"afternoon\": [],\n",
        "            \"evening\": []\n",
        "        }\n",
        "\n",
        "        available_slots = daily_slots[:] # Copy the list\n",
        "\n",
        "        # Handle arrival day\n",
        "        if day_num == 1:\n",
        "            day_plan[\"morning\"].append(\"Arrival at destination.\")\n",
        "            if available_info[\"hotels\"]:\n",
        "                day_plan[\"afternoon\"].append(f\"Check into {available_info['hotels'][0]['name']}.\")\n",
        "                # Assume this takes some time, reduce afternoon capacity slightly\n",
        "                current_afternoon_time = slot_times['afternoon'] - 1.5 # e.g., check-in takes 1.5 hours\n",
        "            else:\n",
        "                 current_afternoon_time = slot_times['afternoon']\n",
        "\n",
        "            current_morning_time = 0 # Morning largely used for arrival\n",
        "            current_evening_time = slot_times['evening']\n",
        "\n",
        "            # Remove morning from available slots for planning activities\n",
        "            if 'morning' in available_slots: available_slots.remove('morning')\n",
        "\n",
        "        # Handle departure day\n",
        "        elif day_num == trip_duration_days:\n",
        "             day_plan[\"evening\"].append(\"Check out from accommodation and depart.\")\n",
        "             if available_info[\"hotels\"]:\n",
        "                 day_plan[\"evening\"][-1] = f\"Check out from {available_info['hotels'][0]['name']} and depart.\"\n",
        "\n",
        "             current_morning_time = slot_times['morning']\n",
        "             current_afternoon_time = slot_times['afternoon']\n",
        "             current_evening_time = 0 # Evening largely used for departure\n",
        "\n",
        "             # Remove evening from available slots for planning activities/meals\n",
        "             if 'evening' in available_slots: available_slots.remove('evening')\n",
        "\n",
        "        # Normal days\n",
        "        else:\n",
        "             current_morning_time = slot_times['morning']\n",
        "             current_afternoon_time = slot_times['afternoon']\n",
        "             current_evening_time = slot_times['evening']\n",
        "\n",
        "\n",
        "        # --- Distribute Attractions and Restaurants ---\n",
        "        # Simple distribution: Try to add activities/meals to slots while respecting time\n",
        "\n",
        "        # Combine attractions and restaurants available for this trip, prioritizing interests\n",
        "        available_items = sorted(\n",
        "            pool_attractions + pool_restaurants,\n",
        "            key=lambda x: any(interest in x.get('type', '').lower() or interest in x.get('cuisine', '').lower() for interest in profile['interests']) or any(interest in ' '.join(x.get('location_tags', [])).lower() for interest in profile['interests']),\n",
        "            reverse=True # Prioritize items matching interests\n",
        "        )\n",
        "\n",
        "        assigned_items_today = []\n",
        "        remaining_capacity = activity_capacity_per_day\n",
        "\n",
        "        # Iterate through available items and try to place them\n",
        "        for item in available_items:\n",
        "            if remaining_capacity <= 0:\n",
        "                break # Stop if we've assigned enough items for today\n",
        "\n",
        "            item_name = item.get('name', 'Unnamed Item')\n",
        "            item_type = item.get('type', '') or item.get('cuisine', '')\n",
        "            item_cost = item.get('cost', 0) or item.get('avg_cost', 0)\n",
        "            visit_time = item.get('visit_time', 2) # Default visit time\n",
        "            item_notes = item.get('transport_notes', '') # Use transport notes for attractions\n",
        "\n",
        "            # Skip if already visited/chosen or already assigned today\n",
        "            if item_name in visited_attractions or item_name in chosen_restaurants or item_name in assigned_items_today:\n",
        "                continue\n",
        "\n",
        "            # Decide which slot to try to place it in\n",
        "            # Simple logic: Attractions in morning/afternoon, Restaurants in evening (mostly)\n",
        "            potential_slots = []\n",
        "            if 'attraction' in item_type.lower() or 'temple' in item_type.lower() or 'shrine' in item_type.lower() or 'museum' in item_type.lower() or 'landmark' in item_type.lower() or 'nature' in item_type.lower() or 'historic district' in item_type.lower():\n",
        "                 potential_slots = [slot for slot in ['morning', 'afternoon'] if slot in available_slots]\n",
        "                 activity_desc = f\"Visit {item_name}\"\n",
        "                 if item_notes: activity_desc += f\" ({item_notes})\"\n",
        "                 if item_cost > 0: activity_desc += f\" (Cost: ${item_cost})\"\n",
        "\n",
        "            elif 'restaurant' in item_type.lower() or 'food' in item_type.lower() or 'cafe' in item_type.lower() or 'desserts' in item_type.lower():\n",
        "                 potential_slots = [slot for slot in ['evening'] if slot in available_slots]\n",
        "                 activity_desc = f\"Dinner at {item_name}\"\n",
        "                 if item_cost > 0: activity_desc += f\" (Budget: ~${item_cost})\"\n",
        "                 visit_time = 1.5 # Assume fixed time for meals\n",
        "\n",
        "            # Try to place in the first available potential slot\n",
        "            placed = False\n",
        "            for slot in potential_slots:\n",
        "                # Check if there's enough time in the slot (simplified)\n",
        "                if slot == 'morning' and current_morning_time >= visit_time:\n",
        "                     day_plan['morning'].append(activity_desc)\n",
        "                     current_morning_time -= visit_time\n",
        "                     placed = True\n",
        "                elif slot == 'afternoon' and current_afternoon_time >= visit_time:\n",
        "                     day_plan['afternoon'].append(activity_desc)\n",
        "                     current_afternoon_time -= visit_time\n",
        "                     placed = True\n",
        "                elif slot == 'evening' and current_evening_time >= visit_time:\n",
        "                     day_plan['evening'].append(activity_desc)\n",
        "                     current_evening_time -= visit_time\n",
        "                     placed = True\n",
        "\n",
        "                if placed:\n",
        "                    assigned_items_today.append(item_name)\n",
        "                    if 'attraction' in item_type.lower() or 'temple' in item_type.lower() or 'shrine' in item_type.lower() or 'museum' in item_type.lower() or 'landmark' in item_type.lower() or 'nature' in item_type.lower() or 'historic district' in item_type.lower():\n",
        "                         visited_attractions.add(item_name)\n",
        "                    elif 'restaurant' in item_type.lower() or 'food' in item_type.lower() or 'cafe' in item_type.lower() or 'desserts' in item_type.lower():\n",
        "                         chosen_restaurants.add(item_name)\n",
        "                    remaining_capacity -= 1\n",
        "                    break # Move to the next item after placing this one\n",
        "\n",
        "        # Add some generic fillers if slots are empty after placing main activities\n",
        "        if 'morning' in available_slots and not day_plan['morning'] and day_num != 1: # Don't add filler on arrival morning\n",
        "            day_plan['morning'].append(\"Start the day with breakfast and preparation.\")\n",
        "        if 'afternoon' in available_slots and not day_plan['afternoon'] and (day_num != 1 or not available_info[\"hotels\"]): # Don't add filler if checking in\n",
        "             # Add a random local transport note as a filler\n",
        "             if destination_data[\"local_transport\"] and random.random() < 0.5:\n",
        "                  transport_option = random.choice(destination_data[\"local_transport\"])\n",
        "                  day_plan['afternoon'].append(f\"Explore the area using {transport_option['type']}.\")\n",
        "             else:\n",
        "                 day_plan['afternoon'].append(\"Free time or explore the local area.\")\n",
        "        if 'evening' in available_slots and not day_plan['evening'] and day_num != trip_duration_days: # Don't add filler on departure evening\n",
        "             # Add a generic dining suggestion if no restaurant was placed\n",
        "             if not any('Dinner at' in item for item in day_plan['evening']):\n",
        "                  day_plan['evening'].append(\"Enjoy dinner at a local restaurant.\")\n",
        "             day_plan['evening'].append(\"Evening relaxation or optional activity.\")\n",
        "\n",
        "\n",
        "        # Clean up empty lists if no activities were assigned\n",
        "        # Create a list of slots to check to avoid modifying the dict during iteration\n",
        "        slots_to_check = ['morning', 'afternoon', 'evening']\n",
        "        for slot in slots_to_check:\n",
        "             # Check if the key exists before trying to access it and check if list is empty\n",
        "             if slot in day_plan and not day_plan[slot]:\n",
        "                  del day_plan[slot] # Remove the key if the list is empty\n",
        "\n",
        "\n",
        "        day_by_day_itinerary.append(day_plan)\n",
        "\n",
        "    generated_dataset.append({\n",
        "        \"user_query\": user_query,\n",
        "        \"available_information\": available_info,\n",
        "        \"day_by_day_itinerary\": day_by_day_itinerary\n",
        "    })\n",
        "\n",
        "# --- 3. Save to JSONL (remains the same) ---\n",
        "output_filename = f\"synthetic_tourism_dataset_{num_entries_to_generate}_entries_enhanced.jsonl\" # New filename to avoid overwriting\n",
        "with open(output_filename, 'w', encoding='utf-8') as f:\n",
        "    for entry in generated_dataset:\n",
        "        f.write(json.dumps(entry, ensure_ascii=False) + '\\n')\n",
        "\n",
        "print(f\"Generated {len(generated_dataset)} synthetic entries with enhanced itineraries to {output_filename}\")\n",
        "print(\"\\nNOTE: The itinerary generation logic has been enhanced but is still a simulation. More sophisticated planning (like geographical routing, opening hours, booking details, etc.) would require more complex code and data.\")"
      ],
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ScE8x3UAD3uo",
        "outputId": "0a893171-427a-48f9-cf34-1c7af59c8b2a"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generated 1000 synthetic entries with enhanced itineraries to synthetic_tourism_dataset_1000_entries_enhanced.jsonl\n",
            "\n",
            "NOTE: The itinerary generation logic has been enhanced but is still a simulation. More sophisticated planning (like geographical routing, opening hours, booking details, etc.) would require more complex code and data.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## fine tune"
      ],
      "metadata": {
        "id": "lvj5UHbLjaO0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 1. Set Up Your Environment ---\n",
        "!pip install scikit-learn -q # For potential evaluation metrics (optional)\n",
        "!pip install -U transformers -q\n",
        "!pip install -U datasets -q\n",
        "!pip install -U accelerate -q\n",
        "!pip install -U peft -q\n",
        "!pip install -U trl -q # For SFTTrainer\n",
        "!pip install -U bitsandbytes -q\n",
        "!pip install unsloth -q # Recommended for speed and efficiency\n",
        "!pip install --force-reinstall --no-cache-dir --no-deps git+https://github.com/unslothai/unsloth.git # For latest Unsloth"
      ],
      "metadata": {
        "id": "7mMhriDvis-w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "source": [
        "# 0. Initial Setup\n",
        "# Install necessary libraries if running in Colab/Jupyter (ensure these are installed first)\n",
        "# !pip install -U transformers datasets accelerate peft trl bitsandbytes unsloth scikit-learn\n",
        "import torch\n",
        "import io\n",
        "import pandas as pd\n",
        "import json\n",
        "from datasets import load_dataset, Dataset # Added Dataset for potential manual splits\n",
        "from unsloth import FastLanguageModel\n",
        "from trl import SFTTrainer\n",
        "from transformers import TrainingArguments, TextStreamer, AutoTokenizer\n",
        "from huggingface_hub import login # Optional: for pushing model to Hub\n",
        "\n",
        "# Ensure you are logged into Hugging Face if you plan to push models or use private datasets\n",
        "# login() # Uncomment and run if needed\n",
        "\n",
        "# 1. Load the Model and Tokenizer\n",
        "print(\"Loading DeepSeek-R1 model and tokenizer...\")\n",
        "model, tokenizer = FastLanguageModel.from_pretrained(\n",
        "    model_name=\"unsloth/DeepSeek-R1-Distill-Llama-8B\",\n",
        "    max_seq_length=2048, # Adjust if your combined input/output is longer\n",
        "    dtype=None, # Automatically chooses bfloat16 or float16 based on GPU\n",
        "    load_in_4bit=True, # Enable 4-bit quantization for memory efficiency\n",
        ")\n",
        "print(\"Model and tokenizer loaded.\")\n",
        "\n",
        "# 2. Apply LoRA Adapters\n",
        "print(\"Applying LoRA adapters...\")\n",
        "model = FastLanguageModel.get_peft_model(\n",
        "    model,\n",
        "    r=16, # Rank of the LoRA matrices (common values: 8, 16, 32, 64)\n",
        "    target_modules=[\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\", \"gate_proj\", \"up_proj\", \"down_proj\"],\n",
        "    lora_alpha=16, # Scaling factor for LoRA weights\n",
        "    lora_dropout=0, # Dropout rate for LORA (set to 0 for inference)\n",
        "    bias=\"none\", # Or \"all\", \"lora_only\"\n",
        "    use_gradient_checkpointing=True, # Recommended for memory saving\n",
        "    random_state=3407,\n",
        "    use_rslora=False,\n",
        "    loftq_config=None,\n",
        ")\n",
        "print(\"LoRA adapters applied.\")\n",
        "\n",
        "# 3. Load Your Synthetic Dataset\n",
        "print(\"Loading and preparing synthetic dataset...\")\n",
        "\n",
        "# --- IMPORTANT: Make sure 'synthetic_tourism_dataset_100_entries.jsonl' is in the same directory\n",
        "# --- as your script, or provide the full path to the file.\n",
        "\n",
        "# Load the full dataset from your .jsonl file\n",
        "#dataset_path = 'synthetic_tourism_dataset_100_entries.jsonl'\n",
        "dataset_path = output_filename\n",
        "full_dataset = load_dataset('json', data_files=dataset_path)\n",
        "\n",
        "# Split the dataset into training and evaluation sets (e.g., 90% train, 10% eval)\n",
        "# The 'train' split comes from the default behavior of load_dataset for single file.\n",
        "raw_dataset_split = full_dataset['train'].train_test_split(test_size=0.1, seed=42)\n",
        "train_dataset_raw = raw_dataset_split['train']\n",
        "eval_dataset_raw = raw_dataset_split['test']\n",
        "\n",
        "print(f\"Raw dataset loaded. Training entries: {len(train_dataset_raw)}, Evaluation entries: {len(eval_dataset_raw)}\")\n",
        "\n",
        "\n",
        "# 4. Define the **MODIFIED** Formatting Function\n",
        "# This function converts your synthetic dataset entries into the\n",
        "# chat format that the DeepSeek-R1 model will be trained on.\n",
        "\n",
        "def format_daily_itinerary_example(example):\n",
        "    user_query = example[\"user_query\"]\n",
        "    available_info = example[\"available_information\"]\n",
        "    day_by_day_itinerary = example[\"day_by_day_itinerary\"]\n",
        "\n",
        "    # --- Construct the 'Available Information' string for the prompt ---\n",
        "    formatted_available_info_str = \"\\nAvailable Information:\\n\"\n",
        "    if \"flights\" in available_info and available_info[\"flights\"]:\n",
        "        formatted_available_info_str += \"Flights:\\n\" + \"\\n\".join([json.dumps(f) for f in available_info[\"flights\"]]) + \"\\n\"\n",
        "    if \"hotels\" in available_info and available_info[\"hotels\"]:\n",
        "        formatted_available_info_str += \"Accommodation:\\n\" + \"\\n\".join([json.dumps(h) for h in available_info[\"hotels\"]]) + \"\\n\"\n",
        "    if \"attractions\" in available_info and available_info[\"attractions\"]:\n",
        "        formatted_available_info_str += \"Attractions:\\n\" + \"\\n\".join([json.dumps(a) for a in available_info[\"attractions\"]]) + \"\\n\"\n",
        "    if \"restaurants\" in available_info and available_info[\"restaurants\"]:\n",
        "        formatted_available_info_str += \"Dining:\\n\" + \"\\n\".join([json.dumps(r) for r in available_info[\"restaurants\"]]) + \"\\n\"\n",
        "    if \"total_budget_usd\" in available_info:\n",
        "        formatted_available_info_str += f\"Total Budget: ${available_info['total_budget_usd']}\\n\"\n",
        "    # Use the correct keys for historical weather data\n",
        "    if \"historical_weather\" in available_info:\n",
        "        # Ensure both keys exist before trying to access them\n",
        "        avg_temp_c = available_info['historical_weather'].get('avg_temp_c', 'N/A')\n",
        "        notes = available_info['historical_weather'].get('notes', 'N/A')\n",
        "        formatted_available_info_str += f\"Historical Weather Context: Avg Temp {avg_temp_c}°C, {notes}\\n\"\n",
        "    if \"local_transportation_options\" in available_info:\n",
        "        formatted_available_info_str += \"Local Transportation Options:\\n\" + \"\\n\".join([f\"- {t['type']}: {t['notes']}\" for t in available_info[\"local_transportation_options\"]]) + \"\\n\"\n",
        "\n",
        "\n",
        "    # --- Construct the TARGET 'assistant' output (the per-day itinerary) ---\n",
        "    generated_itinerary_text = \"Proposed Travel Itinerary:\\n\"\n",
        "    for day_plan in day_by_day_itinerary:\n",
        "        generated_itinerary_text += f\"\\nDay {day_plan['day_number']}: {day_plan['date']}\"\n",
        "        if 'weather_forecast' in day_plan:\n",
        "            generated_itinerary_text += f\" (Weather: {day_plan['weather_forecast']})\"\n",
        "        generated_itinerary_text += f\"\\nFocus: {day_plan['focus']}\\n\" if 'focus' in day_plan else \"\\n\"\n",
        "        if 'morning' in day_plan:\n",
        "            generated_itinerary_text += f\"  Morning: {day_plan['morning']}\\n\"\n",
        "        if 'afternoon' in day_plan:\n",
        "            generated_itinerary_text += f\"  Afternoon: {day_plan['afternoon']}\\n\"\n",
        "        if 'evening' in day_plan:\n",
        "            generated_itinerary_text += f\"  Evening: {day_plan['evening']}\\n\"\n",
        "\n",
        "    # --- Combine into the chat format for training ---\n",
        "    messages = [\n",
        "        {\"role\": \"user\", \"content\": f\"User's travel request: {user_query}\\n\\n{formatted_available_info_str}\\n\\nBased on the user's travel request and the available information, please generate a detailed travel itinerary broken down by day, including flights, activities, restaurant recommendations, and accommodation options. Prioritize minimizing travel time between activities. Format as a day-by-day plan.\"}\n",
        "        ,\n",
        "        {\"role\": \"assistant\", \"content\": generated_itinerary_text}\n",
        "    ]\n",
        "\n",
        "    example[\"text\"] = tokenizer.apply_chat_template(messages, tokenize=False, add_special_tokens=False)\n",
        "    return example\n",
        "\n",
        "# Apply the formatting function to your training and evaluation datasets\n",
        "print(\"Applying formatting function to datasets...\")\n",
        "train_dataset = train_dataset_raw.map(format_daily_itinerary_example, batched=False)\n",
        "eval_dataset = eval_dataset_raw.map(format_daily_itinerary_example, batched=False)\n",
        "print(\"Dataset preparation complete with per-day formatting.\")\n",
        "\n",
        "\n",
        "# 5. Set Up and Configure the Trainer\n",
        "print(\"Setting up SFTTrainer...\")\n",
        "trainer = SFTTrainer(\n",
        "    model=model,\n",
        "    tokenizer=tokenizer,\n",
        "    train_dataset=train_dataset, # Now using the formatted datasets\n",
        "    eval_dataset=eval_dataset,   # Now using the formatted datasets\n",
        "    dataset_text_field=\"text\", # This field holds the formatted chat messages\n",
        "    max_seq_length=2048, # Ensure this is sufficient for your long itineraries\n",
        "    args=TrainingArguments(\n",
        "        per_device_train_batch_size=2,\n",
        "        gradient_accumulation_steps=1,\n",
        "        warmup_steps=10,\n",
        "        num_train_epochs=3,\n",
        "        learning_rate=2e-4,\n",
        "        fp16=not torch.cuda.is_bf16_supported(), # Use fp16 if bfloat16 not supported\n",
        "        bf16=torch.cuda.is_bf16_supported(),     # Use bf16 if supported (recommended)\n",
        "        logging_steps=10,\n",
        "        output_dir=\"./deepseek_r1_tourism_planner_finetuned\", # Consistent output directory name\n",
        "        optim=\"adamw_8bit\",\n",
        "        seed=3407,\n",
        "        save_steps=500,\n",
        "        save_total_limit=2,\n",
        "        eval_strategy=\"steps\",\n",
        "        eval_steps=500,\n",
        "        load_best_model_at_end=True,\n",
        "        metric_for_best_model=\"eval_loss\",\n",
        "        greater_is_better=False, # Lower loss is better\n",
        "        report_to=\"none\", # Disable logging to Weights & Biases if not needed\n",
        "    ),\n",
        ")\n",
        "print(\"SFTTrainer configured.\")\n",
        "\n",
        "\n",
        "# 8. Model Evaluation (Conceptual usage after fine-tuning)\n",
        "# This section demonstrates how you would use the fine-tuned model for inference.\n",
        "# You'd load the model from `output_dir` and pass new prompts to it.\n",
        "# Example inference code would be similar to what was outlined in the evaluation code."
      ],
      "cell_type": "code",
      "metadata": {
        "id": "U1SvndGrk6cc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 6. Start Training\n",
        "print('\\n')\n",
        "print(\"Starting training...\")\n",
        "from unsloth import unsloth_train\n",
        "# trainer_stats = trainer.train() << Buggy gradient accumulation\n",
        "# https://unsloth.ai/blog/gradient\n",
        "trainer_stats = unsloth_train(trainer)\n",
        "#trainer.train() # Uncomment to start the training\n",
        "print(\"Training complete.\")\n",
        "print('\\n')\n",
        "\n",
        "\n",
        "# 7. Save Your Fine-tuned Model\n",
        "output_dir = \"./deepseek_r1_tourism_planner_finetuned\"\n",
        "print(f\"Saving fine-tuned model to {output_dir}...\")\n",
        "model.save_pretrained(output_dir, tokenizer) # Uncomment to save the model and tokenizer\n",
        "print(\"Model saved locally.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 251
        },
        "id": "1lhHJtX5VJ5b",
        "outputId": "a88bd136-319d-41e5-ff0e-dec45cb9d0c1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Starting training...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "==((====))==  Unsloth - 2x faster free finetuning | Num GPUs used = 1\n",
            "   \\\\   /|    Num examples = 900 | Num Epochs = 3 | Total steps = 1,350\n",
            "O^O/ \\_/ \\    Batch size per device = 2 | Gradient accumulation steps = 1\n",
            "\\        /    Data Parallel GPUs = 1 | Total batch size (2 x 1 x 1) = 2\n",
            " \"-____-\"     Trainable parameters = 41,943,040/8,000,000,000 (0.52% trained)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='48' max='1350' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [  48/1350 01:43 < 48:51, 0.44 it/s, Epoch 0.10/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Unsloth: Will smartly offload gradients to save VRAM!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model evaluation"
      ],
      "metadata": {
        "id": "cuWqTrK6kGGm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install colab-env -q\n",
        "import colab_env"
      ],
      "metadata": {
        "id": "SniGbApxqHPQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!cp -r /content/deepseek_r1_tourism_planner_finetuned /content/gdrive/MyDrive/model/deepseek_r1_tourism_planner_finetuned"
      ],
      "metadata": {
        "id": "Txa43qZIql5u"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install rouge_score -q\n",
        "!pip install sacrebleu -q"
      ],
      "metadata": {
        "id": "NsvttctQzyBP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "source": [
        "# --- Evaluation Code Block ---\n",
        "\n",
        "import torch\n",
        "import json\n",
        "import pandas as pd # For saving results\n",
        "from datasets import load_dataset # For loading evaluation data\n",
        "\n",
        "# Import libraries for model loading and generation\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM, TextStreamer # TextStreamer is optional\n",
        "from unsloth import FastLanguageModel # Using Unsloth for efficient loading\n",
        "\n",
        "# Import libraries for metrics calculation\n",
        "from rouge_score import rouge_scorer\n",
        "import sacrebleu\n",
        "import numpy as np # For calculating averages\n",
        "\n",
        "# --- Configuration ---\n",
        "# Define the path where your fine-tuned model was saved\n",
        "# Make sure this path points to the directory containing the saved model files\n",
        "fine_tuned_model_path = \"/content/gdrive/MyDrive/model/deepseek_r1_tourism_planner_finetuned\" # Example Google Drive path\n",
        "# fine_tuned_model_path = \"./deepseek_r1_tourism_planner_finetuned\" # Example local path\n",
        "\n",
        "# Define the path to your synthetic dataset file (JSONL format)\n",
        "dataset_path = 'synthetic_tourism_dataset_100_entries.jsonl'\n",
        "\n",
        "# Number of examples from the evaluation set to run inference on\n",
        "# Set to a smaller number for quick testing, or len(eval_dataset) for full evaluation\n",
        "num_examples_to_evaluate = 10 # Example: Evaluate the first 10 entries\n",
        "\n",
        "# Maximum sequence length used during fine-tuning (must match)\n",
        "max_seq_length = 2048\n",
        "\n",
        "# --- 1. Load the Fine-tuned Model and Tokenizer ---\n",
        "print(f\"Loading fine-tuned model from {fine_tuned_model_path}...\")\n",
        "try:\n",
        "    model, tokenizer = FastLanguageModel.from_pretrained(\n",
        "        model_name=fine_tuned_model_path, # Load from your saved model directory\n",
        "        max_seq_length=max_seq_length,     # Must match the max_seq_length used during fine-tuning\n",
        "        dtype=None,                        # Will auto-detect from saved config\n",
        "        load_in_4bit=True,                 # Load in 4-bit for memory efficiency\n",
        "    )\n",
        "    # Ensure the model is on GPU if available\n",
        "    if torch.cuda.is_available():\n",
        "        model.to(\"cuda\")\n",
        "        print(\"Model moved to GPU.\")\n",
        "    else:\n",
        "        print(\"CUDA not available. Model loading on CPU (will be slower).\")\n",
        "except Exception as e:\n",
        "    print(f\"Error loading model: {e}\")\n",
        "    print(\"Please check that the model path is correct and the model files exist.\")\n",
        "    # Exit or handle the error appropriately if model loading fails\n",
        "    exit() # Example: Exit the script\n",
        "\n",
        "\n",
        "print(\"Model and tokenizer loaded.\")\n",
        "\n",
        "# Optional: Set up TextStreamer for real-time output during generation\n",
        "# streamer = TextStreamer(tokenizer, skip_prompt=True, skip_special_tokens=True)\n",
        "\n",
        "# --- 2. Load the Evaluation Dataset ---\n",
        "print(f\"Loading evaluation dataset from {dataset_path}...\")\n",
        "try:\n",
        "    full_dataset_for_eval = load_dataset('json', data_files=dataset_path)\n",
        "\n",
        "    # Assume the dataset is loaded into a 'train' split by default\n",
        "    # Split the dataset into training and evaluation sets consistently with training\n",
        "    raw_dataset_split_for_eval = full_dataset_for_eval['train'].train_test_split(test_size=0.1, seed=42)\n",
        "    eval_dataset = raw_dataset_split_for_eval['test'] # This is your test set for evaluation\n",
        "\n",
        "    print(f\"Evaluation dataset loaded with {len(eval_dataset)} entries.\")\n",
        "\n",
        "    # Adjust num_examples_to_evaluate if it's larger than the available dataset\n",
        "    num_examples_to_evaluate = min(num_examples_to_evaluate, len(eval_dataset))\n",
        "    print(f\"Evaluating on {num_examples_to_evaluate} examples from the test set.\")\n",
        "\n",
        "except FileNotFoundError:\n",
        "    print(f\"Error: Dataset file not found at {dataset_path}\")\n",
        "    print(\"Please ensure 'synthetic_tourism_dataset_100_entries.jsonl' is in the correct directory.\")\n",
        "    exit() # Example: Exit if dataset not found\n",
        "except Exception as e:\n",
        "    print(f\"Error loading dataset: {e}\")\n",
        "    exit()\n",
        "\n",
        "\n",
        "# --- 3. Define the PROMPT CONSTRUCTION function for inference ---\n",
        "# This function should mirror the 'user' part of your formatting function used during training.\n",
        "# It takes raw data and turns it into the prompt the model expects.\n",
        "\n",
        "def construct_inference_prompt(user_query, available_information):\n",
        "    \"\"\"Constructs the full user prompt for the model based on user query and available info.\"\"\"\n",
        "\n",
        "    formatted_available_info_str = \"\\nAvailable Information:\\n\"\n",
        "    if \"flights\" in available_information and available_information[\"flights\"]:\n",
        "        formatted_available_info_str += \"Flights:\\n\" + \"\\n\".join([json.dumps(f) for f in available_information[\"flights\"]]) + \"\\n\"\n",
        "    if \"hotels\" in available_information and available_information[\"hotels\"]:\n",
        "        formatted_available_info_str += \"Accommodation:\\n\" + \"\\n\".join([json.dumps(h) for h in available_information[\"hotels\"]]) + \"\\n\"\n",
        "    if \"attractions\" in available_information and available_information[\"attractions\"]:\n",
        "        formatted_available_info_str += \"Attractions:\\n\" + \"\\n\".join([json.dumps(a) for a in available_information[\"attractions\"]]) + \"\\n\"\n",
        "    if \"restaurants\" in available_information and available_information[\"restaurants\"]:\n",
        "        formatted_available_info_str += \"Dining:\\n\" + \"\\n\".join([json.dumps(r) for r in available_information[\"restaurants\"]]) + \"\\n\"\n",
        "    if \"total_budget_usd\" in available_information:\n",
        "        formatted_available_info_str += f\"Total Budget: ${available_information['total_budget_usd']}\\n\"\n",
        "    if \"historical_weather\" in available_information:\n",
        "        # Safely access weather keys using .get() to handle potential variations\n",
        "        avg_temp_c = available_information['historical_weather'].get('avg_temp_c', available_information['historical_weather'].get('avg_temp_celsius', 'N/A'))\n",
        "        avg_temp_f = available_information['historical_weather'].get('avg_temp_fahrenheit', 'N/A') # Keep F if it might exist from original data\n",
        "        notes = available_information['historical_weather'].get('notes', 'N/A')\n",
        "\n",
        "        formatted_weather_str = f\"Historical Weather Context:\"\n",
        "        if avg_temp_c != 'N/A':\n",
        "             formatted_weather_str += f\" Avg Temp {avg_temp_c}°C\"\n",
        "        if avg_temp_f != 'N/A':\n",
        "             formatted_weather_str += f\" ({avg_temp_f}°F)\"\n",
        "        if notes != 'N/A':\n",
        "             formatted_weather_str += f\", {notes}\"\n",
        "        formatted_available_info_str += formatted_weather_str + \"\\n\"\n",
        "\n",
        "    if \"local_transportation_options\" in available_information:\n",
        "        formatted_available_info_str += \"Local Transportation Options:\\n\" + \"\\n\".join([f\"- {t.get('type', 'N/A')}: {t.get('notes', 'N/A')}\" for t in available_information[\"local_transportation_options\"]]) + \"\\n\"\n",
        "\n",
        "    # The general instruction for the model to generate a per-day itinerary\n",
        "    instruction = \"Based on the user's travel request and the available information, please generate a detailed travel itinerary broken down by day, including flights, activities, restaurant recommendations, and accommodation options. Prioritize minimizing travel time between activities. Format as a day-by-day plan.\"\n",
        "\n",
        "    # Construct the full user prompt for the model\n",
        "    full_user_prompt = f\"User's travel request: {user_query}\\n\\n{formatted_available_info_str}\\n{instruction}\"\n",
        "\n",
        "    # Apply the chat template for the single user turn\n",
        "    messages = [{\"role\": \"user\", \"content\": full_user_prompt}]\n",
        "    # Tokenize the prompt for generation\n",
        "    # return_tensors=\"pt\" makes it a PyTorch tensor\n",
        "    tokenized_input = tokenizer.apply_chat_template(messages, return_tensors=\"pt\", add_special_tokens=True)\n",
        "\n",
        "    # Move input to GPU if CUDA is available\n",
        "    if torch.cuda.is_available():\n",
        "        tokenized_input = tokenized_input.to(\"cuda\")\n",
        "\n",
        "    return tokenized_input\n",
        "\n",
        "\n",
        "# --- 4. Evaluation Loop with Metrics ---\n",
        "print(\"\\n--- Starting Evaluation Loop ---\")\n",
        "results = []\n",
        "rouge_scores = []\n",
        "bleu_scores = []\n",
        "\n",
        "# Initialize ROUGE scorer\n",
        "# using 'rouge1', 'rouge2', and 'rougeL' f-measure (F1 score)\n",
        "rouge_scorer_obj = rouge_scorer.RougeScorer(['rouge1', 'rouge2', 'rougeL'], use_stemmer=True)\n",
        "\n",
        "# Generation parameters (can be adjusted)\n",
        "generation_kwargs = {\n",
        "    \"max_new_tokens\": 1024, # Max length of the generated itinerary\n",
        "    \"use_cache\": True,\n",
        "    \"temperature\": 0.7,     # Controls randomness (lower = more deterministic)\n",
        "    \"top_p\": 0.95,          # Nucleus sampling (filter tokens based on cumulative probability)\n",
        "    \"do_sample\": True,      # Enable sampling\n",
        "    \"pad_token_id\": tokenizer.eos_token_id, # Set padding token\n",
        "    #\"streamer\": streamer,  # Uncomment if using TextStreamer\n",
        "}\n",
        "\n",
        "\n",
        "for i in range(num_examples_to_evaluate):\n",
        "    example = eval_dataset[i]\n",
        "    original_query = example[\"user_query\"]\n",
        "    reference_info = example[\"available_information\"]\n",
        "    # The ground truth ideal itinerary (structured) from the dataset\n",
        "    ground_truth_itinerary_structured = example[\"day_by_day_itinerary\"]\n",
        "\n",
        "    print(f\"\\n--- Evaluation Case {i+1}/{num_examples_to_evaluate} ---\")\n",
        "    print(f\"Original Query: {original_query}\")\n",
        "\n",
        "    # Convert ground truth structured data to a single string for text-based metrics\n",
        "    # This format should match the expected output format of the model\n",
        "    ground_truth_text = \"Proposed Travel Itinerary:\\n\"\n",
        "    for day_plan in ground_truth_itinerary_structured:\n",
        "        ground_truth_text += f\"\\nDay {day_plan.get('day_number', 'N/A')}: {day_plan.get('date', 'N/A')}\"\n",
        "        if 'weather_forecast' in day_plan:\n",
        "            ground_truth_text += f\" (Weather: {day_plan['weather_forecast']})\"\n",
        "        ground_truth_text += f\"\\nFocus: {day_plan.get('focus', 'N/A')}\\n\"\n",
        "        if 'morning' in day_plan:\n",
        "            ground_truth_text += f\"  Morning: {day_plan.get('morning', 'N/A')}\\n\"\n",
        "        if 'afternoon' in day_plan:\n",
        "            ground_truth_text += f\"  Afternoon: {day_plan.get('afternoon', 'N/A')}\\n\"\n",
        "        if 'evening' in day_plan:\n",
        "            ground_truth_text += f\"  Evening: {day_plan.get('evening', 'N/A')}\\n\"\n",
        "    # Ensure there's a newline at the end for consistency if needed\n",
        "    ground_truth_text = ground_truth_text.strip() + \"\\n\"\n",
        "\n",
        "\n",
        "    print(\"\\n--- Ground Truth Itinerary (from dataset) ---\\n\")\n",
        "    print(ground_truth_text)\n",
        "\n",
        "\n",
        "    # Construct the prompt for the model and get token IDs\n",
        "    input_ids = construct_inference_prompt(original_query, reference_info)\n",
        "\n",
        "    # Generate the itinerary using the model\n",
        "    try:\n",
        "        outputs = model.generate(\n",
        "            input_ids=input_ids,\n",
        "            **generation_kwargs # Pass the generation parameters\n",
        "        )\n",
        "\n",
        "        # Decode the generated text, skipping the prompt part\n",
        "        # inputs_ids.shape[1] gives the number of tokens in the prompt\n",
        "        generated_text = tokenizer.decode(outputs[0][input_ids.shape[1]:], skip_special_tokens=True)\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error during text generation for example {i+1}: {e}\")\n",
        "        generated_text = \"Error generating itinerary.\" # Indicate failure\n",
        "\n",
        "\n",
        "    print(\"\\n--- Generated Itinerary ---\\n\")\n",
        "    print(generated_text)\n",
        "\n",
        "    # --- Calculate Metrics for the current example ---\n",
        "    current_rouge_scores = None\n",
        "    current_bleu_score = None\n",
        "\n",
        "    if generated_text != \"Error generating itinerary.\":\n",
        "        try:\n",
        "            # ROUGE Score Calculation\n",
        "            # Pass ground truth and generated text strings to the scorer\n",
        "            current_rouge_scores = rouge_scorer_obj.score(ground_truth_text, generated_text)\n",
        "            rouge_scores.append(current_rouge_scores)\n",
        "            print(f\"ROUGE Scores: ROUGE-1: {current_rouge_scores['rouge1'].fmeasure:.4f}, ROUGE-2: {current_rouge_scores['rouge2'].fmeasure:.4f}, ROUGE-L: {current_rouge_scores['rougeL'].fmeasure:.4f}\")\n",
        "\n",
        "            # BLEU Score Calculation\n",
        "            # sacrebleu expects references as a list of lists of strings\n",
        "            # and the hypothesis (generated text) as a list of strings.\n",
        "            # For a single example, it's [hypothesis] and [[reference]]\n",
        "            current_bleu = sacrebleu.corpus_bleu([generated_text], [[ground_truth_text]])\n",
        "            current_bleu_score = current_bleu.score\n",
        "            bleu_scores.append(current_bleu_score)\n",
        "            print(f\"BLEU Score: {current_bleu_score:.4f}\")\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error calculating metrics for example {i+1}: {e}\")\n",
        "            # Metrics for this example will be None\n",
        "    else:\n",
        "         print(\"Skipping metric calculation due to generation error.\")\n",
        "\n",
        "\n",
        "    # Store results for later analysis\n",
        "    results.append({\n",
        "        \"original_query\": original_query,\n",
        "        \"generated_itinerary\": generated_text,\n",
        "        \"ground_truth_itinerary\": ground_truth_text, # Store ground truth as text string\n",
        "        \"rouge_scores\": current_rouge_scores,       # Store the detailed ROUGE scores dict\n",
        "        \"bleu_score\": current_bleu_score            # Store the BLEU score (float or None)\n",
        "    })\n",
        "\n",
        "print(\"\\n--- Evaluation Loop Finished ---\")\n",
        "\n",
        "# --- 5. Analysis and Metrics Summary ---\n",
        "print(\"\\n--- Overall Evaluation Summary ---\")\n",
        "\n",
        "# Calculate and print average metrics\n",
        "# Filter out None values before calculating averages\n",
        "valid_rouge_scores = [s for s in rouge_scores if s is not None]\n",
        "valid_bleu_scores = [s for s in bleu_scores if s is not None]\n",
        "\n",
        "if valid_rouge_scores:\n",
        "    avg_rouge1 = np.mean([s['rouge1'].fmeasure for s in valid_rouge_scores])\n",
        "    avg_rouge2 = np.mean([s['rouge2'].fmeasure for s in valid_rouge_scores])\n",
        "    avg_rougeL = np.mean([s['rougeL'].fmeasure for s in valid_rouge_scores])\n",
        "    print(f\"Average ROUGE-1 F-measure (over {len(valid_rouge_scores)} examples): {avg_rouge1:.4f}\")\n",
        "    print(f\"Average ROUGE-2 F-measure (over {len(valid_rouge_scores)} examples): {avg_rouge2:.4f}\")\n",
        "    print(f\"Average ROUGE-L F-measure (over {len(valid_rouge_scores)} examples): {avg_rougeL:.4f}\")\n",
        "else:\n",
        "    print(\"No valid ROUGE scores were calculated.\")\n",
        "\n",
        "\n",
        "if valid_bleu_scores:\n",
        "    avg_bleu = np.mean(valid_bleu_scores)\n",
        "    print(f\"Average BLEU Score (over {len(valid_bleu_scores)} examples): {avg_bleu:.4f}\")\n",
        "else:\n",
        "    print(\"No valid BLEU scores were calculated.\")\n",
        "\n",
        "# --- Save Results ---\n",
        "# Convert the list of results dictionaries to a pandas DataFrame and save to JSONL\n",
        "try:\n",
        "    df_results = pd.DataFrame(results)\n",
        "    output_filename = \"evaluation_results_with_metrics.jsonl\"\n",
        "    df_results.to_json(output_filename, orient=\"records\", lines=True)\n",
        "    print(f\"\\nEvaluation complete. Detailed results saved to '{output_filename}'.\")\n",
        "except Exception as e:\n",
        "    print(f\"Error saving results to JSONL: {e}\")"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "YeaBd1EPze5M"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}