{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/frank-morales2020/Cloud_curious/blob/master/mmlu_eval_openai.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n6ivzleTkjfh"
      },
      "source": [
        "## Building an MMLU Eval\n",
        "\n",
        "This notebook shows how to:\n",
        "- Build and run an eval\n",
        "- Load the results and into a Pandas Dataframe\n",
        "\n",
        "We use the `evals.elsuite.basic.match:Match` Eval class here to check whether new completions match the correct answer. Under the hood, it will generate a completion with the choice of model for each prompt, check if the completion matches the true answer, then logs a result."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/openai/evals.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "adi4d-hUmoUV",
        "outputId": "04b9fcf4-b665-4c40-8231-c444ed05ab52"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'evals'...\n",
            "remote: Enumerating objects: 7848, done.\u001b[K\n",
            "remote: Counting objects: 100% (325/325), done.\u001b[K\n",
            "remote: Compressing objects: 100% (217/217), done.\u001b[K\n",
            "remote: Total 7848 (delta 119), reused 275 (delta 100), pack-reused 7523\u001b[K\n",
            "Receiving objects: 100% (7848/7848), 6.56 MiB | 14.34 MiB/s, done.\n",
            "Resolving deltas: 100% (3937/3937), done.\n",
            "Updating files: 100% (1738/1738), done.\n",
            "Filtering content: 100% (670/670), 785.10 MiB | 30.46 MiB/s, done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Install, and download MMLU if you haven't already\n",
        "%cd /content/evals/\n",
        "%pip install -e ."
      ],
      "metadata": {
        "id": "6f9_j8khnKOr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "7ErfF2Sikjfj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "05c64afc-6e35-43a6-f8a9-2feedac869b7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Obtaining file:///\n",
            "\u001b[31mERROR: file:/// does not appear to be a Python project: neither 'setup.py' nor 'pyproject.toml' found.\u001b[0m\u001b[31m\n",
            "\u001b[0m  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100  158M  100  158M    0     0  1662k      0  0:01:37  0:01:37 --:--:-- 2135k\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "!curl -O https://people.eecs.berkeley.edu/~hendrycks/data.tar\n",
        "!tar -xf data.tar\n",
        "data_path = \"data\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "4ZzD7Azkkjfj"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "# Assuming this notebook is in examples/\n",
        "registry_path = os.path.join(os.getcwd(), \"/content/evals/registry\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "9UjCObjCkjfk"
      },
      "outputs": [],
      "source": [
        "# Build the prompts using Chat format. We support converting Chat conversations to text for non-Chat models\n",
        "\n",
        "choices = [\"A\", \"B\", \"C\", \"D\"]\n",
        "sys_msg = \"The following are multiple choice questions (with answers) about {}.\"\n",
        "def create_chat_prompt(sys_msg, question, answers, subject):\n",
        "    user_prompt = f\"{question}\\n\" + \"\\n\".join([f\"{choice}. {answer}\" for choice, answer in zip(choices, answers)]) + \"\\nAnswer:\"\n",
        "    return [\n",
        "        {\"role\": \"system\", \"content\": sys_msg.format(subject)},\n",
        "        {\"role\": \"user\", \"content\": user_prompt}\n",
        "    ]\n",
        "\n",
        "def create_chat_example(question, answers, correct_answer):\n",
        "    \"\"\"\n",
        "    Form few-shot prompts in the recommended format: https://github.com/openai/openai-python/blob/main/chatml.md#few-shot-prompting\n",
        "    \"\"\"\n",
        "    user_prompt = f\"{question}\\n\" + \"\\n\".join([f\"{choice}. {answer}\" for choice, answer in zip(choices, answers)]) + \"\\nAnswer:\"\n",
        "    return [\n",
        "        {\"role\": \"system\", \"content\": user_prompt, \"name\": \"example_user\"},\n",
        "        {\"role\": \"system\", \"content\": correct_answer, \"name\": \"example_assistant\"},\n",
        "    ]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_path='/content/data'"
      ],
      "metadata": {
        "id": "_VXSOwqloBYJ"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "r-zNsOOUkjfk"
      },
      "outputs": [],
      "source": [
        "import yaml\n",
        "subjects = sorted([f.split(\"_test.csv\")[0] for f in os.listdir(os.path.join(data_path, \"test\")) if \"_test.csv\" in f])\n",
        "\n",
        "registry_yaml = {}\n",
        "\n",
        "for subject in subjects:\n",
        "    subject_path = os.path.join(registry_path, \"data\", \"mmlu\", subject)\n",
        "    os.makedirs(subject_path, exist_ok=True)\n",
        "\n",
        "    # Create few-shot prompts\n",
        "    dev_df = pd.read_csv(os.path.join(data_path, \"dev\", subject + \"_dev.csv\"), names=(\"Question\", \"A\", \"B\", \"C\", \"D\", \"Answer\"))\n",
        "    dev_df[\"sample\"] = dev_df.apply(lambda x: create_chat_example(x[\"Question\"], x[[\"A\", \"B\", \"C\", \"D\"]], x[\"Answer\"]), axis=1)\n",
        "    few_shot_path = os.path.join(subject_path, \"few_shot.jsonl\")\n",
        "    dev_df[[\"sample\"]].to_json(few_shot_path, lines=True, orient=\"records\")\n",
        "\n",
        "    # Create test prompts and ideal completions\n",
        "    test_df = pd.read_csv(os.path.join(data_path, \"test\", subject + \"_test.csv\"), names=(\"Question\", \"A\", \"B\", \"C\", \"D\", \"Answer\"))\n",
        "    test_df[\"input\"] = test_df.apply(lambda x: create_chat_prompt(sys_msg, x[\"Question\"], x[[\"A\", \"B\", \"C\", \"D\"]], subject), axis=1)\n",
        "    test_df[\"ideal\"] = test_df.Answer\n",
        "    samples_path = os.path.join(subject_path, \"samples.jsonl\")\n",
        "    test_df[[\"input\", \"ideal\"]].to_json(samples_path, lines=True, orient=\"records\")\n",
        "\n",
        "    eval_id = f\"match_mmlu_{subject}\"\n",
        "\n",
        "    registry_yaml[eval_id] = {\n",
        "        \"id\": f\"{eval_id}.test.v1\",\n",
        "        \"metrics\": [\"accuracy\"]\n",
        "    }\n",
        "    registry_yaml[f\"{eval_id}.test.v1\"] = {\n",
        "        \"class\": \"evals.elsuite.basic.match:Match\",\n",
        "        \"args\": {\n",
        "            \"samples_jsonl\": samples_path,\n",
        "            \"few_shot_jsonl\": few_shot_path,\n",
        "            \"num_few_shot\": 4,\n",
        "        }\n",
        "    }\n",
        "registry_path = '/content'\n",
        "with open(os.path.join(registry_path, \"evals\", \"mmlu.yaml\"), \"w\") as f:\n",
        "    yaml.dump(registry_yaml, f)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install colab-env --upgrade -q\n",
        "!pip install openai -q\n",
        "import colab_env\n",
        "import os\n",
        "import openai\n",
        "from openai import OpenAI\n",
        "client = OpenAI(api_key = os.getenv(\"OPENAI_API_KEY\"))"
      ],
      "metadata": {
        "id": "Pr12Uo-4omIM"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from openai import OpenAI\n",
        "client = OpenAI()\n",
        "\n",
        "modellist=client.models.list()\n",
        "modellist.data"
      ],
      "metadata": {
        "id": "LhbttKrSpE36"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "DsOr4AI1kjfk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8849d3a1-69d7-4c64-eddb-d4951f8e0340"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2024-05-28 05:35:31,959] [registry.py:271] Loading registry from /content/evals/evals/registry/evals\n",
            "[2024-05-28 05:35:32,848] [registry.py:271] Loading registry from /root/.evals/evals\n",
            "[2024-05-28 05:35:32,860] [registry.py:160] eval 'match_mmlu_anatomy' not found. Closest matches: ['mmlu-anatomy']\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/bin/oaieval\", line 8, in <module>\n",
            "    sys.exit(main())\n",
            "  File \"/content/evals/evals/cli/oaieval.py\", line 304, in main\n",
            "    run(args)\n",
            "  File \"/content/evals/evals/cli/oaieval.py\", line 133, in run\n",
            "    eval_spec is not None\n",
            "AssertionError: Eval match_mmlu_anatomy not found. Available: ['2d_movement', '2d_movement.dev.v0', '3d_globe_movement', '3d_globe_movement.dev.v0', '3d_object_manipulation', '3d_object_manipulation.dev.v0', 'Chinese_character_riddles', 'Chinese_character_riddles.dev.v0', 'GPT-model-text-detection', 'GPT-model-text-detection.dev.v0', 'Unfamiliar-Chinese-Character', 'Unfamiliar-Chinese-Character.dev.v0', 'ab', 'ab.dev.v0', 'aba_mrpc_true_false', 'aba_mrpc_true_false.dev.v0', 'abstract-causal-reasoning-symbolic', 'abstract-causal-reasoning-symbolic.dev.v0', 'abstract-causal-reasoning-text', 'abstract-causal-reasoning-text.dev.v0', 'abstract2title', 'abstract2title.test.v1', 'accounting_audit', 'accounting_audit.dev.v0', 'actors-sequence', 'actors-sequence.dev.match-v1', 'adultery_state_laws', 'adultery_state_laws.dev.v0', 'afrikaans-lexicon', 'afrikaans-lexicon.dev.v0', 'aime_evaluation', 'aime_evaluation.dev.v0', 'albanian-exams-qa', 'albanian-exams-qa.test.v0', 'algebra-word-problems', 'algebra-word-problems.s1.simple-v0', 'allergen-information', 'allergen-information.dev.v0', 'already_said_that', 'already_said_that.ambiguous-sentences', 'already_said_that.distractorless', 'already_said_that.first-letters', 'already_said_that.reverse-sort-words-eng', 'already_said_that.which-is-heavier', 'alternate_numeral_systems', 'alternate_numeral_systems.dev.v0', 'ambiguous-sentences', 'ambiguous-sentences.dev.v0', 'anagrams', 'anagrams.test.v1', 'arabic-exams-qa', 'arabic-exams-qa.test.v0', 'arabic-literature-qa', 'arabic-literature-qa.test.v0', 'arc', 'arc.dev.v0', 'arithmetic-expression', 'arithmetic-expression-meta', 'arithmetic-expression-meta.dev.v0', 'arithmetic-expression.dev.v0', 'arithmetical_puzzles', 'arithmetical_puzzles.dev.v0', 'ascii-digit-recognition', 'ascii-digit-recognition.dev.v0', 'ascii-wordart', 'ascii-wordart.dev.v0', 'asl-classifiers', 'asl-classifiers.dev.v0', 'astro_eval', 'astro_eval.dev.v0', 'atpl_exams', 'atpl_exams.dev.v0', 'automata-and-complexity', 'automata-and-complexity.dev.v0', 'backgammon-can-hit', 'backgammon-can-hit.dev.v0', 'backgammon-illegal-move', 'backgammon-illegal-move.dev.v0', 'balance-chemical-equation', 'balance-chemical-equation.dev.v0', 'ballots', 'ballots.3.testing.v0', 'ballots.5.testing.v0', 'ballots.long.v0', 'ballots.short.v0', 'ballots.testing.v0', 'base64-decode', 'base64-decode-simple.dev.v0', 'beam-analysis', 'beam.analysis.dev.v0', 'belarusian-antonyms', 'belarusian-antonyms.dev.v0', 'belarusian-grammar', 'belarusian-grammar.dev.v0', 'belarusian-lexicon', 'belarusian-lexicon.dev.v0', 'belarusian-numerals', 'belarusian-numerals.dev.v0', 'belarusian-orthography', 'belarusian-orthography.dev.v0', 'belarusian-proverbs', 'belarusian-proverbs.dev.v0', 'belarusian-rhyme', 'belarusian-rhyme.dev.v0', 'belarusian-russian-translation', 'belarusian-russian-translation.dev.v0', 'belarusian-syllable-count', 'belarusian-syllable-count.dev.v0', 'belarusian-synonyms', 'belarusian-synonyms.dev.v0', 'belarusian-word-analogy-inflection', 'belarusian-word-analogy-inflection.dev.v0', 'benjaminmoore_to_hex', 'benjaminmoore_to_hex.dev.v0', 'best', 'best.dev.v0', 'bias_detection', 'bias_detection.dev.v0', 'bigrams', 'bigrams.dev.v0', 'bitwise', 'bitwise.dev.v0', 'blackfoot-numerals-modern', 'blackfoot-numerals-modern.dev.v0', 'bluff', 'bluff.gpt-4', 'bluff.gpt-4.dev5', 'bluff.honest_bot_highest', 'bluff.honest_bot_highest.dev5', 'bluff.human_cli', 'bluff.strong_bot', 'bluff.strong_bot.dev5', 'body-movement', 'body-movement.dev.zero_shot_v0', 'born-first', 'born-first.dev.v0', 'brazilian-lexicon', 'brazilian-lexicon.dev.v0', 'brazilian_laws', 'brazilian_laws.test.v1', 'bugged_tools', 'bugged_tools.all', 'bugged_tools.all_log', 'bugged_tools.all_small', 'building_floorplan', 'building_floorplan.test.v1', 'bulgarian-exams-qa', 'bulgarian-exams-qa.test.v0', 'bulgarian-lexicon', 'bulgarian-lexicon.dev.v0', 'cant_do_that_anymore', 'cant_do_that_anymore.all', 'cant_do_that_anymore.all_diagonal', 'cant_do_that_anymore.all_small', 'canto_wu_pronunciation', 'canto_wu_pronunciation.dev.v0', 'canto_wu_pronunciation_fewshot', 'canto_wu_pronunciation_fewshot.dev.v0', 'cardinal-directions', 'cardinal-directions.dev.v0', 'categorize-with-distractors', 'categorize-with-distractors.dev.v0', 'chess-match', 'chess-piece-count', 'chess-piece-count.s1.simple-v0', 'chess.match.dev.v0', 'chinese-homo', 'chinese-homophonic.dev.v0', 'chinese-lantern-riddles', 'chinese-lantern-riddles.dev.v0', 'chinese-remainder-theorem', 'chinese-remainder-theorem.dev.v0', 'chinese_ancient_masterpieces_dynasty', 'chinese_ancient_masterpieces_dynasty.dev.v0', 'chinese_ancient_poetry', 'chinese_ancient_poetry.dev.v0', 'chinese_chu_ci', 'chinese_chu_ci.dev.v0', 'chinese_famous_novel', 'chinese_famous_novel.dev.v0', 'chinese_hard_translations', 'chinese_hard_translations.dev.v0', 'chinese_homonym', 'chinese_homonym.dev.v0', 'chinese_idioms', 'chinese_idioms.dev.v0', 'chinese_modern_poem_identification', 'chinese_modern_poem_identification.test.v1', 'chinese_poem', 'chinese_poem.dev.v0', 'chinese_shi_jing', 'chinese_shi_jing.test.v1', 'chinese_song_ci', 'chinese_song_ci.dev.v0', 'chinese_tang_poetries', 'chinese_tang_poetries.dev.match-v1', 'chinese_zodiac', 'chinese_zodiac.dev.v0', 'cissp-study-questions', 'cissp-study-questions.test.v1', 'co-sql', 'co-sql.dev.v0', 'code_combination', 'code_combination.dev.v0', 'code_progress', 'code_progress.dev.v0', 'color_theory_complementary', 'color_theory_complementary.dev.v0', 'compare-countries-area', 'compare-countries-area.dev.v0', 'complex-analogies-en-ru', 'complex-analogies-en-ru.dev.v0', 'complex-replace-characters', 'complex-replace-characters.dev.v0', 'comprehensive-graph-reasoning', 'comprehensive-graph-reasoning.dev.v0', 'computer-science-problems', 'computer-science-problems.s1.simple-v0', 'confusing_korean', 'confusing_korean.dev.v0', 'connect4', 'connect4.s1.v1', 'consensus_summary', 'consensus_summary.dev.v0', 'context-free-grammar', 'context-free-grammar.dev.v0', 'convert-hex-hsl-lightness', 'convert-hex-hsl-lightness.dev.v0', 'convert_chinese_lower_case_num_to_num', 'convert_chinese_lower_case_num_to_num.dev.v0', 'convert_chinese_upper_case_num_to_num', 'convert_chinese_upper_case_num_to_num.dev.v0', 'convert_num_to_chinese_lower_case_num', 'convert_num_to_chinese_lower_case_num.dev.v0', 'convert_num_to_chinese_upper_case_num', 'convert_num_to_chinese_upper_case_num.dev.v0', 'coq-editing', 'coq-editing-meta', 'coq-editing-meta.dev.v0', 'coq-editing.dev.v0', 'coq-proof-step-match', 'coq-proof-step-match.dev.v0', 'coqa-closedqa-conciseness', 'coqa-closedqa-conciseness.dev.v0', 'coqa-closedqa-correct', 'coqa-closedqa-correct.dev.v0', 'coqa-closedqa-relevance', 'coqa-closedqa-relevance.dev.v0', 'coqa-fact', 'coqa-fact-expl', 'coqa-fact-expl.dev.v0', 'coqa-fact.dev.v0', 'coqa-match', 'coqa-match.dev.v0', 'corr2cause', 'corr2cause.dev.v0', 'count_intersections_polynomial', 'count_intersections_polynomial.dev.v0', 'count_token_freq_dna', 'count_token_freq_dna.dev.v0', 'counterfactual-reasoning-fuzzy-match', 'counterfactual-reasoning-fuzzy-match.dev.simple-v0', 'countries', 'countries.dev.v0', 'crepe', 'crepe.dev.v2', 'cricket_situations', 'cricket_situations.dev.v0', 'croatian-exams-qa', 'croatian-exams-qa.test.v0', 'crontab', 'crontab.dev.v0', 'csharp-linq', 'csharp-linq.dev.v0', 'css-selectors-explain', 'css-selectors-explain.dev.v0', 'css-selectors-verbal', 'css-selectors-verbal.dev.v0', 'cube-pack', 'cube-pack.dev.v0', 'cybersecurity-filepaths', 'cybersecurity-filepaths.dev.v0', 'date-booking', 'date-booking.dev.v0', 'date-calculator', 'date-calculator.test.v1', 'day-of-week-from-date', 'day-of-week-from-date.dev.v0', 'decrypt-caesar-cipher', 'decrypt-caesar-cipher.dev.v0', 'detect-hshd', 'detect-hshd.dev.v0', 'determinant', 'determinant.test.v1', 'dhammapada-reference', 'dhammapada-reference.dev.v0', 'diabetes', 'diabetes.dev.v0', 'diagrammatic_logic', 'diagrammatic_logic.dev.v2', 'dice-rotation-sequence', 'dice-rotation-sequence.dev.v0', 'direct-speech-tag', 'direct-speech-tag.dev.v0', 'directions', 'directions.dev.v0', 'diversity', 'diversity.dev.v0', 'dna-melting-calculation', 'dna-melting-calculation.dev.v0', 'dutch-lexicon', 'dutch-lexicon.dev.v0', 'dutch-rhymes', 'dutch-rhymes.dev.v0', 'emoji-riddle', 'emoji-riddle.s1.simple-v0', 'emotional-intelligence', 'emotional-intelligence.dev.v0', 'error-recovery', 'error-recovery.main', 'error-recovery.main.other-reasoning', 'error-recovery.medium', 'error-recovery.medium.other-reasoning', 'error-recovery.small', 'error-recovery.small.other-reasoning', 'escher-sentences', 'escher-sentences.dev.v0', 'euler_problems', 'euler_problems.dev.v0', 'european-date-format-challenge', 'european-date-format-challenge.dev.v0', 'event-categories', 'event-categories.dev.v0', 'fcc_amateur_extra', 'fcc_amateur_extra.dev.v0', 'finance', 'finance.dev.v0', 'finance_calc', 'finance_calc.dev.v0', 'financial-derivatives', 'financial-derivatives.dev.v0', 'find-letter', 'find-letter.dev.v0', 'find-thirukkural', 'find-thirukkural.dev.v0', 'find_country_from_svg', 'find_country_from_svg.dev.v0', 'finger-tracking', 'finger-tracking.dev.v0', 'finnish-rhyme', 'finnish-rhyme.dev.v0', 'first-letters', 'first-letters.dev.v0', 'food', 'food.test.v1', 'formal-grammar-to-regex', 'formal-grammar-to-regex.dev.v0', 'formal-logic', 'formal-logic.dev.v0', 'forth-stack-sim', 'forth-stack-sim-basic', 'forth-stack-sim-basic.dev.v0', 'forth-stack-sim-detailed', 'forth-stack-sim-detailed.dev.v0', 'forth-stack-sim.dev.v0', 'french-exams-qa', 'french-exams-qa.test.v0', 'french-lexicon', 'french-lexicon.dev.v0', 'french-part-of-speech', 'french-part-of-speech.dev.v0', 'french_homonym_and_homograph', 'french_homonym_and_homograph.dev.v0', 'function_deduction', 'function_deduction.easy', 'function_deduction.easy.dev5', 'function_deduction.easy.long', 'function_deduction.hard', 'function_deduction.hard.dev5', 'game-theory', 'game-theory.dev.v0', 'gears_rotation', 'gears_rotation.dev.v0', 'geometry_puzzle', 'geometry_puzzle.dev.v0', 'german-exams-qa', 'german-exams-qa.test.v0', 'german-part-of-speech', 'german-part-of-speech.dev.v0', 'gol', 'gol.dev.v1', 'gpt-protocol-buffers', 'gpt-protocol-buffers.dev.v0', 'greek-nt-manuscripts', 'greek-nt-manuscripts.v0', 'greek-vocabulary', 'greek-vocabulary.dev.v0', 'gregorian-to-hebrew-date', 'gregorian-to-hebrew-date.dev.v0', 'guess-the-singer', 'guess-the-singer.dev.v0', 'gujarati-numerals', 'gujarati-numerals.dev.v0', 'hand_ranks-match', 'hand_ranks.test.v1', 'hard_russian_computer_science_tasks', 'hard_russian_computer_science_tasks.dev.v0', 'heart-disease', 'heart-disease.v0', 'hebrew-bible', 'hebrew-bible.dev.v0', 'hebrew-homophones', 'hebrew-homophones.dev.v0', 'hebrew-plurals', 'hebrew-plurals.dev.v0', 'hebrew-rhyme', 'hebrew-rhyme.v0', 'hebrew-same-noun-gender', 'hebrew-same-noun-gender.v0', 'hebrew_grammar', 'hebrew_grammar.dev.v0', 'hebrew_talmud_suka', 'hebrew_talmud_suka.dev.v0', 'hellaswag', 'hellaswag.val.ab-v1', 'hindi_shuddha', 'hindi_shuddha.dev.v0', 'hindi_upsc', 'hindi_upsc.dev.v0', 'hindi_words', 'hindi_words.dev.v0', 'historical-kana-orthography-reading', 'historical-kana-orthography-reading.dev.v0', 'hr-ml-agent-bench.ant', 'hr-ml-agent-bench.ant.cpu.v0', 'hr-ml-agent-bench.ant.gpu.v0', 'hr-ml-agent-bench.bipedal-walker', 'hr-ml-agent-bench.bipedal-walker.v0', 'hr-ml-agent-bench.cartpole', 'hr-ml-agent-bench.cartpole.v0', 'hr-ml-agent-bench.cifar10', 'hr-ml-agent-bench.cifar10.v0', 'hr-ml-agent-bench.feedback', 'hr-ml-agent-bench.feedback.v0', 'hr-ml-agent-bench.house-price', 'hr-ml-agent-bench.house-price.v0', 'hr-ml-agent-bench.humanoid', 'hr-ml-agent-bench.humanoid.cpu.v0', 'hr-ml-agent-bench.humanoid.gpu.v0', 'hr-ml-agent-bench.imdb', 'hr-ml-agent-bench.imdb.v0', 'hr-ml-agent-bench.inverted-pendulum', 'hr-ml-agent-bench.inverted-pendulum.v0', 'hr-ml-agent-bench.ogbn-arxiv', 'hr-ml-agent-bench.ogbn-arxiv.v0', 'hr-ml-agent-bench.parkinsons-disease', 'hr-ml-agent-bench.parkinsons-disease.v0', 'hr-ml-agent-bench.pong', 'hr-ml-agent-bench.pong.cpu.v0', 'hr-ml-agent-bench.pong.gpu.v0', 'hr-ml-agent-bench.pusher', 'hr-ml-agent-bench.pusher.v0', 'hr-ml-agent-bench.spaceship-titanic', 'hr-ml-agent-bench.spaceship-titanic.v0', 'hr-ml-agent-bench.test', 'hr-ml-agent-bench.vectorization', 'hr-ml-agent-bench.vectorization.v0', 'human-safety', 'human-safety.test.v0', 'hungarian-exams-qa', 'hungarian-exams-qa.test.v0', 'iambic-pentameter', 'iambic-pentameter.dev.v0', 'icelandic-inflection-easy', 'icelandic-inflection-easy.dev.v0', 'icelandic-inflection-hard', 'icelandic-inflection-hard.dev.v0', 'icelandic-inflection-medium', 'icelandic-inflection-medium.dev.v0', 'icelandic-sentences-gec', 'icelandic-sentences-gec.dev.v0', 'identifying_variables', 'identifying_variables.corrset.balanced-ctrl', 'identifying_variables.corrset.balanced-ctrl-large', 'identifying_variables.corrset.balanced-hypotheses', 'identifying_variables.corrset.balanced-hypotheses-large', 'identifying_variables.csv.balanced-ctrl', 'identifying_variables.csv.balanced-ctrl-large', 'identifying_variables.csv.balanced-hypotheses', 'identifying_variables.csv.balanced-hypotheses-large', 'identifying_variables.json.balanced-hypotheses', 'identifying_variables.json.balanced-hypotheses-large', 'identifying_variables.language-corrset.balanced-ctrl', 'identifying_variables.language-corrset.balanced-ctrl-large', 'identifying_variables.language-corrset.balanced-hypotheses', 'identifying_variables.language-corrset.balanced-hypotheses-large', 'identifying_variables.language-tabular.balanced-hypotheses', 'identifying_variables.language-tabular.balanced-hypotheses-large', 'identifying_variables.markdown.balanced-hypotheses', 'identifying_variables.markdown.balanced-hypotheses-large', 'illinois-law', 'illinois-law.v0', 'imperial_date_to_string', 'imperial_date_to_string.dev.v0', 'incontext_rl', 'incontext_rl.dev.v0', 'incontext_rl.gymnasium.raw.short.v0', 'incontext_rl.gymnasium.raw.v0', 'incontext_rl.gymnasium.short.v0', 'incontext_rl.gymnasium.v0', 'incontext_rl.raw.short.v0', 'incontext_rl.raw.v0', 'incontext_rl.short.v0', 'incontext_rl.v0', 'indonesian_numbers', 'indonesian_numbers.dev.v0', 'infiniteloop-match', 'infiniteloop-match.s1.simple-v0', 'integer-sequence-predictions', 'integer-sequence-predictions-misc', 'integer-sequence-predictions-misc.dev.v0', 'integer-sequence-predictions-notable', 'integer-sequence-predictions-notable.dev.v0', 'integer-sequence-predictions-obscure', 'integer-sequence-predictions-obscure.dev.v0', 'integer-sequence-predictions.dev.v0', 'interlingual-homograph', 'interlingual-homograph.dev.v0', 'internal_representations', 'internal_representations.dev.v0', 'invert_word_wise', 'invert_word_wise.dev.v0', 'invoice_due_date_leap_day_adjustment', 'invoice_due_date_leap_day_adjustment.dev.v0', 'invoices', 'invoices.dev.v0', 'iqbal-poetry-translation', 'iqbal-poetry-translation.dev.v0', 'irish-lexicon', 'irish-lexicon.dev.v0', 'irish-plural-nouns', 'irish-plural-nouns.dev.v0', 'irony', 'irony.dev.v0', 'irrelevant-negative-diversion', 'irrelevant-negative-diversion.dev.v0', 'iso-to-lunar-calendar', 'iso-to-lunar-calendar.dev.v0', 'isosceles-right-triangle', 'isosceles-right-triangle.dev.v0', 'italian-exams-qa', 'italian-exams-qa.test.v0', 'italian-new-words', 'italian-new-words.dev.v0', 'italian-rhyme', 'italian-rhyme.v0', 'italian_big_math_expression', 'italian_big_math_expression.dev.v0', 'japanese-decimal-units', 'japanese-decimal-units.dev.v0', 'japanese-itpassport-exam01', 'japanese-itpassport-exam01.dev.v0', 'japanese-national-medical-exam01', 'japanese-national-medical-exam01.dev.v0', 'japanese-national-medical-exam02', 'japanese-national-medical-exam02.dev.v0', 'japanese-number-reading', 'japanese-number-reading.dev.v0', 'japanese-remote-island-to-prefecture', 'japanese-remote-island-to-prefecture.dev.v0', 'japanese-station', 'japanese-station.dev.v0', 'japanese_approval', 'japanese_approval.dev.v0', 'japanese_city_name_pronunciation', 'japanese_city_name_pronunciation.dev.v0', 'japanese_driving_license', 'japanese_driving_license.s1.simple-v0', 'japanese_mahjong_discard_tile', 'japanese_mahjong_discard_tile.dev.v0', 'japanese_onomatopoeia', 'japanese_onomatopoeia.dev.v0', 'japanese_populer_video_game_title_and_the_publisher', 'japanese_populer_video_game_title_and_the_publisher.val.v0', 'japanese_prime_minister', 'japanese_prime_minister.dev.v0', 'japanese_romantic_context', 'japanese_romantic_context.dev.v0', 'jee-math', 'jee-math.dev.v0', 'job_listing_title_for_a_caregiver_in_japan', 'job_listing_title_for_a_caregiver_in_japan.test.v1', 'joke-animals-vs-fruits', 'joke-animals-vs-fruits.dev.v0', 'joke-fruits', 'joke-fruits-ans-meta', 'joke-fruits-ans-meta.dev.v0', 'joke-fruits-expl-meta', 'joke-fruits-expl-meta.dev.v0', 'joke-fruits-likert', 'joke-fruits-likert.dev.v0', 'joke-fruits-meta', 'joke-fruits-meta.dev.v0', 'joke-fruits-v2', 'joke-fruits-v2.dev.v0', 'joke-fruits.dev.v0', 'json_patch_object', 'json_patch_object.dev.v0', 'kanji-idioms', 'kanji-idioms.test.v0', 'knot-theory-code-conversion', 'knot-theory-code-conversion.dev.v0', 'knot-theory-unknotting-number', 'knot-theory-unknotting-number.dev.v0', 'knot-theory-unknotting-problem', 'knot-theory-unknotting-problem.dev.v0', 'korean-consonant-vowel-combination', 'korean-consonant-vowel-combination.dev.v0', 'korean-honorific', 'korean-honorific.dev.v0', 'korean-phonetics', 'korean-phonetics.dev.v0', 'korean-postposition', 'korean-postposition.dev.v0', 'korean_date_counting', 'korean_date_counting.dev.v0', 'korean_dialects', 'korean_dialects.dev.v0', 'korean_foreign_words', 'korean_foreign_words.dev.v0', 'korean_romanization', 'korean_romanization.dev.v0', 'korean_spaces', 'korean_spaces.dev.v0', 'korean_spelling', 'korean_spelling.dev.v0', 'korean_yaminjeongeum', 'korean_yaminjeongeum.dev.v0', 'lambada', 'lambada.oaitest.v1', 'largest_country', 'largest_country.dev.v0', 'last-word-nth', 'last-word-nth.s1.simple-v0', 'lat_long_identify', 'lat_long_identify.dev.v0', 'latin-grammar', 'latin-grammar.dev.v0', 'linear-equations', 'linear-equations.dev.v0', 'linear-regression', 'linear-regression-meta', 'linear-regression-meta.dev.v0', 'linear-regression.dev.v0', 'list_comparison_missing_name', 'list_comparison_missing_name.dev.v0', 'lithuanian-exams-qa', 'lithuanian-exams-qa.test.v0', 'logic-container', 'logic-container.dev.v0', 'logic-fact', 'logic-fact.dev.v0', 'logic-grid', 'logic-grid.dev.v0', 'logic-liar-paradox', 'logic-liar-paradox.dev.v0', 'logic-riddles', 'logic-riddles.dev.v0', 'logic-statements', 'logic-statements.dev.v0', 'logic_and_probability', 'logic_and_probability.dev.v0', 'logical-black-scholes', 'logical-black-scholes.test.v1', 'logical_counting', 'logical_counting.dev.v0', 'logical_reasoning_letter_series_test', 'logical_reasoning_letter_series_test.dev.v0', 'logiqa', 'logiqa-logical-reasoning-plus', 'logiqa-logical-reasoning-plus.dev.v0', 'logiqa.dev.v0', 'logiqav2-logical-reasoning-plus', 'logiqav2-logical-reasoning-plus.dev.v0', 'loss-logic-fact', 'loss-logic-fact.dev.v0', 'lunar-calendar-to-iso', 'lunar-calendar-to-iso.dev.v0', 'macedonian-exams-qa', 'macedonian-exams-qa.test.v0', 'make-me-pay', 'make-me-pay.10-turn.balanced.v2', 'make-me-pay.15-turn.balanced.v2', 'make-me-pay.5-turn.balanced.v2', 'make-me-pay.five-minute.balanced.v2', 'make-me-pay.one-minute.balanced.v2', 'make-me-pay.three-minute.balanced.v2', 'make-me-say', 'make-me-say.easy.v0', 'make-me-say.hard.v0', 'make-me-say.medium-and-hard.v0', 'make-me-say.medium.v0', 'make-me-say.very-hard.v0', 'mandaliof-table', 'mandaliof-table.dev.v0', 'manga-translation-bubble', 'manga-translation-bubble.dev.v0', 'manga-translation-page', 'manga-translation-page.dev.v0', 'manga-translation-panel', 'manga-translation-panel.dev.v0', 'map-electronic-component-part-to-fact', 'map-electronic-component-part-to-fact.dev.v0', 'mapping_to_matricies', 'mapping_to_matricies.dev.v0', 'marxist_philosophy_exam', 'marxist_philosophy_exam_simple.dev.v0', 'match_banking77', 'match_banking77.test.v1', 'match_product-matching_fewshot', 'match_product-matching_fewshot.dev.v1', 'match_product-matching_rules', 'match_product-matching_rules.dev.v1', 'match_product-matching_zeroshot', 'match_product-matching_zeroshot.dev.v1', 'mate-in-one', 'mate-in-one.dev.v0', 'math-derivatives', 'math-derivatives.dev.v0', 'math_equations', 'math_equations.dev.v0', 'math_for_5th-grader', 'math_for_5th-grader.dev.v0', 'math_logic_operations', 'math_logic_operations.dev.v0-1', 'math_polish', 'math_polish.dev.v0', 'matrix_mult_rows', 'matrix_mult_rows.dev.v0', 'mazes-10x10', 'mazes-10x10.test.v2', 'mazes-3x3', 'mazes-3x3.test.v2', 'mazes-4x4', 'mazes-4x4.test.v2', 'mazes-singlemove-10x10', 'mazes-singlemove-10x10.test.v2', 'mazes-singlemove-3x3', 'mazes-singlemove-3x3.test.v2', 'mazes-singlemove-4x4', 'mazes-singlemove-4x4.test.v2', 'medication_dose', 'medication_dose.dev.v0', 'medmcqa', 'medmcqa.dev.v0', 'mendelian_inheritance', 'mendelian_inheritance.dev.v0', 'mg-humor-people_jp', 'mg-humor-people_jp.dev.v0', 'missing-operators', 'missing-operators.s1.simple-v0', 'mmlu-abstract-algebra', 'mmlu-abstract-algebra.val.ab-v1', 'mmlu-anatomy', 'mmlu-anatomy.val.ab-v1', 'mmlu-astronomy', 'mmlu-astronomy.val.ab-v1', 'mmlu-business-ethics', 'mmlu-business-ethics.val.ab-v1', 'mmlu-clinical-knowledge', 'mmlu-clinical-knowledge.val.ab-v1', 'mmlu-college-biology', 'mmlu-college-biology.val.ab-v1', 'mmlu-college-chemistry', 'mmlu-college-chemistry.val.ab-v1', 'mmlu-college-computer-science', 'mmlu-college-computer-science.val.ab-v1', 'mmlu-college-mathematics', 'mmlu-college-mathematics.val.ab-v1', 'mmlu-college-medicine', 'mmlu-college-medicine.val.ab-v1', 'mmlu-college-physics', 'mmlu-college-physics.val.ab-v1', 'mmlu-computer-security', 'mmlu-computer-security.val.ab-v1', 'mmlu-conceptual-physics', 'mmlu-conceptual-physics.val.ab-v1', 'mmlu-econometrics', 'mmlu-econometrics.val.ab-v1', 'mmlu-electrical-engineering', 'mmlu-electrical-engineering.val.ab-v1', 'mmlu-elementary-mathematics', 'mmlu-elementary-mathematics.val.ab-v1', 'mmlu-formal-logic', 'mmlu-formal-logic.val.ab-v1', 'mmlu-global-facts', 'mmlu-global-facts.val.ab-v1', 'mmlu-high-school-biology', 'mmlu-high-school-biology.val.ab-v1', 'mmlu-high-school-chemistry', 'mmlu-high-school-chemistry.val.ab-v1', 'mmlu-high-school-computer-science', 'mmlu-high-school-computer-science.val.ab-v1', 'mmlu-high-school-european-history', 'mmlu-high-school-european-history.val.ab-v1', 'mmlu-high-school-geography', 'mmlu-high-school-geography.val.ab-v1', 'mmlu-high-school-government-and-politics', 'mmlu-high-school-government-and-politics.val.ab-v1', 'mmlu-high-school-macroeconomics', 'mmlu-high-school-macroeconomics.val.ab-v1', 'mmlu-high-school-mathematics', 'mmlu-high-school-mathematics.val.ab-v1', 'mmlu-high-school-microeconomics', 'mmlu-high-school-microeconomics.val.ab-v1', 'mmlu-high-school-physics', 'mmlu-high-school-physics.val.ab-v1', 'mmlu-high-school-psychology', 'mmlu-high-school-psychology.val.ab-v1', 'mmlu-high-school-statistics', 'mmlu-high-school-statistics.val.ab-v1', 'mmlu-high-school-us-history', 'mmlu-high-school-us-history.val.ab-v1', 'mmlu-high-school-world-history', 'mmlu-high-school-world-history.val.ab-v1', 'mmlu-human-aging', 'mmlu-human-aging.val.ab-v1', 'mmlu-human-sexuality', 'mmlu-human-sexuality.val.ab-v1', 'mmlu-international-law', 'mmlu-international-law.val.ab-v1', 'mmlu-jurisprudence', 'mmlu-jurisprudence.val.ab-v1', 'mmlu-logical-fallacies', 'mmlu-logical-fallacies.val.ab-v1', 'mmlu-machine-learning', 'mmlu-machine-learning.val.ab-v1', 'mmlu-management', 'mmlu-management.val.ab-v1', 'mmlu-marketing', 'mmlu-marketing.val.ab-v1', 'mmlu-medical-genetics', 'mmlu-medical-genetics.val.ab-v1', 'mmlu-miscellaneous', 'mmlu-miscellaneous.val.ab-v1', 'mmlu-moral-disputes', 'mmlu-moral-disputes.val.ab-v1', 'mmlu-moral-scenarios', 'mmlu-moral-scenarios.val.ab-v1', 'mmlu-nutrition', 'mmlu-nutrition.val.ab-v1', 'mmlu-philosophy', 'mmlu-philosophy.val.ab-v1', 'mmlu-prehistory', 'mmlu-prehistory.val.ab-v1', 'mmlu-professional-accounting', 'mmlu-professional-accounting.val.ab-v1', 'mmlu-professional-law', 'mmlu-professional-law.val.ab-v1', 'mmlu-professional-medicine', 'mmlu-professional-medicine.val.ab-v1', 'mmlu-professional-psychology', 'mmlu-professional-psychology.val.ab-v1', 'mmlu-public-relations', 'mmlu-public-relations.val.ab-v1', 'mmlu-security-studies', 'mmlu-security-studies.val.ab-v1', 'mmlu-sociology', 'mmlu-sociology.val.ab-v1', 'mmlu-us-foreign-policy', 'mmlu-us-foreign-policy.val.ab-v1', 'mmlu-virology', 'mmlu-virology.val.ab-v1', 'mmlu-world-religions', 'mmlu-world-religions.val.ab-v1', 'mmmu-accounting', 'mmmu-accounting.dev.v1', 'mmmu-accounting.validation.v1', 'mmmu-agriculture', 'mmmu-agriculture.dev.v1', 'mmmu-agriculture.validation.v1', 'mmmu-architecture-and-engineering', 'mmmu-architecture-and-engineering.dev.v1', 'mmmu-architecture-and-engineering.validation.v1', 'mmmu-art', 'mmmu-art-theory', 'mmmu-art-theory.dev.v1', 'mmmu-art-theory.validation.v1', 'mmmu-art.dev.v1', 'mmmu-art.validation.v1', 'mmmu-basic-medical-science', 'mmmu-basic-medical-science.dev.v1', 'mmmu-basic-medical-science.validation.v1', 'mmmu-biology', 'mmmu-biology.dev.v1', 'mmmu-biology.validation.v1', 'mmmu-chemistry', 'mmmu-chemistry.dev.v1', 'mmmu-chemistry.validation.v1', 'mmmu-clinical-medicine', 'mmmu-clinical-medicine.dev.v1', 'mmmu-clinical-medicine.validation.v1', 'mmmu-computer-science', 'mmmu-computer-science.dev.v1', 'mmmu-computer-science.validation.v1', 'mmmu-design', 'mmmu-design.dev.v1', 'mmmu-design.validation.v1', 'mmmu-diagnostics-and-laboratory-medicine', 'mmmu-diagnostics-and-laboratory-medicine.dev.v1', 'mmmu-diagnostics-and-laboratory-medicine.validation.v1', 'mmmu-economics', 'mmmu-economics.dev.v1', 'mmmu-economics.validation.v1', 'mmmu-electronics', 'mmmu-electronics.dev.v1', 'mmmu-electronics.validation.v1', 'mmmu-energy-and-power', 'mmmu-energy-and-power.dev.v1', 'mmmu-energy-and-power.validation.v1', 'mmmu-finance', 'mmmu-finance.dev.v1', 'mmmu-finance.validation.v1', 'mmmu-geography', 'mmmu-geography.dev.v1', 'mmmu-geography.validation.v1', 'mmmu-history', 'mmmu-history.dev.v1', 'mmmu-history.validation.v1', 'mmmu-literature', 'mmmu-literature.dev.v1', 'mmmu-literature.validation.v1', 'mmmu-manage', 'mmmu-manage.dev.v1', 'mmmu-manage.validation.v1', 'mmmu-marketing', 'mmmu-marketing.dev.v1', 'mmmu-marketing.validation.v1', 'mmmu-materials', 'mmmu-materials.dev.v1', 'mmmu-materials.validation.v1', 'mmmu-math', 'mmmu-math.dev.v1', 'mmmu-math.validation.v1', 'mmmu-mechanical-engineering', 'mmmu-mechanical-engineering.dev.v1', 'mmmu-mechanical-engineering.validation.v1', 'mmmu-music', 'mmmu-music.dev.v1', 'mmmu-music.validation.v1', 'mmmu-pharmacy', 'mmmu-pharmacy.dev.v1', 'mmmu-pharmacy.validation.v1', 'mmmu-physics', 'mmmu-physics.dev.v1', 'mmmu-physics.validation.v1', 'mmmu-psychology', 'mmmu-psychology.dev.v1', 'mmmu-psychology.validation.v1', 'mmmu-public-health', 'mmmu-public-health.dev.v1', 'mmmu-public-health.validation.v1', 'mmmu-sociology', 'mmmu-sociology.dev.v1', 'mmmu-sociology.validation.v1', 'monthly_metric_comparison', 'monthly_metric_comparison.dev.v0', 'moral_exceptQA', 'moral_exceptQA.test.v1', 'multi-step-equations', 'multi-step-equations.dev.v0', 'multistep-web-tasks', 'multistep-web-tasks.easy', 'multistep-web-tasks.hard', 'multistep-web-tasks.main', 'multistep-web-tasks.medium', 'multistep-web-tasks.simple', 'multistep-web-tasks.task_1', 'multistep-web-tasks.task_2', 'multistep-web-tasks.task_3', 'multistep-web-tasks.task_4', 'multistep-web-tasks.task_5', 'multistep-web-tasks.task_6', 'multistep-web-tasks.task_7', 'multistep-web-tasks.task_8', 'multistep-web-tasks.task_9', 'multistep-word-problems', 'multistep-word-problems.dev.v0', 'music-theory-chord-names', 'music-theory-chord-names.dev.v0', 'music-theory-chord-notes', 'music-theory-chord-notes.dev.v0', 'music-theory-tetrads-identification', 'music-theory-tetrads-identification.dev.v0', 'music-theory-triads-identification', 'music-theory-triads-identification.dev.v0', 'music_theory_scale_modes', 'music_theory_scale_modes.dev.v0', 'naughty_strings', 'naughty_strings.test.v1', 'naughty_strings_fuzzy', 'naughty_strings_fuzzy.test.v1', 'naughty_strings_graded', 'naughty_strings_graded.test.v1', 'naughty_strings_graded_meta', 'naughty_strings_graded_meta.test.v1', 'nepali-numerals', 'nepali-numerals.dev.v0', 'nepali-song-singer', 'nepali-song-singer.dev', 'ner_finance', 'ner_finance.dev.v0', 'newsology', 'newsology.dev.v0', 'next-val-series', 'next-val-series.dev.simple-v0', 'nfl-point-combinations', 'nfl-point-combinations.dev.v0', 'no-sandbagging-all.v1', 'no-sandbagging-subset.v1', 'non-compound-names', 'non-compound-names-meta', 'non-compound-names-meta.dev.v0', 'non-compound-names.dev.v0', 'norwegian-lexicon', 'norwegian-lexicon.dev.v0', 'norwegian-rhymes', 'norwegian-rhymes.dev.v0', 'number-pattern', 'number-pattern.dev.v0', 'number-reading', 'number-reading.dev.v0', 'number_series_test', 'number_series_test.dev.v0', 'numbers_game', 'numbers_game.dev.v0', 'numeral-type-comparisons', 'numeral-type-comparisons.dev.v0', 'numerical-cabbala-casanova', 'numerical-cabbala-casanova.dev.v0', 'nutrition', 'nutrition.dev.v0', 'ordered-history-events', 'ordered-history-events.dev.v0', 'ordering_randomised_versionlist', 'ordering_randomised_versionlist.dev.v0', 'osm_mapping_one_way', 'osm_mapping_one_way.dev.v0', 'override-system-instruction', 'override-system-instruction.dev.v0', 'pantone_to_hex', 'pantone_to_hex.dev.v0', 'parable-to-moral-match-en', 'parable-to-moral-match-en.dev.v0', 'parable-to-moral-match-zh', 'parable-to-moral-match-zh.dev.v0', 'pararule-plus-multi-step-deductive-reasoning', 'pararule-plus-multi-step-deductive-reasoning.dev.v0', 'partially_solved_crossword_clues', 'partially_solved_crossword_clues.dev.v0', 'passing-balls', 'passing-balls.dev.v0', 'path_enclosed_area', 'path_enclosed_area.dev.v0', 'pattern_identification', 'pattern_identification.dev.v0', 'persian-kinship-riddles', 'persian-kinship-riddles.dev.v0', 'ph-calculation', 'ph-calculation.dev.v0', 'phonetics-identify-words-needing-missing-gpcs', 'phonetics-identify-words-needing-missing-gpcs.s1.simple-v0', 'physics-interaction', 'physics.interaction.dev.v0', 'pointer-value-retrieval-easy-few-examples', 'pointer-value-retrieval-easy-few-examples.dev.v0', 'pointer-value-retrieval-easy-many-examples', 'pointer-value-retrieval-easy-many-examples.dev.v0', 'pointer-value-retrieval-hard-few-examples', 'pointer-value-retrieval-hard-few-examples.dev.v0', 'pointer-value-retrieval-hard-many-examples', 'pointer-value-retrieval-hard-many-examples.dev.v0', 'pointer-value-retrieval-medium-few-examples', 'pointer-value-retrieval-medium-few-examples.dev.v0', 'pointer-value-retrieval-medium-many-examples', 'pointer-value-retrieval-medium-many-examples.dev.v0', 'points-on-line', 'points-on-line.dev.v0', 'poker_analysis', 'poker_analysis.test.v1', 'polish-exams-qa', 'polish-exams-qa.test.v0', 'polish-lexicon', 'polish-lexicon.dev.v0', 'polish-proverbs', 'polish-proverbs.dev.v0', 'polish-syllable-count', 'polish-syllable-count.val.v0', 'polish_rhymes_generation', 'polish_rhymes_generation.v0', 'population_span_extraction', 'population_span_extraction.dev.v0', 'portuguese-exams-qa', 'portuguese-exams-qa.test.v0', 'portuguese-kinship-riddles', 'portuguese-kinship-riddles.dev.v0', 'portuguese-sarcasm', 'portuguese-sarcasm.dev.v0', 'portuguese-syllable-count', 'portuguese-syllable-count.dev.v0', 'positive-binary-operations', 'positive-binary-operations.test.v1', 'premature-conclusions', 'premature-conclusions.dev.v0', 'probabilities-word-problems', 'probabilities-word-problems.test.v1', 'probability-questions', 'probability-questions.dev.v0', 'product_information_extraction_one_shot', 'product_information_extraction_one_shot.dev.v0', 'product_information_extraction_zero_shot', 'product_information_extraction_zero_shot.dev.v0', 'prompt-injection', 'prompt-injection.dev.v0', 'proofreader', 'proofreader.dev.v0', 'pure_korean', 'pure_korean.dev.v0', 'python_list_comprehension', 'python_list_comprehension.dev.v0', 'qa', 'qa.dev.v0', 'quartz', 'quartz.test.v1', 'ral_to_hex', 'ral_to_hex.dev.v0', 'rap-animals-vs-fruits', 'rap-animals-vs-fruits.dev.v0', 'rap-people-vs-fruits', 'rap-people-vs-fruits.dev.v0', 'rap-people-vs-people', 'rap-people-vs-people.dev.v0', 'rare-and-loanwords-dutch-lexicon', 'rare-and-loanwords-dutch-lexicon.dev.v0', 'raven-matrices-symbolic-center-single', 'raven-matrices-symbolic-center-single.dev.v0', 'raven-matrices-symbolic-distribute-four', 'raven-matrices-symbolic-distribute-four.dev.v0', 'raven-matrices-symbolic-distribute-nine', 'raven-matrices-symbolic-distribute-nine.dev.v0', 'raven-matrices-symbolic-in-center-single-out-center-single', 'raven-matrices-symbolic-in-center-single-out-center-single.dev.v0', 'raven-matrices-symbolic-in-distribute-four-out-center-single', 'raven-matrices-symbolic-in-distribute-four-out-center-single.dev.v0', 'raven-matrices-symbolic-left-center-single-right-center-single', 'raven-matrices-symbolic-left-center-single-right-center-single.dev.v0', 'raven-matrices-symbolic-open-center-single', 'raven-matrices-symbolic-open-center-single.dev.v0', 'raven-matrices-symbolic-open-distribute-four', 'raven-matrices-symbolic-open-distribute-four.dev.v0', 'raven-matrices-symbolic-open-distribute-nine', 'raven-matrices-symbolic-open-distribute-nine.dev.v0', 'raven-matrices-symbolic-open-in-center-single-out-center-single', 'raven-matrices-symbolic-open-in-center-single-out-center-single.dev.v0', 'raven-matrices-symbolic-open-in-distribute-four-out-center-single', 'raven-matrices-symbolic-open-in-distribute-four-out-center-single.dev.v0', 'raven-matrices-symbolic-open-left-center-single-right-center-single', 'raven-matrices-symbolic-open-left-center-single-right-center-single.dev.v0', 'raven-matrices-symbolic-open-up-center-single-down-center-single', 'raven-matrices-symbolic-open-up-center-single-down-center-single.dev.v0', 'raven-matrices-symbolic-up-center-single-down-center-single', 'raven-matrices-symbolic-up-center-single-down-center-single.dev.v0', 'raven-matrices-text-center-single', 'raven-matrices-text-center-single.dev.v0', 'raven-matrices-text-distribute-four', 'raven-matrices-text-distribute-four.dev.v0', 'raven-matrices-text-distribute-nine', 'raven-matrices-text-distribute-nine.dev.v0', 'raven-matrices-text-in-center-single-out-center-single', 'raven-matrices-text-in-center-single-out-center-single.dev.v0', 'raven-matrices-text-in-distribute-four-out-center-single', 'raven-matrices-text-in-distribute-four-out-center-single.dev.v0', 'raven-matrices-text-left-center-single-right-center-single', 'raven-matrices-text-left-center-single-right-center-single.dev.v0', 'raven-matrices-text-open-center-single', 'raven-matrices-text-open-center-single.dev.v0', 'raven-matrices-text-open-distribute-four', 'raven-matrices-text-open-distribute-four.dev.v0', 'raven-matrices-text-open-distribute-nine', 'raven-matrices-text-open-distribute-nine.dev.v0', 'raven-matrices-text-open-in-center-single-out-center-single', 'raven-matrices-text-open-in-center-single-out-center-single.dev.v0', 'raven-matrices-text-open-in-distribute-four-out-center-single', 'raven-matrices-text-open-in-distribute-four-out-center-single.dev.v0', 'raven-matrices-text-open-left-center-single-right-center-single', 'raven-matrices-text-open-left-center-single-right-center-single.dev.v0', 'raven-matrices-text-open-up-center-single-down-center-single', 'raven-matrices-text-open-up-center-single-down-center-single.dev.v0', 'raven-matrices-text-up-center-single-down-center-single', 'raven-matrices-text-up-center-single-down-center-single.dev.v0', 'reasoning_with_contradictory_statements', 'reasoning_with_contradictory_statements.dev.v0', 'reclor-logical-reasoning-plus', 'reclor-logical-reasoning-plus.dev.v0', 'rectangles', 'rectangles.dev.v0', 'recurrence-relation', 'recurrence-relation.test.v1', 'regex-match', 'regex.match.dev.v0', 'relative-orientations', 'relative-orientations.dev.v0', 'research-question-extraction', 'research-question-extraction.dev.v0', 'resistor-ohm-calculator', 'resistor-ohm-calculator.dev.simple-v0', 'resource_id_extraction', 'resource_id_extraction.dev.v0', 'reverse-polish-notation', 'reverse-polish-notation.dev.v0', 'reverse-shell', 'reverse-shell.dev.v0', 'reverse-sort-words-eng', 'reverse-sort-words-eng-simple.dev.v0', 'reverse-string', 'reverse-string.s1.simple-v0', 'rhetorical-devices', 'rhetorical-devices.dev.v0', 'rock-climbing', 'rock-climbing.dev.v0', 'romanian-logic', 'romanian-logic.dev.v0', 'romanian_homonyms', 'romanian_homonyms.dev.v0', 'rot13', 'rot13.s1.simple-v0', 'ru_rhyming_phrases', 'ru_rhyming_phrases.dev.v0', 'rubiks-colors', 'rubiks-colors.dev.v0', 'rucola', 'rucola.test.v0', 'russe', 'russe.test.v0', 'russian-english-homonym-context-resolution', 'russian-english-homonym-context-resolution.dev.v0', 'russian-lexicon', 'russian-lexicon.dev.v0', 'russian-nlp-tasks', 'russian-nlp-tasks.dev.v0', 'russian-rhyme', 'russian-rhyme.v0', 'russian-verse', 'russian-verse.dev.v0', 'russian_medical', 'russian_medical.dev.v0', 'russian_sarcasm', 'russian_sarcasm.dev.v0', 'sandbagging', 'sandbagging-all-50.v1', 'sandbagging-all-short.v1', 'sandbagging-all.v1', 'sandbagging-non-subset.v1', 'sandbagging-subset.v1', 'sarcasm', 'sarcasm.test.v1', 'schelling_point', 'schelling_point.dev.v0', 'schelling_point.owt.dev.v0', 'schelling_point.rn.dev.v0', 'schelling_point.rw.dev.v0', 'schelling_point.test.dev.v0', 'schelling_point.wikipedia.dev.v0', 'schelling_point_owt', 'schelling_point_rn', 'schelling_point_rw', 'schelling_point_test', 'schelling_point_wikipedia', 'seating_arrangements', 'seating_arrangements.dev.v0', 'security_guide', 'security_guide.dev.v0', 'self_prompting', 'self_prompting.full', 'self_prompting.small', 'seo-keywords', 'seo-keywords.dev.v0', 'serbian-exams-qa', 'serbian-exams-qa.test.v0', 'sexagenary_cycle_calculation', 'sexagenary_cycle_calculation.dev.v0', 'shape-in-shape', 'shape-in-shape.dev.v1', 'shared-borders', 'shared-borders.dev.v0', 'shopping_discount_comparison', 'shopping_discount_comparison.dev.v0', 'simple-block-puzzles', 'simple-block-puzzles.dev.v0', 'simple-charting', 'simple-charting.dev.v0', 'simple-knowledge-mongolian', 'simple-knowledge-mongolian.dev.v0', 'simple-visual-understanding', 'simple-visual-understanding.dev.v0', 'simple_math', 'simple_math.dev.v0', 'simple_physics_engine', 'simple_physics_engine.dev.v0', 'sindarin-fluency', 'sindarin-fluency.dev.v0', 'singapore_data_protection_decisions', 'singapore_data_protection_decisions.dev.v0', 'singlestore-vectorsearch', 'singlestore-vectorsearch.dev.v0', 'skill_acquisition.miskito', 'skill_acquisition.miskito.few_shot.dev5', 'skill_acquisition.miskito.few_shot.full', 'skill_acquisition.miskito.few_shot.manipulation.dev5', 'skill_acquisition.miskito.few_shot.manipulation.full', 'skill_acquisition.miskito.few_shot.translation.dev5', 'skill_acquisition.miskito.few_shot.translation.full', 'skill_acquisition.miskito.zero_shot.dev5', 'skill_acquisition.miskito.zero_shot.full', 'skill_acquisition.miskito.zero_shot.manipulation.dev5', 'skill_acquisition.miskito.zero_shot.manipulation.full', 'skill_acquisition.miskito.zero_shot.translation.dev5', 'skill_acquisition.miskito.zero_shot.translation.full', 'smiles_to_formula', 'smiles_to_formula.dev.v0', 'soc_codes', 'soc_codes.dev.v0', 'solve-for-variable', 'solve-for-variable.dev.v0', 'sort-numbers', 'sort-numbers.s1.simple-v0', 'south-african-bands', 'south-african-bands.dev.v0', 'spanish-exams-qa', 'spanish-exams-qa.test.v0', 'spanish-lexicon', 'spanish-lexicon.dev.v0', 'spanish_feminine_noun_masculine_article', 'spanish_feminine_noun_masculine_article.dev.v0', 'spider-sql', 'spider-sql.dev.v0', 'split_chinese_characters', 'split_chinese_characters.dev.v0', 'squares-gpt', 'squares-gpt.dev.v0', 'stats-tests', 'stats-tests.dev.v0', 'steganography', 'steganography.copypayload', 'steganography.direct', 'steganography.direct_ref', 'steganography.scratch', 'steganography.scratch_ref', 'steganography.task_payload', 'steganography.taskonly', 'stock-option-terms-bear-call-spread', 'stock-option-terms-bear-call-spread.dev.v0', 'stock-option-terms-bull-call-spread', 'stock-option-terms-bull-call-spread.dev.v0', 'stock-option-terms-inverse-iron-butteryfly-spread', 'stock-option-terms-inverse-iron-butteryfly-spread.dev.v0', 'stock-option-terms-inverse-iron-condor-spread', 'stock-option-terms-inverse-iron-condor-spread.dev.v0', 'stock-option-terms-iron-butterfly-spread.dev.v0', 'stock-option-terms-iron-butteryfly-spread', 'stock-option-terms-iron-condor-spread', 'stock-option-terms-iron-condor-spread.dev.v0', 'stock-options-bear-call-spread', 'stock-options-bear-call-spread.dev.v0', 'stock-options-bull-call-spread', 'stock-options-bull-call-spread.dev.v0', 'stock-options-inverse-iron-butterfly-spread', 'stock-options-inverse-iron-butterfly-spread.dev.v0', 'stock-options-inverse-iron-condor-spread', 'stock-options-inverse-iron-condor-spread.dev.v0', 'stock-options-iron-butteryfly-spread', 'stock-options-iron-butteryfly-spread.dev.v0', 'stock-options-iron-condor-spread', 'stock-options-iron-condor-spread.dev.v0', 'superficial-patterns', 'superficial-patterns.dev.v0', 'svg_alphabet', 'svg_alphabet.dev.v0', 'svg_to_text', 'svg_to_text.dev.v0', 'svg_understanding', 'svg_understanding.v0', 'swap-words', 'swap-words.dev.v0', 'swedish-spelling', 'swedish-spelling.dev.v0', 'swedish_sat', 'swedish_sat.dev.v0', 'syllables.dev.v1', 'syllables_long_words', 'syntax-check', 'syntax-check.dev.v1', 'taxes', 'taxes.dev.v0', 'tempo_to_measure_count', 'tempo_to_measure_count.dev.v0', 'test-fuzzy-match', 'test-fuzzy-match.s1.simple-v0', 'test-includes', 'test-includes-ignore-case', 'test-includes-ignore-case.s1.simple-v0', 'test-includes.s1.simple-v0', 'test-japanese-units', 'test-japanese-units.dev.v0', 'test-match', 'test-match.s1.simple-v0', 'test-time-zone-conversion', 'test-time-zone-conversion.dev.v0', 'test_english_pronunciations', 'test_english_pronunciations.dev.v0', 'test_japanese_english_numerals', 'test_japanese_english_numerals.dev.v0', 'test_japanese_radical', 'test_japanese_radical.dev.v0', 'tetris', 'tetris.dev.v0', 'text_compression', 'text_compression.abbreviate', 'text_compression.copytext', 'text_compression.gzip', 'text_compression.instructions', 'text_compression.scratch', 'text_compression.simple', 'theory_of_mind', 'theory_of_mind.hitom', 'theory_of_mind.hitom-multiple-choice', 'theory_of_mind.hitom-multiple-choice_light', 'theory_of_mind.hitom_light', 'theory_of_mind.socialiqa', 'theory_of_mind.socialiqa_light', 'theory_of_mind.tomi', 'theory_of_mind.tomi_light', 'thirty_six_stratagems', 'thirty_six_stratagems.test.v1', 'three-pt-mapping', 'three-pt-mapping.dev.v0', 'tokyo-station-number', 'tokyo-station-number.dev.v0', 'track_objects', 'track_objects.dev.v0', 'track_the_stat', 'track_the_stat.median', 'track_the_stat.mode', 'tracking-shuffled-objects', 'tracking-shuffled-objects.dev.v0', 'translation-meta', 'translation-meta.dev.v0', 'tricky-word-problems', 'tricky-word-problems.dev.v0', 'turkish-exams-qa', 'turkish-exams-qa.test.v0', 'turkish_characters', 'turkish_characters.dev.v0', 'twenty_questions', 'twenty_questions.dev100', 'twenty_questions.dev5', 'twenty_questions.full', 'twenty_questions.shortlist.dev100', 'twenty_questions.shortlist.dev5', 'twenty_questions.shortlist.full', 'ukraine-eit', 'ukraine-eit.val.v0', 'ukraine-gec-fluency-calque', 'ukraine-gec-fluency-calque.dev.v0', 'ukraine-gec-fluency-other', 'ukraine-gec-fluency-other.dev.v0', 'ukraine-gec-fluency-poorflow', 'ukraine-gec-fluency-poorflow.dev.v0', 'ukraine-gec-fluency-repetition', 'ukraine-gec-fluency-repetition.dev.v0', 'ukraine-gec-fluency-style', 'ukraine-gec-fluency-style.dev.v0', 'ukraine-gec-grammar-aspect', 'ukraine-gec-grammar-aspect.dev.v0', 'ukraine-gec-grammar-case', 'ukraine-gec-grammar-case.dev.v0', 'ukraine-gec-grammar-comparison', 'ukraine-gec-grammar-comparison.dev.v0', 'ukraine-gec-grammar-conjunction', 'ukraine-gec-grammar-conjunction.dev.v0', 'ukraine-gec-grammar-gender', 'ukraine-gec-grammar-gender.dev.v0', 'ukraine-gec-grammar-number', 'ukraine-gec-grammar-number.dev.v0', 'ukraine-gec-grammar-other', 'ukraine-gec-grammar-other.dev.v0', 'ukraine-gec-grammar-partvoice', 'ukraine-gec-grammar-partvoice.dev.v0', 'ukraine-gec-grammar-prep', 'ukraine-gec-grammar-prep.dev.v0', 'ukraine-gec-grammar-tense', 'ukraine-gec-grammar-tense.dev.v0', 'ukraine-gec-grammar-ungrammaticalstructure', 'ukraine-gec-grammar-ungrammaticalstructure.dev.v0', 'ukraine-gec-grammar-verbaform', 'ukraine-gec-grammar-verbaform.dev.v0', 'ukraine-gec-grammar-verbvoice', 'ukraine-gec-grammar-verbvoice.dev.v0', 'ukraine_electronic_petitions', 'ukraine_electronic_petitions.val.v0', 'unified-patch', 'unified-patch.dev.v0', 'unique_combinations', 'unique_combinations.dev.v0', 'unsolvable_questions', 'unsolvable_questions.dev.v0', 'unwanted-rhyming', 'unwanted-rhyming.dev.v0', 'urdu-lexicon', 'urdu-lexicon.dev.v0', 'urdu-transliteration', 'urdu-transliteration.dev.v0', 'us-tort-law', 'us-tort-law.dev.v0', 'utah_real_estate.dev.v0', 'utah_real_estateh', 'utility_price_parsing', 'utility_price_parsing.dev.v0', 'vietnamese-exams-qa', 'vietnamese-exams-qa.test.v0', 'viewport_to_grid_size', 'viewport_to_grid_size.dev.v3', 'vigenere', 'vigenere.s1.simple-v0', 'vintage_phone_keyboard_decode', 'vintage_phone_keyboard_decode.dev.v0', 'which-is-heavier', 'which-is-heavier.dev.v0', 'wkt_understanding', 'wkt_understanding.dev.v0', 'word-association-related-words-2', 'word-association-related-words-2.test.v1', 'word-association-related-words-3', 'word-association-related-words-3.test.v1', 'word-association-related-words-4', 'word-association-related-words-4.test.v1', 'word-association-related-words-5', 'word-association-related-words-5.test.v1', 'word_vector_over_reliance', 'word_vector_over_reliance.dev.simple-v0']\n"
          ]
        }
      ],
      "source": [
        "# This will generate a JSONL which will record samples and logs and store it in /tmp/evallogs\n",
        "!oaieval gpt-3.5-turbo match_mmlu_anatomy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "1Plh2y04kjfk",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "outputId": "bb0b0b3e-c634-4f33-fa15-89d96c05f2b0"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: '/tmp/evallogs/{log_name}'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-37-3091723d2ccb>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mevents\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"/tmp/evallogs/{log_name}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevents\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"r\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mevents_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_json\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlines\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/tmp/evallogs/{log_name}'"
          ]
        }
      ],
      "source": [
        "# How to process the log events generated by oaieval\n",
        "events = \"/tmp/evallogs/{log_name}\"\n",
        "\n",
        "with open(events, \"r\") as f:\n",
        "    events_df = pd.read_json(f, lines=True)\n",
        "\n",
        "matches_df = events_df[events_df.type == \"match\"].reset_index(drop=True)\n",
        "matches_df = matches_df.join(pd.json_normalize(matches_df.data))\n",
        "matches_df.correct.value_counts().plot.bar(title=\"Correctness of generated answers\", xlabel=\"Correctness\", ylabel=\"Count\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "kkzH5K8Nkjfk",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 228
        },
        "outputId": "0b2690ba-2225-4230-9488-6f503334a147"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'events_df' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-19-fed389a9f3aa>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Inspect samples\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mr\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjson_normalize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevents_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mevents_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"sampling\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miterrows\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Prompt: {r.prompt}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Sampled: {r.sampled}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"-\"\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m25\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'events_df' is not defined"
          ]
        }
      ],
      "source": [
        "# Inspect samples\n",
        "for i, r in pd.json_normalize(events_df[events_df.type == \"sampling\"].data).iterrows():\n",
        "    print(f\"Prompt: {r.prompt}\")\n",
        "    print(f\"Sampled: {r.sampled}\")\n",
        "    print(\"-\" * 25)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "oss_evals",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.9"
    },
    "orig_nbformat": 4,
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}