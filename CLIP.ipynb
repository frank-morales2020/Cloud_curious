{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "L4",
      "authorship_tag": "ABX9TyNxQU1EjIzyyrP4LtrKLFqn",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/frank-morales2020/Cloud_curious/blob/master/CLIP.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://github.com/openai/CLIP"
      ],
      "metadata": {
        "id": "fcCCrrS4IsD9"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6apg-armHXO5"
      },
      "outputs": [],
      "source": [
        "!pip install ftfy regex tqdm -q\n",
        "\n",
        "#!pip install colab-env --upgrade -q\n",
        "#!pip install openai -q\n",
        "\n",
        "!pip install git+https://github.com/openai/CLIP.git"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#import colab_env\n",
        "#import os\n",
        "\n",
        "#import openai\n",
        "##openai.api_key = os.getenv(\"OPENAI_API_KEY\")"
      ],
      "metadata": {
        "id": "c6cqlNIlIGz5"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5kXPRyOGIIpH",
        "outputId": "28f8fd6e-86c5-44fa-c7d7-69e22f67edf2"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Thu Apr 11 05:26:09 2024       \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 535.104.05             Driver Version: 535.104.05   CUDA Version: 12.2     |\n",
            "|-----------------------------------------+----------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                      |               MIG M. |\n",
            "|=========================================+======================+======================|\n",
            "|   0  NVIDIA L4                      Off | 00000000:00:03.0 Off |                    0 |\n",
            "| N/A   43C    P8              12W /  72W |      1MiB / 23034MiB |      0%      Default |\n",
            "|                                         |                      |                  N/A |\n",
            "+-----------------------------------------+----------------------+----------------------+\n",
            "                                                                                         \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                            |\n",
            "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
            "|        ID   ID                                                             Usage      |\n",
            "|=======================================================================================|\n",
            "|  No running processes found                                                           |\n",
            "+---------------------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/openai/CLIP.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zELxWMwNJbRm",
        "outputId": "42899c92-e475-484d-b65b-059f9f9ee22f"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'CLIP'...\n",
            "remote: Enumerating objects: 251, done.\u001b[K\n",
            "remote: Counting objects: 100% (8/8), done.\u001b[K\n",
            "remote: Compressing objects: 100% (8/8), done.\u001b[K\n",
            "remote: Total 251 (delta 3), reused 2 (delta 0), pack-reused 243\u001b[K\n",
            "Receiving objects: 100% (251/251), 8.93 MiB | 14.24 MiB/s, done.\n",
            "Resolving deltas: 100% (127/127), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import clip\n",
        "from PIL import Image\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "model, preprocess = clip.load(\"ViT-B/32\", device=device)\n",
        "\n",
        "image = preprocess(Image.open(\"/content/CLIP/CLIP.png\")).unsqueeze(0).to(device)\n",
        "text = clip.tokenize([\"a diagram\", \"a dog\", \"a cat\"]).to(device)\n",
        "\n",
        "with torch.no_grad():\n",
        "    image_features = model.encode_image(image)\n",
        "    text_features = model.encode_text(text)\n",
        "\n",
        "    logits_per_image, logits_per_text = model(image, text)\n",
        "    probs = 100 * logits_per_image.softmax(dim=-1).cpu().numpy()\n"
      ],
      "metadata": {
        "id": "-W2yjPhXHxXl"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Label probs:\", probs)  # prints: [[0.9927937  0.00421068 0.00299572]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FtKPLrf1To_D",
        "outputId": "eeeb2042-a687-423f-8b30-adcb7a0cb9b7"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Label probs: [[99.25    0.4185  0.3015]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import clip\n",
        "import torch\n",
        "from torchvision.datasets import CIFAR100\n",
        "\n",
        "# Load the model\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "model, preprocess = clip.load('ViT-B/32', device)\n",
        "\n",
        "# Download the dataset\n",
        "cifar100 = CIFAR100(root=os.path.expanduser(\"~/.cache\"), download=True, train=False)\n",
        "\n",
        "# Prepare the inputs\n",
        "image, class_id = cifar100[3637]\n",
        "image_input = preprocess(image).unsqueeze(0).to(device)\n",
        "text_inputs = torch.cat([clip.tokenize(f\"a photo of a {c}\") for c in cifar100.classes]).to(device)\n",
        "\n",
        "\n",
        "# Calculate features\n",
        "with torch.no_grad():\n",
        "    image_features = model.encode_image(image_input)\n",
        "    text_features = model.encode_text(text_inputs)\n",
        "\n",
        "# Pick the top 10 most similar labels for the image\n",
        "image_features /= image_features.norm(dim=-1, keepdim=True)\n",
        "text_features /= text_features.norm(dim=-1, keepdim=True)\n",
        "similarity = (100.0 * image_features @ text_features.T).softmax(dim=-1)\n",
        "values, indices = similarity[0].topk(10)"
      ],
      "metadata": {
        "id": "GrEJUITJJKdZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(cifar100.classes)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pdmgaXVs6lPk",
        "outputId": "1fe2b03c-3e54-494e-98b4-2bd05352b150"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['apple', 'aquarium_fish', 'baby', 'bear', 'beaver', 'bed', 'bee', 'beetle', 'bicycle', 'bottle', 'bowl', 'boy', 'bridge', 'bus', 'butterfly', 'camel', 'can', 'castle', 'caterpillar', 'cattle', 'chair', 'chimpanzee', 'clock', 'cloud', 'cockroach', 'couch', 'crab', 'crocodile', 'cup', 'dinosaur', 'dolphin', 'elephant', 'flatfish', 'forest', 'fox', 'girl', 'hamster', 'house', 'kangaroo', 'keyboard', 'lamp', 'lawn_mower', 'leopard', 'lion', 'lizard', 'lobster', 'man', 'maple_tree', 'motorcycle', 'mountain', 'mouse', 'mushroom', 'oak_tree', 'orange', 'orchid', 'otter', 'palm_tree', 'pear', 'pickup_truck', 'pine_tree', 'plain', 'plate', 'poppy', 'porcupine', 'possum', 'rabbit', 'raccoon', 'ray', 'road', 'rocket', 'rose', 'sea', 'seal', 'shark', 'shrew', 'skunk', 'skyscraper', 'snail', 'snake', 'spider', 'squirrel', 'streetcar', 'sunflower', 'sweet_pepper', 'table', 'tank', 'telephone', 'television', 'tiger', 'tractor', 'train', 'trout', 'tulip', 'turtle', 'wardrobe', 'whale', 'willow_tree', 'wolf', 'woman', 'worm']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Print the result\n",
        "print(\"\\nTop predictions:\\n\")\n",
        "for value, index in zip(values, indices):\n",
        "    print(f\"{cifar100.classes[index]:>16s}: {100 * value.item():.2f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pbCjSTs7LJN-",
        "outputId": "9c208bd4-f91f-48be-abf2-86b294adb8b7"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Top predictions:\n",
            "\n",
            "           snake: 65.14%\n",
            "          turtle: 12.43%\n",
            "    sweet_pepper: 3.85%\n",
            "          lizard: 1.91%\n",
            "       crocodile: 1.74%\n",
            "         leopard: 1.68%\n",
            "           snail: 1.61%\n",
            "            worm: 0.86%\n",
            "        flatfish: 0.85%\n",
            "          beetle: 0.82%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import clip\n",
        "import torch\n",
        "\n",
        "import numpy as np\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision.datasets import CIFAR100\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Load the model\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "model, preprocess = clip.load('ViT-B/32', device)\n",
        "\n",
        "# Load the dataset\n",
        "root = os.path.expanduser(\"~/.cache\")\n",
        "train = CIFAR100(root, download=True, train=True, transform=preprocess)\n",
        "test = CIFAR100(root, download=True, train=False, transform=preprocess)\n",
        "\n",
        "\n",
        "def get_features(dataset):\n",
        "    all_features = []\n",
        "    all_labels = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for images, labels in tqdm(DataLoader(dataset, batch_size=100)):\n",
        "            features = model.encode_image(images.to(device))\n",
        "\n",
        "            all_features.append(features)\n",
        "            all_labels.append(labels)\n",
        "\n",
        "    return torch.cat(all_features).cpu().numpy(), torch.cat(all_labels).cpu().numpy()\n",
        "\n",
        "# Calculate the image features\n",
        "train_features, train_labels = get_features(train)\n",
        "test_features, test_labels = get_features(test)\n",
        "\n",
        "# Perform logistic regression\n",
        "classifier = LogisticRegression(random_state=0, C=0.316, max_iter=10000, verbose=1) ## Accuracy = 80.020\n",
        "#classifier = LogisticRegression(random_state=0, C=0.316, max_iter=800, verbose=1) ## Accuracy = 79.940\n",
        "classifier.fit(train_features, train_labels)"
      ],
      "metadata": {
        "id": "3OvmdM_cJWLh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate using the logistic regression classifier\n",
        "predictions = classifier.predict(test_features)\n",
        "accuracy = np.mean((test_labels == predictions).astype(float)) * 100.\n",
        "print(f\"Accuracy = {accuracy:.3f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pT9oksrPLWLK",
        "outputId": "366993cd-bfbd-4660-afd6-074ee71b5448"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy = 79.990\n"
          ]
        }
      ]
    }
  ]
}