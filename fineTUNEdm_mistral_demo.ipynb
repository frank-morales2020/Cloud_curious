{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "L4",
      "authorship_tag": "ABX9TyP+Fx0f56MYGQZPQQjHH+cK",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "6406244b40d44af4b9cb11f6745a5655": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d4d81e3d625d4924a0740d867f8d0803",
              "IPY_MODEL_7807b02263be48828e01e12621005445",
              "IPY_MODEL_3eeeecc7c08d417fb40cc97ab16cc9bd"
            ],
            "layout": "IPY_MODEL_f028b7219b5148bb81e2c04a5d1495e6"
          }
        },
        "d4d81e3d625d4924a0740d867f8d0803": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_653208d5681e43eebfffca78d8c6ed2e",
            "placeholder": "​",
            "style": "IPY_MODEL_b72e9f686a994577921a4b4355d37c41",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "7807b02263be48828e01e12621005445": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a86360152cd148298330fd1728b84812",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e028de172ad54e6ca14ff965454e2a4b",
            "value": 2
          }
        },
        "3eeeecc7c08d417fb40cc97ab16cc9bd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bdbe864f3d3a4c5389cbc586c69d9653",
            "placeholder": "​",
            "style": "IPY_MODEL_6606775008af46409af7d88e23c9fd58",
            "value": " 2/2 [00:05&lt;00:00,  2.47s/it]"
          }
        },
        "f028b7219b5148bb81e2c04a5d1495e6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "653208d5681e43eebfffca78d8c6ed2e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b72e9f686a994577921a4b4355d37c41": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a86360152cd148298330fd1728b84812": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e028de172ad54e6ca14ff965454e2a4b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "bdbe864f3d3a4c5389cbc586c69d9653": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6606775008af46409af7d88e23c9fd58": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b1273e2386834fa5ae0d27fba086560c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_45885ce8e11445d591cb45db02268853",
              "IPY_MODEL_a2a2b152912545c78c82005fe0ee96ac",
              "IPY_MODEL_aefbdfbfbf184ce2b8a811328b616979"
            ],
            "layout": "IPY_MODEL_372b4cc822c6455cbe15079141496c37"
          }
        },
        "45885ce8e11445d591cb45db02268853": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d0d09a7c85d54e9c930a6c8e9c97b0f9",
            "placeholder": "​",
            "style": "IPY_MODEL_3fa2658b657b4351b135996f1a356a15",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "a2a2b152912545c78c82005fe0ee96ac": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3aa810731a5a429fa65f36d8f31a5694",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_fff877577c61442a864e65d33ea14e1d",
            "value": 2
          }
        },
        "aefbdfbfbf184ce2b8a811328b616979": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b6e2c28fedaf40158e3e7ca8dc7d867b",
            "placeholder": "​",
            "style": "IPY_MODEL_fef1b405085f46b981a8f9e660d70036",
            "value": " 2/2 [00:01&lt;00:00,  1.82it/s]"
          }
        },
        "372b4cc822c6455cbe15079141496c37": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d0d09a7c85d54e9c930a6c8e9c97b0f9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3fa2658b657b4351b135996f1a356a15": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3aa810731a5a429fa65f36d8f31a5694": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fff877577c61442a864e65d33ea14e1d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b6e2c28fedaf40158e3e7ca8dc7d867b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fef1b405085f46b981a8f9e660d70036": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/frank-morales2020/Cloud_curious/blob/master/fineTUNEdm_mistral_demo.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers -q\n",
        "!pip install torch -q\n",
        "!pip install accelerate -q\n",
        "!pip install bitsandbytes -q\n",
        "!pip install datetime -q\n",
        "!pip install unsloth -q\n",
        "!pip install openai -q\n",
        "!pip install openai-agents -q"
      ],
      "metadata": {
        "id": "7FPAs9pVLCDL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## mistral with unsloth"
      ],
      "metadata": {
        "id": "2-k2AAkmoqU0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from unsloth import FastLanguageModel\n",
        "import torch\n",
        "from transformers import AutoTokenizer\n",
        "import sqlite3\n",
        "import datetime\n",
        "from agents import Agent, Runner  # Assuming 'agents.py' is in the same directory\n",
        "from unsloth import FastLanguageModel, is_bfloat16_supported\n",
        "\n",
        "# --- Load Tokenizer ---\n",
        "unsloth_model_id = \"unsloth/mistral-7b-instruct-v0.3-bnb-4bit\"\n",
        "max_seq_length = 2048\n",
        "# Change dtype from string to torch.float16\n",
        "dtype = torch.float16\n",
        "load_in_4bit = True\n",
        "model, tokenizer = FastLanguageModel.from_pretrained(\n",
        "                            model_name=unsloth_model_id,\n",
        "                            max_seq_length=max_seq_length,\n",
        "                            dtype=dtype,\n",
        "                            load_in_4bit=True,\n",
        "                        )"
      ],
      "metadata": {
        "id": "DEiZ5WDGLl84"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## mistral with transformer"
      ],
      "metadata": {
        "id": "zI5BrByVo0id"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Install Pytorch & other libraries\n",
        "!pip install torch tensorboard --quiet\n",
        "\n",
        "# Install Hugging Face libraries\n",
        "!pip install  --upgrade transformers datasets accelerate evaluate bitsandbytes --quiet\n",
        "\n",
        "! pip install peft --quiet\n",
        "\n",
        "# Uncomment only if you're using A100 GPU\n",
        "#!pip install flash-attn --no-build-isolation\n",
        "!pip install diffusers safetensors  --quiet\n",
        "!pip install colab-env --quiet"
      ],
      "metadata": {
        "id": "FjkG2Bvdf5Jo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\n",
        "from trl import setup_chat_format\n",
        "\n",
        "# Hugging Face model id\n",
        "model_id = \"mistralai/Mistral-7B-Instruct-v0.1\"\n",
        "\n",
        "# BitsAndBytesConfig int-4 config\n",
        "bnb_config = BitsAndBytesConfig(\n",
        "    load_in_4bit=True, bnb_4bit_use_double_quant=True, bnb_4bit_quant_type=\"nf4\", bnb_4bit_compute_dtype=torch.bfloat16\n",
        ")\n",
        "\n",
        "# Load model and tokenizer\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    model_id,\n",
        "    device_map=\"auto\",\n",
        "    #attn_implementation=\"flash_attention_2\",\n",
        "    torch_dtype=torch.bfloat16,\n",
        "    quantization_config=bnb_config\n",
        ")\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_id,use_fast=True)\n",
        "tokenizer.padding_side = 'right' # to prevent warnings\n",
        "\n",
        "# We redefine the pad_token and pad_token_id with out of vocabulary token (unk_token)\n",
        "tokenizer.pad_token = tokenizer.unk_token\n",
        "tokenizer.pad_token_id = tokenizer.unk_token_id"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "6406244b40d44af4b9cb11f6745a5655",
            "d4d81e3d625d4924a0740d867f8d0803",
            "7807b02263be48828e01e12621005445",
            "3eeeecc7c08d417fb40cc97ab16cc9bd",
            "f028b7219b5148bb81e2c04a5d1495e6",
            "653208d5681e43eebfffca78d8c6ed2e",
            "b72e9f686a994577921a4b4355d37c41",
            "a86360152cd148298330fd1728b84812",
            "e028de172ad54e6ca14ff965454e2a4b",
            "bdbe864f3d3a4c5389cbc586c69d9653",
            "6606775008af46409af7d88e23c9fd58"
          ]
        },
        "id": "6MRrIbkaf2Jd",
        "outputId": "28f98b81-e618-4974-dd88-3592b090bc5d"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6406244b40d44af4b9cb11f6745a5655"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## code2dataset"
      ],
      "metadata": {
        "id": "MlrjB_36oZnS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://medium.com/ai-simplified-in-plain-english/ai-driven-disruption-management-for-next-gen-flight-scheduling-using-openai-51c7064af3e5"
      ],
      "metadata": {
        "id": "tRM4w2D6n3k6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = [\n",
        "    {\n",
        "        \"agent_name\": \"CrewAgent\",\n",
        "        \"code\": \"\"\"\n",
        "    class CrewAgent:\n",
        "        def __init__(self, db):\n",
        "            self.db = db  # Database connection\n",
        "\n",
        "        def assign_crew_to_flight(self, crew_id, flight_id):\n",
        "            \\\"\\\"\\\"Assigns a crew member to a flight.\\\"\\\"\\\"\n",
        "            # Code to update database with crew assignment\n",
        "            print(f\"Crew {crew_id} assigned to flight {flight_id}\")\n",
        "\n",
        "        def update_crew_schedule(self, crew_id, new_schedule):\n",
        "            \\\"\\\"\\\"Updates the schedule for a crew member.\\\"\\\"\\\"\n",
        "            # Code to update crew schedule in the database\n",
        "            print(f\"Crew {crew_id} schedule updated to {new_schedule}\")\n",
        "\n",
        "        def reassign_crew(self, flight_id, disruption_type):\n",
        "            \\\"\\\"\\\"Reassigns crew members due to a disruption.\\\"\\\"\\\"\n",
        "            # Code to handle crew reassignment logic\n",
        "            print(f\"Crew reassigned for flight {flight_id} due to {disruption_type}\")\n",
        "\n",
        "        # ... other CrewAgent methods ...\n",
        "    \"\"\",\n",
        "        \"description\": \"\"\"\n",
        "    The CrewAgent class is responsible for managing crew-related operations in the flight disruption management system.\n",
        "    It handles tasks such as assigning crew members to flights, updating crew schedules, and coordinating crew reassignments during disruptions.\n",
        "    The CrewAgent interacts with the database to store and retrieve crew information.\n",
        "    \"\"\"\n",
        "    },\n",
        "    {\n",
        "        \"agent_name\": \"PassengerAgent\",\n",
        "        \"code\": \"\"\"\n",
        "    class PassengerAgent:\n",
        "        def __init__(self, db):\n",
        "            self.db = db  # Database connection\n",
        "\n",
        "        def get_passenger_manifest(self, flight_id):\n",
        "            \\\"\\\"\\\"Retrieves the passenger manifest for a flight.\\\"\\\"\\\"\n",
        "            # Code to query the database for passenger list\n",
        "            print(f\"Passenger manifest for flight {flight_id} retrieved\")\n",
        "            return [\"PassengerA\", \"PassengerB\", ...]\n",
        "\n",
        "        def notify_passenger(self, passenger_id, message):\n",
        "            \\\"\\\"\\\"Sends a notification to a passenger.\\\"\\\"\\\"\n",
        "            # Code to send notification (e.g., email, SMS)\n",
        "            print(f\"Passenger {passenger_id} notified: {message}\")\n",
        "\n",
        "        def rebook_passenger(self, passenger_id, new_flight_id):\n",
        "            \\\"\\\"\\\"Rebooks a passenger on a new flight.\\\"\\\"\\\"\n",
        "            # Code to update the booking information in the database\n",
        "            print(f\"Passenger {passenger_id} rebooked on flight {new_flight_id}\")\n",
        "\n",
        "        # ... other PassengerAgent methods ...\n",
        "    \"\"\",\n",
        "        \"description\": \"\"\"\n",
        "    The PassengerAgent class is responsible for handling passenger-related operations in the flight disruption management system.\n",
        "    It manages tasks such as retrieving passenger manifests, notifying passengers of changes or disruptions, rebooking passengers on new flights,\n",
        "    and communicating with passengers.\n",
        "    \"\"\"\n",
        "    },\n",
        "    {\n",
        "        \"agent_name\": \"FleetAgent\",\n",
        "        \"code\": \"\"\"\n",
        "    class FleetAgent:\n",
        "        def __init__(self, db, crew_agent, passenger_agent):\n",
        "            self.db = db  # Database connection\n",
        "            self.crew_agent = crew_agent\n",
        "            self.passenger_agent = passenger_agent\n",
        "\n",
        "        def assess_disruption_impact(self, disruption_event):\n",
        "            \\\"\\\"\\\"Analyzes the impact of a disruption event.\\\"\\\"\\\"\n",
        "            # Code to analyze delayed flights, affected passengers, etc.\n",
        "            print(f\"Disruption impact assessed: {disruption_event}\")\n",
        "            return {\"delayed_flights\": 10, \"affected_passengers\": 200}\n",
        "\n",
        "        def orchestrate_recovery(self, disruption_event):\n",
        "            \\\"\\\"\\\"Orchestrates the recovery efforts after a disruption.\\\"\\\"\\\"\n",
        "            # Code to coordinate crew reassignment, passenger rebooking, etc.\n",
        "            print(f\"Recovery orchestrated for disruption: {disruption_event}\")\n",
        "\n",
        "        def reschedule_flights(self, disruption_event):\n",
        "            \\\"\\\"\\\"Reschedules flights to minimize disruption.\\\"\\\"\\\"\n",
        "            # Code to generate new flight schedules\n",
        "            print(f\"Flights rescheduled after disruption: {disruption_event}\")\n",
        "\n",
        "        # ... other FleetAgent methods ...\n",
        "    \"\"\",\n",
        "        \"description\": \"\"\"\n",
        "    The FleetAgent class is responsible for orchestrating the overall recovery strategy in case of flight disruptions.\n",
        "    It assesses the impact of disruptions, coordinates crew and passenger actions through the CrewAgent and PassengerAgent,\n",
        "    and reschedules flights to minimize the impact of disruptions.\n",
        "    \"\"\"\n",
        "    },\n",
        "    {\n",
        "        \"agent_name\": \"Database Operations\",\n",
        "        \"code\": \"\"\"\n",
        "def create_database(db_name):\n",
        "    \\\"\\\"\\\"Creates a new SQLite database.\\\"\\\"\\\"\n",
        "    # Code to create a database file\n",
        "    print(f\"Database {db_name} created\")\n",
        "\n",
        "def connect_to_database(db_name):\n",
        "    \\\"\\\"\\\"Establishes a connection to the SQLite database.\\\"\\\"\\\"\n",
        "    # Code to connect to the database\n",
        "    print(f\"Connected to database {db_name}\")\n",
        "    return sqlite3.connect(db_name)\n",
        "\n",
        "def close_database_connection(db_connection):\n",
        "    \\\"\\\"\\\"Closes the connection to the SQLite database.\\\"\\\"\\\"\n",
        "    # Code to close the database connection\n",
        "    print(\"Database connection closed\")\n",
        "    db_connection.close()\n",
        "\"\"\",\n",
        "        \"description\": \"\"\"\n",
        "    These functions handle database operations for the flight disruption management system.\n",
        "    They include creating a new SQLite database, connecting to the database, and closing the database connection.\n",
        "    \"\"\"\n",
        "    },\n",
        "    {\n",
        "        \"agent_name\": \"Analytics Functions\",\n",
        "        \"code\": \"\"\"\n",
        "def analyze_disruption_impact(disruption_event):\n",
        "    \\\"\\\"\\\"Analyzes the impact of a disruption event.\\\"\\\"\\\"\n",
        "    # Code to analyze delayed flights, affected passengers, etc.\n",
        "    print(f\"Disruption impact analysis for: {disruption_event}\")\n",
        "    return {\"delayed_flights\": 15, \"affected_passengers\": 300}\n",
        "\n",
        "def calculate_disruption_cost(delayed_flights):\n",
        "    \\\"\\\"\\\"Calculates the estimated cost of a disruption.\\\"\\\"\\\"\n",
        "    # Code to calculate disruption cost based on delays\n",
        "    cost_per_flight = 1000  # Example cost per delayed flight\n",
        "    total_cost = delayed_flights * cost_per_flight\n",
        "    print(f\"Disruption cost: ${total_cost}\")\n",
        "    return total_cost\n",
        "\"\"\",\n",
        "        \"description\": \"\"\"\n",
        "    These functions provide analytics capabilities for the flight disruption management system.\n",
        "    They include analyzing the impact of disruption events and calculating the estimated cost of disruptions.\n",
        "    \"\"\"\n",
        "    },\n",
        "    {\n",
        "        \"agent_name\": \"Disruption Simulation\",\n",
        "        \"code\": \"\"\"\n",
        "def simulate_disruption(db, airport_code, start_time, end_time):\n",
        "    \\\"\\\"\\\"Simulates a disruption event at a specific airport.\\\"\\\"\\\"\n",
        "    # Code to introduce delays or cancellations in the database\n",
        "    print(f\"Disruption simulated at {airport_code} from {start_time} to {end_time}\")\n",
        "\n",
        "    # Example: Introduce a delay to a flight\n",
        "    # Assuming you have a function to fetch flights and update their status\n",
        "    # flight_to_delay = get_flight_at_airport(db, airport_code, start_time)\n",
        "    # if flight_to_delay:\n",
        "    #     update_flight_status(db, flight_to_delay['flight_id'], 'delayed')\n",
        "    return \"Simulated disruption event\"\n",
        "\"\"\",\n",
        "        \"description\": \"\"\"\n",
        "    This function simulates a disruption event at a specific airport within a defined time frame.\n",
        "    It introduces delays or cancellations to flights in the database to mimic real-world disruptions.\n",
        "    \"\"\"\n",
        "    }\n",
        "]\n",
        "\n",
        "# Save the dataset to a JSON file\n",
        "with open(\"flight_agent_code_dataset.json\", \"w\") as f:\n",
        "    json.dump(dataset, f, indent=4)\n",
        "\n",
        "print(\"Dataset created and saved to flight_agent_code_dataset.json\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "xTq3J5dvkD-9",
        "outputId": "fc986939-b64a-4d61-b557-055c35d4e839"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset created and saved to flight_agent_code_dataset.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "with open(\"flight_agent_code_dataset.json\", \"r\") as f:\n",
        "    dataset = json.load(f)\n",
        "\n",
        "print(f\"Dataset loaded with {len(dataset)} entries\")\n",
        "# Now 'dataset' is a list of dictionaries, just like before"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "V0iKoWCxY87w",
        "outputId": "4ac3e9d0-6f4a-4325-b471-9c02136ee1c7"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset loaded with 6 entries\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## fine tuning"
      ],
      "metadata": {
        "id": "oLf7VpcKoTo_"
      }
    },
    {
      "source": [
        "import json\n",
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM, TrainingArguments, Trainer\n",
        "from peft import LoraConfig, get_peft_model\n",
        "from unsloth import FastLanguageModel\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "\n",
        "\n",
        "# 1. Load the Dataset\n",
        "with open(\"flight_agent_code_dataset.json\", \"r\") as f:\n",
        "    dataset = json.load(f)\n",
        "\n",
        "print(f\"Dataset loaded with {len(dataset)} entries\")\n",
        "\n",
        "# 2. Load Tokenizer and Model (Unsloth)\n",
        "\n",
        "\n",
        "# 3. Tokenize the Dataset and Create Labels\n",
        "# Tokenize the dataset and create labels\n",
        "def tokenize_function(examples):\n",
        "    tokenized_output = tokenizer(examples[\"code\"], truncation=True, padding=\"max_length\", max_length=256)\n",
        "    input_ids = tokenized_output[\"input_ids\"]\n",
        "    attention_mask = tokenized_output[\"attention_mask\"]\n",
        "\n",
        "    # Create labels by shifting input_ids\n",
        "    labels = input_ids[1:].copy()\n",
        "    labels.append(tokenizer.eos_token_id)\n",
        "    item[\"input_ids\"] = input_ids[:-1]\n",
        "    item[\"attention_mask\"] = attention_mask[:-1]\n",
        "    item[\"labels\"] = labels\n",
        "\n",
        "    return tokenized_output  # Return the tokenized output\n",
        "\n",
        "for item in dataset:\n",
        "    tokenized_output = tokenize_function({\"code\": item[\"code\"]})\n",
        "    item[\"input_ids\"] = tokenized_output[\"input_ids\"]\n",
        "    item[\"attention_mask\"] = tokenized_output[\"attention_mask\"]\n",
        "    item[\"labels\"] = item[\"input_ids\"].copy()  # Or your label creation logic\n",
        "\n",
        "\n",
        "print(\"Dataset tokenized and labels created using tokenizer\")\n",
        "\n",
        "\n",
        "# Data collator (ensure it handles padding if necessary or use the default)\n",
        "def data_collator(data):\n",
        "    input_ids = [item['input_ids'] for item in data]\n",
        "    attention_mask = [item['attention_mask'] for item in data]\n",
        "    labels = [item['labels'] for item in data]\n",
        "\n",
        "    # Pad the sequences manually if needed, or rely on the tokenizer's padding\n",
        "    input_ids = torch.nn.utils.rnn.pad_sequence([torch.tensor(ids) for ids in input_ids], batch_first=True, padding_value=tokenizer.pad_token_id)\n",
        "    attention_mask = torch.nn.utils.rnn.pad_sequence([torch.tensor(mask) for mask in attention_mask], batch_first=True, padding_value=0)\n",
        "    labels = torch.nn.utils.rnn.pad_sequence([torch.tensor(label) for label in labels], batch_first=True, padding_value=-100)  # Or your padding value\n",
        "\n",
        "    return {'input_ids': input_ids,\n",
        "            'attention_mask': attention_mask,\n",
        "            'labels': labels}\n",
        "\n",
        "\n",
        "# 4. Configure PEFT (LoRA)\n",
        "lora_config = LoraConfig(\n",
        "    r=8,\n",
        "    lora_alpha=16,\n",
        "    lora_dropout=0.05,\n",
        "    bias=\"none\",\n",
        "    target_modules=[\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\",\"gate_proj\", \"up_proj\", \"down_proj\"],\n",
        "    task_type=\"CAUSAL_LM\"\n",
        ")\n",
        "\n",
        "model = get_peft_model(model, lora_config)\n",
        "model.print_trainable_parameters()\n",
        "\n",
        "# 5. Define Training Arguments\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./mistral-fine-tuned\",\n",
        "    num_train_epochs=3,\n",
        "    per_device_train_batch_size=2,\n",
        "    gradient_accumulation_steps=1,\n",
        "    learning_rate=2e-4,\n",
        "    weight_decay=0.01,\n",
        "    logging_dir=\"./logs\",\n",
        "    logging_steps=10,\n",
        "    save_total_limit=2,\n",
        "    report_to=\"none\"\n",
        ")\n",
        "\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=dataset,\n",
        "    data_collator=data_collator # Use the defined data_collator\n",
        ")\n",
        "\n",
        "trainer.train()\n",
        "\n",
        "print(\"Mistral fine-tuning complete!\")\n",
        "\n",
        "# 7. Save the Fine-tuned Model\n",
        "model.save_pretrained(\"./mistral-fine-tuned\")\n",
        "tokenizer.save_pretrained(\"./mistral-fine-tuned\")\n",
        "\n",
        "print(\"Fine-tuned model and tokenizer saved!\")"
      ],
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 162
        },
        "id": "rQkOU_zmdFeH",
        "outputId": "8342cfed-481e-4aeb-8394-e2c26b5c05d8"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset loaded with 6 entries\n",
            "Dataset tokenized and labels created using tokenizer\n",
            "trainable params: 20,971,520 || all params: 7,262,703,616 || trainable%: 0.2888\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='9' max='9' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [9/9 00:06, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mistral fine-tuning complete!\n",
            "Fine-tuned model and tokenizer saved!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## evaluation"
      ],
      "metadata": {
        "id": "fIPl_sxpmGeu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
        "from peft import PeftModel\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "# Load the fine-tuned model and tokenizer\n",
        "model_path = \"./mistral-fine-tuned\"  # Path to your saved model\n",
        "base_model_path = \"mistralai/Mistral-7B-Instruct-v0.1\" # The original base model\n",
        "\n",
        "# Load the base model\n",
        "base_model = AutoModelForCausalLM.from_pretrained(\n",
        "    base_model_path,\n",
        "    device_map=\"auto\",\n",
        "    torch_dtype=torch.bfloat16,\n",
        "    #quantization_config=bnb_config  # If you used quantization, include this\n",
        ")\n",
        "\n",
        "# Load the PEFT adapter and apply it to the base model\n",
        "model = PeftModel.from_pretrained(base_model, model_path)\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(base_model_path, use_fast=True)\n",
        "tokenizer.padding_side = 'right'\n",
        "tokenizer.pad_token = tokenizer.unk_token\n",
        "tokenizer.pad_token_id = tokenizer.unk_token_id\n",
        "\n",
        "# Evaluation Function (Code Generation)\n",
        "def evaluate_code_generation(model, tokenizer, prompt):\n",
        "    \"\"\"\n",
        "    Evaluates the model's code generation for a given prompt.\n",
        "\n",
        "    Args:\n",
        "        model: The fine-tuned model.\n",
        "        tokenizer: The tokenizer.\n",
        "        prompt: A string describing the desired code functionality.\n",
        "\n",
        "    Returns:\n",
        "        generated_code: The code generated by the model.\n",
        "    \"\"\"\n",
        "    inputs = tokenizer(prompt, return_tensors=\"pt\")\n",
        "    outputs = model.generate(**inputs, max_length=200)  # Adjust max_length as needed\n",
        "    generated_code = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "    return generated_code\n",
        "\n",
        "# Evaluation Function (Simulation - Simplified Example)\n",
        "def evaluate_simulation(generated_code, scenario):\n",
        "    \"\"\"\n",
        "    Evaluates the generated code in a simplified simulation.\n",
        "\n",
        "    Args:\n",
        "        generated_code: The code generated by the model.\n",
        "        scenario: A dictionary representing a disruption scenario.\n",
        "\n",
        "    Returns:\n",
        "        results: A dictionary containing evaluation metrics.\n",
        "    \"\"\"\n",
        "    # **Note:** This is a simplified example. A real simulation would involve\n",
        "    # executing the generated code in a controlled environment and\n",
        "    # measuring its effects.\n",
        "\n",
        "    # In this example, we'll just check if the generated code contains\n",
        "    # keywords related to handling the scenario.\n",
        "\n",
        "    results = {}\n",
        "    if \"delay\" in scenario and \"reassign_crew\" in generated_code:\n",
        "        results[\"crew_reassignment\"] = \"Handled\"\n",
        "    else:\n",
        "        results[\"crew_reassignment\"] = \"Not Handled\"\n",
        "\n",
        "    if \"passenger\" in scenario and \"rebook_passenger\" in generated_code:\n",
        "        results[\"passenger_rebooking\"] = \"Handled\"\n",
        "    else:\n",
        "        results[\"passenger_rebooking\"] = \"Not Handled\"\n",
        "\n",
        "    return results\n",
        "\n",
        "# --- Example Usage ---\n",
        "\n",
        "# 1. Code Generation Evaluation\n",
        "prompt = \"Generate Python code for a CrewAgent to reassign crew members due to a weather delay.\"\n",
        "generated_code = evaluate_code_generation(model, tokenizer, prompt)\n",
        "print(\"Generated Code:\\n\", generated_code)\n",
        "\n",
        "# 2. Simulation Evaluation (Simplified)\n",
        "scenario = {\"delay\": True, \"passenger\": True}  # Example scenario: weather delay affecting passengers\n",
        "simulation_results = evaluate_simulation(generated_code, scenario)\n",
        "print(\"Simulation Results:\\n\", simulation_results)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104,
          "referenced_widgets": [
            "b1273e2386834fa5ae0d27fba086560c",
            "45885ce8e11445d591cb45db02268853",
            "a2a2b152912545c78c82005fe0ee96ac",
            "aefbdfbfbf184ce2b8a811328b616979",
            "372b4cc822c6455cbe15079141496c37",
            "d0d09a7c85d54e9c930a6c8e9c97b0f9",
            "3fa2658b657b4351b135996f1a356a15",
            "3aa810731a5a429fa65f36d8f31a5694",
            "fff877577c61442a864e65d33ea14e1d",
            "b6e2c28fedaf40158e3e7ca8dc7d867b",
            "fef1b405085f46b981a8f9e660d70036"
          ]
        },
        "id": "TrqhXGAgmEnZ",
        "outputId": "0536267c-73b8-4eab-cd35-39882ce95b84"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b1273e2386834fa5ae0d27fba086560c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:accelerate.big_modeling:Some parameters are on the meta device because they were offloaded to the cpu.\n",
            "WARNING:accelerate.big_modeling:Some parameters are on the meta device because they were offloaded to the cpu.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## attention test"
      ],
      "metadata": {
        "id": "vLuEdNytoJHV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import xformers\n",
        "print(\"PyTorch version:\", torch.__version__)\n",
        "print(\"xformers version:\", xformers.__version__)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "ScExQL7ZehOn",
        "outputId": "c9ddfc97-c89f-4e58-b45a-c811e6e123b0"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PyTorch version: 2.6.0+cu124\n",
            "xformers version: 0.0.29.post3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import xformers.ops as xops\n",
        "\n",
        "# Example input shapes (from your error message)\n",
        "batch_size = 2\n",
        "seq_len = 291\n",
        "num_heads = 8\n",
        "num_groups = 4\n",
        "d_head = 128\n",
        "\n",
        "# Create dummy tensors\n",
        "query = torch.randn(batch_size, seq_len, num_heads, num_groups, d_head, dtype=torch.float16).cuda()\n",
        "key = torch.randn(batch_size, seq_len, num_heads, num_groups, d_head, dtype=torch.float16).cuda()\n",
        "value = torch.randn(batch_size, seq_len, num_heads, num_groups, d_head, dtype=torch.float16).cuda()\n",
        "\n",
        "# Create attention mask\n",
        "attn_bias = xops.fmha.attn_bias.LowerTriangularMask()\n",
        "\n",
        "try:\n",
        "    # Try memory-efficient attention\n",
        "    output = xops.memory_efficient_attention(query, key, value, attn_bias=attn_bias)\n",
        "    print(\"Attention successful!\")\n",
        "    print(\"Output shape:\", output.shape)\n",
        "except Exception as e:\n",
        "    print(\"Error:\", e)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "ia33YUXreu-0",
        "outputId": "4199184f-30eb-4cbe-c3d0-613b333611ad"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Attention successful!\n",
            "Output shape: torch.Size([2, 291, 8, 4, 128])\n"
          ]
        }
      ]
    }
  ]
}