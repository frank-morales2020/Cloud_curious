{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/frank-morales2020/Cloud_curious/blob/master/FineTuning_VertexAISDK_GPU.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Installations"
      ],
      "metadata": {
        "id": "KThk5ET4q4fo"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UiVwfFuZ9axh"
      },
      "outputs": [],
      "source": [
        "!pip install google-cloud-aiplatform -q\n",
        "!pip install google-cloud-storage -q\n",
        "!pip install google-cloud-bigquery -q\n",
        "!pip install google-cloud-bigquery-storage -q\n",
        "!pip install google-cloud-aiplatform -q\n",
        "!pip install datasets -q\n",
        "!pip install colab-env -q\n",
        "\n",
        "# Install necessary libraries\n",
        "!pip install  -q gcsfs==2024.3.1\n",
        "!pip install  -q accelerate==0.31.0\n",
        "!pip install  -q transformers==4.45.2\n",
        "!pip install  -q  datasets==2.19.2\n",
        "!pip install google-cloud-aiplatform[all] -q\n",
        "!pip install vertexai  -q\n",
        "!pip install tensorflow_datasets -q\n",
        "\n",
        "!pip install google-cloud-aiplatform -q -U\n",
        "\n",
        "print('\\n')\n",
        "\n",
        "\n",
        "import google.cloud.bigquery\n",
        "import google.cloud.bigquery_storage\n",
        "import google.cloud.aiplatform\n",
        "import google.cloud.storage\n",
        "\n",
        "print(f\"google-cloud-aiplatform: {google.cloud.aiplatform.__version__}\")\n",
        "print(f\"google-cloud-storage: {google.cloud.storage.__version__}\")\n",
        "print(f\"google-cloud-bigquery: {google.cloud.bigquery.__version__}\")\n",
        "print(f\"google-cloud-bigquery-storage: {google.cloud.bigquery_storage.__version__}\")\n",
        "print(f\"google-cloud-aiplatform: {google.cloud.aiplatform.__version__}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import datasets\n",
        "import colab_env\n",
        "print('\\n\\n')\n",
        "print(f\"datasets: {datasets.__version__}\")\n",
        "print(f\"colab-env: {colab_env.__version__}\")\n",
        "import google.cloud.aiplatform\n",
        "import google.cloud.storage\n",
        "print(f\"google-cloud-aiplatform: {google.cloud.aiplatform.__version__}\")\n",
        "print(f\"google-cloud-storage: {google.cloud.storage.__version__}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GN259O2MOxp2",
        "outputId": "99fdbba2-c678-46d0-b359-ae5c5c5e2dea"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n",
            "\n",
            "\n",
            "\n",
            "datasets: 2.19.2\n",
            "colab-env: 0.2.0\n",
            "google-cloud-aiplatform: 1.87.0\n",
            "google-cloud-storage: 2.19.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## data preparation"
      ],
      "metadata": {
        "id": "R7-1paG9ps6s"
      }
    },
    {
      "source": [
        "!gsutil cp gs://{BUCKET_NAME}/cmapss_FD004_train_text.jsonl .\n",
        "!gsutil cp gs://{BUCKET_NAME}/cmapss_FD004_test_text.jsonl ."
      ],
      "cell_type": "code",
      "metadata": {
        "id": "c6d_EJRnh5ks"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import logging\n",
        "\n",
        "def validate_jsonl_format(file_path, check_transformed_cmapss=True):\n",
        "    \"\"\"\n",
        "    Validates JSONL format and optionally checks for the transformed CMAPSS\n",
        "    data structure.\n",
        "\n",
        "    Args:\n",
        "        file_path (str): Path to the JSONL file.\n",
        "        check_transformed_cmapss (bool): If True, checks for \"prompt\" and\n",
        "                                         \"completion\" both being strings.\n",
        "    Returns:\n",
        "        bool: True if valid, False otherwise.\n",
        "    \"\"\"\n",
        "    with open(file_path, 'r') as f:\n",
        "        for line in f:\n",
        "            try:\n",
        "                data = json.loads(line)\n",
        "                if \"prompt\" not in data or \"completion\" not in data:\n",
        "                    logging.error(\n",
        "                        f\"Invalid format: Missing 'prompt' or 'completion' in line: {line.strip()}\"\n",
        "                    )\n",
        "                    return False\n",
        "\n",
        "                if check_transformed_cmapss:\n",
        "                    if not isinstance(data[\"prompt\"], str) or not isinstance(\n",
        "                        data[\"completion\"], str\n",
        "                    ):\n",
        "                        logging.error(\n",
        "                            f\"Invalid transformed CMAPSS format in line: {line.strip()}\"\n",
        "                        )\n",
        "                        return False\n",
        "            except json.JSONDecodeError:\n",
        "                logging.error(f\"Invalid JSON in line: {line.strip()}\")\n",
        "                return False\n",
        "    logging.info(f\"File '{file_path}' has valid format.\")\n",
        "    return True\n",
        "\n",
        "# Create a dummy JSONL file for transformed CMAPSS data\n",
        "transformed_cmapss_file_path = \"cmapss_FD004_test_text_transformed.jsonl\"\n",
        "with open(transformed_cmapss_file_path, \"w\") as f:\n",
        "    f.write(\n",
        "        '{\"prompt\": \"Sensor readings from test: 25.1, 1200.5, 45.6\", \"completion\": \"185\"}\\n'\n",
        "    )\n",
        "    f.write(\n",
        "        '{\"prompt\": \"More test data: 25.2, 1199.8, 45.5\", \"completion\": \"170\"}\\n'\n",
        "    )\n",
        "\n",
        "# Validate the transformed CMAPSS file\n",
        "if validate_jsonl_format(\n",
        "    transformed_cmapss_file_path, check_transformed_cmapss=True\n",
        "):\n",
        "    print(f\"'{transformed_cmapss_file_path}' has a valid transformed CMAPSS format.\")\n",
        "else:\n",
        "    print(f\"'{transformed_cmapss_file_path}' has an invalid format.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zdFeTeLT9uK8",
        "outputId": "c44eacc6-5341-4f79-c86f-1463780bafac"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "'cmapss_FD004_test_text_transformed.jsonl' has a valid transformed CMAPSS format.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import logging\n",
        "\n",
        "def validate_jsonl_format(file_path, check_time_series=True):\n",
        "    \"\"\"\n",
        "    Validates JSONL format and optionally checks for time-series data structure.\n",
        "\n",
        "    Args:\n",
        "        file_path (str): Path to the JSONL file.\n",
        "        check_time_series (bool): If True, checks for \"prompt\" containing a list\n",
        "                                   and \"completion\" being a number.\n",
        "    Returns:\n",
        "        bool: True if valid, False otherwise.\n",
        "    \"\"\"\n",
        "    with open(file_path, 'r') as f:\n",
        "        for line in f:\n",
        "            try:\n",
        "                data = json.loads(line)\n",
        "                if \"prompt\" not in data or \"completion\" not in data:\n",
        "                    logging.error(f\"Invalid format: Missing 'prompt' or 'completion' in line: {line.strip()}\")\n",
        "                    return False\n",
        "\n",
        "                if check_time_series:\n",
        "                    if not isinstance(data[\"prompt\"], list) or not isinstance(data[\"completion\"], (int, float)):\n",
        "                        logging.error(f\"Invalid time-series format in line: {line.strip()}\")\n",
        "                        return False\n",
        "            except json.JSONDecodeError:\n",
        "                logging.error(f\"Invalid JSON in line: {line.strip()}\")\n",
        "                return False\n",
        "    logging.info(f\"File '{file_path}' has valid format.\")\n",
        "    return True"
      ],
      "metadata": {
        "id": "HenJN85-8oJH"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "def validate_jsonl_format(file_path):\n",
        "    with open(file_path, 'r') as f:\n",
        "        for line in f:\n",
        "            try:\n",
        "                data = json.loads(line)\n",
        "                if \"prompt\" not in data or \"completion\" not in data:\n",
        "                    print(f\"Invalid format in line: {line}\")\n",
        "                    return False  # Indicate invalid format\n",
        "            except json.JSONDecodeError:\n",
        "                print(f\"Invalid JSON in line: {line}\")\n",
        "                return False  # Indicate invalid JSON\n",
        "    return True  # Indicate valid format\n",
        "\n",
        "# Example usage\n",
        "if validate_jsonl_format(\"cmapss_FD004_train_text.jsonl\"):\n",
        "    print(\"Training data has valid format.\")\n",
        "\n",
        "else:\n",
        "    print(\"Training data has invalid format.\")\n",
        "\n",
        "if validate_jsonl_format(\"cmapss_FD004_test_text.jsonl\"):\n",
        "    print(\"Testing data has valid format.\")\n",
        "else:\n",
        "    print(\"Testing data has invalid format.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8wduiO5kiPLL",
        "outputId": "144b78ec-f14e-45f7-8c67-f0cc0ab7fe4f"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Invalid format in line: {\"contents\": [{\"role\": \"user\", \"parts\": [{\"text\": \"Engine sensor readings over time: [1.0, 41.9993, 0.8409, 100.0, 445.0, 548.68, 1343.85, 1111.03, 3.91, 5.69, 137.26, 2211.96, 8296.96, 1.01, 41.69, 129.46, 2387.97, 8068.65, 9.3383, 0.02, 328.0, 2212.0, 100.0, 10.48, 6.3841, 2.0, 42.0073, 0.84, 100.0, 445.0, 548.5, 1343.11, 1108.02, 3.91, 5.69, 138.4, 2211.93, 8304.82, 1.01, 41.56, 129.91, 2387.98, 8075.72, 9.3616, 0.02, 330.0, 2212.0, 100.0, 10.58, 6.3506, 3.0, 20.0058, 0.7, 100.0, 491.19, 607.22, 1478.88, 1244.42, 9.35, 13.6, 332.86, 2323.66, 8709.26, 1.07, 43.99, 312.69, 2387.85, 8053.84, 9.1826, 0.02, 363.0, 2324.0, 100.0, 24.59, 14.688, 4.0, 10.0039, 0.25, 100.0, 489.05, 604.1, 1488.19, 1297.5, 10.52, 15.46, 393.88, 2318.63, 8773.14, 1.26, 44.95, 370.86, 2387.83, 8124.24, 8.6464, 0.03, 367.0, 2319.0, 100.0, 28.8, 17.0438, 5.0, 9.999, 0.25, 100.0, 489.05, 604.46, 1490.03, 1294.91, 10.52, 15.46, 393.25, 2318.65, 8766.53, 1.25, 44.9, 370.42, 2387.86, 8123.0, 8.634, 0.03, 368.0, 2319.0, 100.0, 28.69, 17.1511, 6.0, 10.0026, 0.2502, 100.0, 489.05, 604.27, 1494.16, 1296.92, 10.52, 15.46, 393.29, 2318.68, 8766.33, 1.26, 44.94, 370.36, 2387.8, 8119.08, 8.6057, 0.03, 368.0, 2319.0, 100.0, 28.59, 17.162, 7.0, 42.0008, 0.84, 100.0, 445.0, 548.97, 1345.93, 1113.35, 3.91, 5.69, 137.82, 2211.93, 8308.47, 1.02, 41.74, 130.11, 2388.01, 8076.4, 9.3611, 0.02, 329.0, 2212.0, 100.0, 10.48, 6.244, 8.0, 25.0009, 0.62, 60.0, 462.54, 536.1, 1256.69, 1039.64, 7.05, 9.0, 174.17, 1915.3, 7999.26, 0.94, 36.25, 164.45, 2028.14, 7866.22, 10.8508, 0.02, 305.0, 1915.0, 84.93, 14.11, 8.5265, 9.0, 20.0069, 0.7009, 100.0, 491.19, 607.16, 1474.6, 1236.38, 9.35, 13.6, 332.3, 2323.7, 8709.01, 1.07, 44.06, 312.91, 2387.83, 8056.18, 9.1841, 0.02, 363.0, 2324.0, 100.0, 24.39, 14.781, 10.0, 20.0029, 0.7, 100.0, 491.19, 606.52, 1472.97, 1237.01, 9.35, 13.6, 331.93, 2323.73, 8709.08, 1.07, 43.81, 313.11, 2387.78, 8056.7, 9.1609, 0.02, 364.0, 2324.0, 100.0, 24.37, 14.6485, 11.0, 35.0023, 0.84, 100.0, 449.44, 555.46, 1356.92, 1121.6, 5.48, 7.97, 193.09, 2222.69, 8336.41, 1.02, 41.42, 181.56, 2387.88, 8058.17, 9.3069, 0.02, 332.0, 2223.0, 100.0, 14.96, 8.8942, 12.0, 25.0053, 0.62, 60.0, 462.54, 536.14, 1257.85, 1037.93, 7.05, 9.0, 174.69, 1915.23, 8004.94, 0.93, 36.44, 164.23, 2028.12, 7869.6, 10.8539, 0.02, 305.0, 1915.0, 84.93, 14.4, 8.5892, 13.0, 10.0048, 0.2512, 100.0, 489.05, 604.52, 1488.35, 1296.25, 10.52, 15.46, 393.92, 2318.67, 8767.1, 1.26, 44.95, 370.54, 2387.83, 8121.41, 8.6636, 0.03, 369.0, 2319.0, 100.0, 28.58, 17.0841, 14.0, 41.9995, 0.8411, 100.0, 445.0, 548.8, 1347.47, 1108.13, 3.91, 5.69, 136.93, 2211.92, 8308.48, 1.01, 41.59, 129.38, 2388.1, 8073.51, 9.3705, 0.02, 328.0, 2212.0, 100.0, 10.52, 6.3349, 15.0, 35.0041, 0.84, 100.0, 449.44, 555.47, 1354.37, 1118.38, 5.48, 7.97, 192.73, 2222.84, 8330.96, 1.02, 41.56, 181.65, 2387.83, 8057.53, 9.2828, 0.02, 330.0, 2223.0, 100.0, 14.85, 8.9279, 16.0, 0.0022, 0.0019, 100.0, 518.67, 642.18, 1580.84, 1395.59, 14.62, 21.57, 552.68, 2387.92, 9037.28, 1.3, 47.0, 520.1, 2387.96, 8132.35, 8.4202, 0.03, 389.0, 2388.0, 100.0, 38.99, 23.3926, 17.0, 0.0008, 0.0, 100.0, 518.67, 642.16, 1577.31, 1410.4, 14.62, 21.57, 550.13, 2387.44, 9033.27, 1.3, 47.4, 518.66, 2387.45, 8119.5, 8.431, 0.03, 390.0, 2388.0, 100.0, 38.75, 23.3105, 18.0, 0.0017, 0.0003, 100.0, 518.67, 641.93, 1581.46, 1388.97, 14.62, 21.58, 553.1, 2387.93, 9045.55, 1.3, 47.06, 520.62, 2387.91, 8131.35, 8.3643, 0.03, 391.0, 2388.0, 100.0, 39.03, 23.3312, 19.0, 25.0033, 0.62, 60.0, 462.54, 536.43, 1250.98, 1046.44, 7.05, 9.0, 173.99, 1915.23, 7999.16, 0.94, 36.21, 163.76, 2028.11, 7864.16, 10.8778, 0.02, 306.0, 1915.0, 84.93, 14.34, 8.5085, 20.0, 42.0022, 0.8419, 100.0, 445.0, 548.88, 1345.82, 1118.14, 3.91, 5.69, 137.8, 2211.94, 8309.34, 1.02, 41.63, 130.14, 2388.01, 8073.12, 9.4139, 0.02, 328.0, 2212.0, 100.0, 10.57, 6.3277, 21.0, 35.0031, 0.84, 100.0, 449.44, 554.53, 1353.8, 1115.1, 5.48, 7.97, 193.85, 2222.8, 8336.98, 1.02, 41.48, 181.26, 2387.87, 8060.47, 9.3042, 0.02, 332.0, 2223.0, 100.0, 14.73, 8.8853, 22.0, 35.0052, 0.84, 100.0, 449.44, 555.35, 1356.03, 1115.69, 5.48, 7.97, 192.3, 2222.77, 8339.85, 1.02, 41.46, 181.64, 2387.85, 8058.92, 9.3209, 0.02, 332.0, 2223.0, 100.0, 14.75, 9.0376, 23.0, 20.0029, 0.7, 100.0, 491.19, 607.24, 1471.62, 1240.87, 9.35, 13.6, 332.83, 2323.71, 8715.73, 1.07, 43.95, 312.61, 2387.83, 8052.18, 9.2063, 0.02, 363.0, 2324.0, 100.0, 24.43, 14.5783, 24.0, 25.0007, 0.62, 60.0, 462.54, 536.36, 1255.3, 1034.07, 7.05, 9.0, 174.47, 1915.17, 8001.92, 0.94, 36.28, 163.46, 2028.1, 7869.87, 10.9055, 0.02, 306.0, 1915.0, 84.93, 14.2, 8.5442, 25.0, 10.0066, 0.25, 100.0, 489.05, 604.16, 1499.06, 1297.28, 10.52, 15.46, 392.61, 2318.7, 8769.6, 1.26, 44.97, 370.29, 2387.88, 8131.15, 8.6462, 0.03, 367.0, 2319.0, 100.0, 28.63, 17.1791, 26.0, 20.0017, 0.7001, 100.0, 491.19, 606.63, 1476.01, 1240.68, 9.35, 13.61, 333.5, 2323.74, 8706.31, 1.07, 43.95, 313.12, 2387.84, 8053.67, 9.2287, 0.02, 363.0, 2324.0, 100.0, 24.37, 14.6487, 27.0, 35.0053, 0.8406, 100.0, 449.44, 555.72, 1352.7, 1115.26, 5.48, 7.97, 193.19, 2222.78, 8338.26, 1.02, 41.53, 181.62, 2387.85, 8055.3, 9.3151, 0.02, 332.0, 2223.0, 100.0, 14.74, 8.8494, 28.0, 0.0023, 0.0, 100.0, 518.67, 641.46, 1578.0, 1391.41, 14.62, 21.57, 552.45, 2387.91, 9041.62, 1.3, 47.26, 520.7, 2387.97, 8124.89, 8.3982, 0.03, 390.0, 2388.0, 100.0, 39.06, 23.3468, 29.0, 10.0058, 0.2502, 100.0, 489.05, 604.95, 1487.8, 1296.24, 10.52, 15.46, 394.29, 2318.69, 8765.7, 1.26, 45.02, 370.53, 2387.81, 8122.23, 8.6295, 0.03, 368.0, 2319.0, 100.0, 28.74, 17.2175, 30.0, 25.0067, 0.6215, 60.0, 462.54, 536.19, 1253.47, 1046.27, 7.05, 9.0, 174.47, 1915.26, 7999.46, 0.94, 36.29, 163.4, 2028.13, 7863.18, 10.885, 0.02, 305.0, 1915.0, 84.93, 14.3, 8.6312]\"}]}, {\"role\": \"model\", \"parts\": [{\"text\": \"Remaining Useful Life: 0\"}]}]}\n",
            "\n",
            "Training data has invalid format.\n",
            "Invalid format in line: {\"contents\": [{\"role\": \"user\", \"parts\": [{\"text\": \"Engine sensor readings over time: [1.0, 42.0025, 0.84, 100.0, 445.0, 548.84, 1351.8, 1120.22, 3.91, 5.71, 138.64, 2211.82, 8314.46, 1.02, 41.93, 130.58, 2387.95, 8080.84, 9.3828, 0.02, 329.0, 2212.0, 100.0, 10.95, 6.4505, 2.0, 42.001, 0.8415, 100.0, 445.0, 549.29, 1353.61, 1122.44, 3.91, 5.72, 138.87, 2211.8, 8318.27, 1.02, 42.03, 130.97, 2387.89, 8079.57, 9.3323, 0.02, 331.0, 2212.0, 100.0, 10.58, 6.379, 3.0, 0.0021, 0.0014, 100.0, 518.67, 642.21, 1584.14, 1401.05, 14.62, 21.6, 554.19, 2388.02, 9045.54, 1.3, 47.08, 521.91, 2388.05, 8131.77, 8.3806, 0.03, 392.0, 2388.0, 100.0, 38.91, 23.3686, 4.0, 25.0056, 0.6213, 60.0, 462.54, 536.51, 1254.46, 1049.04, 7.05, 9.02, 175.62, 1915.22, 8004.47, 0.94, 36.58, 164.97, 2028.17, 7870.93, 10.8598, 0.02, 306.0, 1915.0, 84.93, 14.27, 8.4886, 5.0, 25.0065, 0.6214, 60.0, 462.54, 536.91, 1261.02, 1037.92, 7.05, 9.03, 175.66, 1915.27, 8000.15, 0.94, 36.62, 165.19, 2028.17, 7874.11, 10.8835, 0.02, 306.0, 1915.0, 84.93, 14.13, 8.627, 6.0, 25.0006, 0.6212, 60.0, 462.54, 536.39, 1258.8, 1035.98, 7.05, 9.02, 176.16, 1915.31, 8007.25, 0.94, 36.56, 164.69, 2028.13, 7869.02, 10.8548, 0.02, 308.0, 1915.0, 84.93, 14.19, 8.5983, 7.0, 42.0003, 0.84, 100.0, 445.0, 549.61, 1345.78, 1114.04, 3.91, 5.71, 138.67, 2211.8, 8310.19, 1.02, 41.89, 130.3, 2387.95, 8078.99, 9.3337, 0.02, 329.0, 2212.0, 100.0, 10.82, 6.47, 8.0, 20.0006, 0.7007, 100.0, 491.19, 607.62, 1484.55, 1237.83, 9.35, 13.65, 335.31, 2323.89, 8717.13, 1.08, 44.18, 315.29, 2388.02, 8055.03, 9.1757, 0.02, 363.0, 2324.0, 100.0, 24.64, 14.6284, 9.0, 10.0017, 0.25, 100.0, 489.05, 604.62, 1494.62, 1302.19, 10.52, 15.49, 395.1, 2318.81, 8775.51, 1.26, 45.3, 372.21, 2388.08, 8123.79, 8.6478, 0.03, 368.0, 2319.0, 100.0, 28.69, 17.2425, 10.0, 20.0043, 0.7009, 100.0, 491.19, 607.22, 1480.51, 1247.93, 9.35, 13.65, 334.92, 2323.95, 8716.0, 1.08, 44.14, 315.0, 2388.01, 8056.76, 9.203, 0.02, 363.0, 2324.0, 100.0, 24.61, 14.7302, 11.0, 42.0075, 0.8419, 100.0, 445.0, 549.71, 1351.93, 1123.07, 3.91, 5.71, 138.82, 2211.85, 8322.98, 1.02, 41.99, 131.38, 2387.97, 8081.95, 9.3225, 0.02, 329.0, 2212.0, 100.0, 10.68, 6.3938, 12.0, 42.0062, 0.8413, 100.0, 445.0, 549.23, 1354.96, 1119.93, 3.91, 5.72, 138.71, 2211.88, 8314.66, 1.02, 41.81, 131.04, 2387.93, 8078.35, 9.3346, 0.02, 330.0, 2212.0, 100.0, 10.66, 6.4781, 13.0, 25.0031, 0.6219, 60.0, 462.54, 536.8, 1262.52, 1053.19, 7.05, 9.03, 175.25, 1915.23, 8006.69, 0.94, 36.61, 164.89, 2028.11, 7866.46, 10.8463, 0.02, 308.0, 1915.0, 84.93, 14.37, 8.628, 14.0, 41.9994, 0.84, 100.0, 445.0, 548.85, 1343.17, 1115.38, 3.91, 5.71, 138.09, 2211.9, 8317.64, 1.02, 41.87, 130.74, 2387.95, 8078.07, 9.3172, 0.02, 329.0, 2212.0, 100.0, 10.74, 6.3614, 15.0, 0.0025, 0.0018, 100.0, 518.67, 642.49, 1576.37, 1402.43, 14.62, 21.61, 554.42, 2388.06, 9054.3, 1.3, 47.24, 522.45, 2388.04, 8127.99, 8.3834, 0.03, 392.0, 2388.0, 100.0, 38.84, 23.4045, 16.0, 20.0035, 0.7, 100.0, 491.19, 606.93, 1470.74, 1243.97, 9.35, 13.65, 334.38, 2323.91, 8718.59, 1.08, 44.05, 315.14, 2388.04, 8061.59, 9.1794, 0.02, 364.0, 2324.0, 100.0, 24.44, 14.9018, 17.0, 25.001, 0.62, 60.0, 462.54, 536.9, 1251.04, 1043.33, 7.05, 9.02, 175.04, 1915.23, 8002.0, 0.94, 36.57, 164.63, 2028.19, 7865.85, 10.861, 0.02, 306.0, 1915.0, 84.93, 14.15, 8.7183, 18.0, 0.0017, 0.0007, 100.0, 518.67, 642.2, 1582.14, 1401.68, 14.62, 21.61, 554.24, 2388.06, 9049.71, 1.3, 47.31, 522.19, 2388.08, 8129.74, 8.438, 0.03, 391.0, 2388.0, 100.0, 38.96, 23.3218, 19.0, 20.0049, 0.7, 100.0, 491.19, 607.4, 1487.56, 1236.8, 9.35, 13.65, 334.76, 2323.85, 8712.4, 1.08, 44.16, 315.5, 2388.05, 8057.47, 9.207, 0.02, 364.0, 2324.0, 100.0, 24.54, 14.6396, 20.0, 10.0052, 0.2502, 100.0, 489.05, 604.51, 1493.06, 1300.43, 10.52, 15.49, 395.36, 2318.83, 8764.62, 1.26, 45.27, 371.83, 2388.03, 8120.33, 8.6169, 0.03, 368.0, 2319.0, 100.0, 28.67, 17.2512, 21.0, 42.0067, 0.84, 100.0, 445.0, 549.28, 1353.84, 1108.12, 3.91, 5.71, 138.94, 2211.85, 8316.46, 1.02, 42.14, 130.83, 2387.82, 8076.75, 9.357, 0.02, 329.0, 2212.0, 100.0, 10.66, 6.4032, 22.0, 20.0072, 0.7, 100.0, 491.19, 607.48, 1486.35, 1248.28, 9.35, 13.65, 334.36, 2323.89, 8723.95, 1.08, 44.16, 316.11, 2388.03, 8054.37, 9.1691, 0.02, 364.0, 2324.0, 100.0, 24.49, 14.7336, 23.0, 10.0051, 0.2513, 100.0, 489.05, 605.01, 1497.12, 1297.97, 10.52, 15.49, 395.09, 2318.83, 8770.52, 1.26, 45.15, 372.31, 2388.03, 8129.27, 8.6249, 0.03, 369.0, 2319.0, 100.0, 28.69, 17.2518, 24.0, 20.0009, 0.7, 100.0, 491.19, 607.26, 1485.35, 1245.76, 9.35, 13.65, 335.02, 2323.85, 8717.77, 1.08, 44.14, 315.28, 2388.03, 8056.55, 9.1971, 0.02, 364.0, 2324.0, 100.0, 24.66, 14.7319, 25.0, 19.9987, 0.7017, 100.0, 491.19, 607.2, 1479.2, 1246.29, 9.35, 13.65, 334.63, 2323.9, 8722.97, 1.08, 44.11, 314.85, 2387.98, 8057.73, 9.1802, 0.02, 366.0, 2324.0, 100.0, 24.5, 14.7636, 26.0, 42.0028, 0.84, 100.0, 445.0, 548.89, 1341.54, 1117.29, 3.91, 5.72, 138.36, 2211.95, 8323.52, 1.02, 41.91, 130.95, 2387.94, 8078.34, 9.3368, 0.02, 332.0, 2212.0, 100.0, 10.62, 6.3036, 27.0, 20.0072, 0.7, 100.0, 491.19, 607.28, 1491.92, 1249.63, 9.35, 13.65, 334.97, 2323.92, 8711.54, 1.08, 44.18, 315.29, 2388.05, 8058.05, 9.1585, 0.02, 363.0, 2324.0, 100.0, 24.6, 14.7049, 28.0, 25.004, 0.62, 60.0, 462.54, 536.95, 1262.86, 1052.11, 7.05, 9.03, 175.46, 1915.26, 8004.82, 0.94, 36.55, 164.84, 2028.12, 7870.99, 10.8511, 0.02, 306.0, 1915.0, 84.93, 14.4, 8.5828, 29.0, 42.0012, 0.8418, 100.0, 445.0, 549.79, 1358.14, 1119.97, 3.91, 5.71, 138.32, 2211.8, 8316.6, 1.02, 41.76, 130.47, 2387.91, 8076.3, 9.3691, 0.02, 331.0, 2212.0, 100.0, 10.64, 6.4467, 30.0, 10.0065, 0.2501, 100.0, 489.05, 604.04, 1491.6, 1298.64, 10.52, 15.49, 395.34, 2318.87, 8766.94, 1.26, 45.31, 372.33, 2388.07, 8130.8, 8.6208, 0.03, 369.0, 2319.0, 100.0, 28.72, 17.1779]\"}]}, {\"role\": \"model\", \"parts\": [{\"text\": \"Remaining Useful Life: 26\"}]}]}\n",
            "\n",
            "Testing data has invalid format.\n"
          ]
        }
      ]
    },
    {
      "source": [
        "import json\n",
        "\n",
        "def transform_jsonl_to_prompt_completion(input_file_path, output_file_path):\n",
        "    \"\"\"Transforms chat-style JSONL to prompt-completion JSONL.\"\"\"\n",
        "    with open(input_file_path, 'r') as infile, open(output_file_path, 'w') as outfile:\n",
        "        for line in infile:\n",
        "            try:\n",
        "                data = json.loads(line)\n",
        "                # Extract prompt and completion from 'contents'\n",
        "                prompt = \"\".join([part[\"text\"] for part in data[\"contents\"][0][\"parts\"]])  # Assumes user role is first\n",
        "                completion = str(data.get(\"completion\", \"\")) # Handle if completion is missing\n",
        "\n",
        "                # Construct prompt-completion dictionary\n",
        "                prompt_completion_data = {\"prompt\": prompt, \"completion\": completion}\n",
        "\n",
        "                # Write to output file\n",
        "                outfile.write(json.dumps(prompt_completion_data) + \"\\n\")\n",
        "\n",
        "            except (json.JSONDecodeError, KeyError, IndexError) as e:\n",
        "                print(f\"Skipping invalid or unprocessable line: {line.strip()}, Error: {e}\")\n",
        "\n",
        "# Example usage:\n",
        "input_file_path = \"cmapss_FD004_train_text.jsonl\"\n",
        "output_file_path = \"cmapss_FD004_train_text_transformed.jsonl\"\n",
        "\n",
        "transform_jsonl_to_prompt_completion(input_file_path, output_file_path)\n",
        "print(f\"Transformed data written to: {output_file_path}\")\n",
        "\n",
        "input_file_path = \"cmapss_FD004_test_text.jsonl\"\n",
        "output_file_path = \"cmapss_FD004_test_text_transformed.jsonl\"\n",
        "\n",
        "transform_jsonl_to_prompt_completion(input_file_path, output_file_path)\n",
        "print(f\"Transformed data written to: {output_file_path}\")\n"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "bjco9kxvinpu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "def validate_jsonl_format(file_path):\n",
        "    with open(file_path, 'r') as f:\n",
        "        for line in f:\n",
        "            try:\n",
        "                data = json.loads(line)\n",
        "                if \"prompt\" not in data or \"completion\" not in data:\n",
        "                    print(f\"Invalid format in line: {line}\")\n",
        "                    return False  # Indicate invalid format\n",
        "            except json.JSONDecodeError:\n",
        "                print(f\"Invalid JSON in line: {line}\")\n",
        "                return False  # Indicate invalid JSON\n",
        "    return True  # Indicate valid format\n",
        "\n",
        "# Example usage\n",
        "if validate_jsonl_format(\"cmapss_FD004_train_text_transformed.jsonl\"):\n",
        "    print(\"Training data has valid format.\")\n",
        "\n",
        "else:\n",
        "    print(\"Training data has invalid format.\")\n",
        "\n",
        "if validate_jsonl_format(\"cmapss_FD004_test_text_transformed.jsonl\"):\n",
        "    print(\"Testing data has valid format.\")\n",
        "else:\n",
        "    print(\"Testing data has invalid format.\")"
      ],
      "metadata": {
        "id": "IR5YBFj0pj9k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "source": [
        "!gsutil cp cmapss_FD004_train_text_transformed.jsonl gs://{BUCKET_NAME}/\n",
        "!gsutil cp cmapss_FD004_test_text_transformed.jsonl gs://{BUCKET_NAME}/"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "u6lLBqz5jNkC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## FINE TUNING - NASA DATASET"
      ],
      "metadata": {
        "id": "Ge_1sCQo3TSX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!gsutil ls -lh gs://{BUCKET_NAME}/*text*"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d0runBTWYDQE",
        "outputId": "81849777-98b3-4a21-cae3-e9afe9eef08a"
      },
      "execution_count": 120,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  1.41 MiB  2025-04-03T05:12:19Z  gs://poc-my-new-staging-bucket-2025-1/cmapss_FD004_test_text.jsonl\n",
            "  1.39 MiB  2025-04-04T07:15:31Z  gs://poc-my-new-staging-bucket-2025-1/cmapss_FD004_test_text_transformed.jsonl\n",
            "  1.26 MiB  2025-04-03T05:12:17Z  gs://poc-my-new-staging-bucket-2025-1/cmapss_FD004_train_text.jsonl\n",
            "  1.24 MiB  2025-04-04T07:15:28Z  gs://poc-my-new-staging-bucket-2025-1/cmapss_FD004_train_text_transformed.jsonl\n",
            "TOTAL: 4 objects, 5567928 bytes (5.31 MiB)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install google-cloud-aiplatform -U -q\n",
        "\n",
        "from google.cloud import aiplatform\n",
        "import os\n",
        "\n",
        "# Get project details from environment variables\n",
        "PROJECT_ID = os.environ.get(\"GOOGLE_CLOUD_PROJECT\")\n",
        "REGION = os.environ.get(\"GOOGLE_CLOUD_REGION\")\n",
        "\n",
        "\n",
        "# Initialize Vertex AI with error handling\n",
        "try:\n",
        "    aiplatform.init(project=PROJECT_ID, location=REGION)\n",
        "except Exception as e:\n",
        "    print(f\"Error initializing Vertex AI: {e}\")\n",
        "    exit(1)  # Exit with error code\n",
        "\n",
        "# List the models with error handling (without filters)\n",
        "try:\n",
        "    models = aiplatform.Model.list()  # No filter applied\n",
        "\n",
        "    print(\"Available models in Vertex AI:\")\n",
        "    for model in models:\n",
        "        print(f\"- {model.display_name} ({model.resource_name})\")\n",
        "except Exception as e:\n",
        "    print(f\"Error listing models: {e}\")\n",
        "    exit(1)  # Exit with error code"
      ],
      "metadata": {
        "id": "xB5cgtjedEWP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vertexai_index=10\n",
        "models = aiplatform.Model.list()\n",
        "\n",
        "name=models[vertexai_index].display_name\n",
        "resource_name=models[vertexai_index].resource_name\n",
        "print(f\"name: {name}\")\n",
        "print(f\"resource_name: {resource_name}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P9QJsoAWs7v2",
        "outputId": "f5826f9a-bc86-4c61-b9dd-2ded67044ca1"
      },
      "execution_count": 121,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "name: cmapss-text-tuned-gemini-2.0-flash-001-1.0\n",
            "resource_name: projects/677155171887/locations/us-central1/models/3735556670508498944\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tuned_model_display_name_or_index=9\n",
        "try:\n",
        "    # Try loading by display name first\n",
        "    models = aiplatform.Model.list()\n",
        "    if models:\n",
        "        base_model = models[vertexai_index]\n",
        "        logging.info(f\"Loaded {base_model.resource_name} by display name.\")\n",
        "        embedding_dim = base_model.predict(instances=[{\"content\": \"test\"}]).predictions[0].shape[0]\n",
        "\n",
        "        print(f\"{base_model.resource_name}\")\n",
        "    else:\n",
        "        # If not found, assume it's an index\n",
        "        vertexai_index = int(tuned_model_display_name_or_index)\n",
        "        models = aiplatform.Model.list()\n",
        "        if 0 <= vertexai_index < len(models):\n",
        "            base_model = models[vertexai_index]\n",
        "            logging.info(f\"Loaded {base_model.resource_name} by index.\")\n",
        "        else:\n",
        "            raise ValueError(f\"Invalid vertexai_index or display_name: {tuned_model_display_name_or_index}\")\n",
        "except ValueError as e:\n",
        "    logging.error(f\"Error loading model: {e}\")\n",
        "    raise\n",
        "except Exception as e:\n",
        "    logging.error(f\"Unexpected error loading model: {e}\")\n",
        "    raise\n"
      ],
      "metadata": {
        "id": "-JDthjMnymwe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "source": [
        "train_py_content = \"\"\"\n",
        "import argparse\n",
        "import os\n",
        "import json\n",
        "import logging\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader\n",
        "import time\n",
        "import subprocess\n",
        "from google.cloud import storage\n",
        "import pandas as pd\n",
        "from typing import List\n",
        "import numpy as np\n",
        "import torch.utils.data as data\n",
        "import vertexai\n",
        "from google.cloud import aiplatform  # Import aiplatform\n",
        "import re  # Import the regular expression module\n",
        "import tensorflow as tf\n",
        "\n",
        "\n",
        "logging.basicConfig(level=logging.INFO)\n",
        "\n",
        "# --- Helper Functions ---\n",
        "def create_gcs_dir(model_dir, bucket_name):  # Add bucket_name as argument\n",
        "    # Creates a directory in Google Cloud Storage (GCS) if it doesn't exist.\n",
        "    try:\n",
        "        storage_client = storage.Client()\n",
        "        # bucket_name = model_dir.split('/')[2]  <-- Remove this line\n",
        "        blob_prefix = '/'.join(model_dir.split('/')[3:])\n",
        "        bucket = storage_client.bucket(bucket_name)\n",
        "\n",
        "        subdirs = blob_prefix.split('/')\n",
        "        current_prefix = ''\n",
        "        for subdir in subdirs:\n",
        "            current_prefix = os.path.join(current_prefix, subdir)\n",
        "            blob = bucket.blob(current_prefix + '/')\n",
        "            blob.upload_from_string('')\n",
        "            logging.info(\"Created GCS directory: %s\", current_prefix)\n",
        "    except Exception as e:\n",
        "        logging.error(f\"Error creating GCS directory: {e}\")\n",
        "        raise\n",
        "\n",
        "\n",
        "def load_jsonl_dataset(data_path, sequence_length=30):\n",
        "    # Loads a JSONL dataset with the specific format.\n",
        "    data = []\n",
        "    try:\n",
        "        with tf.io.gfile.GFile(data_path, 'r') as f:\n",
        "            for line in f:\n",
        "                try:\n",
        "                    record = json.loads(line)\n",
        "\n",
        "                    # Extract prompt (sensor readings)\n",
        "                    prompt_text = record[\"contents\"][0][\"parts\"][0][\"text\"]  # Assumes user role is first\n",
        "                    sensor_readings_match = re.search(r\"\\[(.*?)\\]\", prompt_text)\n",
        "                    if sensor_readings_match:\n",
        "                        sensor_readings_str = sensor_readings_match.group(1)\n",
        "                        prompt = [float(x) for x in sensor_readings_str.split(\",\")]\n",
        "                    else:\n",
        "                        logging.warning(f\"Could not find sensor readings in text: {prompt_text}\")\n",
        "                        continue  # Skip this line if sensor readings not found\n",
        "\n",
        "                    # Extract completion (RUL)\n",
        "                    completion_text = record[\"contents\"][1][\"parts\"][0][\"text\"]  # Assumes model role is second\n",
        "                    completion_match = re.search(r\"Remaining Useful Life: (.*)\", completion_text)\n",
        "                    if completion_match:\n",
        "                        completion = float(completion_match.group(1))\n",
        "                    else:\n",
        "                        logging.warning(f\"Could not find Remaining Useful Life in text: {completion_text}\")\n",
        "                        continue  # Skip this line if RUL not found\n",
        "\n",
        "                    data.append((prompt, completion))  # Append the extracted data\n",
        "\n",
        "                except (json.JSONDecodeError, KeyError, IndexError, ValueError) as e:\n",
        "                    logging.warning(\"Skipping invalid JSON line: %r, Error: %s\", repr(line), e)\n",
        "\n",
        "        return data  # Return the extracted data\n",
        "\n",
        "    except Exception as e:\n",
        "        logging.error(f\"Error loading dataset: {e}\")\n",
        "        raise\n",
        "\n",
        "\n",
        "# --- Dataset Class ---\n",
        "class CMAPSSJSONLDataset(data.Dataset):\n",
        "    def __init__(self, data_path, sequence_length=30, use_gcs=False, model=None, bucket_name=None):\n",
        "        self.data = []\n",
        "        self.sequence_length = sequence_length\n",
        "        self.model = model\n",
        "        self.bucket_name = bucket_name\n",
        "\n",
        "        # GCS file handling (if use_gcs is True and data_path is a GCS URI)\n",
        "        if use_gcs and data_path.startswith('gs://'):\n",
        "            storage_client = storage.Client()\n",
        "            # bucket_name = os.environ.get(\"GOOGLE_CLOUD_BUCKET_NAME\")  # Removed redundant line\n",
        "            blob_name = data_path.replace(f\"gs://{self.bucket_name}/\", \"\")  # Use self.bucket_name\n",
        "            bucket = storage_client.bucket(self.bucket_name)  # Use self.bucket_name\n",
        "            blob = bucket.blob(blob_name)\n",
        "            tmp_file = \"/tmp/temp_data.jsonl\"  # Temporary file for download\n",
        "            blob.download_to_filename(tmp_file)\n",
        "            data_file = tmp_file\n",
        "        else:\n",
        "            # Local file handling\n",
        "            data_file = data_path\n",
        "\n",
        "        with open(data_file, 'r') as f:\n",
        "            for line in f:\n",
        "                try:\n",
        "                    record = json.loads(line)\n",
        "\n",
        "                    # Extract sensor readings from the first \"parts\" element\n",
        "                    text_content = record[\"contents\"][0][\"parts\"][0][\"text\"]\n",
        "                    sensor_readings_match = re.search(r\"\\[(.*?)\\]\", text_content)\n",
        "                    if sensor_readings_match:\n",
        "                        sensor_readings_str = sensor_readings_match.group(1)\n",
        "                        prompt = [float(x) for x in sensor_readings_str.split(\",\")]\n",
        "                    else:\n",
        "                        logging.warning(f\"Could not find sensor readings in text: {text_content}\")\n",
        "                        continue\n",
        "\n",
        "                    # Extract completion (Remaining Useful Life) from the second \"parts\" element\n",
        "                    completion_text = record[\"contents\"][1][\"parts\"][0][\"text\"]\n",
        "                    completion_match = re.search(r\"Remaining Useful Life: (.*)\", completion_text)\n",
        "                    if completion_match:\n",
        "                        completion = float(completion_match.group(1))\n",
        "                    else:\n",
        "                        logging.warning(f\"Could not find Remaining Useful Life in text: {completion_text}\")\n",
        "                        continue\n",
        "\n",
        "                    self.data.append((prompt, completion))\n",
        "\n",
        "                except (json.JSONDecodeError, KeyError, ValueError, IndexError) as e:\n",
        "                    logging.warning(f\"Skipping invalid line: {line.strip()}, Error: {e}\")\n",
        "\n",
        "        # Remove the temporary file if it was created\n",
        "        if use_gcs and data_path.startswith('gs://'):\n",
        "            os.remove(tmp_file)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.data[idx]\n",
        "\n",
        "    def generate_embeddings(self, model):\n",
        "        embeddings_data = []\n",
        "        for prompt, completion in self.data:\n",
        "            try:\n",
        "                # Check if prompt is already an embedding (during inference)\n",
        "                if isinstance(prompt, torch.Tensor):\n",
        "                    embeddings_tensor = prompt\n",
        "                else:\n",
        "                    # Generate embeddings if prompt is a list of sensor readings\n",
        "                    prompt_text = ','.join(map(str, prompt))  # Convert prompt to string for embedding\n",
        "                    embeddings = model.predict(instances=[{\"content\": prompt_text}]).predictions[0]\n",
        "                    embeddings_tensor = torch.tensor(embeddings, dtype=torch.float32)\n",
        "\n",
        "                rul = torch.tensor([completion], dtype=torch.float32)  # Assuming 'completion' represents RUL\n",
        "                embeddings_data.append((embeddings_tensor, rul))\n",
        "            except Exception as e:\n",
        "                logging.warning(f\"Error generating embeddings for prompt: {prompt}, Error: {e}\")\n",
        "        self.data = embeddings_data  # Update the data with embeddings\n",
        "\n",
        "# --- Model Definition (Using Gemini Embeddings and LSTM) ---\n",
        "class RULPredictionModel(nn.Module):\n",
        "    def __init__(self, embedding_dim, hidden_size, num_layers=2, dropout=0.2):\n",
        "        super().__init__()\n",
        "        self.lstm = nn.LSTM(embedding_dim, hidden_size, num_layers, batch_first=True, dropout=dropout)\n",
        "        self.fc = nn.Linear(hidden_size, 1)  # Output layer for RUL prediction\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Pass embeddings through LSTM\n",
        "        out, _ = self.lstm(x)\n",
        "        # Take the output from the last time step\n",
        "        out = out[:, -1, :]\n",
        "        # Pass through fully connected layer for RUL prediction\n",
        "        out = self.fc(out)\n",
        "        return out\n",
        "\n",
        "# --- Training Function ---\n",
        "def train_model(model_name, train_dataset_path, eval_dataset_path,\n",
        "                staging_bucket, bucket_name, base_output_dir,\n",
        "                project_id, region,  # Add project_id and region arguments\n",
        "                use_rolling_features=False, tuned_model_display_name_or_index=None):  # Add tuned_model_display_name\n",
        "\n",
        "    global logging\n",
        "\n",
        "    logging.info(\"Training configuration:\")\n",
        "    logging.info(f\"Model name: {model_name}\")\n",
        "    logging.info(f\"Train Dataset Path: {train_dataset_path}\")\n",
        "    logging.info(f\"Eval Dataset Path: {eval_dataset_path}\")\n",
        "    logging.info(f\"Staging Bucket: {staging_bucket}\")\n",
        "    logging.info(f\"Bucket Name from args: {bucket_name}\")  # Log bucket_name\n",
        "    logging.info(f\"Base Output Dir: {base_output_dir}\")\n",
        "    logging.info(f\"Project ID: {project_id}\")  # Log project_id\n",
        "    logging.info(f\"Region: {region}\")  # Log region\n",
        "    logging.info(f\"Use Rolling Features: {use_rolling_features}\")\n",
        "\n",
        "    # Initialize Vertex AI with project_id and region\n",
        "    vertexai.init(project=project_id, location=region)\n",
        "\n",
        "    # 1. Model Initialization (Modified to handle both cases)\n",
        "    vertexai_index=10\n",
        "    models = aiplatform.Model.list()\n",
        "    name=models[vertexai_index].display_name\n",
        "    resource_name=models[vertexai_index].resource_name\n",
        "    #print(f\"name: {name}\")\n",
        "    #print(f\"resource_name: {resource_name}\")\n",
        "\n",
        "    try:\n",
        "        # Try loading by display name first\n",
        "        models = aiplatform.Model.list()\n",
        "        if models:\n",
        "            base_model = models[vertexai_index]\n",
        "            logging.info(f\"Loaded {base_model.resource_name} by display name.\")\n",
        "        else:\n",
        "            # If not found, assume it's an index\n",
        "            vertexai_index = int(tuned_model_display_name_or_index)\n",
        "            models = aiplatform.Model.list()\n",
        "            if 0 <= vertexai_index < len(models):\n",
        "                base_model = models[vertexai_index]\n",
        "                logging.info(f\"Loaded {base_model.resource_name} by index.\")\n",
        "            else:\n",
        "                raise ValueError(f\"Invalid vertexai_index or display_name: {tuned_model_display_name_or_index}\")\n",
        "    except ValueError as e:\n",
        "        logging.error(f\"Error loading model: {e}\")\n",
        "        raise\n",
        "    except Exception as e:\n",
        "        logging.error(f\"Unexpected error loading model: {e}\")\n",
        "        raise\n",
        "\n",
        "    # 2. Fine-tuning Job\n",
        "    try:\n",
        "        # fine_tuning_job = jobs.FineTuningJob(\n",
        "        #     model=base_model,\n",
        "        #     training_data_uri=train_dataset_path,\n",
        "        #     validation_data_uri=eval_dataset_path,\n",
        "        # )\n",
        "\n",
        "        # fine_tuned_model = fine_tuning_job.run(timeout=3600)\n",
        "        fine_tuned_model = base_model\n",
        "    except Exception as e:\n",
        "        logging.error(f\"Error in fine-tuning job: {e}\")\n",
        "        raise e\n",
        "\n",
        "    # 3. Create Datasets\n",
        "\n",
        "    train_dataset = CMAPSSJSONLDataset(train_dataset_path, use_gcs=True, bucket_name=bucket_name)  # Pass bucket_name\n",
        "    eval_dataset = CMAPSSJSONLDataset(eval_dataset_path, use_gcs=True, bucket_name=bucket_name)  # Pass bucket_name\n",
        "\n",
        "    train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
        "    eval_loader = DataLoader(eval_dataset, batch_size=64)\n",
        "\n",
        "    # 4. Model and Optimizer Setup\n",
        "    embedding_dim = fine_tuned_model.predict(instances=[{\"content\": \"test\"}]).predictions[0].shape[0]\n",
        "    hidden_size = 128\n",
        "    model = RULPredictionModel(embedding_dim, hidden_size)\n",
        "    optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
        "    criterion = nn.MSELoss()\n",
        "\n",
        "    # 5. Training Loop\n",
        "    num_epochs = 10\n",
        "    for epoch in range(num_epochs):\n",
        "        model.train()\n",
        "        train_loss = 0.0\n",
        "        for embeddings, targets in train_loader:\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(embeddings)\n",
        "            targets = targets.unsqueeze(1).float()\n",
        "            loss = criterion(outputs, targets)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            train_loss += loss.item() * embeddings.size(0)\n",
        "\n",
        "        train_loss /= len(train_loader.dataset)\n",
        "\n",
        "        # 6. Evaluation\n",
        "        model.eval()\n",
        "        eval_loss = 0.0\n",
        "        with torch.no_grad():\n",
        "            for embeddings, targets in eval_loader:\n",
        "                outputs = model(embeddings)\n",
        "                targets = targets.unsqueeze(1).float()\n",
        "                loss = criterion(outputs, targets)\n",
        "                eval_loss += loss.item() * embeddings.size(0)\n",
        "\n",
        "        eval_loss /= len(eval_loader.dataset)\n",
        "\n",
        "        logging.info(f\"Epoch [{epoch + 1}/{num_epochs}], \"\n",
        "                     f\"Train Loss: {train_loss:.4f}, \"\n",
        "                     f\"Eval Loss: {eval_loss:.4f}\")\n",
        "\n",
        "\n",
        "    # 7. Save the Model to GCS Bucket\n",
        "    model_dir = os.path.join(base_output_dir, model_name)\n",
        "    model_path = os.path.join(model_dir, 'model-gemini-nasa-cmapss.pth')\n",
        "\n",
        "    # Save the model locally first\n",
        "    torch.save(model.state_dict(), \"model-gemini-nasa-cmapss.pth\")\n",
        "\n",
        "    # Upload the model to GCS\n",
        "    try:\n",
        "        storage_client = storage.Client()\n",
        "        bucket = storage_client.bucket(bucket_name)\n",
        "        blob = bucket.blob(model_path)  # Use the full GCS path for the blob\n",
        "        blob.upload_from_filename(\"model-gemini-nasa-cmapss.pth\")  # Upload the local file\n",
        "\n",
        "        logging.info(f\"Model uploaded to: gs://{bucket_name}/{model_path}\")\n",
        "    except Exception as e:\n",
        "        logging.error(f\"Error uploading model to GCS: {e}\")\n",
        "        raise\n",
        "\n",
        "\n",
        "# --- Main Execution ---\n",
        "if __name__ == \"__main__\":\n",
        "    parser = argparse.ArgumentParser()\n",
        "    parser.add_argument('--model', type=str, required=True, help='Name of the model.')\n",
        "    parser.add_argument('--train_dataset', type=str, required=True, help='Path to the training dataset.')\n",
        "    parser.add_argument('--eval_dataset', type=str, required=True, help='Path to the evaluation dataset.')\n",
        "    parser.add_argument('--staging_bucket', type=str, required=True, help='GCS staging bucket.')\n",
        "    parser.add_argument('--bucket_name', type=str, required=True, help='GCS bucket name.')\n",
        "    parser.add_argument('--base_output_dir', type=str, required=True, help='Base output directory.')\n",
        "    parser.add_argument('--project_id', type=str, required=True, help='Google Cloud Project ID.')  # Add project_id argument\n",
        "    parser.add_argument('--region', type=str, required=True, help='Google Cloud Region.')  # Add region argument\n",
        "    parser.add_argument('--use_rolling_features', action='store_true',\n",
        "                        help='Whether to use rolling features for training.')\n",
        "    parser.add_argument('--tuned_model_display_name_or_index', type=str, required=True,\n",
        "                        help='Display name or index of the tuned Gemini model to use.')\n",
        "    args = parser.parse_args()\n",
        "\n",
        "    train_model(args.model, args.train_dataset, args.eval_dataset,\n",
        "                args.staging_bucket, args.bucket_name, args.base_output_dir,\n",
        "                args.project_id, args.region,\n",
        "                args.use_rolling_features, args.tuned_model_display_name_or_index)\n",
        "\"\"\""
      ],
      "cell_type": "code",
      "metadata": {
        "id": "xeyKpCKuw18X"
      },
      "execution_count": 106,
      "outputs": []
    },
    {
      "source": [
        "import os\n",
        "from google.cloud import aiplatform\n",
        "import argparse\n",
        "import json\n",
        "import logging\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader\n",
        "import time\n",
        "import subprocess\n",
        "from google.cloud import storage\n",
        "import pandas as pd\n",
        "from typing import List\n",
        "import numpy as np\n",
        "import torch.utils.data as data\n",
        "import vertexai\n",
        "from vertexai.preview.language_models import TextGenerationModel\n",
        "\n",
        "\n",
        "# --- Main Script ---\n",
        "if __name__ == \"__main__\":\n",
        "    # Get project details from environment variables\n",
        "    PROJECT_ID = os.environ.get(\"GOOGLE_CLOUD_PROJECT\")\n",
        "    REGION = os.environ.get(\"GOOGLE_CLOUD_REGION\")\n",
        "    SERVICEACCOUNT = os.environ.get(\"GOOGLE_CLOUD_SERVICEACCOUNT\")\n",
        "    PROJECT_NUMBER = os.environ.get(\"GOOGLE_CLOUD_PROJECT_NUMBER\")\n",
        "    BUCKET_NAME = os.environ.get(\"GOOGLE_CLOUD_BUCKET_NAME\")\n",
        "    STAGING_BUCKET = f\"gs://{BUCKET_NAME}/staging\"\n",
        "\n",
        "    # Initialize Vertex AI\n",
        "    aiplatform.init(project=PROJECT_ID, location=REGION)\n",
        "\n",
        "    # --- Data and Output Paths ---\n",
        "    TRAINING_DATA_PATH = f\"gs://{BUCKET_NAME}/cmapss_FD004_train_text.jsonl\"\n",
        "    EVAL_DATA_PATH = f\"gs://{BUCKET_NAME}/cmapss_FD004_test_text.jsonl\"\n",
        "    BASE_OUTPUT_DIR = f\"gs://{BUCKET_NAME}/model_output\"\n",
        "\n",
        "    # Create or overwrite trainer/train.py\n",
        "    os.makedirs('trainer', exist_ok=True)\n",
        "    with open('trainer/train.py', 'w') as f:\n",
        "        f.write(train_py_content)\n",
        "\n",
        "    # Create and run the custom training job\n",
        "    job = aiplatform.CustomTrainingJob(\n",
        "    display_name=\"cmapss-rul-gemini-finetuning\",\n",
        "    script_path=\"trainer/train.py\",\n",
        "    requirements=[\"google-cloud-aiplatform\", \"google-generativeai\", \"transformers\", \"pandas\", \"torch\", \"tensorflow\"], # Added tensorflow to the requirements\n",
        "    container_uri=\"us-docker.pkg.dev/vertex-ai/training/pytorch-gpu.2-4.py310:latest\",  # Updated container URI\n",
        "    staging_bucket=STAGING_BUCKET,\n",
        "    model_serving_container_image_uri=\"us-docker.pkg.dev/vertex-ai/prediction/pytorch-gpu.2-4:latest\"  # Updated serving container URI\n",
        "    )\n",
        "\n",
        "\n",
        "    model = job.run(\n",
        "        replica_count=1,\n",
        "        machine_type=\"a2-highgpu-1g\",  # Machine type with A100 GPU\n",
        "        accelerator_type=\"NVIDIA_TESLA_A100\",  # A100 accelerator\n",
        "        accelerator_count=1,\n",
        "        base_output_dir=BASE_OUTPUT_DIR,\n",
        "        args=['--model', 'rul_predictor_cmapss',\n",
        "              '--train_dataset', TRAINING_DATA_PATH,\n",
        "              '--eval_dataset', EVAL_DATA_PATH,\n",
        "              '--staging_bucket', STAGING_BUCKET,\n",
        "              '--bucket_name', BUCKET_NAME,\n",
        "              '--base_output_dir', BASE_OUTPUT_DIR,\n",
        "              '--project_id', PROJECT_ID,  # Add PROJECT_ID argument\n",
        "              '--region', REGION],  # Add REGION argument\n",
        "        # Add timeout to prevent the job from running indefinitely if it's stuck\n",
        "        timeout=3600,  # Timeout in seconds (1 hour)\n",
        "        sync=True # Added this line\n",
        "    )\n",
        "\n",
        "    model.wait()  # Wait for training to complete\n",
        "\n",
        "    print('\\n\\n')\n",
        "    print(f\"Model name: {model.display_name}\")\n",
        "    print(f\"Model resource name: {model.resource_name}\")\n",
        "    print(f\"Model training start time: {model.create_time}\")\n",
        "    print(f\"Model training end time: {model.update_time}\")\n",
        "    print(f\"Model training duration: {model.update_time - model.create_time}\")\n",
        "    print('\\n')\n",
        "\n",
        "    # Accessing metrics from training job completion statistics metadata\n",
        "    if model.training_job and hasattr(model.training_job, 'completion_stats') and model.training_job.completion_stats and model.training_job.completion_stats.metadata:\n",
        "        metrics = model.training_job.completion_stats.metadata\n",
        "        # Use .get() for safety\n",
        "        print(f\"Model training loss: {metrics.get('train_loss')}\")\n",
        "        print(f\"Model evaluation loss: {metrics.get('eval_loss')}\")\n",
        "        print(f\"Model evaluation metrics: {metrics}\")\n",
        "    else:\n",
        "        print(\"Training job or completion statistics metadata not available.\")\n",
        "\n",
        "    print('\\n')\n",
        "\n",
        "    logging.info(f\"Fine-tuned model: {model.resource_name}\")"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "JYw_PYCU0Nf7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## MODEL EVALUATION"
      ],
      "metadata": {
        "id": "rA39w2VJXCPo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.cloud import storage\n",
        "import torch\n",
        "\n",
        "# Initialize the GCS client\n",
        "client = storage.Client()\n",
        "\n",
        "# Specify the bucket and blob (file)\n",
        "bucket_name = os.environ.get(\"GOOGLE_CLOUD_BUCKET_NAME\")\n",
        "bucket = client.bucket(bucket_name)\n",
        "blob_name = \"model_output/model-nasa-gpu.pth\"\n",
        "\n",
        "blob_name = \"model_output/model-nasa-gpu.pth\"\n",
        "bucket = client.bucket(bucket_name)\n",
        "blob = bucket.blob(blob_name)\n",
        "\n",
        "# Download the file to a local path\n",
        "local_file_path = \"model-nasa-gpu.pth\"  # Or your desired local path\n",
        "blob.download_to_filename(local_file_path)\n",
        "\n",
        "print(f\"Downloaded '{blob_name}' from '{bucket_name}' to '{local_file_path}'\")"
      ],
      "metadata": {
        "id": "PUhLGQq8PX5M",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c8927d51-d289-4cee-8dc1-bb2e8481af96"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloaded 'model_output/model-nasa-gpu.pth' from 'poc-my-new-staging-bucket-2025-1' to 'model-nasa-gpu.pth'\n"
          ]
        }
      ]
    },
    {
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import DataLoader\n",
        "import numpy as np\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
        "\n",
        "# Assuming this is how the CMAPSSJSONLDataset is defined in the document\n",
        "import torch\n",
        "from torch.utils import data\n",
        "import json\n",
        "from google.cloud import storage\n",
        "import logging\n",
        "import os\n",
        "\n",
        "class CMAPSSJSONLDataset(data.Dataset):\n",
        "    def __init__(self, data_path, sequence_length=30):\n",
        "        self.data = []\n",
        "        self.sequence_length = sequence_length\n",
        "\n",
        "        # Check if data_path is a local file or a GCS URI\n",
        "        if data_path.startswith('gs://'):\n",
        "            # If GCS URI, download to a temporary file\n",
        "            storage_client = storage.Client()\n",
        "            bucket_name = data_path.split('/')[2]\n",
        "            blob_name = '/'.join(data_path.split('/')[3:])\n",
        "            bucket = storage_client.bucket(bucket_name)\n",
        "            blob = bucket.blob(blob_name)\n",
        "            tmp_file = \"/tmp/temp_data.jsonl\"\n",
        "            blob.download_to_filename(tmp_file)\n",
        "            data_file = tmp_file\n",
        "        else:\n",
        "            # If local file, use it directly\n",
        "            data_file = data_path\n",
        "\n",
        "        with open(data_file, 'r') as f:\n",
        "            for line in f:\n",
        "                try:\n",
        "                    record = json.loads(line)\n",
        "                    sequence = torch.tensor(record[\"sequence\"], dtype=torch.float32)\n",
        "                    rul = torch.tensor([record[\"rul\"]], dtype=torch.float32)\n",
        "                    self.data.append((sequence, rul))\n",
        "                except json.JSONDecodeError as e:\n",
        "                    logging.warning(\"Skipping invalid JSON line: %s, Error: %s\", line, e)\n",
        "\n",
        "        # Remove the temporary file if it was created\n",
        "        if data_path.startswith('gs://'):\n",
        "            os.remove(tmp_file)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.data[idx]\n",
        "\n",
        "class RULPredictionModel(nn.Module):\n",
        "    #LSTM-based model for RUL prediction\n",
        "    def __init__(self, input_size, hidden_size, num_layers=3, dropout=0.3): # Match the architecture in train.py\n",
        "        super().__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.num_layers = num_layers\n",
        "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True, dropout=dropout)\n",
        "        self.fc1 = nn.Linear(hidden_size, hidden_size // 2)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.fc2 = nn.Linear(hidden_size // 2, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out, _ = self.lstm(x)\n",
        "        out = self.fc1(out[:, -1, :])\n",
        "        out = self.relu(out)\n",
        "        out = self.dropout(out)\n",
        "        out = self.fc2(out)\n",
        "        return out\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "def calculate_cmapss_score(true_rul, predicted_rul):\n",
        "    \"\"\"Calculates a simplified CMAPSS score.\"\"\"\n",
        "    d = np.array(predicted_rul) - np.array(true_rul)  # Difference between predicted and true RUL\n",
        "    score = sum([\n",
        "        np.exp(-d[i] / 13) - 1 if d[i] < 0 else np.exp(d[i] / 10) - 1\n",
        "        for i in range(len(d))\n",
        "    ])\n",
        "    return score\n",
        "\n",
        "\n",
        "def evaluate_model(model_path, eval_dataset_path, input_size, hidden_size, sequence_length):\n",
        "    \"\"\"Evaluates the trained RUL prediction model.\"\"\"\n",
        "\n",
        "    # Load the saved model using the correct model architecture\n",
        "    model = RULPredictionModel(input_size, hidden_size, num_layers=3)  # Change num_layers to 3 to match the training architecture\n",
        "\n",
        "    # Explicitly load the model to the CPU\n",
        "    model.load_state_dict(torch.load(model_path, map_location=torch.device('cuda')))\n",
        "\n",
        "    model.eval()  # Set to evaluation mode\n",
        "\n",
        "\n",
        "\n",
        "    # Load the evaluation dataset\n",
        "    eval_dataset = CMAPSSJSONLDataset(eval_dataset_path, sequence_length)\n",
        "    eval_loader = DataLoader(eval_dataset, batch_size=64, shuffle=False)  # No need to shuffle for evaluation\n",
        "\n",
        "    # Make predictions and calculate metrics\n",
        "    all_predictions = []\n",
        "    all_targets = []\n",
        "    with torch.no_grad():  # Disable gradient calculations during evaluation\n",
        "        for sequences, ruls in eval_loader:\n",
        "            predictions = model(sequences)\n",
        "            all_predictions.extend(predictions.flatten().tolist())\n",
        "            all_targets.extend(ruls.flatten().tolist())\n",
        "\n",
        "    # Calculate evaluation metrics (e.g., MAE, RMSE)\n",
        "    mae = mean_absolute_error(all_targets, all_predictions)\n",
        "    rmse = np.sqrt(mean_squared_error(all_targets, all_predictions))\n",
        "    mse = mean_squared_error(all_targets, all_predictions)  # Calculate MSE\n",
        "\n",
        "    # Calculate CMAPSS score\n",
        "    cmapss_score = calculate_cmapss_score(all_targets, all_predictions)\n",
        "\n",
        "    # Print the results\n",
        "    print(f\"Evaluation Results:\")\n",
        "    print(f\"Average Evaluation Loss (MSE): {mse:.2f}\")\n",
        "    print(f\"Mean Absolute Error (MAE): {mae:.2f}\")\n",
        "    print(f\"Root Mean Squared Error (RMSE): {rmse:.2f}\")\n",
        "    print(f\"CMAPSS Score: {cmapss_score:.2f}\")\n",
        "\n",
        "\n",
        "\n",
        "# --- Example Usage (if __name__ == \"__main__\": block) ---\n",
        "if __name__ == \"__main__\":\n",
        "    model_path = \"model-nasa-gpu.pth\"  # Replace with the actual path to your saved model\n",
        "    eval_dataset_path = f\"gs://{BUCKET_NAME}/cmapss_FD004_test_sequences.jsonl\"  # Replace with your evaluation data path (GCS URI)\n",
        "    input_size = 25  # Updated to match the input size used during training\n",
        "    hidden_size = 128 # Updated to match the hidden size used during training\n",
        "    sequence_length = 30  # Replace with the sequence length used during training\n",
        "\n",
        "    evaluate_model(model_path, eval_dataset_path, input_size, hidden_size, sequence_length)"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "nkS9rqGJi8XJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "06f78fca-e701-4f29-c9ae-c2780eb70ce3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation Results:\n",
            "Average Evaluation Loss (MSE): 675.03\n",
            "Mean Absolute Error (MAE): 25.98\n",
            "Root Mean Squared Error (RMSE): 25.98\n",
            "CMAPSS Score: 1607.38\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "N=10\n",
        "\n",
        "Evaluation Results:\n",
        "Average Evaluation Loss (MSE): 675.91\n",
        "Mean Absolute Error (MAE): 26.00\n",
        "Root Mean Squared Error (RMSE): 26.00\n",
        "CMAPSS Score: 1609.80\n",
        "\n",
        "N=200\n",
        "\n",
        "Evaluation Results:\n",
        "Average Evaluation Loss (MSE): 676.00\n",
        "Mean Absolute Error (MAE): 26.00\n",
        "Root Mean Squared Error (RMSE): 26.00\n",
        "CMAPSS Score: 1610.04\n",
        "\n"
      ],
      "metadata": {
        "id": "7y32T44pVnYQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "print(\"GOOGLE_CLOUD_PROJECT:\", os.environ.get(\"GOOGLE_CLOUD_PROJECT\"))\n",
        "print(\"GOOGLE_CLOUD_REGION:\", os.environ.get(\"GOOGLE_CLOUD_REGION\"))\n",
        "print(\"GOOGLE_CLOUD_SERVICEACCOUNT:\", os.environ.get(\"GOOGLE_CLOUD_SERVICEACCOUNT\"))\n",
        "print(\"GOOGLE_CLOUD_PROJECT_NUMBER:\", os.environ.get(\"GOOGLE_CLOUD_PROJECT_NUMBER\"))\n",
        "print(\"GOOGLE_CLOUD_BUCKET_NAME:\", os.environ.get(\"GOOGLE_CLOUD_BUCKET_NAME\"))"
      ],
      "metadata": {
        "id": "9GwxZc-gfKaM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "VERTEX_AI_SERVICE_AGENT = !gcloud projects describe $PROJECT_ID --format='value(project_number)' | xargs -I{} gcloud iam service-accounts list --filter=\"displayName:Compute Engine default service account\" --project=$PROJECT_ID --format=\"value(email)\"\n",
        "VERTEX_AI_SERVICE_AGENT = VERTEX_AI_SERVICE_AGENT[0].strip()  # Access the first element (index 0)\n",
        "print(\"Vertex AI Service Agent:\", VERTEX_AI_SERVICE_AGENT)"
      ],
      "metadata": {
        "id": "S11Sx5YhfO8k"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "KThk5ET4q4fo",
        "R7-1paG9ps6s",
        "rA39w2VJXCPo"
      ],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyMgBnVf4tuOy01JLcBE6NMb",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}