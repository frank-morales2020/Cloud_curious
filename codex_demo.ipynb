{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMOdj/5yD6JjaGWXob0QRW9",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/frank-morales2020/Cloud_curious/blob/master/codex_demo.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://github.com/openai/codex"
      ],
      "metadata": {
        "id": "wCpfALDcmun4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install colab-env -q\n",
        "!pip install openai -q"
      ],
      "metadata": {
        "id": "EAtUAc5jcopP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fd2f7895-7f9e-4d87-c2da-e46816d45f67"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for colab-env (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3h9oQYsBcIgS"
      },
      "outputs": [],
      "source": [
        "!npm install -g @openai/codex"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import colab_env\n",
        "import os\n",
        "import openai\n",
        "from openai import OpenAI, APIError # Import OpenAI client and base APIError\n",
        "\n",
        "# It automatically uses the OPENAI_API_KEY environment variable\n",
        "client = OpenAI()"
      ],
      "metadata": {
        "id": "MFYLlMXMdFrm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fda781ff-0c16-4d4e-df1d-747929fa21ec"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!codex"
      ],
      "metadata": {
        "id": "dmhZTyIicUmr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Using gpt-3.5-turbo-instruct (similar to the original Codex in its instruction-following approach):"
      ],
      "metadata": {
        "id": "Brvh320zlq9v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "openai.api_key = os.getenv(\"OPENAI_API_KEY\")  # Get API key from environment variable\n",
        "\n",
        "def generate_python_code(prompt):\n",
        "    try:\n",
        "        # Use client.completions.create for completion models\n",
        "        response = client.completions.create(\n",
        "            model=\"gpt-3.5-turbo-instruct\",\n",
        "            prompt=prompt,\n",
        "            max_tokens=200,  # Adjust as needed for the expected length of the code\n",
        "            n=1,             # Number of code snippets to generate\n",
        "            stop=[\"#\", \"\\n\\n\\n\"], # Stop generating when these sequences are encountered\n",
        "            temperature=0.7, # Controls randomness (0.0 is more deterministic, 1.0 is more random)\n",
        "        )\n",
        "        # The response structure is slightly different; access text via .choices[0].text\n",
        "        return response.choices[0].text.strip()\n",
        "    # Use the new exception handling structure, e.g., APIError or its subclasses\n",
        "    except APIError as e:\n",
        "        print(f\"An OpenAI API error occurred: {e}\")\n",
        "        return None\n",
        "    except Exception as e:\n",
        "        print(f\"An unexpected error occurred: {e}\")\n",
        "        return None\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    user_prompt = \"Write a Python function that calculates the factorial of a given number.\"\n",
        "    generated_code = generate_python_code(user_prompt)\n",
        "    if generated_code:\n",
        "        print(\"Generated Python code:\")\n",
        "        print(generated_code)\n",
        "        # You can then execute or further process the generated code"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KvURoz1elSbM",
        "outputId": "64c2f928-44ea-4d5e-da3e-1ebde7bc6baa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generated Python code:\n",
            "def factorial(n):\n",
            "    result = 1\n",
            "    for i in range(1, n+1):\n",
            "        result *= i\n",
            "    return result\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Using gpt-4 (often provides more sophisticated and context-aware code):"
      ],
      "metadata": {
        "id": "lHa_y5uDlx9j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
        "\n",
        "def generate_python_code_gpt4(prompt):\n",
        "    try:\n",
        "        # This part of the code already uses the newer client.chat.completions.create structure\n",
        "        response = client.chat.completions.create(\n",
        "            model=\"gpt-4\",\n",
        "            messages=[\n",
        "                {\"role\": \"user\", \"content\": prompt}\n",
        "            ],\n",
        "            max_tokens=200,\n",
        "            n=1,\n",
        "            stop=[\"#\", \"\\n\\n\\n\"],\n",
        "            temperature=0.7,\n",
        "        )\n",
        "        # Access content via .choices[0].message.content\n",
        "        return response.choices[0].message.content.strip()\n",
        "    # Update exception handling for the newer library\n",
        "    except APIError as e:\n",
        "        print(f\"An OpenAI API error occurred (GPT-4): {e}\")\n",
        "        return None\n",
        "    except Exception as e:\n",
        "        print(f\"An unexpected error occurred (GPT-4): {e}\")\n",
        "        return None\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    user_prompt = \"Write a Python class for a simple to-do list with methods to add tasks, remove tasks, and list tasks.\"\n",
        "    generated_code = generate_python_code_gpt4(user_prompt)\n",
        "    if generated_code:\n",
        "        print(\"Generated Python code (using GPT-4):\")\n",
        "        print(generated_code)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZEPfLXVfmAjc",
        "outputId": "d3db699b-9517-4f4a-9b9c-942e8a5051d6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generated Python code (using GPT-4):\n",
            "Here is a simple Python class for a to-do list:\n",
            "\n",
            "```python\n",
            "class ToDoList:\n",
            "    def __init__(self):\n",
            "        self.tasks = []\n",
            "\n",
            "    def add_task(self, task):\n",
            "        self.tasks.append(task)\n",
            "\n",
            "    def remove_task(self, task):\n",
            "        if task in self.tasks:\n",
            "            self.tasks.remove(task)\n",
            "        else:\n",
            "            print(\"Task not found in the list.\")\n",
            "\n",
            "    def list_tasks(self):\n",
            "        for task in self.tasks:\n",
            "            print(task)\n",
            "```\n",
            "\n",
            "In this class, `__init__` is the constructor that initializes an empty list of tasks. The `add_task` method appends a task to the tasks list. The `remove_task` method removes a task from the tasks list if it exists, if not it prints a message saying the task was not found. The `list_tasks` method prints all tasks in the tasks list.\n",
            "\n",
            "You can use this class like this:\n",
            "\n",
            "```python\n",
            "todo = ToDoList()\n",
            "todo.add_task(\"Do laundry\")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Key Considerations:\n",
        "\n",
        "* Prompt Engineering: The quality of the generated code heavily depends on the clarity and detail of your prompt. Be specific about the programming language, the functionality you need, and any constraints or requirements.\n",
        "\n",
        "* Error Handling: The generated code might not always be perfect or error-free. You'll likely need to review, test, and debug it.\n",
        "\n",
        "* Security: Be cautious when executing code generated by an AI, especially if it involves file system access or network operations. Always understand what the code does before running it.\n",
        "\n",
        "* Cost: OpenAI API usage is based on token consumption. Be mindful of the number of tokens in your prompts and the generated code, especially when making frequent or lengthy requests.\n",
        "\n",
        "By using the OpenAI Python library with models like gpt-3.5-turbo-instruct or gpt-4, you can effectively leverage the code generation capabilities that were pioneered by OpenAI Codex within your Python projects. Let me know if you have any specific coding tasks you'd like to try generating!"
      ],
      "metadata": {
        "id": "ofichZw6mUKG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
        "\n",
        "def generate_python_code_gpt4(prompt):\n",
        "    try:\n",
        "        # This part of the code already uses the newer client.chat.completions.create structure\n",
        "        response = client.chat.completions.create(\n",
        "            model=\"gpt-4\",\n",
        "            messages=[\n",
        "                {\"role\": \"user\", \"content\": prompt}\n",
        "            ],\n",
        "            max_tokens=1024,\n",
        "            n=1,\n",
        "            stop=[\"#\", \"\\n\\n\\n\"],\n",
        "            temperature=0.1,\n",
        "        )\n",
        "        # Access content via .choices[0].message.content\n",
        "        return response.choices[0].message.content.strip()\n",
        "    # Update exception handling for the newer library\n",
        "    except APIError as e:\n",
        "        print(f\"An OpenAI API error occurred (GPT-4): {e}\")\n",
        "        return None\n",
        "    except Exception as e:\n",
        "        print(f\"An unexpected error occurred (GPT-4): {e}\")\n",
        "        return None"
      ],
      "metadata": {
        "id": "hwyCaSDksoR4"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "code_request=\"\"\" Generate Python code for a travel itinerary planning system using CrewAI. The code should include:\n",
        "\n",
        "1.  **A multi-line string variable named `prompt1`** containing the following text (preserve newlines and formatting exactly):\n",
        "\n",
        "    ```\n",
        "    \\n\\nHuman: How do you plan out your trip?\n",
        "\n",
        "    Here's a scenario:\n",
        "\n",
        "    A traveler is visiting London.\n",
        "\n",
        "    Trip Details:\n",
        "    1.  The traveler has the following preferences: They enjoy history, art, and trying new foods. They prefer walking or public transportation.\n",
        "    2.  The trip starts on 2024-03-15 and ends on 2024-03-20.\n",
        "    3.  The traveler is interested in activities like visiting museums, historical sites, exploring local markets, and trying authentic cuisine.\n",
        "\n",
        "    The Question:\n",
        "    Considering the traveler's preferences, desired location, trip dates, and preferred activities, please provide a detailed itinerary.\n",
        "\n",
        "    Important Considerations:\n",
        "    * Time: The traveler has limited time and needs to account for travel time between activities.\n",
        "    * Budget: Suggest activities that are reasonably priced or free.\n",
        "    * Interests: Focus on activities that align with the traveler's preferences.\n",
        "\n",
        "    Desired Output:\n",
        "    Provide a structured response in JSON format with the following details:\n",
        "\n",
        "    * \"title\": A title for the itinerary.\n",
        "    * \"description\": A brief description of the itinerary.\n",
        "    * \"days\": A list of days, each containing:\n",
        "        * \"day\": The day number (e.g., 1, 2, 3).\n",
        "        * \"activities\": A list of activities for that day, each containing:\n",
        "            * \"name\": The name of the activity.\n",
        "            * \"description\": A description of the activity.\n",
        "            * \"duration\": The estimated duration of the activity.\n",
        "            * \"cost\": The estimated cost of the activity.\n",
        "    \\n\\nAssistant:\n",
        "    ```\n",
        "\n",
        "2.  **Code that defines a CrewAI agent, task, and crew:**\n",
        "\n",
        "    * Agent:\n",
        "        * Role:  \"Travel Itinerary Planner\"\n",
        "        * Goal: \"Create a detailed, multi-day travel itinerary in the specified JSON format.\"\n",
        "        * Backstory: \"You are an experienced travel agent specializing in crafting personalized itineraries based on user preferences, dates, and desired activities. You are meticulous about formatting the output precisely in JSON.\"\n",
        "        * Variable for the LLM client should be named: `client`\n",
        "        * `verbose` should be set to `True`\n",
        "        * `allow_delegation` should be set to `False`\n",
        "    * Task:\n",
        "        * Description:  Use an f-string to create the task description. The task description should instruct the agent to generate a travel itinerary using the `prompt1` variable, and include placeholders for `location`, `start_date`, `end_date`, `preferences`, and `activities`.  Explicitly state that the output MUST be a valid JSON string.\n",
        "        * Expected output: \"A valid JSON string representing the travel itinerary, matching the structure requested in the provided prompt.\"\n",
        "        * Agent:  The agent defined above.\n",
        "    * Crew:\n",
        "        * Agents:  A list containing the agent defined above.\n",
        "        * Tasks:  A list containing the task defined above.\n",
        "        * Process:  `Process.sequential`\n",
        "        * `verbose`: `False`\n",
        "\n",
        "3.  **A Python function named `generate_itinerary_with_llm_task`:**\n",
        "\n",
        "    * This function should take arguments: `current_user`, `preferences`, `location`, `start_date`, `end_date`, and `activities`.\n",
        "    * The function should:\n",
        "        * Print \"Starting itinerary generation process using CrewAI...\"\n",
        "        * Define the `planner_agent` as specified above.\n",
        "        * Define the `itinerary_task` as specified above, using f-strings to incorporate the function arguments.\n",
        "        * Define the `travel_crew` as specified above.\n",
        "        * Call `travel_crew.kickoff()` with the input arguments as a dictionary (e.g., `{'preferences': preferences, ...}`).\n",
        "        * Convert the result to a string using `str()`\n",
        "        * Return the string result.\n",
        "        * Include a `try...except` block to catch exceptions and print an error message.  In the `except` block, the function should return `None`.\n",
        "  \"\"\"\n",
        "\n",
        ""
      ],
      "metadata": {
        "id": "1UUjM9cRr8BH"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\":\n",
        "    generated_code = generate_python_code_gpt4(code_request)\n",
        "    if generated_code:\n",
        "        print(\"Generated Python code (using GPT-4):\")\n",
        "        print(generated_code)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7Hv-8CAzsxC_",
        "outputId": "674d09a5-f963-4d86-94a1-b629c146f86c"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generated Python code (using GPT-4):\n",
            "Here is the Python code for a travel itinerary planning system using CrewAI:\n",
            "\n",
            "```python\n",
            "from crewai import Agent, Task, Crew, Process\n",
            "from crewai.llm import LLMClient\n"
          ]
        }
      ]
    }
  ]
}